#----------------------------------------------------------------------------------------------------------------------------
                                    
                                            Yapay Zeka, Makine öğrenmesi ve Veri Bilimi
                                                            Kursu
               
                                         Sınıfta Yapılan Örnekler ve Özet Notlar 
                                                        2.Bölüm

                                                    Eğitmen: Kaan ASLAN
                                            
            Bu notlar Kaan ASLAN tarafından oluşturulmuştur. Kaynak belirtmek koşulu ile her türlü alıntı yapılabilir.
            Kaynak belirtmek için aşağıdaki referansı kullanabilirsiniz:           

            Aslan, K. (2025), "Yapay Zekâ, Makine Öğrenmesi ve Veri Bilimi Kursu", Sınıfta Yapılan Örnekler ve Özet Notlar, 
                C ve Sistem Programcıları Derneği, İstanbul.

                        (Notları okurken editörünüzün "Line Wrapping" özelliğini pasif hale getiriniz.)

                                               Son Güncelleme: 16/06/2025 - Pazartesi

#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Kursumuzun bu bölümünde geçici süre yapay sinir ağlarından uzaklaşacağız ve denetimsiz öğrenme (unsupervised learning) 
    konusu üzerinde duracağız.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Anımsanacağı gibi makine öğrenmesi kabaca üç bölümde ele alınıyordu:

    1) Denetimli Öğrenme (Supervised Learning)
    2) Denetimsiz Öğrenme (Unsupervised Learning)
    3) Pekiştirmeli Öğrenme (Reinforcement Learning)

    Biz şimdiye kadar "yapay sinir ağları ile denetimli öğrenme" konularını inceledik. Tabii denetimli öğrenme yalnızca yapay 
    sinir ağlarıyla değil istatistiksel ve matematiksel başka yöntemlerle de gerçekleştirilebilmektedir. 

    x ve y verileri arasında eğitim yoluyla bir ilişki kurmaya çalışan öğrenme yöntemlerine denetimli öğrenme yöntemleri denilmektedir.  
    Yani denetimli öğrenmede bir eğitim süreci vardır. Ancak eğitimden sonra kestirim yapılabilmektedir. Örneğin elimizde elma, 
    armut ve kayısı olmak üzere üç meyve olsun. Biz önce eğitim sırasında hangi resmin ne olduğunu modele veririz. Model bunlardan 
    hareketle x ve y değerleri arasında bir ilişki kurar. Sonra biz bir resim verdiğimizde model onun elma mı, armut mu, kayısı 
    olduğunu bize söyler.

    Denetimsiz (unsupervised) modellerde ise elimizde yalnızca x verileri vardır. Dolayısıyla biz bu öğrenme yöntemlerinde bir 
    eğitim uygulamayız. Denetimsiz öğrenmede biz modele birtakım verileri veririz. Model bu verileri inceler. Bunlar arasındaki 
    benzerlik ve farklılıkaladan hareketle bunları gruplayabilir. Dolayısıyla bu gruplama için bir y veri kümesine ihtiyaç duyulmaz. 
    Örneğin elimizde bol miktarda elma, armut, kayısı resimleri olsun. Biz modele "bu resimler bazı bakımlardan birbirlerine 
    benziyor, birbirlerine benzeyenleri gruplandır" deriz. Model de aslında hangi resmin elma, hangi resmin armut ve hangi 
    resmin kayısı olduğunu bilmeden bunların benzerliklerine bakarak bunları bir araya getirebilmektedir. Burada dikkat edilmesi 
    gereken nokta bir eğitim sürecinin olmamasıdır. Pekiyi denetimsiz öğrenmede kestirim yapılabilir mi? Evet yapılabilir. 
    Örneğin biz modele bir resim verip onun hangi gruba daha fazla benzediğini sorabiliriz. Bu da bir çeşit kestirimdir. 

    Denetimsiz öğrenme için çeşitli yöntemler bulunmaktadır. Ancak denetimsiz öğrenmede kullanılan en önemli yüntem grubu  
    "kümeleme (clustering)" denilen yöntem grubudur. Bu nedenle denetimsiz öğrenme denildiğinde akla ilk gelen yöntem grubu 
    kümelemedir. Biz de önce kümeleme yöntemlerini ele alıp inceleyeceğiz.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Makine öğrenmesinde "sınıflandırma (classification)" ve "kümeleme (clustering)" kavramları farklı anlamlarda kullanılmaktadır. 
    Sınıflandırma belli bir olgunun önceden belirlenmiş sınıflardan birine atanması ile ilgilidir. Kümeleme ise bu sınıfların 
    bizzat oluşturulması ile ilgidir. Yani sınıflandırmada sınıflar zaten bellidir. Kümelemede ise sınıflar benzerliklerden 
    ve farklılıklardan hareketle oluşturulmaya çalışılmaktadır. Dolayısıyla sınıflandırma "denetimli (supervised)" bir yöntem 
    grubunu belirtirken, kümeleme "denetimsiz (unsupervised)" bir yöntem grubunu belirtmektedir. 

    Elimizde hem x ve hem y verileri varken genellikle denetimli öğrenme yöntemleri tercih edilmektedir. Ancak bazen elimizde
    yeteri kadar x verileri olduğu halde y verileri olmayabilir. Örneğin anomali içeren banka işlemlerini tespit etmek isteyelim. 
    Elimizde anomali içerdiğini açıkça bildiğimiz fazlaca y verisi olmayabilir. Bazen x ve y verilerinin çeşitliliğinden dolayı 
    denetimli öğrenme uygun yöntem olmaktan çıkabilir. Örneğin bir dosyanın virüslü olup olmadığına yönelik bir model oluşturmak 
    isteyelim. Elimizde virüslü dosyalarla virüssüz dosyalar bulunuyor olabilir. Ancak virüs yöntemleri sürekli değişebilmektedir. 
    Bu durumda yeni veriler daha oluşmadan biz eğitimi yapamayız. Bu tür durumlarda da denetimsiz öğrenme yöntemleri tercih 
    edilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Kümeleme işlemleri aslında istatistikte uzun süredir incelenmekte olan bir konudur. Kümeleme işlemlerine istatistikte 
    "kümeleme analizi (cluster analysis)" denilmektedir. Ancak son yirmi yıldır kümeleme işlemleri bir makine öğrenmesi yöntemi 
    olarak da kullanılmaya başlanmıştır ve bu konuda eskisinden çok daha fazla yöntemler ve algoritmalar geliştirilmiştir. Bu 
    nedenle kümeleme işlemleri artık klasik istatistik bağlamından çok makine öğrenmesi ve veri bilimi bağlamında ele alınıp 
    incelenen bir konu haline gelmiştir. (Tabii biz kümeleme analizinin klasik istatistikteki kullanımını ve önemini inkar 
    etmiyoruz. Ancak bu alanın en çok makine öğrenmesi bağlamında uygulama bulduğunu ve ele alındığını vurguluyoruz.)
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Kümeleme benzer olanların ya da benzer olmayanların bir araya getirilmesi süreci olduğuna göre benzerlik nasıl ölçülmektedir? 
    Yani bir veri kümesinde satırlar varlıkları temsil ediyorsa, iki satırın birbirine benzer olması nasıl ölçülecektir? Benzerlik 
    insan sezgisi ile ilgili bir kavramdır. Oysa makine öğrenmesinde benzerlik ancak sayısal yöntemlerle somut hale getirilebilir. 

    İşte bir veri kümesindeki satırlar n boyutlu uzayda bir nokta gibi düşünülebilir. Benzerlik de "uzaklık (distance)" temeline 
    dayandırılabilmektedir. Eğer n boyutlu uzayda iki nokta arasındaki uzaklık düşük ise bu iki nokta benzer, yüksek ise bu iki 
    nokta benzer değildir. Ancak uzaklık da aslında farklı yöntemlerle hesaplanabilmektedir. En yaygın kullanılan uzaklık ölçütü 
    Ööklit uzaklığı (Euclidean distance)" denilen ölçüttür. Öklit uzaklığı n boyutlu uzayda iki nokta arasındaki uzaklıktır. 
    Ancak "Hamming uzaklığı (Hamming distance)", gibi "Manhattan uzaklığı (Manhattan distance)" gibi çeşitli uzaklık ölçütleri 
    değişik problemlerde bazen tercih edilebilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    İki özellikli (sütunlu) bir veri kümesindeki satırlar kartezyen koordinat sisteminde birer nokta belirtmektedir. Bu iki 
    nokta arasındaki Öklit uzaklığı noktalar a ve b olmak üzere sqrt((ax - bx) ** 2 + (ay - by) ** 2) biçimindedir. N boyutlu 
    uzaydaki iki nokta arasındaki uzaklık da benzer biçimde hesaplanmaktadır. Yani her boyutun karşılıklı bileşenlerinin 
    farklarının karelerinin toplamının karekörü alınır. NumPy kullanarak N boyutlu uzayda iki nokta arasındaki Öklit uzaklığını 
    hesaplayan bir fonksiyon basit bir biçimde şöyle yazılabilir:
    
    import numpy as np

    def euclidean_distance(a, b):
        return np.sqrt(np.sum((a - b) ** 2))

    a = np.array([1, 4, 6, 2])
    b = np.array([4, 2, -1, 7])

    d = euclidean_distance(a, b)
    print(d)

    Öklit uzaklığı hesaplamak için NumPy içerisinde hazır bir fonksiyon yoktur. Ancak bunun için SciPy içerisinde scipy.spatial.distance 
    modülünde euclidean isimli bir fonksiyon bulunmaktadır. 

    from scipy.spatial.distance import euclidean

    a = np.array([1, 4, 6, 2])
    b = np.array([4, 2, -1, 7])
    
    dst = euclidean(a, b)
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np

def euclidean_distance(x, y):
    return np.sqrt(np.sum((x - y) ** 2))

a = np.array([1, 1, 5, 6, 7, 8])
b = np.array([2, 2, 3, 6, 4, 6])

dist = euclidean_distance(a, b)
print(dist)

from scipy.spatial.distance import euclidean

dist = euclidean(a, b)
print(dist)

#----------------------------------------------------------------------------------------------------------------------------
    Öklit uzaklığının dışında daha az kullanılıyor olsa da birkaç önemli uzaklık tanımı daha vardır. Manhattan uzaklığı 
    (Manhattan distance) iki nokta arasındaki birbirine dik doğrularla gidilebilen uzaklıktır. (New York'taki Manhattan denilen 
    bölge birbirlerini kesen büyük caddelerden oluşmaktadır. Bir yerden bir yere gitmek için bu cadde kesişimlerinden geçmek 
    gerekir. Bu nedenle bu uzaklık "Manhattan uzaklığı" biçiminde isimlendirilmiştir.) a ve b noktalar, i'ise uzayın boyut 
    indeksi olmak üzere Manhattan uzaklığı matematiksel olarak Σ|aᵢ - bᵢ| biçiminde hesaplanmaktadır.  Bu hesabı yapan fonksiyonu 
    NumPy kullanılarak şöyle yazabiliriz:

    import numpy as np

    def manhattan_distance(a, b):
        return np.sum(np.abs(a - b))

    a = np.array([1, 2, 3, 4])
    b = np.array([5, 6, 7, 8])

    mdist = manhattan_distance(a, b)
    print(mdist)

    Manhattan uzaklığı için SciPy kütüphanesinde scipy.spatial.distance modülündeki cityblock isimli bir fonksiyon bulunmaktadır:

    from scipy.spatial.distance import cityblock

    mdist = cityblock(a, b)
    print(mdist)
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np

def manhattan_distance(a, b):
    return np.sum(np.abs(a - b))

a = np.array([1, 1, 5, 6, 7, 8])
b = np.array([2, 2, 3, 6, 4, 6])

dist = manhattan_distance(a, b)
print(dist)

from scipy.spatial.distance import cityblock

dist = cityblock(a, b)
print(dist)

#----------------------------------------------------------------------------------------------------------------------------
    Öklit ve Manhattan uzaklıklarının daha genel bir biçimine Minkowski uzaklığı da denilmektedir. x ve y noktaları arasındaki
    Minkowski uzaklığı şöyle ifade edilebilir:

    Minkowski Uzaklığı = (sigma(abs(xi - yi)^p))^ (1/p)

    Burada p = 2 ise Öklit uzaklığı p = 0 ise Manhattan uzaklığı söz konusu olmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Özellikle görüntü işleme (genel olarak sayısal işaret işleme) uygulamalarında "Hamming uzaklığı (Hamming distance)" denilen 
    bir uzaklık da kullanılmaktadır. Hamming uzaklığı "ikili (binary)" kategorik sütunlara sahip noktalar söz konusu olduğunda
    tercih edilen bir uzaklık türüdür. Hamming uzaklığı "farklı olan elemanların sayısının toplam eleman sayısına oranı" ile 
    hesaplanmaktadır. Örneğin:

    ankara
    ayazma

    Bu iki yazının Hamming uzaklığı 4/6'dır. 
    
    Hamming uzaklığı SciPy kütüphanesinde scipy.spatial.distance modülündeki hamming isimli fonksiyonla hesaplanabilir. Örneğin:

    from scipy.spatial.distance import hamming

    a = np.array([1, 0, 0, 1])
    b = np.array([1, 1, 0, 0])

    hdist = hamming(a, b)
    print(hdist)                # 0.5
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                            84. Ders - 07/12/2024 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Kosinüs uzaklığı da bazı uygulamalarda kullanılmaktadır. İki nokta arasındaki açının kosinüsü ile hesaplanmaktadır. Bu 
    uzaklık da scipy.spatial.distance modülündeki cosine fonksiyonu ile hesaplanmaktadır. Örneğin:

    import numpy as np
    from scipy.spatial.distance import cosine

    a = np.array([1, 0, 0, 1])
    b = np.array([1, 1, 0, 0])

    hdist = cosine(a, b)
    print(hdist)                # 0.5 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
from scipy.spatial.distance import cosine

a = np.array([1, 0, 0, 1])
b = np.array([1, 1, 0, 0])

hdist = cosine(a, b)
print(hdist)                # 0.5

#----------------------------------------------------------------------------------------------------------------------------   
    Bazı algoritmalarda (örneğin agglomerative hiyerarşik kümeleme algoritmasında) belli sayıda noktanın biribiri arasındaki 
    tüm uzaklıklarının bir uzaklık matirisi biçiminde hesaplanması gerekebilmektedir. Bunun için SciPy kütüphanesinde
    scipy.spatial.distance modülünde pdist ve cdist fonksiyonları bulundurulmuştur. cdist fonksiyonu bize simetrik bir matris 
    verirken pdist fonksiyonu tek boyutlu kompakt hale getirilmiş bir diziyi (yani simetrik matrisin yalnızca bir yarısının 
    tek boyutlu dizi haline getirilmiş biçimini) vermektedir. Bu fonksiyonların ayrıntılarını dokümanlardan inceleyebilirsiniz. 
    Aşağıda bir örnek kullanım verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------   

import numpy as np
from scipy.spatial.distance import pdist, cdist

points = np.array([[1, 2], [1, 3], [3, 1], [4, 2], [2, 3]])

result = cdist(points, points, metric='euclidean')
print(result)

print('-' *20)

result = pdist(points, metric='euclidean')
print(result)

#----------------------------------------------------------------------------------------------------------------------------   
    Aslında daha pek çok uzaklık türü tanımlanmıştır. Bu uzaklıklar için scipy.spatial.distance modülündeki fonksiyonları 
    inceleyebilirsiniz. Fakat bu modülde bulunmayana ancak kümeleme işlemlerinde kullanılan başka uzaklıklar da bulunmaktadır.
#----------------------------------------------------------------------------------------------------------------------------   

#----------------------------------------------------------------------------------------------------------------------------   
    Pek çok uzaklıklık türü sütunsal biçimde hesaplandığına için sütunlar arasındaki skala farklılıkları bu uzaklık hesaplarını
    olumsuz etkileyecektir. Örneğin üç sütüunda oluşan aşağıdaki gibi bir veri kümesi olsun:

    F1      F2      F3
    0.2     123     1234678
    0.4     567     2567865
    0.7     328     1876345
    ...     ...     ...

    Burada iki nokta arasındaki Öklit uzaklığında asıl etkili olan sütun üçüncü sütundur. Birinci sütunun neredeyse hiçbir 
    etkisi yoktur. O halde bizim bu tür uzaklık hesaplarında sütunların skalalarını benzer hale getirmemiz gerekir. Yani 
    kümeleme işlemlerinde çoğu kez özellik ölçeklemesinin uygulanması gerekebilmektedir. Tabii bazı uzaklık ölçütleri (örneğin 
    kosinüs uzaklığı gibi) sütunların skala farklılıklarından olumsuz etkilenmez. Ancak Öklük uzaklığı gibi, Manhattan uzaklığı 
    gibi uzaklıklar bu skala farklılıklarından etkilenmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Veri kümesinde kategorik veriler varsa uzaklık yöntemlerinin bir bölümü bu kategorik verilerde anlamlı olmaktan çıkabilecektir. 
    Örneğin Öklit uzaklığının kullanıldığını düşünelim. Aşağıdaki gibi bir veri kümesi söz konusu olsun:

    F1      F2      F3
    0.2     123     Ankara
    0.4     567     İzmir
    0.7     328     Eskişehir
    .....

    Burada F3 özelliğinin şehirlere ilişkin kategorik olduğunu görüyorsunuz. Türkiye'de şu anda 81 şehir vardır. Biz eğer 
    bu sütunu LabelEncoder iile sayısal hale getirirsek bu kategorileri [0, 81] arasında bir sayıya dönüştürürüz. Bu durumda 
    0 ile 80 arasındaki uzaklık 0 ile 1 arasındaki uzaklıktan çok fazla hale gelecektir. Örneğin böyle bir dönüştürmede Ankara 
    ile Zonguldak arasındaki uzaklık Ankara ile Ağrı arasındaki uzaklıktan çok fazla hale gelecektir. Halbuki bunun bizim 
    için mantıksal hiçbir gerekçesi yoktur. Bu tür kategorik sütunları one-hot-encoding yaptığımızda da bu kategoriler 
    arasında bir farklılık oluşmayacaktır. İşte buradan da görüldüğü gibi aslında kategorik sütunlar için başka uzaklık 
    ölütlerinin kullanılması uygun olmaktadır. Örneğin Hamming uzaklığı bu amaçla kullanılabilmektedir. Pekiyi bir veri 
    kümesi hem nümerik hem de kategorik sütunlar içeriyorsa bu durumda nasıl bir uzaklık yöntemi uygulanmalıdır? İşte bu tür 
    durumlarda seçeneklerden biri hem nümerik hem de kategorik sütunlarla çalışabilecek başka bir uzaklık yöntemi seçmektir. 
    Diğeri ise kümeleme algoritmasını bu duruma uygun olarak değiştirmektir. 

    Kategorik verilerin de bulunduğu veri kümelerinde kategorik sütunları farklı bir biçimde ele alan "Gower Uzaklığı" 
    denilen bir uzaklık da kulanılmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Bu bölümde kümeleme işlemlerinde kullanılan kümeleme algoritmaları ve bu algoritmaları uygulayan fonksiyonlar ve sınıflar
    üzerinde duracağız.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Yüzün üzerinde kümeleme algoritması oluşturulmuştur. Bazı algoritmalar bazı algoritmaların biraz değiştirilmiş biçimleri 
    gibidir. Ancak bazı algoritmalar tamamen farklı fikirlere dayanmaktadır. Kümeleme algoritmalarını kendi aralarında algortimanın 
    dayandığı fikir bakımından beş gruba ayırabiliriz:

    1) Ağırlık Merkezi (Centroid) Tamelli Algoritmalar
    2) Bağlantı (Connectivity) Temelli Algoritmalar (Hiyerarşik Kümeleme Algoritmaları)
    3) Yoğunluk Temelli (Density Based) Algoritmalar
    4) Dağılım Temelli (Distribution Based) Algoritmalar
    5) Bulanık Temelli (Fuzzy Based) Algortimalar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Kümeleme algortimalarının en popüler ve yaygın olarak kullanılanı ve en iyi bilineni K-Means denilen algoritmadır. K-Means 
    ağırlık merkezi temelli bir algoritmadır. Buradaki "Means" ağırlık merkezi oluştururken ortalamanın dikkate alınması nedeniyle 
    kullanılmış olan bir sözcüktür. Aslında ağırlık merkezi oluşturulurken ortalamanın dışında başka hesaplamalar da kullanılabilmektedir. 
    Dolayısıyla bu yöntemin K-XXX biçiminde (burada XXX alt yöntemi belirten bir isimdir) varyasyonları vardır. Bu varyasyonların 
    bazıları şunlardır:

    K-Medoids
    K-Modes
    K-Prototypes
    K-Centers
    K-Medians
    K-Nearest Neighbors
    
    Ancak bu aileden en çok kullanılanı K-Means isimli algoritmadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    K-Means kümeleme algoritmasında işin başında uygulamacının noktalardan kaç küme oluşturulacağını belirlemiş olması gerekir. 
    Küme sayıları bazı uygulamalarda zaten biliniyor durumda olabilir. Örneğin çok sayıda resim söz konusu olabilir ve bu resimlerin
    10 farklı meyveye ilişkin olduğu zaten biliniyor olabilir. Ancak bazı uygulamalarda küme sayısını uygulamacı da bilmiyor 
    olabilir. Bu tür durumlarda uygun küme sayısının belirlenmesi ayrı bir problem biçiminde karşımıza çıkmaktadır. Biz burada 
    küme sayısının baştan bilindiğini ve bunun k olduğunu varsayacağız. (K-Means ismindeki K harfi de k tane küme sayısından 
    gelmektedir.) 
    
    Algoritmanın tipik işleyişi şöyledir:

    1) k tane küme için işin başında rastgele k tane ağırlık merkezi belirten nokta oluşturulur. Bu noktalar mevcut noktalar 
    içerisinden rastgele seçilebilir.

    2) Tüm noktaların bu k tane ağırlık merkezine uzaklıkları hesaplanır. Noktalar hangi ağırlık merkezine daha yakınsa o kümenin 
    içerisine dahil edilir. Artık k tane kümeden oluşan ilk kümeleme yapılmıştır.

    3) Kümelerin yeni ağırlık merkezleri küme içerisindeki noktalardan hareketle hesaplanır. Küme içerisindeki noktaların ağırlık 
    merkezleri her boyutun kendi aralarındaki ortalamaları ile hesaplanmaktadır. Örneğin x, y, z boyutlarına sahip a, b, c 
    noktalarının ağırlık merkezleri şöyle hesaplanır:

    centroidx = (ax + bx + cx) / 3
    centroidy = (ay + by + cy) / 3
    centroidz = (az + bz + cz) / 3

    Zaten bu yönteme K-Means ismi ağırlık merkezi bulunurken her boyutun kendi aralarındaki ortalamasının hesaplanması nedeniyle
    verilmiştir. 

    Aslında burada yapılan işlem noktalar dataset biçiminde iki boyutlu bir NumPy matrisi biçiminde ise np.mean(dataset, axis=0) 
    işlemidir. 

    4) Tüm noktaların yeniden bu yeni ağırlık merkezlerine uzaklığı hesaplanır. Hangi noktalar hangi ağırlık merkezine daha 
    yakınsa o kümeye dahil edilir. Böylece bazı noktalar küme değiştirecekir. Sonra 3'üncü adıma geri dönülür ve işlemler bu 
    biçimde devam ettirlir. 

    5) Eğer yeni ağırlık merkezine göre hiçbir nokta küme değiştirmiyorsa artık yapılacak bir şey kalmamıştır ve algoritma 
    sonlandırılır.

    K-Means yönteminin burada uygulanan algoritmasına "Lloyd" algoritması denilmektedir. Bu algoritma Stuart Lloyd tarafından 
    1957 yılında geliştirilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi K-Means Llyod algoritmasına sayısal bir örnek verelim. İki özelliği olan aşağıdaki gibi bir veri kümesi söz 
    konusu olsun:

    Sıra    X1  X2
    1       7    8
    2       2    4
    3       6    4
    4       3    2
    5       6    5
    6       5    7
    7       3    3
    8       1    4
    9       5    4
    10      7    7
    11      7    6
    12      2    1

    Biz bu noktaları iki kümeye ayırmak isteyelim. Yani k değerinin 2 olduğunu varsayalım. Algoritmaya iki ağırlık merkezi 
    oluşturmakla başlayalım. Bu ağırlık merkezlerinin şunlar olduğunu varsayalım:

    C1 = (1, 4)
    C2 = (7, 8)

    Şimdi buradaki 12 noktanın tek tek bu iki ağırlık merkezine Öklit uzaklıklarını hesaplayıp ilk kümeleri oluşturalım:

    Sıra    X1    X2    C1 Uzaklığı     C2 Uzaklığı          Atanan Küme
    -------------------------------------------------------------------
    1        7    8    7.21                   0                Cluster-2
    2        2    4    1.00                6.40                Cluster-1
    3        6    4    5.00                4.12                Cluster-2
    4        3    2    2.83                7.21                Cluster-1
    5        6    5    5.10                3.16                Cluster-2
    6        5    7    5.00                2.24                Cluster-2
    7        3    3    2.24                6.40                Cluster-1
    8        1    4    0.00                7.21                Cluster-1
    9        5    4     4.0                4.47                Cluster-1
    10       7    7    6.71               1.00                 Cluster-2
    11       7    6    6.32               2.00                 Cluster-2
    12       2    1    3.16               8.60                 Cluster-1

    Şimdi iki kümenin gerçek ağırlık merkezlerini hesaplayalım. Bu gerçek ağırlık merkezleri şöyledir:

    C1 = (2.67, 3.00) 
    C2 = (6.33, 6.17)

    Şimndi yeniden 12 noktanın da bu yeni ağırlık merkezlerine uzaklıklarını hesaplayıp yeni kümeleri elde edelim:

    Sıra    X1  X2           C1 Uzaklığı        C2 Uzaklığı     Atanan Küme
    -----------------------------------------------------------------------
    1        7    8                6.61                1.95        Cluster-2
    2        2    4                1.20                4.84        Cluster-1
    3        6    4                3.48                2.19        Cluster-2
    4        3    2                1.05                5.34        Cluster-1
    5        6    5                3.88                1.22        Cluster-2
    6        5    7                4.63                1.57        Cluster-2
    7        3    3                0.33                4.60        Cluster-1
    8        1    4                1.95                5.75        Cluster-1
    9        5    4                2.54                2.55        Cluster-1
    10       7    7                5.89                1.07        Cluster-2
    11       7    6                5.27                0.69        Cluster-2
    12       2    1                2.11                6.74        Cluster-1

    Bu işlemden sonra kümelerde bir değişiklik olmadığı için algoritma sonlandırılacaktır.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    K-Means yönteminde işin başında ağırlık merkezleri rastgele alındığı için algoritmanın her çalıştırılmasında birbirinden 
    farklı kümeler elde edilebilmektedir. (Tabii bu kümelerin çok az sayıda elemanı farklı olabilmektedir.) Bu tür durumlarda 
    algoritma birden fazla kez çalıştırılıp en iyi kümeleme seçilebilir. 

    Pekiyi K-Means yönteminde en iyi kümeyi belirleyebilmek için performans ölçütü olarak neyi kullanabiliriz? Yani iki alternatif 
    kümelemede hangi kümelemenin daha iyi olduğunu nasıl ölçebiliriz? İşte en çok kullanılan performans ölçütü "atalet (inertia)" 
    denilen ölçüttür. Atalet "noktaların kendi ağırlık merkezlerine uzaklıklarının karelerinin toplamına" denilmektedir. Bu 
    aslında istatistikteki varyans işlemi gibidir. Yani aslında bu yöntemde en küçük toplam varyansa bakılmaktadır. O halde 
    biz K-Means algoritmasını birden fazla kez çalıştırıp her kümelemenin ataletine bakıp en iyi atalete sahip olan kümelemeyi 
    seçebiliriz. 

    Algoritmanın başlangıcında rastgele nokta seçmek için çeşitli yöntemler de önerilmiştir. Bunlardan en yaygın kullanılanı 
    "kmeans++" denilen yöntemdir. 

    Pekiyi biz K-Means algoritmasında kestirimde bulunabilir miyiz? Yani kümeleme işleminden sonra elimizdeki bir noktanın 
    hangi kümeye ilişkin olabileceğini kestirebilir miyiz? Eğer bir kez kümeleme yapılmışsa yeni bir noktanın bu kümelerden 
    hangisinin içerisine girebileceği basit bir biçimde noktanın tüm ağırlık merkezlerine uzaklığına bakılarak belirlenebilir. 
    Yani bu yöntem bize bir kestirim yapma olanağı da sağlamaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıda biraz kusurlu da olsa basit bir biçimde K-Means kümeleme işlemini yapan bir fonksiyon örneği verilmiştir. Fonksiyonun 
    parametrik yapısı şöyledir:

    kmeans(dataset, nclusters, centroids=None)

    Fonksiyonun birinci parametresi kümelenecek olan noktaları ikinci parametresi ise oluşturulacak küme sayını belirtir. Üçüncü 
    parametre başlangıçtaki ağırlık merkezlerini almaktadır. Bu parametre için argüman girilmezse başlangıçtaki ağırlık merkezleri 
    rastgele bir biçimde alınmaktadır. Fonksiyon dörtlü bir demete geri dönmektedir. Demetin birinci elemanı noktaların tek tek 
    0 orijinli olarak hangi kümeler içerisinde bulunduğu bilgisidir. İkinci eleman NumpPy dizilerinden oluşan bir liste biçimindedir. 
    Bu listenin içerisindeki dizilerde sırasıyla ilgili kümedeki noktalar bulunmaktadır. Demetin çüncü elemanı nihai durumdaki 
    ağırlık merkezlerini vermektedir. Son eleman ise noktaların kendi ağırlık merkezlerine uzaklıklarının karelerinin toplamınını 
    belirtir. Buna atalet (inertia) dendiğini anımsayınız.

    Burada gerçekleştirdiğimiz algoritmada ağırlık merkezlerinin rastgele seçilmesinde bir sorun vardır. Eğer işin başında rastgele
    seçilen ağırlık merkezine yakın hiçbir nokta yoksa (yani işin başında kümelerden biri boş olursa) algoritmada bir daha o 
    kümenin içerisine herhangi bir nokta dahil edilememektedir. Bu nedenle işin başındaki rastgele ağırlık merkezlerinin seçimine 
    dikkat edilmelidir. "K-means++" denilen ilkdeğer verme algoritmasını inceleyerek o algoritmayı uygulayabilirsiniz. 

    K-Means kümeleme yöntemi temel olarak Öklit uzaklığına dayalı bir ağırlık merkezi oluşturmaktadır. Kategorik verilerin Öklit
    uzaklıklarının anlamlı olmadığını belirtmiştik. Bu nedenle K-Means algoritması özünde nümerik sütunlara sahip veri kümelerinde
    kullanılmaktadır. Kategorik sütunlara da sahip olan veri kümeleri için dolaylı önişlemler yapılarak K-Means yöntemi kullanılabilir. 
    Ancak bu tür veri kümeleri için K-Prototypes gibi diğer K-XXX alternatiflerleri daha uygun bir seçenek oluşturmaktadır.

    Aşağıdaki örnekte kullanılan "points.csv" dosyasının içeriği şöyledir:

    X1,X2
    7,8
    2,4
    6,4
    3,2
    6,5
    5,7
    3,3
    1,4
    5,4
    7,7
    7,6
    2,1
#----------------------------------------------------------------------------------------------------------------------------

NCLUSTERS = 3

import numpy as np
from scipy.spatial.distance import euclidean

def kmeans(dataset, nclusters, centroids=None):
    nrows = dataset.shape[0]
    clusters = np.full(nrows, -1)
    if centroids == None:
        centroids = rand_centroids(dataset, nclusters)

    change_flag = True
    while change_flag:
        change_flag = False
        for i in range(nrows):
            min_val = np.inf
            min_index = -1
            for k in range(nclusters):
                if not np.any(np.isnan(centroids[k])):
                    result = euclidean(dataset[i], centroids[k])
                    if result < min_val:
                        min_val = result
                        min_index = k
            if clusters[i] != min_index:
                change_flag = True
            clusters[i] = min_index

        for i in range(nclusters):
            idataset = dataset[clusters == i]
            centroids[i] = np.mean(idataset, axis=0) if len(idataset) else np.nan

    dataset_clusters = []
    inertia = 0
    for i in range(nclusters):
        idataset = dataset[clusters == i]
        dataset_clusters.append(idataset)
        inertia += np.sum((idataset - centroids[i]) ** 2) if len(idataset) > 0 else 0

    return clusters, dataset_clusters, centroids, inertia

    def rand_centroids(dataset, nclusters):
        random_indices = np.random.choice(dataset.shape[0], size=nclusters, replace=False)
        centroids = dataset[random_indices]
        
        return centroids

import pandas as pd

df = pd.read_csv('points.csv', dtype='float32')
dataset = df.to_numpy(dtype='float32')

clusters, dataset_clusters, centroids, inertia = kmeans(dataset, NCLUSTERS)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
plt.title('Clustered Points')

for i in range(NCLUSTERS):
    plt.scatter(dataset_clusters[i][:, 0], dataset_clusters[i][:, 1], color='ygb'[i])    

plt.scatter(centroids[:, 0], centroids[:, 1], 60, color='red', marker='s')
legends = [f'Cluster-{i}' for i in range(1, NCLUSTERS + 1)]
legends.append('Centroids')
plt.legend(legends)

plt.show()

#----------------------------------------------------------------------------------------------------------------------------
                                            85. Ders - 08/12/2024 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    K-Means kümeleme algoritması scikit-learn içerisinde sklearn.cluster modülündeki KMeans isimli sınıfla gerçekleştirilmiştir. 
    Sınıfın __init__ metodunun parametrik yapısı şöyledir:

   class sklearn.cluster.KMeans(n_clusters=8, *, init='k-means++', n_init='auto', max_iter=300, tol=0.0001, verbose=0, 
        random_state=None, copy_x=True, algorithm='lloyd')

    Metodun n_clusters parametresi ayrıştırılacak küme sayısını (k değerini), init parametresi başlangıçtaki rastgele ağırlık
    merkezlerinin nasıl oluşturulacağını belirtmektedir. init parametresinin default değeri "kmeans++" biçimindedir. Bu parametreye 
    "random" değeri de girilebilir. Bu durumda ilk ağırlık merkezleri rastgele satırlardan seçilecektir. Ayrıca bu parametreye 
    programcı kendi ağırlık merkezlerini bir NumPy matrisi biçiminde de girebilir. Metodun n_init parametresi algoritmanın kaç 
    kere çalıştırılıp en iyisinin bulunacağını belirtmektedir. Bu parametrenin default değeri "auto" biçimdedir. Bu "auto" default 
    değeri kullanıldığında algoritmanın keç kez çalıştırılacağı metodun init parametresine bağlı olarak değişmektedir. Eğer init 
    parametresi "k-means++" ya da NumPy dizisi biçimindeyse algoritma 1 kez çalıştırılır, "random" biçimindeyse 10 kez çalıştırılır.
    En iyi değer "atalete (inertia)" bağlı olarak belirlenmektedir. Metodun max_iter parametresi bir çalıştırmanın toplamda en 
    fazla kaç iterasyon süreceğini belirtmektedir. Bu parametrenin default değerinin 300 olduğunu görüyorsunuz. Yani algoritma 
    300 adımda kararlı noktaya gelmezse sonlandırılmaktadır. Metodun algorithm parametresi kullanılacak algoritmanın varyasyonunu 
    belirtmektedir. Bu parametrenin default değeri "llyod" biçimindedir. K-Means algoritmaları arasında küçük farklılıklar vardır. 
    Yukarıda açıkladığımız algoritma Llyod algoritmasıdır. Ancak noktaların durumuna göre bu varyasyonlar arasında hız açısından 
    farklılıklar söz konusu olabilmektedir. 
    
    KMeans nesnesi yaratıldıktan sonra kümeleme algoritması fit metodu ile çalıştırılır. fit metodu parametre olarak veri kümesini 
    iki boyutlu bir matris biçiminde bizden alır ve kümelemeyi yapar,  nesnenin kendisiyle geri döner. Kümeleme işlemi bittikten 
    sonra nesnenin aşağıda belirttiğimiz özniteliklerinden kümeleme sonucundaki bilgiler elde edilebilmektedir. 

    cluster_centers_: Bu öznitelik nihai durumdaki ağırlık merkezlerini vermektedir. 
    
    labels_: Her noktanın hangi küme içerisinde yer aldığına yönelik tek boyutlu bir NumPy dizisini belirtir. Buradaki kümeler 
    0'dan  başlanarak numaralandırılmıştır. Örneğin biz labels_ özniteliğinden aşağıdaki gibi bir NumPy dizisi elde edebiliriz:

    array([2, 1, 0, 1, 0, 2, 1, 1, 0, 2, 2, 1])

    Burada sırasıyla noktaların kaç numaralı kümeye ilişkin olduğu belirtilmektedir. Kümelemede kümelenmiş olan olguların ne 
    olduğu bilinmemektedir dolayısıyla da bunlara bir isim verilememektedir. KMeans sınıfı bize ayrıca kümelerdeki noktaları 
    vermemektedir. Ancak biz bu öznitelikten hareketle hangi noktaların hangi kümelerin içerisinde olduğunu dataset[km.labels_ == n] 
    işlemi ile elde edebiliriz. 
    
    inertia_: Bu öznitelik tüm noktaların kendi ağırlık merkezlerine uzaklıklarının karelerinin toplamını vermektedir. Bu değerin 
    bir performans ölçütü olarak kullanıldığını belirtmiştik.
    
    n_iter_: Bu öznitelik sonuca varmak için kaç iterasyonun uygulandığını bize verir. 
    
    n_features_in_: Veri kümesindeki sütunların sayısını belirtir.

    Sınıfın transform metodu önemli bir işlem yapmamaktadır. transform metoduna biz birtakım noktalar verdiğimizde metot bize 
    o noktaların tüm ağırlık merkezlerine uzaklığını verir. Benzer biçimde fit_transform metodu da önce fit işlemi ile önce 
    kümelemeyi yapıp sonra da transform işlemi yapar. Ancak bu sınıfta transform ve fit_transform çok kullanılan metotlar değildir. 
    Yani:

    km.fit(dataset)
    result = km.transform(dataset)

    işlemi ile:

    result = fit_transform(dataset)

    aynı işleve sahiptir. fit_transform işlemi ile biz önce K-Means algoritmasını uygulayıp sonra her noktanın tüm ağırlık 
    merkezlerine uzaklıklarını iki boyutlu bir NumPy dizisi biçiminde elde ederiz. 

    Sınıfın predict metodu bizden alınan noktaların hangi kümeler içerisinde yer alabileceğini belirtmektedir. Yani aslında metot 
    aldığı noktaların tüm ağırlık merkezlerine uzaklığını hesaplayıp en yakın ağırlık mrkezinin ilişkin olduğu kümeyi vermektedir. 
    Sınıfın fit_predict isimli metodu ise önce fit işlemi yapıp sonra predict işlemi yapmaktadır. Yani:

    predict_result = km.fit(dataset).predict(dataset)

    İşleminin eşdeğeri şöyledir:

    predict_result = fit_predict(dataset)

    Aşağıda KMeans sınıfının kullanımına ilişkin bir örnek verilmiştir. Örnekte kümeleme işlemi şöyle yapılmıştır:

    df = pd.read_csv('points.csv')
    dataset = df.to_numpy(dtype='float32')

    km = KMeans(n_clusters=NCLUSTERS, n_init=10)
    km.fit(dataset)
        
    Biz burada küme sayısını temsil eden NCLUSTERS değerini 3 olarak belirledik. Örnekte kümeleme sonucunda elde edilen tüm 
    bilgiler yazdırılmıştır ve her kümedeki noktalar saçılma grafiği ile gösterilmiştir. Ayrıca örnekte bir kestirim işlemi 
    yapılıp kestirilen noktaların da hangi kümeler içerisine düştüğü ayrı bir grafikle gösterilmiştir. Örnekte kullandığımız 
    "points.csv" dosyasının içeriği de şöyledir:

    X1,X2
    7,8
    2,4
    6,4
    3,2
    6,5
    5,7
    3,3
    1,4
    5,4
    7,7
    7,6
    2,1
#----------------------------------------------------------------------------------------------------------------------------

NCLUSTERS = 3

import pandas as pd
from sklearn.cluster import KMeans

df = pd.read_csv('points.csv')
dataset = df.to_numpy(dtype='float32')

km = KMeans(n_clusters=NCLUSTERS, n_init=10)
km.fit(dataset)

print(f'Inertia: {km.inertia_}')
print('-' * 20)

for i in range(NCLUSTERS):
    print(f'Cluster {i}', end='\n\n')
    cluster = dataset[km.labels_ == i]
    print(cluster)
    print('-' * 20)
    
print('Dataset', end='\n\n')
df['Cluster'] = km.labels_
print(df)

print('-' * 20)
print('Centroids')
print(km.cluster_centers_)

import matplotlib.pyplot as plt

plt.title('Clustered Points', fontsize=12)

for i in range(NCLUSTERS):
    plt.scatter(dataset[km.labels_ == i, 0], dataset[km.labels_ == i, 1])
plt.scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1], 60, color='red', marker='s')

plt.show()

import numpy as np

predict_dataset = np.array([[3, 4], [4, 6], [6, 2]], dtype='float32')
predict_result = km.predict(predict_dataset)
print(f'Predict result: {predict_result}')

cluster_colors = np.array(['orange', 'green', 'magenta'])

plt.title('Clustered Points With Predicted Data', fontsize=12)

for i in range(NCLUSTERS):
    plt.scatter(dataset[km.labels_ == i, 0], dataset[km.labels_ == i, 1], color=cluster_colors[i])
plt.scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1], 60, color='red', marker='s')

plt.scatter(predict_dataset[:, 0], predict_dataset[:, 1], 60, color=cluster_colors[predict_result], marker='^')

plt.show()
 
#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de K-Means kümeleme yöntemini daha önce üzerinde çalıştığımız "zambak (iris)" veri kümesine uygulayalım. Anımsanacağı 
    gibi "zambak" veri kümesinde ilk sütun sıra numalarından oluşuyordu son sütun da zambakların sınıflarını belirtiyordu. Toplamda 
    üç zambak sınıfının olduğunu anımsayınız. O zaman biz bu veri kümesini üç kümeye ayırmaya çalışabiliriz. Önce veri kümesini 
    okuyup özellik ölçeklemesi yapalım:

    NCLUSTERS = 3
 
    df = pd.read_csv('iris.csv')
    dataset = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')

    ss = StandardScaler()
    ss.fit(dataset)
    transformed_dataset = ss.transform(dataset)

    Sonra KMeans algoritmasını ölçeklendirilmiş verilere uygulayalım:

    from sklearn.cluster import KMeans

    km = KMeans(n_clusters=NCLUSTERS, n_init=10)
    km.fit(transformed_dataset)

    df['Cluster'] = km.labels_    

    Şimdi kümelenmiş noktaların grafiğini çizdirelim. Ancak noktalar dört boyutlu uzaya ilişkin olduğu için onu iki boyuta 
    indirgeyeceğiz. Bu işleme "boyutsal özellik indirgemesi (dimentionality feature reduction)" denilmektedir. Bu konu ilerde
    ayrı bir bölümde ele alınacaktır. Biz bu işlemi ismine "temel bileşenler analizi (principle component analysis)" denilen 
    yöntemle aşağıdaki gibi gerçekleştireceğiz:

    from sklearn.decomposition import PCA

    pca = PCA(n_components=2)
    pca.fit(dataset)
    reduced_dataset = pca.transform(dataset)

    Artık iki boyuta indirgenmiş olan noktaların saçılma grafiğini çizebiliriz. Burada her kümenin noktalarını ayrı bir renkle
    görüntüleyeceğiz:

    transformed_centroids = ss.inverse_transform(km.cluster_centers_)
    reduced_centroids = pca.transform(transformed_centroids)

    plt.title('Clustered Points', fontsize=12)
    for i in range(NCLUSTERS):
        plt.scatter(reduced_dataset[km.labels_ == i, 0], reduced_dataset[km.labels_ == i, 1])    
    plt.scatter(reduced_centroids[:, 0], reduced_centroids[:, 1], color='red', marker='s')    
    plt.show()

    Kestirim işlemleri benzer biçimde yapılabilir:

    predict_data = np.array([[5.0,3.5,1.6,0.6], [4.8,3.0,1.4,0.3], [4.6,3.2,1.4,0.2]], dtype='float32')
    transformed_predict_data = ss.transform(predict_data)

    predict_result = km.predict(transformed_predict_data)
    print(predict_result)

    Örneğin kodları bir bütün olarak aşağıda verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

NNCLUSTERS = 3

import pandas as pd

df = pd.read_csv('iris.csv')
dataset = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset)
transformed_dataset = ss.transform(dataset)

from sklearn.cluster import KMeans

km = KMeans(n_clusters=NCLUSTERS, n_init=10)
km.fit(transformed_dataset)

df['Cluster'] = km.labels_

import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
pca.fit(dataset)
reduced_dataset = pca.transform(dataset)

transformed_centroids = ss.inverse_transform(km.cluster_centers_)
reduced_centroids = pca.transform(transformed_centroids)

plt.title('Clustered Points', fontsize=12)
for i in range(NCLUSTERS):
    plt.scatter(reduced_dataset[km.labels_ == i, 0], reduced_dataset[km.labels_ == i, 1])    
plt.scatter(reduced_centroids[:, 0], reduced_centroids[:, 1], color='red', marker='s')    
plt.show()

import numpy as np

predict_data = np.array([[5.0,3.5,1.6,0.6], [4.8,3.0,1.4,0.3], [4.6,3.2,1.4,0.2]], dtype='float32')
transformed_predict_data = ss.transform(predict_data)

predict_result = km.predict(transformed_predict_data)
print(predict_result)

#----------------------------------------------------------------------------------------------------------------------------
    K-Means yönteminde bizim işin başında noktaları kaç kümeye ayıracağmızı belirlemiş olmamız gerekir. Pekiyi biz bunu nasıl 
    belirleyebiliriz? İşte bazen problemin kendi içerisinde zaten küme sayısı bilinmektedir. Örneğin birisi bize çok sayıda 
    elma, armut, kayısı, şeftali, karpuz resimleri vermiş olsun. Ama biz hangi resmin hangi meyveye ilişkin olduğunu bilmiyor 
    olalım. Bu problemde biz resimlerin beş farklı meyveye ilişkin olduğunu zaten bilmekteyiz. Ancak hangi meyvelerin hangi 
    resimlerle ilişkili oluğunu bilmemekteyiz. Tabii pek çok durumda biz küme sayısını da bilmiyor durumda oluruz. En iyi 
    küme sayısının belirlenmesi için birkaç yöntem kullanılmaktadır. En çok kullanılan iki yöntem şöyledir:

    1) Dirsek Noktası Yöntemi (Elbow Point Method)
    2) Silüet Yöntemi (Silhouette Method)
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Dirsek noktası yönteminde önce 1'den başlanarak n'e kadar küme sayıları ile kümeleme yapılır. Her kümedeki toplam atalet 
    elde edilir. (Toplam ataletin KMeans sınıfının inertia_ özniteliği ile verildiğini anımsayınız. Toplam atalet her noktanın 
    kendi ağırlık merkezine uzaklığının kareleri toplamıdır.) Sonra yatay eksende küme sayısı düşey eksende toplam atalet 
    olacak biçimde bir grafik çizilir. Bu grafikte "eğrinin yataya geçtiği nokta" gözle tespit edilir. Eğrinin yataya geçtiği 
    noktaya "dirsek noktası (elbow point)" denilmektedir. Ancak dirsek noktası yöntemi gözle tespite dayılıdır. Bu yöntemde 
    uygulamacı tarafından dirsek gözle tespit edilmesi sırasında tereddütler oluşabilmektedir.

    Aşağıdaki örnekte daha önce kullanmış olduğumuz "points.csv" noktaları için dirsek noktası grafiği çizilmiştir. Bu örnekte 
    toplam ataletler aşağıdaki gibi bir liste içlemi ile elde edilmiştir:

    inertias = [KMeans(n_clusters=i, n_init=10).fit(dataset).inertia_  for i in range(1, 10)]

    Grafik şöyle çizdirilmiştir:

    plt.title('Elbow Point Method', fontsize=12)
    plt.plot(range(1, 10), inertias)
    plt.show()

    Buradan elde edilen grafiğe bakıldığında dirsek noktasının 3 ya da 4 olabileceği anlaşılmaktadır. Örnekte kullanılan noktalar
    şöyledir:

    X1,X2
    7,8
    2,4
    6,4
    3,2
    6,5
    5,7
    3,3
    1,4
    5,4
    7,7
    7,6
    2,1
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd
from sklearn.cluster import KMeans

df = pd.read_csv('points.csv')
dataset = df.to_numpy(dtype='float32')

inertias = [KMeans(n_clusters=i, n_init=10).fit(dataset).inertia_ for i in range(1, 10)]

import matplotlib.pyplot as plt

plt.title('Elbow Point Method', fontsize=12)
plt.plot(range(1, 10), inertias)
plt.show()

# Dirsek noktasının 3 olduğu tespit edilmiştir

km = KMeans(n_clusters=3, n_init=10)
km.fit(dataset)

plt.title('Clustered Points', fontsize=12)

for i in range(3):
    plt.scatter(dataset[km.labels_ == i, 0], dataset[km.labels_ == i, 1])
plt.scatter(km.cluster_centers_[:, 0], km.cluster_centers_[:, 1], 60, color='red', marker='s')

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de "zambak (iris) veri" kümesi için dirsek noktası yöntemiyle en iyi küme sayısını belirlemeye çalışalım. Bu işlem 
    sonucunda elde edilen grafikten dirsek noktasının 3 olduğu görülmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('iris.csv')
dataset = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset)
transformed_dataset = ss.transform(dataset)

from sklearn.cluster import KMeans

inertias = [KMeans(n_clusters=i, n_init=10).fit(transformed_dataset).inertia_ for i in range(1, 10)]

import matplotlib.pyplot as plt

plt.title('Elbow Point Method', fontsize=12)
plt.plot(range(1, 10), inertias)
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
                                            86. Ders - 14/12/2024 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Silüet (silhouette) yönteminde yine 2'den başlanarak belli sayıda küme için çözümler yapılır. Sonra her çözüm için "silüet 
    skoru (silhouette score)" denilen bir değer elde edilmektedir. Bu değerin en yüksek olduğu küme sayısından bir fazla küme 
    sayısı en iyi küme sayısı olarak belirlenmktedir. Silüet skoru sklearn.metrics modülündeki silhouette_score isimli fonksiyonla 
    elde edilebilmektedir. Bu fonksiyona parametre olarak veri kümesi ve kümelenmiş sonuçlar (yani labels_ değeri) verilir. 
    Silüet skor işlemi tek kümeyle yapılamamaktadır. Yani bu yöntemde silüet skorları kümesi 2'den başlatılarak hesaplanmalıdır. 

    silhouette_score fonksiyonun parametrik yapısı şöyledir:

    sklearn.metrics.silhouette_score(X, labels, *, metric='euclidean', sample_size=None, random_state=None, **kwds)

    Fonksiyonun birinci parametresi kümelenecek veri kümesini ikinci parametresi ise kümeleme sonucunda elde edilmiş olan kümeleme
    bilgisini (yani KMeans nesnesinin labels_ özniteliğini) almaktadır. 

    Şimdi yukarıdaki "points.csv" veri kümesi için en iyi küme sayısını silüet skoru ile tespit edelim. Aşağıdaki gibi bir
    döngü ile küme sayıları için silüet skor değerleri elde edilebilir:

    ss_list = []
    for i in range(2, 10):
        labels = KMeans(n_clusters=i, n_init=10).fit(dataset).labels_
        ss = silhouette_score(dataset, labels)
        ss_list.append(ss)
        print(f'{i} => {ss}')
    
    Buradan elde edilen skorlar şöyledir:

    2 => 0.5544097423553467
    3 => 0.47607627511024475
    4 => 0.4601795971393585
    5 => 0.4254012405872345
    6 => 0.3836685121059418
    7 => 0.29372671246528625
    8 => 0.21625620126724243
    9 => 0.11089805513620377

    Bizim amacımız en yüksek skora ilişkin küme sayısından bir bir fazlasını elde etmektir. Gözle baktığımızda en yüksek 
    değerin 0.5544097423553467 olduğu görülmektedir. Bu değer 2 kümeye ilişkin olan değerdir. O halde en iyi küme sayısı 
    3'tür. Bu işlemi şöyle de yapabiliriz:

    optimal_cluster = np.argmax(ss_list) + 3

    Tabii aslında fonksiyonel tarzda bu tespit işlemi tek bir ifade ile de yapılabilirdi:

    optimal_cluster = np.argmax([silhouette_score(dataset, KMeans(i, n_init=10).fit(dataset).labels_) 
            for i in range(2, 10)]) + 3

    Aşağıdaki örnekte dana önceden kullandığımız "points.csv" verileir için Silhouette skor değeri elde edilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd
from sklearn.cluster import KMeans

df = pd.read_csv('points.csv')
dataset = df.to_numpy(dtype='float32')

import numpy as np
from sklearn.metrics import silhouette_score

ss_list = []
for i in range(2, 10):
    labels = KMeans(n_clusters=i, n_init=10).fit(dataset).labels_
    ss = silhouette_score(dataset, labels)
    ss_list.append(ss)
    print(f'{i} => {ss}')
    
optimal_cluster = np.argmax(ss_list) + 3
print(f'Optimal cluster: {optimal_cluster}' )

optimal_cluster = np.argmax([silhouette_score(dataset, KMeans(i, n_init=10).fit(dataset).labels_) 
        for i in range(2, 10)]) + 3
print(f'Optimal cluster: {optimal_cluster}' )
    
#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte yine "zambak (iris)" veri kümesi için en uygun küme sayısı silüet skor yöntemi ile elde edilmiştir. 
    Elde edilen skor deeğerleri şöyledir:

    2 => 0.6808136105537415
    3 => 0.5525919795036316
    4 => 0.4978257119655609
    5 => 0.48851755261421204
    6 => 0.3712180554866791
    7 => 0.35612809658050537
    8 => 0.3631969094276428
    9 => 0.34673967957496643

    Burada en yüksek değerin 2'li kümelemeye ilişkin olduğunu görüyorsunuz. Bu durumda en uygun küme sayısı 3 olacaktır.  
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('iris.csv')
dataset = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset)
transformed_dataset = ss.transform(dataset)

from sklearn.cluster import KMeans
import numpy as np
from sklearn.metrics import silhouette_score

ss_list = []
for i in range(2, 10):
    labels = KMeans(n_clusters=i, n_init=10).fit(dataset).labels_
    ss = silhouette_score(dataset, labels)
    ss_list.append(ss)
    print(f'{i} => {ss}')
    
optimal_cluster = np.argmax(ss_list) + 3
print(f'Optimal cluster: {optimal_cluster}' )
    
#----------------------------------------------------------------------------------------------------------------------------
    Silüet Skor Yönteminin Açıklanması Buraya Eklenecek, Notun Yazılması Uzunutulmuş
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Biz yukarıdaki örneklerde bütün sütunları nümerik olan veri kümeleri üzerinde K-Means yöntemini uyguladık. Pekiyi kategorik 
    sütunlar da içeren veri kümelerinde K-Means kümeleme işlemi nasıl uygulanacaktır? Anımsanacağı gibi K-Means kümeleme yönteminde
    Öklit uzaklığı kullanılmaktadır. Öklit uzaklığı nümerik değerlerle hesaplanan bir uzaklık cinsidir. O halde biz kategorik 
    sütunlar da içeren veri kümeleri için K-Means yöntemini kullanacaksak bir biçimde bu kategorik sütunları sayısal hale 
    dönüştürmemiz gerekir. Pekiyi bunu nasıl yapabiliriz? Örneğin aşağıdaki gibi bir veri kümesi olsun:

    A       B       C       Renk
    ----------------------------
    3.2     2.1     4.2     Kırmızı
    2.1     4.2     3.2     Mavi
    6.1     5.2     1.2     Yeşil
    4.1     1.2     3.2     Yeşil

    Burada "Renk" sütunu kategorik bir sütundur. Uzaklığı hesaplanacak iki nokta şöyle olsun:

    2.1     4.2     3.2     Mavi
    4.1     1.2     3.2     Yeşil

    Buradaki kategorik değerler nasıl sayısallaştırılacaktır? Bunun için biz LabelEncoder kullanamayız. Çünkü LabelEncoder 
    her kategoriye 0'dan itibaren bir tamsayı karşılık düşürmektedir. Bu durumda gerçekte var olmayan renkler arasında anlamsız 
    bir uzaklık oluşur. (Bu tür durumlarda Hamiing uzaklığının tercih edildiğini anımsayınız.) Bu tür durumlarda one-hot-encoding 
    dönüştürmesi nispeten iş görebilmektedir. Bu dönüştürme yapıldığında aynı renkler arasındaki uzaklık 0 farklı renkler 
    arasındaki uzaklık sabit fakat aynı bir değer haline gelir. Tabii one-hot-encoding dönüştürmesinden sonra özellik ölçeklemesinin 
    yapılması  gerekecektir. Her ne kadar one-hot-encoding dönüştürmesi bu tür durumlarda kullanılabiliyorsa da bu uygulamanın 
    bazı dezavantakları da vardır. Kategorik sütunlarla sayısal sütunları bir araya getirmek bazı bilgi kayıplarına yol 
    açabilmektedir. Ayrıca sütun sayısının fazlalaşması diğer bir problem olarak karşımıza çıkacaktır. One-hot-encoding yapılmış 
    fazla sayıda sütun nümerik işlemleri yavaşlatır ve diğer sütunların etkisini azaltabilir. Hem kategorik hem de nümerik 
    sütunların bulunduğu veri kümelerinde K-Means uygulamadan önce kategorik sütunlar tamamen veri kümesinden de atılabilir. 
    Ancak şüphesiz bu işlem bilgi kaybına yol açacaktır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------  
    Şimdi bir sektördeki müşterilere ilişkin kategorik sütunlar da içeren ("mixed") "customer clustering" isimli veri kümesi 
    üzerinde K-Means uygulamaya çalışalım. Bu veri kümesini aşağıdaki bağlantıdan indirebilirsiniz:

    https://www.kaggle.com/datasets/dev0914sharma/customer-clustering?resource=download

    Bu veri kümesinde şu sütunlar bulunmaktadır:'Sex', 'Marital status', 'Age', 'Education', 'Income', 'Occupation', 
    'Settlement size'. "Sex" sütunu cinsiyet belirten iki kategorili bir sütundur. "Marital status" yine iki kategorili, 
    "Education" 4 kategorili, "Occupation" 3 kategorili ve "Settlement size" da 3 kategorili sütunlardır. Veri kümesinin görünümü 
    aşağıdaki gibidir:

    ID,Sex,Marital status,Age,Education,Income,Occupation,Settlement size
    100000001,0,0,67,2,124670,1,2
    100000002,1,1,22,1,150773,1,2
    100000003,0,0,49,1,89210,0,0
    100000004,0,0,45,1,171565,1,1
    100000005,0,0,53,1,149031,1,1
    ...

    Veri kümesinde fazla sayıda kategorik sütun olduğunu görüyorsunuz. Aslında bu veri kümesi için K-Means uygun bir kümeleme
    yöntemi değildir. Ancak biz burada 2'den fazla olan kategorik sütunları one-hot-encoding yapıp K-Means yöntemini uygulayacağız.

    Örneğin kodlarını aşağıda veriyoruz.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('segmentation data.csv')
df.drop(labels=['ID'], axis=1, inplace=True)

ohe_df = pd.get_dummies(df, columns=['Education', 'Occupation', 'Settlement size'], dtype='uint8')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
scaled_dataset = ss.fit_transform(ohe_df.to_numpy())

from sklearn.cluster import KMeans

total_inertias = [KMeans(n_clusters=i, n_init=10).fit(scaled_dataset).inertia_ for i in range(1, 100)]

import matplotlib.pyplot as plt

plt.figure(figsize=(15, 8))
plt.title('Elbow Graph')
plt.plot(range(1, 100), total_inertias, marker='o')
plt.xticks(range(1, 100, 5))
plt.show()

import numpy as np
from sklearn.metrics import silhouette_score

optimal_cluster = np.argmax([silhouette_score(scaled_dataset, KMeans(i, n_init=10).fit(scaled_dataset).labels_) 
        for i in range(2, 10)]) + 3

km = KMeans(n_clusters=optimal_cluster, n_init=100)
km.fit(scaled_dataset)

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
transformed_dataset = pca.fit_transform(scaled_dataset)

plt.figure(figsize=(12, 10))
plt.title('Clustered Points')
for i in range(1, optimal_cluster + 1):
    plt.scatter(transformed_dataset[km.labels_ == i, 0], transformed_dataset[km.labels_ == i, 1])
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Kümeleme işlemlerinde kümelenecek nokta sayısı çok fazla ise ve bu bakımdan bir bellek sorunu ortaya çıkıyorsa yine parçalı
    eğitim uygulamak gerekebilir. Ancak her kümeleme yöntemi parçalı eğitime uygun değildir. K-Means kümeleme yöntemi parçalı 
    eğitim yapmaya nispetem uygun bir yöntemdir. scikit-learn kütüphanesinde K-Means yöntemi ile parçalı eğitim yapmak için 
    MiniBatchKMeans isimli bir sınıf da bulundurulmuştur. Bu sınıfın fit metoduna biz veri kümesini bir bütün olarak versek 
    bile fit aslında bu veri kümesinden satırları batch batch alıp işleme sokmaktadır. Ancak sınıfın asıl önemli özelliği 
    partial_fit isimli bir metoda sahip olmasıdır. Bu sayede biz bir dosyadan satırları parça parça okuyup fit işlemi yapabiliriz. 
    MiniBatchKMeans sınıfının __init__ metodunun parametrik yapısı şöyledir:

    class sklearn.cluster.MiniBatchKMeans(n_clusters=8, *, init='k-means++', max_iter=100, batch_size=1024, 
        verbose=0, compute_labels=True, random_state=None, tol=0.0, max_no_improvement=10, init_size=None, 
        n_init='auto', reassignment_ratio=0.01)[source]

    Buradaki batch_size veri kümesinden satırların kaçarlı çekilip işleme sokulacağını belirtmektedir. partial_fit metoduna 
    burada belirtilen batch_size kadar satırın verilmesi gerekmektredir. MiniBatchKMeans nesnesi yaratıldıktan partial_fit
    işlemi yapılabilir. partial_fit metodunun parametrik yapısı şöyledir:

    partial_fit(X, y=None, sample_weight=None)

    "kmodes" ve "pyclustering" kütüphanelerindeki K-XXX algoritmalarında bir parçalı eğitim olanağı yoktur.

    Aşağıda daha önce üzerinde çalıştığımız "customer clustering" veri kümesi üzerinde parçalı eğitime ilişkin bir örnek verilmiştir. 
    Bu örnekte veri kümesi parçalı bir biçimde iki kere dolaşılmıştır. Birinci dolaşımda nümerik sütunların özellik ölçeklemesi 
    için ve kategorik sütunların one-hot-encoding işlemine sokulabilmesi için gerekli olan bilgiler toplanmıştır. Kodun bu kısmı 
    şöyledir:

    unique_list = [set(), set(), set()]
    count = 0
    total = 0
    total_square = 0
    for df in pd.read_csv('segmentation data.csv', chunksize=BATCH_SIZE):
        unique_list[0].update(df['Education'])
        unique_list[1].update(df['Occupation'])
        unique_list[2].update(df['Settlement size'])
        
        total += df[numeric_features].sum()
        total_square += (df[numeric_features] ** 2).sum()
        count += df.shape[0]

    numeric_mean = total / count
    numeric_std = (total_square / count - numeric_mean  ** 2) ** 0.5
    unique_list = [list(us) for us in unique_list]

    Pandas'ın read_csv fonksiyonu chunksize parametresi ile kullanıldığında bize bir iteratör nesnesi verir. Bu iteratör 
    her dolaşıldığında chunskize kadar elemandan oluşan DataFrame nesnesi elde edilmektedir. Tabii fonksiyon tüm dosyayı tek 
    hamlede belleğe okuyarak bu işlemi yapmaz. Kendi içerisinde her defasında chunksize kadar kısmı okumaktadır. 

    Örneğimizde daha sonra ikinci geçişte veriler parça parça okunup önişlemlere sokulup partial_firt metoduna verilmiştir:

    ohe = OneHotEncoder(sparse_output=False, categories=unique_list)

    for df in pd.read_csv('segmentation data.csv', chunksize=BATCH_SIZE):
        categoric_array = ohe.fit_transform(df[categoric_features])
        numeric_array = ((df[numeric_features] - numeric_mean) / numeric_std).to_numpy()
        binary_array = df[binary_features].to_numpy()
        combined_array = np.hstack((categoric_array, binary_array, numeric_array))
        mbkm.partial_fit(combined_array)

    Örnek aşağıda bir bütün olarak verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

NCLUSTERS = 5
BATCH_SIZE = 10

import numpy as np
import pandas as pd
from sklearn.cluster import MiniBatchKMeans
from sklearn.preprocessing import OneHotEncoder

mbkm = MiniBatchKMeans(n_clusters=NCLUSTERS, batch_size=BATCH_SIZE)

numeric_features = ['Age', 'Income']
categoric_features = ['Education', 'Occupation', 'Settlement size']
binary_features = ['Sex', 'Marital status']

unique_list = [set(), set(), set()]
count = 0
total = 0
total_square = 0
for df in pd.read_csv('segmentation data.csv', chunksize=BATCH_SIZE):
    unique_list[0].update(df['Education'])
    unique_list[1].update(df['Occupation'])
    unique_list[2].update(df['Settlement size'])
    
    total += df[numeric_features].sum()
    total_square += (df[numeric_features] ** 2).sum()
    count += df.shape[0]
    
numeric_mean = total / count
numeric_std = (total_square / count - numeric_mean  ** 2) ** 0.5
unique_list = [list(us) for us in unique_list]

ohe = OneHotEncoder(sparse_output=False, categories=unique_list)

for df in pd.read_csv('segmentation data.csv', chunksize=BATCH_SIZE):
    categoric_array = ohe.fit_transform(df[categoric_features])
    numeric_array = ((df[numeric_features] - numeric_mean) / numeric_std).to_numpy()
    binary_array = df[binary_features].to_numpy()
    combined_array = np.hstack((categoric_array, binary_array, numeric_array))
    mbkm.partial_fit(combined_array)

print(mbkm.labels_)        

#----------------------------------------------------------------------------------------------------------------------------
    Daha önce K-Means yönteminin K-XXX biçiminde isimlendirilen çeşitli varyasyonlarının olduğunu belirtmiştik. Bunları 
    anımsayalım:

    K-Medoids
    K-Modes
    K-Prototypes
    K-Centers
    K-Medians
    K-Nearest Neighbors

    Şimdi bu yöntemlerin bazıları hakkında açıklamalar yapmak istiyoruz.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    K-Medoids yönteminde ana algoritma K-Means yöntemindeki gibidir. Ancak kümenin ağırlık merkezi o kümedeki noktaların 
    boyutsal temelde ortalaması ile değil bu noktalardan bir tanesinin seçilmesiyle yapılmaktadır. Yani bu yöntemde her zaman
    kümenin ağırlık merkezi zaten var olan noktalardan biri olarak seçilir. ("Medoid" sözcüğü zaten İngilizce "bir grup verideki 
    onu temsil eden bir tanesi" anlamına gelmektedir.) K-Means yönteminde kümeler için ağırlık merkezleri aslında küme içerisinde 
    hiç bulunmayan bir nokta olarak elde edilmektedir. Ancak bu yöntemde küme içerisindeki noktalardan biri ağırlık merkezi 
    olarak seçilir. Pekiyi küme içerisindeki hangi nokta en iyi ağırlık merkezi olmaya adaydır? İşte tipik olarak küme içerisindeki 
    her noktanın ağırlık merkezi olduğunu varsayarak bu noktaya toplam uzaklık (ya da atalet) hesaplanır. Bu toplam uzaklığın 
    en az olduğu nokta kümenin yeni ağırlık merkezi olarak seçilir. K-Medoids yöntemi "ağırlık merkezlerinin var olan noktalardan 
    biri olması gerektiği durumlarda ve/veya aşırı uçta değerlerin (outliers) bulunduğu veri kümelerinde" tercih edilebilir. 
    Ancak bu yöntem K-Means yöntemine göre daha fazla işlem zamanına gereksinim duymaktadır. (K-Means yönteminde yeni ağırlık 
    merkezi için noktaların orta noktalarını hesaplamak O(N) karşıklıkta bir işlem olduğu halde nokta sayısı fazlalıştığında 
    K-Medoids yönteminde ağırlık merkezi O(N^2) karmaşıklıkta hesaplanabilmektedir.)

    K-Medoids yöntemi doğrudan scikit-learn tarafından desteklenmemektedir. Ancak bu kütüphanenin "extra" paketinde KMedoids 
    isimli bir sınıf bulunmaktadır. (scikit-learn-extra paketi scikit-learn kütüphanesinde bulunmayan bazı özelliklerin 
    eklenmesiyle oluşturulmuş, onun eksiklerini kapatmayı hedefleyen bir kütüphanedir.) Tabii bunun için önce scikit-learn-extra 
    paketi aşağıdaki gibi kurulmalıdır:

    pip install scikit-learn-extra

    K-Medoids sınıfının kullanımı KMeans sınıfının kullanımına çok benzerdir. 
    
    K-Medoids yöntemi "pyclustering" isimli kütüphane içerisinde de gerçekleştirilmiştir. Bu kütüphaneyi de kullanabilirsiniz.    
    
    Aşağıda "zambak (iris)" veri kümesi üzerinde K-Medoids yönteminin uygulandığı bir kod verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

NCLUSTERS = 3

import pandas as pd

df = pd.read_csv('iris.csv')
dataset = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset)
transformed_dataset = ss.transform(dataset)

from sklearn_extra.cluster import KMedoids

km = KMedoids(n_clusters=NCLUSTERS)
km.fit(transformed_dataset)

df['Cluster'] = km.labels_

import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
pca.fit(dataset)
reduced_dataset = pca.transform(dataset)
reduced_centroids = pca.transform(km.cluster_centers_)

plt.title('Clustered Points', fontsize=12)
for i in range(NCLUSTERS):
    plt.scatter(reduced_dataset[km.labels_ == i, 0], reduced_dataset[km.labels_ == i, 1])    
plt.scatter(reduced_dataset[km.medoid_indices_, 0], reduced_dataset[km.medoid_indices_, 1], color='red')    
plt.show()

import numpy as np

predict_data = np.array([[5.0,3.5,1.6,0.6], [4.8,3.0,1.4,0.3], [4.6,3.2,1.4,0.2]], dtype='float32')
transformed_predict_data = ss.transform(predict_data)

predict_result = km.predict(transformed_predict_data)
print(predict_result)

#----------------------------------------------------------------------------------------------------------------------------
                                            87. Ders - 15/12/2024 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    K-Medians yöntemi de K-Means yöntemi gibidir. Ancak kümeler oluşturulduktan sonra kümelerin ağırlık merkezleri sütun
    ortalamaları ile değil sütunlarım median değerleriyle yapılmaktadır. Böylece uç değerlerin ortalamadaki olumsuz etkisi 
    giderilmiş olur. Tabii median bulma bir sıraya dizme gerektirdiği için daha fazla zaman alan bir işlemdir. Bu yöntem ancak
    uç değerlerin bulunduğu ve bunların veri kümelerinden atılmadığı durumlarda tercih edilebilecek bir yöntemdir. Ayrıca K-Medians
    yönteminde noktaların biribirine uzaklığını hesaplamak için genellikle Öklit uzaklığı yerine Manhattan uzaklığı tercih 
    edilmektedir. Manhattan uzaklığı medyan işlemiyle daha uyumludur. 

    K-Medians yöntemi sckit-learn kütüphanesi tarafından gerçekleştirilmemiştir. Bunun için "pyclustering" kütüphanesi kullanılabilir. 
    Bu kütüphaneyi şöyle kurabilirsiniz:

    pip install pyclustering

    Bu kütüphane kullanılarak K-Medians uygulamasına yönelik bir örnek aşağıda verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------  

import pandas as pd
from pyclustering.cluster.kmedians import kmedians

df = pd.read_csv('points.csv')
dataset = df.to_numpy(dtype='float32')

km = kmedians(dataset, initial_medians=[[5, 4], [1, 2]])
km.process()

clusters = km.get_clusters()
print(clusters)

#----------------------------------------------------------------------------------------------------------------------------
    K-Modes tüm sütunların kategorik ölçekte olduğu veri kümelerinde kullanılabilen bir kümeleme yöntemidir. Örneğin aşağıdaki 
    gibi bir veri kümesi olsun:

    İndex   Renk        Cinsiyet    Ülke
    ------------------------------------
    0       Kırmızı     Kadın        Türkiye
    1       Mavi        Erkek        Almanya
    2       Yeşil       Kadın        Fransa
    3       Mavi        Kadın        İngiltere
    4       Kırmızı     Erkek        Türkiye
    5       Yeşil       Erkek        Almanya
    6       Kırmızı     Kadın        Fransa
    7       Mavi        Erkek        Türkiye
    8       Yeşil       Kadın        İngiltere
    9       Mavi        Kadın        Almanya

    Bu veri kümesinde biz kümeleme yapmak isteyelim. K-Means bunun için uygun değildir. Çünkü K-Means Öklit uzaklığını kullanır.
    Buradaki kategorilerin Öklit uzaklığına dönüştürülmesi anlam kaybına yol açacaktır. İşte sütunların hepsinin kategorik
    olduğu durumlarda K-Means yerine K-Modes yöntemi tercih edilmelidir. 

    K-Modes algoritmasının ana işleyişi K-Means gibidir. Ancak uzaklık hesaplamaları "Hamming uzaklığı" kullanılarak yapılır.
    Anımsanacağı gibi Hamming uzaklığı "farklı olanların ortalaması" ile hesaplanmaktadır. Ancak burada Hamming uzaklığı için 
    ortalama almaya gerek yoktur. Farklı olanların sayısının elde edilmesi yeterlidir. K-Modes algoritmasında yine başlangıçta 
    kaç kümenin oluşturulacağı uygulamacı tarafından belirlenmelidir. Örneğin biz yukarıdaki veri kümesi için 2 kümenin oluşturulmasını 
    isteyelim. Küme sayısı belirlendikten sonra küme sayısı kadar rastgele nokta alınmaktadır. Bu iki reastgele nokta şunlar 
    olsun:

    0'ıncı küme için rastgele ağırlık merkezi  ===>       Yeşil       Kadın        Fransa
    1'inci küme için rastgele ağırlık merkezi  ===>       Mavi        Erkek        Türkiye

    Bundan sonra K-Means algoritmasında olduğu gibi tüm noktaların bu iki noktaya Hamming uzaklıklarını hesaplayıp bu noktalar 
    hangisine yakınsa o kümeye dahil etmektir. Örneğin ilk elemanın ("Kırmızı Kadın Türkiye") her iki noktaya Hamming uzaklığını 
    hesaplayalım: 

    "Kırmızı Kadın Türkiye"  ile  "Yeşil Kadın  Fransa" arasındaki Hamming uzaklığı 2'dir.
    "Kırmızı Kadın Türkiye"  ile  "Mavi  Erkek  Türkiye" arasındaki Hamming uzaklığı 2'dir.

    "Kırmızı Kadın Türkiye" noktasının her iki noktaya Hamming uzaklığı aynı olduğuna göre biz bu noktayı bu kümelerden 
    herhangi birine dahil edebiliriz. Şimdi "Mavi Erkek Almanya" noktasının iki noktaya Hamming uzaklıklarını hesaplayalım:

    "Mavi Erkek Almanya"  ile  "Yeşil Kadın  Fransa" arasındaki Hamming uzaklığı 3'tür.
    "Mavi Erkek Almanya"  ile  "Mavi  Erkek  Türkiye" arasındaki Hamming uzaklığı 1'dir.

    O halde bu nokta 1 numaralı kümeye atanmalıdır. İşte böyle her nokta Hamming uzaklığı temelinde bir kümeye atanır. Bunun 
    sonucunda ilk kümeleme yapılmış olur. Bundan sonra K-Means yönteminde olduğu gibi kümelerin gerçek ağırlık merkezleri 
    kendi elemanlarına göre belirlenmelidir. K-Means yönteminde biz kümedeki elemanların sütunsal ortalamaları ile yeni ağırlık 
    merkezini buluyorduk. Sütunlar kategorik olduğuna göre K-Modes yönteminde biz her sütunun ortalama yerine mod'unu alarak 
    yeni ağırlık merkezini buluruz. Örneğin kümelerden biri şu noktalara sahip olsun:

    Mavi        Erkek        Türkiye
    Mavi        Kadın        Almanya
    Yeşil       Erkek        Türkiye
    Kırmızı     Erkek        Türkiye

    Buradaki yeni ağırlık merkezleri şöyle oluşturulacaktır:

    Mavi Erkek Türkiye

    Görüldüğü gibi nasıl K-Means yönteminde her sütunun ortalaması alınarak yeni ağırlık merkezleri bulunuyorsa K-Modes 
    yönteminde her sütunun mod değeri alınarak ortalama bulunmaktadır. K-Means ismi nasıl "ortalama almakla yeni ağırlık 
    merkezinin bulbulunmasından" geliyorsa K-Modes ismi de "mod alarak yeni ağırlık merkezinin bulunmasından" gelmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi biz tüm sütunların kategorik olduğu durumda en uygun küme sayısını nasıl belirleyebiliriz? Bunun için dirsek yöntemi
    kullanılabilir ancak dirsek yöntemi pek uygun bir yöntem değildir. Ancak silüet yöntemi "Hamming uzaklığı temelinde" 
    uygulanabilir. scikit-learn içerisindeki silhouette_score fonksiyonun parametrik yapısını hatırlayınız:

    sklearn.metrics.silhouette_score(X, labels, *, metric='euclidean', sample_size=None, random_state=None, **kwds)

    Fonksiyonun metric parametresi "Hamming" geçilirse fonksiyon silüet yöntemini "Hamming uzaklığını" kullanarak uygulayacaktır.
    Ancak kategorik verilerin de önce LabelEncoder sınıfı ile sayısal biçime dönüştrülmesi gerekmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    K-Modes yöntemi scikit-learn kütüphanesinde gerçekleştirilmemiştir. scikit-learn extra paketi içerisinde de gerçekleştirimi
    yoktur. Ancak bu yöntemin "kmodes" kütüpanesinde ve "pyclustering" kütüphanesinde gerçekleştirimi bulunmaktadır. Biz burada 
    "kmodes" kütüphanesini kullanarak bir örnek vereceğiz. "kmodes" kütüphanesinin kurulumu şöyle yapılabilir:

    pip install kmodes

    Kütüphane içerisinde K-Modes yöntemi KModes isimli sınıf kullanılarak uygulanmaktadır. Sınıfın kullanımı tamamen scikit-learn'deki
    KMeans sınıfının kullanımına benzetilmiştir. Sınıfın __init__ metodunun parametrik yapısı şöyledir:

    KModes(n_clusters=8, max_iter=100, cat_dissim=matching_dissim, init='Cao', n_init=10, verbose=0, random_state=None, n_jobs=1):
    
    Yine önce KModes sınıfı türünden nesne yaratılır. Sonra fit işlemi yapılır. Kümeleme işlemi sonucunda elde edilen bilgiler
    yine nesnenin özniteliklerinden elde edilir. Örneğin nesnenin labels_ özniteliğinden biz hangi noktaların hangi kümelere 
    atandığını belirleyebiliriz. KModes sınıfının kullanımına şöyle bir örnek verebiliriz:

    dataset_dict = {
        'Renk': ['Kırmızı', 'Mavi', 'Yeşil', 'Mavi', 'Kırmızı', 'Yeşil', 'Kırmızı', 'Mavi', 'Yeşil', 'Mavi'],
        'Cinsiyet': ['Kadın', 'Erkek', 'Kadın', 'Kadın', 'Erkek', 'Erkek', 'Kadın', 'Erkek', 'Kadın', 'Kadın'],
        'Ülke': ['Türkiye', 'Almanya', 'Fransa', 'İngiltere', 'Türkiye', 'Almanya', 'Fransa', 'Türkiye', 'İngiltere', 'Almanya']
    }

    dataset_df = pd.DataFrame(dataset_dict)

    km = KModes(n_clusters=3, n_init=10)
    km.fit(dataset_df)

    cluster_0 = dataset_df.iloc[km.labels_ == 0]
    cluster_1 = dataset_df.iloc[km.labels_ == 1]
    cluster_2 = dataset_df.iloc[km.labels_ == 2]

    Burada veri kümesi K-Modes yöntemiyle üç kümeye ayrıştırılmıştır. 

    En uygun küme sayısını da silüet yöntemiyle şöyle belirleyebiliriz:

    le = LabelEncoder()

    encoded_df = pd.DataFrame()

    for column in dataset_df.columns:
        encoded_df[column] = le.fit_transform(dataset_df[column])

    optimal_cluster = np.argmax([silhouette_score(encoded_df, KModes(i, n_init=10).fit(dataset_df).labels_, metric='hamming') 
            for i in range(2, 8)]) + 3

    Aşağıdaki örnekte önce en uygun küme sayısı tespit edilip sonra KModes sınıfı kullanılarak K-Modes kümeleme işlemi 
    yapılmıştır.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

dataset_dict = {
    'Renk': ['Kırmızı', 'Mavi', 'Yeşil', 'Mavi', 'Kırmızı', 'Yeşil', 'Kırmızı', 'Mavi', 'Yeşil', 'Mavi'],
    'Cinsiyet': ['Kadın', 'Erkek', 'Kadın', 'Kadın', 'Erkek', 'Erkek', 'Kadın', 'Erkek', 'Kadın', 'Kadın'],
    'Ülke': ['Türkiye', 'Almanya', 'Fransa', 'İngiltere', 'Türkiye', 'Almanya', 'Fransa', 'Türkiye', 'İngiltere', 'Almanya']
}

dataset_df = pd.DataFrame(dataset_dict)

import numpy as np
from sklearn.metrics import silhouette_score
from kmodes.kmodes import KModes
from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

encoded_df = pd.DataFrame()

for column in dataset_df.columns:
    encoded_df[column] = le.fit_transform(dataset_df[column])

optimal_cluster = np.argmax([silhouette_score(encoded_df, KModes(i, n_init=10).fit(dataset_df).labels_, metric='hamming') 
        for i in range(2, 8)]) + 3

km = KModes(n_clusters=optimal_cluster, n_init=10)
km.fit(dataset_df)

for i in range(optimal_cluster):
    cluster = dataset_df.iloc[km.labels_ == 0]
    print(f'cluster {i}')
    print(cluster)
    print('-' * 10)
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                            88. Ders - 21/12/2024 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    K-Prototypes yöntemi hem sayısal hem de kategorik sütunlara sahip olan veri kümeleri için tercih edilen kümeleme yöntemlerinden 
    biridir. Biz daha önce bu tür karma (mixed) veri kümeleri için K-Means yönteminin de kullanılabileceğini belirtmiştik. 
    Ancak K-Means yöntemi uygulanmadan önce kategorik sütunların one-hot-encoding gibi bir yolla sayısallaştırılması gerekiyordu. 
    One-hot-encoding yoluyla sayısallaştırmanın bazı dezavantajlarından da bahsetmiştik. 

    K-Prototypes yönteminde önce sayısal sütunlarla kategorik sütunlar birbirlerinden ayrıştırılır. Ağırlık merkezi sayısal 
    sütunların ortalaması, kategorik sütunların ise mod'ları elde edilerek oluşturulur. Örneğin aşağıdaki gibi bir karma veri 
    kümesi söz konusu olsun:

    Yaş    Gelir (Bin TL)   Eğitim Süresi    Cinsiyet    Şehir
    ---------------------------------------------------------------------
    25      45.3             5                Kadın       İstanbul
    34      52.1            12                Erkek       Ankara
    29      63.5             8                Kadın       İzmir
    41      58.7            15                Erkek       İstanbul
    23      49.4             4                Kadın       Antalya
    37      54.8            10                Erkek       İstanbul
    30      61.3             9                Kadın       İzmir
    28      57.9             7                Erkek       Ankara
    26      50.2             6                Kadın       Antalya
    35      62.4            11                Erkek        İzmir

    Buradaki Yaş, Gelir ve Eğitim Süresi sütunları sayısal, Cinsiyet ve Şehir sütunları ise kategorik bilgiler içermektedir. 
    Şimdi kümeleme işlemi sırasında oluşturulan bir kümenin noktalarının aşağıdaki gibi olduğunu varsayalım:

    37      54.8            10              Erkek       İstanbul
    26      50.2             6              Kadın       Antalya
    29      63.5             8              Kadın       İzmir
    41      58.7            15              Erkek       İstanbul
    35      62.4            11              Erkek       İzmir
    
    Bu noktaların ağırlık merkezleri oluşturulurken sayısal sütunların ortalamaları, kategorik sütunların ise modları elde 
    edilmektedir. Böylece aşağıdaki gibi bir ağırlık merkezi oluşacaktır:

    33.6    57.92           10              Erkek       İstanbul

    Bu biçimde elde edilen ağırlık merkezine "prototip (prototype)" de denilmektedir.

    K-Prototypes algoritmasında da yine başlangıçta küme sayısı kadar rastgele ağırlık merkezleri elde edilir. (Bu noktalar 
    genellikle var olan noktalardan seçilmektedir.) Sonra her noktanın bu ağırlık merkezlerine uzaklığı hesaplanır. Sonra 
    yine noktalar kendilerine en yakın ağırlık merkezlerine ilişkin kümelere atanır. Pekiyi K-Prototypes yönteminde iki 
    nokta arasındaki uzaklık nasıl hesaplanmaktadır? Örneğin aşağıdaki gibi iki nokta arasındaki uzaklık nasıl hesaplanacak 
    olsun:

    30          61.3             9        Kadın     İzmir
    33.6        57.92           10        Erkek     İstanbul

   Eğer sütunların hepsi sayısal olsaydı biz Öklit uzaklığını kullanırdık. Sütunların hepsi kategorik olsaydı bu durumda da
   Hamming uzaklığını kullanırdık. Ancak burada bazı sütunları nümerik olan bazı sütunları kategorik olan bir veri kümesi
   söz konusudur. İşte bu tür karma sütunların bulunduğu durumlarda iki nokta arasındaki uzaklık da karma bir biçimde yani 
   nümerik uzaklıklarla kategorik uzaklıkların toplamı biçiminde hesaplanmaktadır. Hesaplama tipik olarak şöyle yapılmaktadır:

   Uzaklık = Nümerik sütunların uzaklığı + gamma * kategorik sütunların uzaklığı

   Sayısal sütunların uzaklığı için Öklit uzaklığı, kategorik sütunların uzaklığı için Hamming uzaklığı kullanılabilir. Buradaki
   "gamma" deneme yanılma yoluyla ya da bazı sezgisel yaklaşımlarla belirlenecek olan iki tür sütunun uyumlandırılmasını sağlayan 
   çarpansal bir değerdir. Tabii bu uzaklık hesabı yapılmadan önce sayısal sütunlar özellik ölçeklemesine sokulmalıdır. Ölçekleme 
   için standart ölçekleme ya da min-max ölçeklemesi kullanılabilir. 
   
   Pekiyi yukarıdaki uzaklık hesabında gamma çarpanının deneme yanıl deneme yanılma yoluyla nasıl tespit edilebilir? Bunun için 
   çeşitli gamma değerleriyle kümeleme yapılıp bunlar arasından en iyi kümelemeye lişkin gamma değeri seçilebilir. Ancak gamma 
   değerinin deneme yanılma yöntemi kullanılmadan seçilmesine yönelik deb çeşitli yaklaşımlar bulunmaktadır. Bu yaklaşımların 
   bazıları gamma değerini sayısal sütunların standart sapmalarının ortalamalarına dayalı olarak belirlemektedir. Örneğin "kmodes" 
   kütüphanesindeki KPrototypes sınıfında gamma değeri programcı tarafından belirtilmediyse default olarak aşağıdaki gibi elde 
   edilmektedir:

    gamma = 0.5 * np.mean(Xnum.std(axis=0))

    Burada Xnum nümerik sütunları belirtmektedir. Burada gamma değeri sayısal sütunların standart sapmalarının ortalamasının 
    yarısı biçiminde elde edilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    K-Prototypes yöntemi scikit-learn içerisinde gerçekleştirilmemiştir. Ancak bu yöntemin "kmodes" kütüphanesinde ve "pyclustering" 
    kütüphanelerinde gerçekleştirimi bulunmaktadır. Biz burada scikit-learn kütüphanesine benzer bir kullanıma sahip olduğu 
    için "kmodes" kütüphanesindeki gerçekleştirim için bir örnek vereceğiz. 

    "kmodes" kütüphanesindeki KPrototypes sınıfı öyle kullanılmaktadır:

    1) Önce veri kümesindeki sayısal ve kategorik sütunlar belirlenir. 

    2) Nümerik sütunlar özellik ölçeklemesine sokulur.

    3) Kategorik sütunlar LabelEncoder sınıfı ile sayısallaştırılır. 

    Bu işlemler sonucunda dataset isimli bir NumPy dizisinin elde edildiğini varsayalım. 

    4) Şimdi KPrototypes nesnesi oluşturulur. Örneğin:

    kp = KPrototypes(n_clusters=5)

    5) fit işlemi yapılır. fit işleminde tüm veri kümesi ve kategorik sütunların indeksleri categorical paraetresiyle metoda 
    verilir. Örneğin:

    kp.fit(dataset, categorical=[0, 1, 3, 5, 6])

    Artık sınıfın labels_ örnek özniteliğinden hangi satırların hangi kümeye atandığı bilgisini elde edebiliriz. Yine nesnenin
    cluster_centroids_ özniteliğinden kümelerin ağırlık merkezleri elde edilebilmektedir.  

    Aşağıda KPrototypes sınıfının kullanımına ilişkin bir örnek verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

NCLUSTERS = 5

import pandas as pd

df = pd.read_csv('segmentation data.csv')
df.drop(labels=['ID'], axis=1, inplace=True)

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
df[['Age', 'Income']] = ss.fit_transform(df[['Age', 'Income']])

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()

for column in ['Sex', 'Marital status', 'Education', 'Occupation', 'Settlement size']:
    df[column] = le.fit_transform(df[column])
    
dataset = df.to_numpy()

from kmodes.kprototypes import KPrototypes

kp = KPrototypes(n_clusters=NCLUSTERS)

kp.fit(dataset, categorical=[0, 1, 3, 5, 6])

for i in range(NCLUSTERS):
    print(f'{i}. Cluster points', end='\n\n')
    print(df.iloc[kp.labels_ == i, :])
    print('-' * 20, end='\n\n')

#----------------------------------------------------------------------------------------------------------------------------
                                            89. Ders - 22/12/2024 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    MiniBatchKMeans kullanımına ilişkin bir örnek yapılmıştır. Bu örnek yukarıya eklenmiştir.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de MNIST veri kümesine K-Means yöntemini uygulayalım. Bunu şöyle bir problemi çözmek için yapıyor olabiliriz: Birisi 
    bize 28x28'lik binlerce resim versin. Bu resimleri veren kişi bu resimlerin 10 farklı nesneye ilişkin olduğunu bize 
    söylesin. Resimleri veren kişinin amacı bunların otomatik bir biçimde ayrıştırılmasını sağlamak olsun. Biz de K-Means 
    yöntemiyle bunu yapmaya çalışalım.

    Bilindiği gibi aslında resimler pixellerden pixeller de sayılardan oluşmaktadır. MNIST resimlerinin "gri tonlamalı (gray 
    scale) olduğunu anımsayınız. (Yani resimlerdeki her pixel 1 byte'lık bir sayı ile temsil edilmektedir.) O halde resimler 
    toplamda 28 * 28 = 784 tane nümerik sütundan oluşan noktalar gibi ele alınabilir. 
#----------------------------------------------------------------------------------------------------------------------------

NCLUSTERS = 10

from tensorflow.keras.datasets import mnist

(training_dataset_x, training_dataset_y), (test_dataset_x, test_dataset_y) = mnist.load_data()

scaled_training_dataset_x  = training_dataset_x.reshape(-1, 28 * 28) / 255
scaled_test_dataset_x  = test_dataset_x.reshape(-1, 28 * 28) / 255

from sklearn.cluster import KMeans

km = KMeans(n_clusters=NCLUSTERS, n_init=10)
km.fit(scaled_training_dataset_x)

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
transformed_dataset_x = pca.fit_transform(scaled_training_dataset_x)

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.title('Clustered Points')
for i in range(NCLUSTERS):
    plt.scatter(transformed_dataset_x[km.labels_ == i, 0], transformed_dataset_x[km.labels_ == i, 1])
plt.show()

# etiketlendirmenin örnek sonuçları

import matplotlib.pyplot as plt

for cluster_no in range(10):
    plt.figure(figsize=(6, 10))
    print(f'Cluster No: {cluster_no}')
    for i, picture in enumerate(training_dataset_x[km.labels_ == cluster_no][:50]):
        plt.subplot(13, 5, i + 1)
        plt.imshow(picture, cmap='gray')
    plt.show()
    print('-' * 30)
    
#----------------------------------------------------------------------------------------------------------------------------
    K-Means yöntemi uç değerlerden oldukça etkilenmektedir. Bu nedenle uygulamacının verilerdeki uç değerleri (outliers) 
    temizlemesi uygun olur. İzleyen paragraflarda uç değerlerden daha az etkilenecek yöntemler göreceğiz. K-Means algoritma 
    karmaşıklığı bakımından hızlı bir yöntemdir. K-Means yönteöminin yalnızca Öklit uzaklığını kullanması da bir dezavantaj 
    olarak değerlendirilebilir. K-Means yönteminde en önemli noktalardan biri başlangıçta kümelerin ağırlık merkezlerinin nasıl 
    seçileceğidir. Ayrıca bu yöntemde uygulamacının küme sayısını işin başında kendisinin tespit etmiş olması gerekmektedir. 
    İşte K-Means yönteminin başlangıçtaki ağırlık merkezlerinin nasıl seçileceğine yönelik birkaç varyasyonu vardır. Bunlardan 
    en fazla tercih edileni "KMeans++" denilen algoritmadır. Zaten scikit-leran kütüphanesindeki KMeans sınıfı default olarak 
    bu yöntemi kullanmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Çok kullanılan diğer bir kümeleme yöntem grubu da "bağlantı temelli (connecivity based)" ya da "hiyerarşik kümeleme 
    (hierarchical clustering)" denilen yöntem grubudur. Bu yöntem grubu kendi içerisinde "agglomerative" ve "divisive" olmak 
    üzere ikiye ayrılmaktadır. Agglomerative algoritmalar "aşağıdan yukarı (bottom-up)", divise algoritmalar ise "yukarıdan 
    aşağıya (top-down)" doğru işlem yapmaktadır. Uygulamada hemen her zaman agglomerative yöntemler tercih edilmektedir. Bu 
    yöntemlere de "agglomerative hiyerarşik kümeleme" denilmektedir. 

    Agglomerative kümeleme algoritması tipik olarak aşağıdaki gibi yürütülmektedir. Toplam n tane nokta olduğunu varsaylım:

    1) Önce her nokta ayrı bir küme gibi ele alınır. 

    2) Tüm noktalarla tüm noktalar arasındaki uzaklık hesaplanır. Bu simetrik bir matris oluşturacaktır. 

    3) En yakın iki nokta tespit edilip bir küme olarak birleştirilir. Artık bu küme tek bir nokta gibi ele alınacaktır. 
    Dolayısıyla artık elimizde n - 1 tane nokta bulunmaktadır. Burada 2. Adıma dönülerek yine tüm noktalarla tüm noktalar 
    arasındaki uzaklıklar hesaplanır. Ancak iki elemanlı küme sanki tek bir nokta gibi değerlendirilecektir. Bu aşamadan 
    sonra yeniden bir birleştirme yapılır. Böylece n - 2 tane nokta elde edilir. İşlemler istenen k tane küme elde edilene 
    kadar devam ettirilir. 

    Algoritmadaki önemli noktalar şunlardır:

    - Noktalar arasındaki uzaklıklar değişik yöntemlerle ölçülebilmektedir. En çok kullanılan uzaklık ölçütü yine Öklit 
    uzaklığıdır.

    - Birden fazla noktadan oluşan küme tek nokta olarak nasıl ele alınmaktadır? Bu durumda bu kümeye olan uzaklık nasıl 
    hesaplanacaktır? İşte burada birkaç hesaplama yöntemi kullanılabilmektedir:

    Min Yöntemi: Kümelerin en yakın elemanları tespit edilip uzaklık bu en yakın elemanlara göre hesaplanır.

    Max Yöntemi: Kümelerin en uzak elemanları tespit edilip uzaklık bu en uzak elemanlara göre hesaplanır.

    Grup Ortalaması Yöntemi: Noktalarla kümenin tüm noktalarının uzaklıkları hesaplanıp ortalama uzaklık elde edilir ve bu 
    ortalama uzaklık dikkate alınır.

    Ward Yöntemi: Noktalarla kümenin tüm noktalarının uzaklıklarının karesi elde edilir ve bu kareli ortalama uzaklık 
    olarak dikkate alınır.

    Uygulamada en fazla "ward yöntemi" denilen yöntem kullanılmaktadır. 

    Agglomerative hiyerarşik kümelemede hangi noktaların ve kümelerin hangi nokta ve kümelerle birleştirildiğine yönelik bir 
    ağaç grafiği çizilebilmektedir. Buna "dendrogram" denilmektedir. 

    Agglomaerative hiyerarşik kümelemede her kümeleme işleminde aynı kümeler elde edilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Agglomerative hiyerarşik kümeleme algoritmasının gerçekleştirilmesi zor değildir. Tüm noktaların diğer noktalara uzaklığı 
    iç içe iki döngü ile hesaplanabilir. Tabii algoritmada kümeleri daraltan dış bir döngü de bulunmak zorundadır. Bu durumda
    algoritma karmaşıklığı O(n^3) halline gelebilmektedir. Algoritmada ek birtakım önlemler alınarak algoritima O(n^2) karmaşıklığına 
    yaklaştırılabilmektedir. 

    Aşağıda ChatGPT ile üretilen (ancak prompt'larla yönlendirme de yapılmıştır) agglomerative hiyearşik kümeleme algoritmasına
    bir örnek verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np

def euclidean_distance(a, b):
    """
    Compute the Euclidean distance between two points a and b.
    """
    return np.sqrt(np.sum((a - b) ** 2))

def calculate_pairwise_distances(X):
    """
    Calculate the pairwise Euclidean distance between all data points.
    
    Parameters:
    X : ndarray of shape (n_samples, n_features)
        The input data points.
        
    Returns:
    distance_matrix : ndarray of shape (n_samples, n_samples)
        A matrix containing pairwise distances.
    """
    n_samples = X.shape[0]
    distance_matrix = np.zeros((n_samples, n_samples))
    
    # Compute the pairwise Euclidean distance between all points
    for i in range(n_samples):
        for j in range(i + 1, n_samples):
            distance = euclidean_distance(X[i], X[j])
            distance_matrix[i, j] = distance
            distance_matrix[j, i] = distance
    
    return distance_matrix

def update_distances(distance_matrix, clusters, new_cluster_index):
    """
    Update the distance matrix after merging two clusters.
    
    Parameters:
    distance_matrix : ndarray of shape (n_samples, n_samples)
        The distance matrix.
    
    clusters : dict
        A dictionary of clusters with cluster ids as keys and lists of data points as values.
        
    new_cluster_index : int
        The index of the newly formed cluster.
    
    Returns:
    distance_matrix : ndarray
        Updated distance matrix.
    """
    # Remove the distances related to the merged cluster
    distance_matrix = np.delete(distance_matrix, new_cluster_index, axis=0)
    distance_matrix = np.delete(distance_matrix, new_cluster_index, axis=1)
    
    # Recalculate the distances for the new merged cluster
    new_distances = []
    for cluster_id in clusters:
        if cluster_id != new_cluster_index:
            # Calculate the average linkage: distance between clusters by average
            dist = np.mean([distance_matrix[idx1, idx2] for idx1 in clusters[cluster_id] for idx2 in clusters[new_cluster_index]])
            new_distances.append(dist)
    
    # Add the new distances to the distance matrix
    new_row = np.array(new_distances)
    distance_matrix = np.vstack([distance_matrix, new_row])
    new_col = np.append(new_row, 0).reshape(-1, 1)
    distance_matrix = np.hstack([distance_matrix, new_col])
    
    return distance_matrix

def agglomerative_hierarchical_clustering(X, n_clusters=2):
    """
    Perform Agglomerative Hierarchical Clustering using average linkage.
    
    Parameters:
    X : ndarray of shape (n_samples, n_features)
        The input data points.
    
    n_clusters : int
        The number of clusters to form.
        
    Returns:
    labels : ndarray of shape (n_samples,)
        Cluster labels for each data point.
    """
    # Step 1: Calculate the pairwise distance matrix
    distance_matrix = calculate_pairwise_distances(X)
    
    # Step 2: Initialize each point as its own cluster
    clusters = {i: [i] for i in range(X.shape[0])}  # Use a dictionary for clusters
    
    # Step 3: Merge clusters until the number of clusters equals n_clusters
    while len(clusters) > n_clusters:
        # Step 3.1: Find the closest pair of clusters (minimum distance)
        min_dist = np.inf
        cluster_pair = None
        
        for i in clusters:
            for j in clusters:
                if i < j:  # To avoid checking the same pair twice
                    # Calculate distance between clusters using average linkage
                    dist = np.mean([distance_matrix[idx1, idx2] for idx1 in clusters[i] for idx2 in clusters[j]])
                    
                    # Update the minimum distance and the pair of clusters
                    if dist < min_dist:
                        min_dist = dist
                        cluster_pair = (i, j)
        
        # Step 3.2: Merge the two closest clusters
        i, j = cluster_pair
        # Merge clusters by updating the dictionary
        clusters[i] = clusters[i] + clusters[j]  # Merge clusters
        del clusters[j]  # Remove the merged cluster
        
        # Step 3.3: Update the distance matrix after merging the clusters
        distance_matrix = update_distances(distance_matrix, clusters, j)
    
    # Step 4: Assign labels to data points based on final clusters
    labels = np.zeros(X.shape[0])
    for cluster_id, cluster in clusters.items():
        for idx in cluster:
            labels[idx] = cluster_id
    
    return labels

# Example usage
np.random.seed(42)
X = np.random.rand(10, 2)  # 10 data points with 2 features

# Perform Agglomerative Hierarchical Clustering with average linkage
labels = agglomerative_hierarchical_clustering(X, n_clusters=3)

# Print the resulting cluster labels
print("Cluster labels:", labels)

#----------------------------------------------------------------------------------------------------------------------------
    Agglomerative hiyerarşik kümeleme işlemleri için scikit-learn kütüphanesinde AgglomerativeClustering isimli bir sınıf 
    bulundurulmuştur. Sınıfın __init__ metodunun parametrik yapısı şöyledir:

    class sklearn.cluster.AgglomerativeClustering(n_clusters=2, *, metric='euclidean', memory=None, connectivity=None, 
            compute_full_tree='auto', linkage='ward', distance_threshold=None, compute_distances=False)

    Metodun n_clusters parametresi oluşturulacak nihai küme sayısını belirtmektedir. affinity parametresi kaldırılmış bunun 
    yerine "metric" parametresi kullanılmaya başlanmıştır. (Yani bu anlamda terminolojide bir değişiklik yapılmıştır.) Eğer 
    sklearn veriyonunuz 1.4'ten geri ise metric yerine affinity parametresini kullanınız. metrik parametresi uzaklık hesaplama 
    yöntemini belirtmektedir. Bu parametrenin default değerinin "euclidean" olduğunu görüyorsunuz. linkage parametresi kümeye 
    ilişkin noktaların temsil edildiği noktanın nasıl belirleneceğini belirlemek için kullanılmaktadır. Yani bu parametre eğer 
    bir küme birden fazla nokta içeriyorsa bu kümenin tek nokta gibi ele alınabilmesi için hangi hesaplama yönteminin kullanılacağını 
    belirtmektedir. Bu parametreye şu değerlerden biri girilebilir: "ward", "average", "complete (ya da maximum)", ve "single". 
    Bu parametrenin default değeri "ward" biçimindedir. Bu durum kümenin tüm noktalarına uzaklıklarının karelerinin ortalaması 
    yönteminin kullanılacağını belirtir. "average" grup ortalaması anlamına, "complete ya da maximum" maksimum uzaklık anlamına 
    "single" ise minimum uzaklık anlamına gelir. Metodun compute_distances parametresi default durumda False biçimdedir. eğer 
    bu parametre True geçilirse bu durumda fit işlemi sonrasında nesnede noktaların uzaklığına ilişkin bilgi veren distances_ 
    özniteliği oluşturulmaktadır. Metodun diğer parametrelerini dokümanlardan inceleyebilirsiniz.

    AgglomerativeClustering nesnesi yaratıldıktan sonra yine sınıfın fit metoduyla işlemler yapılır. Yani kümeleme işlemini 
    asıl yapan metot fit metodudur. fit işleminden sonra sonuçlar nesnenin özniteliklerinden alınabilir. Nesnenin özniteliklerleri 
    şunlardır:

    n_clusters_: Elde edilen küme sayısını belirtmektedir. Tabii küme sayısını aslında biz vermekteyiz. Ancak __init__ metodunun 
    distance_threshold isimli parametresi için bir değer girilirse bu durumda bu eşik uzaklığının ötesinde kümeleme yapılmamaktadır. 
    Eğer distance_threshold parametresi girilirse bu durumda __init__ metodunun birinci parametresi None girilmelidir. Çünkü 
    küme sayısı artık bu şik uzaklığa bağlı olarak hesaplanacktır. Eğer distance_threshold için bir değer girilirse aynı zamanda 
    __init__ metodunun compute_full_tree parametresi True girilmek zorundadır. 

    labels_: Tıpkı KMenas sınıfında olduğu gibi noktaların sırasıyla hangi kümeler içerisinde yer aldığını blirten bir NumPy 
    dizisidir. 

    n_features_in_: fit işlemine sokulan veri kümesindeki sütun sayısını belirtmektedir. 

    distances_: Eğer nesne yaratılırken compute_distances parametresi True geçilmişse bu örnek özniteliği oluşturulur. Bu durumda 
    bu elemanda uzaklık değerleri bulunur. Bu uzaklık değerleri dendrogram çizerken kullanılabilmektedir. 

    Aşağıdaki örnekte daha önce üzerinde çalıştığımız "points.csv" noktaları bu kez AgglomerativeClustering sınıfıyla kümelenmiştir. 
    Buradaki "points.csv" dosyasının içeriği şöyledir:

    7,8
    2,4
    6,4
    3,2
    6,5
    5,7
    3,3
    1,4
    5,4
    7,7
    7,6
    2,1
#----------------------------------------------------------------------------------------------------------------------------

NCLUSTERS = 3

import pandas as pd

df = pd.read_csv('points.csv')

dataset = df.to_numpy(dtype='float32')

from sklearn.cluster import AgglomerativeClustering

ac = AgglomerativeClustering(n_clusters=NCLUSTERS, linkage='ward', compute_distances=True)

ac.fit(dataset)

df['Cluster'] = ac.labels_

import matplotlib.pyplot as plt

for i in range(NCLUSTERS):
    plt.scatter(dataset[ac.labels_ == i, 0], dataset[ac.labels_ == i, 1])
    
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
                                            91. Ders - 05/01/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de agglomerative hiyerarşik kümeleme yöntemini "zambak (iris) veri kümesine" uygulayalım. Buradan elde edilen 
    sonuçları K-Means kümelemesinden elde edilen sonuçlarla kaşılaştırdığımızda birbirne benzediğini ancak birkaç noktanın 
    farklı kümelendiğini görmekteyiz. 
#----------------------------------------------------------------------------------------------------------------------------

NCLUSTERS = 3

import pandas as pd

df = pd.read_csv('iris.csv')
dataset = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset)
transformed_dataset = ss.transform(dataset)

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
pca.fit(dataset)
reduced_dataset = pca.transform(dataset)

from sklearn.cluster import AgglomerativeClustering

ac = AgglomerativeClustering(n_clusters=NCLUSTERS)
ac.fit(transformed_dataset)

import matplotlib.pyplot as plt

plt.title('Agglomerative Clustered Points', fontsize=12)
for i in range(NCLUSTERS):
    plt.scatter(reduced_dataset[ac.labels_ == i, 0], reduced_dataset[ac.labels_ == i, 1])     
plt.show()

from sklearn.cluster import KMeans

km = KMeans(n_clusters=NCLUSTERS, n_init=10)
km.fit(transformed_dataset)

transformed_centroids = ss.inverse_transform(km.cluster_centers_)
reduced_centroids = pca.transform(transformed_centroids)

plt.title('K-Means Clustered Points', fontsize=12)
for i in range(NCLUSTERS):
    plt.scatter(reduced_dataset[km.labels_ == i, 0], reduced_dataset[km.labels_ == i, 1])    
plt.scatter(reduced_centroids[:, 0], reduced_centroids[:, 1], color='red', marker='s')    
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    KMeans sınıfında bir predict metodu vardı. Bu metot mevcut ağırlık merkezlerini dikkate alarak noktanın hangi ağırlık 
    merkezine yakın olduğunu hesaplayıp noktanın sınıfını ona göre belirliyordu. Ancak AgglomerativeClustering sınıfında bir 
    predict metodu yoktur. Çünkü yöntemde bir ağırlık mekezi olmadığı için kestirimi yapılacak noktanın neye göre kestiriminin 
    yapılacağı belli değildir. Kümeleme işlemi bütün noktalar temelinde yapılmaktadır. Gerçi sınıfın fit_predict isimli bir 
    metodu vardır. Ancak bu metot önce fit işlemi yapıp sonra labels_ örnek özniteliği ile geri dönmektedir. Başka bir deyişle:
    
    result = ac.fit_predict(dataset) 

    işlemi ile aşağıdaki işlem eşdeğerdir:

    ac.fit(dataset)
    result = ac.labels_

    Aşağıda fit_predict metodunun kullanımına bir örnek verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

NCLUSTERS = 3

import pandas as pd

df = pd.read_csv('points.csv')

dataset = df.to_numpy(dtype='float32')

from sklearn.cluster import AgglomerativeClustering

ac = AgglomerativeClustering(n_clusters=NCLUSTERS, linkage='ward', compute_distances=True)

ac.fit(dataset)

df['Cluster'] = ac.labels_

import matplotlib.pyplot as plt

for i in range(NCLUSTERS):
    plt.scatter(dataset[ac.labels_ == i, 0], dataset[ac.labels_ == i, 1])
    
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    scikit-learn içerisinde kümeleme ve sınıflandırma işlemleri için rastgele veri üreten bazı fonksiyonlar da oluşturulmuştur. 
    Bunlar sklearn.datasets modülü içerisindedir. make_blobs fonksiyonu belli merkezlerden hareketle onun çevresinde rastgele 
    noktalar üretmektedir. Fonksiyonun parametrik yapısı şöyledir:

    sklearn.datasets.make_blobs(n_samples=100, n_features=2, *, centers=None, cluster_std=1.0, center_box=(-10.0, 10.0), 
            shuffle=True, random_state=None, return_centers=False)

    Buradaki n_samples parametresi üretilecek noktaların sayısını,  n_features parametresi üretilecek rastgele verilerin kaç 
    sütundan oluşacağını belirtmektedir. (Başka bir deyişle n_features kaç boyutlu uzay için nokta üretileceğini belirtmektedir.) 
    centers parametresi etiket sayısını belirtir. Yani toplam kaç merkezden hareketle rastgele noktalar üretilecektir? cluster_std 
    parametresi rastgele noktaların küme içerisinde birbirinden uzaklığını ayarlamakta kullanılır. Bu değer küçültülürse noktalar 
    kendi merkezlerine daha yakın, büyütülürse kendi merkezlerinden daha uzak olabilecek biçimde üretilmektedir. center_box 
    parametresi ikili bir demet almaktadır. Rastgele üretilecek değerlerin aralığını belirtir. Default değerler -10 ile +10 
    arasındadır. random_state parametresi rassal sayı üreticisi için tohum değeri belirtmektedir. Bu parametreye spesifik bir 
    değer girilirse hep aynı noktalar elde edilir. Bu parametreye değer girilmezse programın her çalışmasında farklı noktalar 
    elde edilecektir.

    Fonksiyon bize normal olarak iki elemanlı NumPy dizilerinden oluşan bir demet vermektedir. Bu demetin birinci elemanı 
    üretilmiş olan rastgele noktaları, ikinci elemanı ise onların sınıflarını belirtmektedir. Eğer fonksiyonda return_centers 
    parametresi True girilirse bu durumda fonksiyon üçlü bir demete geri döner. Demetin üçüncü elemanı kümelere ilişkin merkez 
    noktalarını belirtir. 

    Aşağıda make_blobs fonksiyonu ile 3 merkezli (default durumda da zaten 3 merkez alınıyor) rastgele noktalar oluşturulup 
    grafiği çizdirilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

from sklearn.datasets import make_blobs

dataset, labels = make_blobs(100, 3, cluster_std=1, centers=3)

import matplotlib.pyplot as plt

plt.title('make_blobs Sample points')
plt.scatter(dataset[:, 0], dataset[:, 1])
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki make_blobs fonksiyonu ile rastgele noktalar elde edilmiş daha sonra bu noktalar KMeans ve AgglomerativeClustering 
    sınıflarıyla kümelenmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

NCLUSTERS = 3

from sklearn.datasets import make_blobs

dataset, _ = make_blobs(100, 3, cluster_std=1, centers=NCLUSTERS)

from sklearn.cluster import KMeans, AgglomerativeClustering

km = KMeans(NCLUSTERS, n_init=10)
km.fit(dataset)

ac = AgglomerativeClustering(NCLUSTERS)
ac.fit(dataset)

import matplotlib.pyplot as plt

plt.title('Agglomerative Clustering')
for i in range(NCLUSTERS):
    plt.scatter(dataset[ac.labels_ == i, 0], dataset[ac.labels_ == i, 1])
plt.show()

plt.title('K-Means Clustering')
for i in range(NCLUSTERS):
    plt.scatter(dataset[km.labels_ == i, 0], dataset[km.labels_ == i, 1])
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    sklearn.datasets modülünde make_classification isimli benzer bir fonksiyon da bulunmaktadır. Bu fonksiyon özellikle sınıflandırma
    problemleri için rastgele noktalar üretmektedir. Fonksiyonun parametrik yapısı şöyledir:

    sklearn.datasets.make_classification(n_samples=100, n_features=20, *, n_informative=2, n_redundant=2, n_repeated=0, 
            n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, 
            scale=1.0, shuffle=True, random_state=None)

    Fonksiyonun birinci parametresi üretilecek nokta sayısını ikinci parametresi sütun sayısını belirtmektedir. Fonksiyonun 
    n_classes parametresi ise üretilecek noktaların ilişkin olduğu sınıfların sayısını belirtir. Bu parametrenin default değeri
    2'dir. Fonksiyon yine bize ikili bir demet verir. Demetin birinci elemanı rastgele üretilen noktalardan ikinci elemanı ise 
    bunların ilişkin olduğu sınıflardan oluşmaktadır. Fonksiyonun n_informative parametresi default olarak 2'dir. Bu parametrenin 
    anlamı biraz karışıktır. Bunun için  dokümantasyona başvurabilirsiniz. Ancak n_classes parametresi ile n_informative parametresini 
    aynı değere çekerseniz bir oluşmayacaktır.

    make_classification fonksiyonu standart normal dağılma uygun rastgele noktalar üretmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

from sklearn.datasets import make_classification

dataset, labels = make_classification(100, 10, n_classes=4, n_informative=4)

print(dataset)
print(labels)

#----------------------------------------------------------------------------------------------------------------------------
    sklearn.datasets modülü içerisindeki make_circles isimli fonksiyon eliptik tarzda veri üretmek için kullanılmaktadır. 
    Eliptik tarzda veriler birbirlerini çevreleyen tarzda verilerdir. Bunlar özellikle bazı kümeleme algoritmalarını test 
    etmek için kullanılmaktadır. Fonksiyonun parametrik yapısı şöyledir:

    sklearn.datasets.make_circles(n_samples=100, *, shuffle=True, noise=None, random_state=None, factor=0.8)
    
    Fonksiyon her zaman iki sütuna ilişkin (yani kartezyen koordinat sistemi için) nokta üretmektedir. Fonksiyonun birinci 
    parametresi üretilecek noktaların sayısını belirtir. Default durumda fonksiyon iki sınıfa ilişkin eşit sayıda rastgele nokta 
    üretmektedir. Eğer birinci parametre iki elemanlı bir demet olarak girilirse bu durumda 0 ve 1 sınıflarından kaçar tane değer 
    üretileceği de gizlice belirtilmiş olur. Örneğin:

    dataset, labels = make_circles((100, 200))

    Burada 100 tane 0, 200 tane 1 sınıfına ilişkin rastgele nokta üretilecektir. Fonksiyonun factor parametresi iç içe çemberlerin 
    birbirine yakınlığını ayarlamak için kullanılmaktadır. Bu parametre (0, 1) arasında değer alır. 1'ye yaklaşıldıkça çemberler 
    birbirine yaklaşır, 0'a yaklaşıldıkça çemberler birbirinden uzaklaşır. Bu parametrenin default değeri 0.8 biçimindedir. 
    Fonksiyonun noise parametresi çemberlerin düzgünlüğü konusunda etkili olmaktadır. Bu parametre de 0 ile 1 arasında değer 
    alır. Noise değeri Yükseltildikçe gürültü artar yani çemberler çember görünümünden çıkar. Testlerde 0.05 gibi değerleri 
    kullanabilirsiniz.
#----------------------------------------------------------------------------------------------------------------------------

from sklearn.datasets import make_circles

dataset, labels = make_circles(100, factor=0.8, noise=0.05)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
plt.title('Clustered Points')

for i in range(2):
    plt.scatter(dataset[labels == i, 0], dataset[labels == i, 1])    
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Agglomerative hiyerarşik kümelemede sırasıyla hangi noktaların hangi noktalarla birleştirildiğine ilişkin ağaç grafiğine 
    "dendrogram" denilmektedir. scikit-learn kütüphanesinde doğrudan dendrogram çizmek için fonksiyonlar yoktur. Ancak SciPy
    kütüphanesinde scipy.cluster.hierarchy modülü içerisinde bunun için linkage ve dendrogram isimli iki fonksiyon bulunmaktadır. 

    Burada hiyeararşik kümeleme işlemini linkage isimli fonksiyon yapar. Bu fonksiyon bize dendrogram çizmek için Nx4 boyutunda 
    bir matris vermektedir. Fonksiyonun parametrik yapısı şöyledir:

    scipy.cluster.hierarchy.linkage(y, method='single', metric='euclidean', optimal_ordering=False)

    Fonksiyon zorunlu olarak yalnızca bizden dataset verilerini almaktadır. Aşağıdaki "points.csv" verilerini linkage fonksiyonuna 
    sokmuş olalım:

    X1,X2
    7,8
    2,4
    6,4
    3,2
    6,5
    5,7
    3,3
    1,4
    5,4
    7,7
    7,6
    2,1

    Burada toplam 12 tane veri vardır. Şimdi linkage fonksiyonu kullanalım:

    df = pd.read_csv('points.csv')
    dataset = df.to_numpy(dtype='float32')

    from scipy.cluster.hierarchy import linkage

    linkage_data = linkage(dataset)
    print(linkage_data)

    Şöyle bir matris elde edilmiştir:

    [[ 0.          9.         1.          2.        ]
    [10.         12.          1.          3.        ]
    [ 2.          4.          1.          2.        ]
    [ 8.         14.          1.          3.        ]
    [ 3.          6.          1.          2.        ]
    [ 1.          7.          1.          2.        ]
    [13.         15.          1.41421356  6.        ]
    [16.         17.          1.41421356  4.        ]
    [11.         19.          1.41421356  5.        ]
    [ 5.         18.          2.          7.        ]
    [20.         21.          2.23606798 12.        ]]

    Matris her zaman toplam nokta sayısından bir eksik satıra ve 4 sütüna sahiptir. Bu matristeki ilk iki sütun birleştirme 
    bilgilerini belirtmektedir. Nokta sayısı N olmak üzere bu iki stundaki [0, N - 1] arasındaki sayılar asıl noktaları 
    (yaprak düğüm (leaf nodes) de denilmektedir) belirtir. Her birleştirmeye N'den başlanarak sırasıyla numara verilmektedir. 
    Bu örnekte 0 ile 11 arasındaki tüm sayılar asıl noktalara ilişkindir. Her birleştirmeye sırasıyla 12, 13, 14, ... biçiminde 
    numaralar verilecektir. İlk satırdaki 0 ile 9, "0 numaralı satırdaki noktayla 9 numaralı satırdaki noktanın birleştirildiği 
    anlamına gelmektedir. Bu birleşmeden elde edilen kümeye 12 numarası verilir. İkinci satırdaki 10 ve 12 değerleri ise 10 
    numaralı nokta ile 12 numaralı noktanın birleştirileceğini belirtmektedir. 12 numaralı nokta zaten 0 ile 9'un birleşmesinden 
    elde edilen kümedir. O halde burada önce 0 ile 9 birleştirilmiş bir küme elde edilmiş sonra da bu küme ile 10 birleştirilmiştir. 
    Tabii burada elde edilen yeni küme 13 numaralı küme olacaktır. İşlemler bu biçimde devam ettirilmektedir. Matrisin üçüncü 
    sütunu o satırdaki birleştirmenin alınan ölçüte göre uzaklığını son sütun ise oluşturulan o kümedeki nokta sayısını belirtmektedir. 

    Linkage bilgisi elde edildikten sonra dendrogram fonksiyonu asıl dendrogram grafiğini çizmektedir. dendrogram fonksiyonu 
    oldukça fazla sayıda parametreye sahiptir:

    dendrogram(Z, p=30, truncate_mode=None, color_threshold=None, get_leaves=True, orientation='top', labels=None, 
            count_sort=False, distance_sort=False, show_leaf_counts=True, no_plot=False, 
            no_labels=False, leaf_font_size=None, leaf_rotation=None, leaf_label_func=None, 
            show_contracted=False, link_color_func=None, ax=None, above_threshold_color='C0')

    dendrogram fonksiyonu matplotlib kütüphanesi kullanılarak yazılmıştır. Ancak fonksiyon kendi içerisinde show yapmamaktadır. 
    Bu nedenle fonksiyonu çağırdıktan sonra show işlemini yapmalısınız. show işlemi grafiği kapattığı için kütüphaneyi tasarlayanlar 
    show yapmamayı tercih etmiştir. Örneğin:

    import matplotlib.pyplot as plt

    linkage_data= linkage(dataset)
    dendrogram(linkage_data)
    plt.show()  

    Burada zorunlu parametre ilk parametre olan linkage bilgileridir. Biz bu ilk parametreye linkage fonksiyonundan elde 
    ettiğimiz matrisi geçeririz. Fonksiyonun parametreleri için SciPy dokümanlarına başvurulabilir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('points.csv')
dataset = df.to_numpy(dtype='float32')

from scipy.cluster.hierarchy import linkage, dendrogram

linkage_data= linkage(dataset)

plt.title('Points Dendrogram')
dendrogram(linkage_data)
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    K-Means yöntemiyle agglomerative hiyerarşik kümeleme yönteminin temel özelliklerini birbirleriyle karşılaştırdığımızda 
    şunları söyleyebiliriz:

    - K-Means algoritması oldukça etkindir. Algoritmik karmaşıklığı O(n * k) biçimindedir. (Burada n nokta sayısını k ise 
    sınıf sayısını belirtiyor.) Halbuki agglomerative hiyerarşik kümelemede karmaşıklık O(n ** 3) biçimine kadar yükselmektedir. 
    Her ne kadar agglomerative yöntemin SLINK, CLink gibi özelleştirilmiş gerçekleştirimlerinde karmaşıklık O(n ** 2)'ye düşürülüyor 
    olsa da K-Means her zaman agglomerative kümelemeden daha hızlıdır.

    - K-Means yöntemi uç dğerlerden (outliers) oldukça etkilenmektedir. Çünkü bir ağırlık merkezi oluşturulurken küme içerisindeki 
    tüm noktalar dikkate alınmaktadır. Halbuki agglomerative kümeleme yöntemi uç değerlerden etkilenmemektedir. 

    - K-Means yönteminde ilk ağırlık merkezlerinin seçimine göre algoritmanın her çalıştırılmasında farklı kümeler elde 
    edilebilmektedir. Halbuki agglomerative kümelemede her zaman aynı kümeler elde edilir. Çünkü noktaların birbirine uzaklığı
    hiç değişmez.

    - K-Means yönteminde her kümenin bir ağırlık merkezi olduğu için atalet (inertia) hesabı yapılabilmektedir. Halbuki agglomerative
    yöntemde atalet kavramı kullanılmamaktadır. 

    - K-Means yönteminde dendrogram çizilemez. Halbuki agglomerative yöntemde hangi kümenin hangi kümeyle birleştirildiğini 
    belirten bir dendrogram çizilebilmektedir. 

    - K-Means yönteminde ağırlık merkezlerine uzaklıklar minimize edilmeye çalışıldığı için kestirim yapılabilmektedir. (Örneğin 
    KMeans sınıfının bir predict metodu vardır.) Ancak agglomerative yöntemde bu anlamda bir kestirim yapılamamaktadır. 
    AgglomerativeClustering sınıfının bir predict metodunun olmadığını anımsayınız. 

    - K-Means yönteminde küme sayısı işin başında sabit bir biçimde belirlenmiş olmak zorundadır. Halbuki agglomerative 
    yöntemde aslında birleştirme tek küme oluşana kadar devam ettirilebilir. Örneğin bu yöntemde her birleştirmedeki durum 
    kaydedilerek farklı miktarda kümeler için kümeleme tek hamlede yapılabilmektedir. Oysa K-Means yönteminde her küme sayısı 
    için algoritmayı baştan başlatmak gerekir. (Tabii biz agglomerativeCllustering sınıfında yazlnızca son durumdaki kümelemeyi 
    elde etmekteyiz.)

    - K-Means ve agglomerative yöntemin her ikisi de "küresel (spherical) olmayan" veri kümelerinde başarısız olmaktadır. 
    Küresel veri kümesi demekle bir merkez etrafında serpişmiş veriler anlaşılmaktadır. Eliptik tarzda veriler bu anlamda küresel 
    değildir. Dolayısıyla örneğin make_circles gibi fonksiyonlar elde ettiğimiz birbirini kapsayan çembersel verilerde bu iki 
    yöntem de başarız olmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte birbirini kapsayan iki eliptik veri kümesinde K-Means ve agglomerative yöntemlerin başarıları grafiksel 
    ve sayısal olarak gösterilmeye çalışılmıştır. Ancak bu örnekte kümeleme sonucunda elde edilmiş olan verilerin küme numaraları 
    ile gerçek küme numaraları uyuşmayabilir. Bu durumda elde edilen oransal değerler "bazen başarı durumunu" bazen de "başarısızlık" 
    durumunu beelirtir hale gelecektir. Ancak ne olursa olsun bu oranların %50 civarında olduğu görülmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

NCLUSTERS = 2

from sklearn.datasets import make_circles

dataset, labels = make_circles(100, factor=0.8, noise=0.05)

import matplotlib.pyplot as plt

plt.title('Points')
for i in range(2):
    plt.scatter(dataset[labels == i, 0], dataset[labels == i, 1])    
plt.show()

from sklearn.cluster import KMeans

km = KMeans(NCLUSTERS, n_init=10)
km.fit(dataset)

plt.title('K-Means Clustering')
for i in range(NCLUSTERS):
    plt.scatter(dataset[km.labels_ == i, 0], dataset[km.labels_ == i, 1])
plt.show()

from sklearn.cluster import AgglomerativeClustering

ac = AgglomerativeClustering(NCLUSTERS)
ac.fit(dataset)

import matplotlib.pyplot as plt

plt.title('Agglomerative Clustering')
for i in range(NCLUSTERS):
    plt.scatter(dataset[ac.labels_ == i, 0], dataset[ac.labels_ == i, 1])
plt.show()

import numpy as np

kmeans_ratio = np.sum(km.labels_ == labels) / len(labels)
agglomerative_ratio= np.sum(ac.labels_ == labels) / len(labels)

print(f'K-Means ratio: {kmeans_ratio}')
print(f'Agglomerative ratio: {agglomerative_ratio}')

#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                        92. Ders - 11/01/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Kümelemede diğer çok kullanılan yöntem grubundan biri de "yoğunluk tabanlı (density based)" kümeleme yöntemleridir. Yoğunluk 
    tabanlı kümeleme yöntemlerinde "yoğunluk (density)" en önemli unsurdur. Bir bölge yoğunsa onun bir küme belirtmesi olasıdır. 
    Pekiyi yoğunluk nasıl ölçülmektedir? Yoğunluk belli bir küresel alan içerisinde kalan nokta sayısına göre ölçülmektedir. 
    Yöntemde iki parametre başlangıçta uygulamacı tarafından tespit edilir. Bu parametrelere "eps (epsilon)" ve "min_samples" 
    denilmektedir. Eps parametresi küresel bölgenin yarıçapını, min_samples parametresi ise o küresel bölgenin yoğun kabul 
    edilebilmesi için gerekli olan minimum nokta sayısını belirtmektedir. Örneğin eps = 1, min_samples = 10 demek, "eğer 1 
    yarıçaplı küre içerisinde en az 10 nokta varsa o küresel alan yoğun" demektir. Burada biz "küresel (spherical)" terimini 
    kullandık. Aslında söz konusu uzay iki boyutluysa bir daire, üç boyutluysa bir küre çok boyutluysa o uzayın bir küresini 
    kastetmekteyiz. Üç boyuttan daha fazla boyuta sahip uzaylarda küre (sphere) terimi yerine "hiper küre (hypersphere)" 
    terimi kullanılmaktadır. Yani aslında buradaki küresel kavramının genel terimi hiper küresel (hyperspherical) biçimindedir.   
    
    İki boyutlu kartezyen koordinat sisteminde boyutlar x ve y olmak üzere merkezi (a, b) noktasında ve yarıçapı r olan daire 
    denklemi şöyledir:

    (x - a) ** 2 + (y - b) ** 2 = r ** 2

    Üç boyutlu uzay için merkez koordinatı (a, b, c) olan ve boyutları x, y, ve z olan küre denklemi ise şöyledir:

    (x - a) ** 2 + (y - b) ** 2 + (z - c) ** 2= r ** 2

    Yarıçağı r olan ve merkez koordibnatı ci'lerden oluşan N boyutlu uzayın küresinin denklemi de genel olarak şöyle ifade
    edilebilir:

    sigma((xi - ci) ** 2) = r ** 2
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Yoğunluk tabanlı algoritmaların en çok kullanılanı DBSCAN (Density Based Spatial Clustering of Applications with Noise) 
    isimli algoritmadır. Algoritma 1996 yılında geliştirilmiştir. Algoritmanın işleyişi birkaç terimden faydalanılarak 
    açıklanmaktadır. Bu terimler ve anlamları şöyledir:

    - Ana Noktalar (Core Points): Eğer bir nokta merkez kabul edildiğinde onun "eps" yarıçaplı küresinde en az "min_pts" kadar 
    nokta varsa o nokta bir ana noktadır. Bu durumda bir nokta belirlenen "eps" ve "min_samples" değerlerine göre ya ana 
    noktadır ya da değildir. 

    Bir Ana Noktadan Doğrudan Erişilebilen Noktalar (Direct Reachable Points): Bir ana noktanın küresi içerisinde kalan noktalar 
    o ana noktanın doğrudan erişilen noktalarıdır. 

    - Ana Bir Noktanın Yoğunluk Yoluyla Erişilebilen Noktaları (Density Reachable Points): Bir noktanın doğrudan erişilebilen 
    noktalarından biri bir ana nokta ise o ana noktanın da doğrudan erişilebilen noktaları ilk ana noktanın yoğunluk yoluyla 
    erişileben noktaları olur. Yani yoğunluk yoluyla erişilebilen noktalar "arkadaşımım arkadaşı arkadaşımdır" gibi geçili olarak 
    devam etmektedir. Bu geçişlilik yoğunluk yoluyla erişilebilen noktaların uzayabilmesi anlamına gelir. Burada şu duruma dikkat 
    ediniz: Bir ana noktanın yoğunluk yoluyla erişilebilen noktaları içerisindeki tüm ana noktaların yoğunluk yoluyla erişilebilen 
    noktaları aynıdır. Yani başka bir deyişle bir ana noktanın tüm yoğunluk yoluyla erişilebilen noktalarındaki ana noktaların 
    yoğunluk yoluyla erişilebilen noktaları aynıdır. DBSCAN algoritması aslında bir ana noktanın yoğunluk yoluyla erişilebilen 
    noktalarını bir küme olarak ele alır. 
 
    - Bir Ana Noktanın Sınır Noktaları (Border Points): Bir ana noktanın yoğunluk yoluyla erişilebilen fakat ana nokta olmayan 
    noktaları o ana noktanın sınır noktalarıdır. Sınır noktalar ana nokta olmadığı için alanı genişletememektedir. Yani yoğunluk 
    geçişli olarak o noktalardan öteye geçememektedir. 

    - Gürültü Noktaları (Noise Points): Bir nokta hiçbir ana noktanın yoğunluk yoluyla erişilebilen noktası durumunda değilse o 
    noktaya "gürültü noktası" denilmektedir. Gürültü noktaları aslında yoğun bölgelerden kopuk olarak genellikle izole biçimde 
    bulunan noktalardır. 

    Bu durumda algoritma şöyle işletilir:

    1) Önce "Kalan Noktalar Kümesi", "Gürültü Noktaları Kümesi" biçiminde iki küme oluşturulur. İşin başında tüm noktalar "Kalan 
    Noktalar Kümesine" yerleştirilir. Gürültü Noktaları Kümesi Boştur. 

    2) Kalan Noktalar Kümesinden rastgele bir nokta alınır. Eğer o nokta bir ana nokta değilse o nokta Kalan Noktalar Kümesinden 
    çıkartılıp Gürültü Noktaları Kümesine yerleştirilir. Eğer alınan nokta bir ana nokta ise o noktanın yoğunluk yoluyla erişilebilen 
    tüm noktaları elde edilir. Bu noktalar Kalan Noktalar Kümesinden çıkartılır ve bir küme yaratlırak o kümeye dahil edilir. 
    Tabii başta Gürültü Noktaları Kümesine girmiş olan bir nokta sonra bir kümeye dahil edilebilmektedir. 

    3) Yeniden 2. Adıma dönülür. Algoritma Kalan Noktalar Kalan Noktalar Kümesinde nokta kalmayana kadar devam ettirilir. Bu 
    işlemlerin sonucunda K tane küme ve bir de Gürültü Noktaları Kümesi elde edilmiş olur. 

    Algoritmadaki önemli noktalar şunlardır:

    - Bu algoritmada yoğunluk yoluyla erişilebilen noktalar bir küme olarak elde edilmektedir. 

    - Kümeler arasında yoğun bir bölge oluşturmayan noktalar bulunuyor olabilir. Bu noktalar gürültü noktaları haline gelmektedir. 
    Bu durumu şöyle bir örnekle açıklayabiliriz. Uzayda yoğun yıldızların olduğu bölgelere "galaksi" denilmektedir. İki galaksi 
    arasında yine tek tük yıldızlar olabilir. İşte bu yıldızlar hiçbir galaksiye dahil olmayan gürültü noktalarıdır. 

    - Bu algoritmada biz algoritmaya yalnızca eps (yarıçap) ve min_samples değerlerini veririz. Küme sayısını biz vermeyiz. 
    Küme sayısı bu değerlerden hareketle algoritma tarafından belirlenecektir. 

    - Bu algoritmada iki hyper parametre vardır: eps ve min_samples. Bu değerlerin farklı seçimleri farklı kümelerin oluşturulmasına 
    yol açacaktır. 

    - eps ve min_samples parametresi sabit kalmak üzere algoritmanın her çalıştırılmasından yine aynı kümeler elde edilmeketdir. 
    
    - Algortimada yine bir uzaklık hesaplama yöntemi (yani metrik) söz konsudur. Yine tipik olarak Öklit uzaklığı kullanılmaktadır. 

    - DBSCAN algoritmasında bir kestirim olanağı yoktur. 

    - DBSCAN algortimasında da bir uzaklık hesabı söz konusu olduğu için farklı skalalara ship veri kümelerinde özellik 
    ölçeklemesi yapılmalıdır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıda ChatGPT'nin bedava versiyonu tarafından yazılan bir DBSCAN gerçekleştirimini veriyoruz. Bu gerçekleştirimi 
    incelediğinizde yukarıdaki algoritmanın uygulandığını göreceksiniz. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
from collections import deque

def dbscan(data, eps=0.5, min_samples=5):
    """
    DBSCAN kümeleme algoritmasının sıfırdan implementasyonu.
    
    Parametreler:
    data: numpy array, veri seti (n, m) boyutunda, n: örnek sayısı, m: özellik sayısı
    eps: float, iki nokta arasındaki maksimum mesafe. Kümeleme için eşik değeri.
    min_samples: int, bir küme için minimum örnek sayısı.
    
    Döndürülenler:
    - labels: numpy array, her veri noktasının küme etiketi.
      - -1 değeri gürültü noktalarını belirtir.
    """
    
    # Veri setinin boyutları
    n_points = data.shape[0]
    
    # Etiketler, -1 gürültü anlamına gelir.
    labels = -np.ones(n_points)
    
    # Ziyaret edilen noktaları takip etmek için bir liste
    visited = np.zeros(n_points, dtype=bool)
    
    # Komşuları hesaplamak için bir yardımcı fonksiyon
    def region_query(point_idx):
        """
        Belirli bir noktaya yakın olan noktaların indekslerini döndürür.
        """
        neighbors = []
        for i in range(n_points):
            if np.linalg.norm(data[point_idx] - data[i]) <= eps:
                neighbors.append(i)
        return neighbors
    
    # Küme numarasını izlemek için bir sayaç
    cluster_id = 0
    
    # DBSCAN algoritması
    for i in range(n_points):
        if visited[i]:
            continue
        
        # Noktayı ziyaret et
        visited[i] = True
        
        # Komşuları bul
        neighbors = region_query(i)
        
        # Yeterli komşuya sahip değilse, bu nokta gürültü olarak işaretlenir
        if len(neighbors) < min_samples:
            labels[i] = -1
        else:
            # Yeni bir küme başlat
            labels[i] = cluster_id
            cluster_id += 1
            
            # Komşuları işle
            queue = deque(neighbors)
            while queue:
                current_point = queue.popleft()
                
                if not visited[current_point]:
                    visited[current_point] = True
                    current_neighbors = region_query(current_point)
                    
                    # Eğer yeterli komşu varsa, komşuları kuyruğa ekle
                    if len(current_neighbors) >= min_samples:
                        queue.extend(current_neighbors)
                
                # Komşu zaten başka bir kümeye ait değilse, onu mevcut kümeye dahil et
                if labels[current_point] == -1:
                    labels[current_point] = labels[i]
    
    return labels

#----------------------------------------------------------------------------------------------------------------------------
    DBSCAN algoritması için sklearn.cluster modülündeki DBSCAN isimli sınıf bulundurulmuştur. Sınıfın __init__ metodunun 
    parametrik yapısı şöyledir:

    class sklearn.cluster.DBSCAN(eps=0.5, *, min_samples=5, metric='euclidean', metric_params=None, algorithm='auto', 
            leaf_size=30, p=None, n_jobs=None)[source]

    Metodun ilk parametresi yarıçap belirten eps parametresidir. Bu parametrenin default değerinin 0.5 olduğunu görüyorsunuz. 
    Özellik ölçeklemesinden sonra bu 0.5 değeri denemerl için uygun bir değerdir. İkinci parametre olan min_samples bir noktanın 
    ana nokta olması için gereken minimum nokta sayısını belirtmektedir. metric parametresi uzaklık ölçütü için kullanılacak 
    yöntemi belirtir. Diğer parametreler için dokümanlara bakabilirsiniz. 

    DBSCAN sınıfı türünden nesne yaratıldıktan sonra yine klasik sklearn işlemleri yapılmaktadır. Kümeleme sınıfın fit metodu 
    ile gerçekleştirilir. fit işlemi sonrasında nesnenin özniteliklerinden kümeleme bilgileri alınabilir . Sınıfın örnek 
    öznitelikleri şunlardır:

    labels_: Bu öznitelik hangi noktaların hangi kümeler içerisinde kümelendiğini belirtmektedir. Buradaki -1 değeri gürültü 
    noktası anlamına gelir. 
    
    core_sample_indices_: Ana noktaların veri kümesindeki indeks numalaralarını vermektedir.
    
    components_: Ana noktaların hepsinin bulunduğu NumPy dizisini vermektedir.

    n_features_in_: Veri kümesindeki sütun sayısını vermektedir.   

    DBSCAN algoritmasında uygulamacının eps ve min_samples değerlerini belirlemiş olması gerekmektedir. Eğer bu değerler geniş 
    belirlenirse küme sayısı azalır, dar belirlenirse küme sayısı artar. Pekiyi uygulamacı bu değerleri nasıl belirlemelidir? 
    Aslında bu konuda pratik şeyler söylemek o kadar kolay değildir. Ancak min_samples değerinin 1 olmaması gerekir. 2 olması 
    da uygun değildir. Buradaki değer için alt limit özellik sayısından bir fazla biçimde seçilebilir. Örneğin iki özellikli 
    (yani kartezyen koordinat sisteminde gösterebileceğimiz) noktalar söz konusu olduğunda bu değerin en az üç olması uygun 
    olur. Örneğin 10 özelliğin (sütunun) söz konusu olduğu bir veri kümesinde min_samples değeri de 11 olabilir. Ancak yüksek 
    min_samples seçimi daha fazla küme oluşmasına yol açacaktır. DBSCAN sınıfındaki default min_samples değerinin 5 olduğuna 
    dikkat ediniz. 5 değeri bir başlangıç için kullanılabilir. Deneme yanılma yöntemiyle bu değer artırılıp azaltılabilir. 
    
    Epsilon değerinin belirlenmesi için "en yakın komuşuğa (nearest neighbours)" yönelik yöntemler önerilmiştir. Ancak bu 
    değerin deneme yanılma yöntemiyle belirlenmesi daha iyi bir sonucun elde edilmesini sağlayacaktır. O halde uygulamacı 
    önce min_samples parametresini belirleyip daha sonra eps parametresiyle oynayarak nihai ayarlamayı yapabilir. 

    Aşağıda örnekte daha önce kullanmış olduğumuz "points.csv" verileri üzerinde DBSCAN algoritmasını uyguluyoruz. Noktalar 
    şunlardır:

    7,8
    2,4
    6,4
    3,2
    6,5
    5,7
    3,3
    1,4
    5,4
    7,7
    7,6
    2,1

    Biz buradaki noktalar için eps=1.5 ve min_samples=3 parametrelerini kullandık. Bu değerler için algoritma iki küme oluşturmuştur. 
    Örneğimizde çizdiğimiz grafikte ayrıca gürültü noktalarını da gösterdik. Siz de örneğimizdek, eps ve min_samples değerlerini 
    değiştirerek elde edilen grafiği gözlemleyebilirsiniz. Örneğin eps=1, min_samples=2 değerleri için dört küme oluşturulmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('points.csv')
dataset = df.to_numpy(dtype='float32')

from sklearn.cluster import DBSCAN

dbs = DBSCAN(eps=1.5, min_samples=3)
dbs.fit(dataset)

nclusters = np.max(dbs.labels_) + 1;
if nclusters == -1:
    nclusters = 0

plt.title('DBSCAN Clustered Points', fontsize=12)
for i in range(nclusters):
    plt.scatter(dataset[dbs.labels_ == i, 0], dataset[dbs.labels_ == i, 1])     
plt.scatter(dataset[dbs.labels_ == -1, 0], dataset[dbs.labels_ == -1, 1], marker='x', color='black')
legends = [f'Cluster-{i}' for i in range(1, nclusters + 1)]
legends.append('Noise Points')
plt.legend(legends)
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de "zambak (iris)" veri kümesini DBSCAN algoritmasıyla kümelere ayıralım. Biz DBSCAN nesnesini eps = 0.5, 
    min_samples = 5 parametresiyle yarattığımızda (yani default değerle yarattığımızda) iki küme oluşmaktadır. Parametrelerde 
    oynamalar yaparak değişik küme sayılarını elde edebiriz. Örneğin eps = 0.45 ve min_samples = 5 parametreleri için üç küme
    oluşmaktadır. Biz aşağıdaki örnekte default değerleri kullandık. Ancak siz bu parametreler üzerinde oynamalar yaparak 
    oluşturulan kümeleri gözlemleyebilirsiniz.
#----------------------------------------------------------------------------------------------------------------------------

NCLUSTERS = 3

import pandas as pd

df = pd.read_csv('iris.csv')
dataset = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset)
transformed_dataset = ss.transform(dataset)

from sklearn.cluster import DBSCAN

dbs = DBSCAN()
dbs.fit(transformed_dataset)

import numpy as np

nclusters = np.max(dbs.labels_) + 1

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
reduced_dataset = pca.fit_transform(dataset)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
plt.title('Clustered Points')

plt.title('DBSCAN Clustered Points', fontsize=12)
for i in range(nclusters):
    plt.scatter(reduced_dataset[dbs.labels_ == i, 0], reduced_dataset[dbs.labels_ == i, 1])     

plt.scatter(reduced_dataset[dbs.labels_ == -1, 0], reduced_dataset[dbs.labels_ == -1, 1], marker='x', color='black')

legends = [f'Cluster-{i}' for i in range(1, nclusters + 1)]
legends.append('Noise Points')
plt.legend(legends, loc='lower right')

plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Bir merkez etrafında yayılmayan (yani küresel olmayan) veri kümelerinde (örneğin iç içe geçmiş elips'ler gibi noktalara 
    sahip) daha önce K-Means ve agglomerative hiyerarşik kümeleme yöntemlerinin iyi çalışmdığını görmüştük. İşte bu tarzdaki 
    veri kümelerinde yoğunluk tabanlı yöntemler iç ve dış elips verilerini iyi bir biçimde kümeleyebilmektedir. 

    Aşağıdaki örnekte iç içe iki eliptik veri kümesi oluşturulup DBSCAN yöntemiyle bunlar kümelendirilmiştir. Bu örnekte biz 
    min_samples değerini default değer olan 5'te tuttuk ve eps 0.35 olarak aldık. 
#----------------------------------------------------------------------------------------------------------------------------

from sklearn.datasets import make_circles

dataset, labels = make_circles(100, factor=0.4, noise=0.06)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
plt.title('Random Points')
for i in range(2):
    plt.scatter(dataset[labels == i, 0], dataset[labels == i, 1])    
plt.show()

from sklearn.cluster import DBSCAN

dbs = DBSCAN(eps=0.35)
dbs.fit(dataset)

import numpy as np

nclusters = np.max(dbs.labels_) + 1

plt.figure(figsize=(10, 8))
plt.title('DBSCAN Clustered Points', fontsize=12)
for i in range(nclusters):
    plt.scatter(dataset[dbs.labels_ == i, 0], dataset[dbs.labels_ == i, 1])     
plt.scatter(dataset[dbs.labels_ == -1, 0], dataset[dbs.labels_ == -1, 1], marker='x', color='black')
legends = [f'Cluster-{i}' for i in range(1, nclusters + 1)]
legends.append('Noise Points')
plt.legend(legends)
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
                                            93. Ders - 12/01/2024 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Diğer bir yoğunluk tabanlı kümeleme algoritması da OPTICS  (Ordering Points To Identify Clustering Structure) denilen 
    algoritmadır. Aslında OPTICS algoritması DBSCAN algoritmasının bir uzantısı gibidir. OPTICS algortimasında bir yoğunluk 
    grafiği elde edilir. Bu yoğunluk grafiğinden hareketle kümeleme yapılır. Dolayısıyla algoritma yalnızca kümeleme işlemi 
    dışında değişik amaçlarla da kullanılabilmektedir. OPTICS algoritmasında iki temel uzaklık kavramı vardır: "Ana uzaklık 
    (core distance)" ve "erişilebilir uzaklık (reachability distance)". Algoritma için öncelikle bu uzaklıkların ne anlama 
    geldiğinin anlaşılması gerekir. Algoritmada yineyarıçap belirten eps ve en az nokta sayısını belirten min_pts değerlerinin 
    girdi olarak verildiğini düşünelim. 
    
    Ana uzaklık (core distance) bir ana nokta için söz konusu olan bir uzaklıktır. Yani eğer bir noktanın eps yarıçapında min_pts 
    kadar nokta varsa bu noktanın bir ana uzaklığı vardır. Ana uzaklık tam olarak min_pts kadar noktayı içine alan uzaklıktır. 
    Örneğin bir ana noktanın eps uzaklığında 10 tane nokta olsun. Ancak min_pts değerinin 3 olduğunu düşünelim. Bu duurmda ana 
    uzaklık bu ana noktanın tam olarak 3 tane noktayı içine alacak yarıçapının uzunluğudur. Yani başka bir deyişle biz bu ana 
    noktanın eps komşuluğunda olan 10 tane noktayı ele alıp bunların bu ana noktadan uzaklıklarını küçükten büyüğe sıraya dizersek
    3'üncü sıradaki uzaklık bu ana noktanın ana uzaklığı olacaktır. Eps değerinin çok büyük seçildiğini düşünelim. Bu durumda 
    tüm noktalar eps komşuluğunda kalacaktır. İşte bu noktaya en yakın min_pts'inci nokta o ana noktanın ana uzaklığıdır. 
    OPTICS algoritmasında tüm ana noktalar için bir ana uzaklık hesaplanabilmektedir. Tabii ana nokta olmayan noktaların ana 
    uzaklığı söz konusu değildir. Eps değerinin çok büyük seçildiği durumda tüm noktaların ana nokta haline geleceğine dikkat 
    ediniz. 

    Bir ana noktanın eps komşuluğundaki tüm noktalarının bir erişilebilir uzaklığı vardır. Ana nokta cp olmak üzere bu ana 
    noktanın eps komuşupundaki nokta da pp olmak üzere bu pp noktasının erişilebilir uzaklığı şöyle hesaplanmaktadır:

    max(cp'nin_ana_uzaklığı, cp_ile_pp'nin_uzaklığı)
    
    Böylece bir ana noktanın eps komşuluğundaki bir naktasının erişilebilir uzaklığı için şu durum söz konusudur:

    - Eğer ana noktadan bu noktaya uzaklık ana noktanın ana uzaklığından düşükse bu noktanın erişebilir uzaklığı ana uzaklık 
    olacaktır.
    - Eğer ana noktadan bu noktaya uzaklık ana noktanın erişilebilir uzaklığından yüksekse bu noktanın erişilebilir uzaklığı
    ana noktanın bu noktaya uzaklığı olacaktır.

    Burada bir noktaya dikkatiniz çekmek istiyoruz. Bir nokta birden fazla ana noktanın eps komşuluğunda bukunuyor olabilir. 
    Bu durumda bu noktanın erişilebilir uzaklığı en küçük erişilebilir uzaklığı olarak ele alınmaktadır. 

    OPTICS algoritmasında yukarıdaki işlemler uygulanıp verilen eps ve min_pts için her noktaya ilişkin bir erişilebilir uzaklık 
    elde edilmektedir. Bu erişilebilirlik uzaklıklarının oluşturduğu grafiğe "erişilebilirlik grafiği" denilmektedir. Algoritmanın
    amacı her noktanın erişilebilirlik uzaklığını tespit etmektir. Kümeleme işlemi noktaların elde edilmiş olan erişilebilirlik 
    uzaklıkları göz önüne alınarak birkaç yöntemle yapılmaktadır. 

    OPTICS algoritmasında eps değerinin çok büyük olduğunu varsayalım. Bu durumda ne olur? İşte bu durumda her nokta bir ana 
    nokta durumuna gelir. Bu duurmda her noktanın bir erişilebilirlik uzaklığı söz konusu olacaktır. 

    OPTICS algoritmasında bir nokta hiçbir ana noktanın eps komşuluğunda değilse bu nokta yine gürültü noktası olarak tespit 
    edilecektir. Eğer eps değeri çok yüksek tutulursa bu durumda erişilebilirlik uzunluklarına bakılarak da gürültü noktaları 
    tespit edilebilir. 

    Her noktanın erişilebilirlik uzaklığı belirlendikten sonra kümelemenin nasıl yapılacağına yönelik çeşitli yöntemler bulunmaktadır. 
    Örneğin erişilebilirlik uzaklıkları sıraya dizilebilir. Bu sıralamada yüksek atlamaların olduğu yerler küme geçişleri olarak 
    belirlenebilir. Biz burada bu ayrıntılara girmeyeceğiz. 

    Aşağıda ChatGPT tarafından yazılan OPTICS algoritması verilmiştir. Buradaki gerçekleştirim size bir fikir verebilir. 
    Ancak bu gerçekleştirim performans açısından sorunludur. 
#---------------------------------------------------------------------------------------------------------------------------- 

import numpy as np
import math

# 1. Adım: Mesafe Hesaplama (Euclidean Distance)
def euclidean_distance(p1, p2):
    return np.sqrt(np.sum((p1 - p2) ** 2))

# 2. Adım: Core Distance Hesaplama
def core_distance(p, points, min_pts, epsilon):
    # Diğer noktalarla olan mesafeleri hesapla
    distances = [euclidean_distance(p, other) for other in points]
    
    # `epsilon` mesafesi içinde kalan komşuları al
    neighbors = [dist for dist in distances if dist <= epsilon]
    
    # Eğer komşu sayısı yeterliyse, çekirdek mesafesini döndür
    if len(neighbors) >= min_pts:
        return sorted(neighbors)[min_pts-1]  # En uzak `MinPts`-1'ci komşunun mesafesini döndür
    else:
        return None  # Yeterli komşu yoksa çekirdek mesafesi yoktur (gürültü)

# 3. Adım: Reachability Distance Hesaplama
def reachability_distance(p, q, core_distances, epsilon):
    distance = euclidean_distance(p, q)
    if core_distances[p] is None:  # P bir çekirdek noktası değilse
        return None
    return max(core_distances[p], distance)

# 4. Adım: OPTICS Algoritmasının Çalıştırılması
def optics(points, epsilon, min_pts):
    n = len(points)
    
    # Başlangıçta tüm noktalar "işlenmemiş" olarak işaretlenir
    visited = [False] * n
    processed = [False] * n  # İşlem tamamlanmamış noktalar
    reachability_distances = [None] * n  # Her nokta için erişilebilirlik mesafeleri
    core_distances = [None] * n  # Çekirdek mesafeleri
    ordering = []  # Sıralama (OPTICS sıralaması)
    
    # Her noktayı sırasıyla işleyelim
    for i in range(n):
        if not visited[i]:
            visited[i] = True
            # Core distance hesapla
            core_distances[i] = core_distance(points[i], points, min_pts, epsilon)
            
            # Eğer çekirdek mesafesi yoksa, o zaman bu nokta gürültü noktasıdır
            if core_distances[i] is not None:
                # Sıralamayı başlat
                ordering.append(i)
                expand_cluster(i, points, epsilon, min_pts, core_distances, reachability_distances, processed, ordering)
    
    return ordering, reachability_distances, core_distances

# 5. Adım: Kümeleme ve Gürültülerin Ayırt Edilmesi
def expand_cluster(p_index, points, epsilon, min_pts, core_distances, reachability_distances, processed, ordering):
    # Komşu noktaları topla
    neighbors = []
    for i in range(len(points)):
        if i != p_index and euclidean_distance(points[p_index], points[i]) <= epsilon:
            neighbors.append(i)
    
    for q_index in neighbors:
        if not processed[q_index]:  # Eğer q işlenmemişse
            processed[q_index] = True
            core_distances[q_index] = core_distance(points[q_index], points, min_pts, epsilon)
        
        # Reachability mesafesini güncelle
        new_reachability_distance = reachability_distance(p_index, q_index, core_distances, epsilon)
        if reachability_distances[q_index] is None or new_reachability_distance < reachability_distances[q_index]:
            reachability_distances[q_index] = new_reachability_distance
            ordering.append(q_index)

# Örnek Veri Kümesi
points = np.array([
    [1, 1],
    [1, 2],
    [2, 2],
    [8, 8],
    [8, 9],
    [25, 25]
])

# Parametreler
epsilon = 2  # Mesafe eşik değeri
min_pts = 2  # MinPts

# Algoritmayı çalıştır
ordering, reachability_distances, core_distances = optics(points, epsilon, min_pts)

# Sonuçları yazdır
print("Ordering (OPTICS sıralaması):", ordering)
print("Reachability Mesafeleri:", reachability_distances)
print("Core Mesafeleri:", core_distances)

#---------------------------------------------------------------------------------------------------------------------------- 
    OPTICS algoritması scikit-learn kütüphanesindeki sklearn.cluster modülünde bulunan OPTICS isimli sınıfla geçekleştirilmiştir. 
    Sınıfın __init__ metodunun parametrik yapısı şöyledir:

    class sklearn.cluster.OPTICS(*, min_samples=5, max_eps=inf, metric='minkowski', p=2, metric_params=None, 
            cluster_method='xi', eps=None, xi=0.05, predecessor_correction=True, min_cluster_size=None, 
            algorithm='auto', leaf_size=30, memory=None, n_jobs=None)

    Mettotaki cluster_method parametresi "xi" biçimde ya da "dbscan" biçiminde girilebilir. Bu parametrenin default durumunun  
    "xi" biçiminde olduğunu görüyorsunuz. Bu durumda algortima yukarıda açıkladığımız biçimde yürütülür. Yani noktaların 
    erişilebilen uzaklıklarına dayalı olarak kümeleme yapmaktadır. "xi" yönteminde xi parametresi de etkili olmaktadır. Bu 
    parametre kümeleri tespit edebilmek için sıraya dizilmiş erişilebilir uzaklıklardaki farklılaşmanın eşik değerini belirtmek 
    için kullanılmaktadır. Eğer cluster_method parametresi "dbscan" olarak girilirse bu durumda DBSCAN algoritması uygulanır. 
    Yani bu durumda uygulanan algoritmanın DBSCAN algoritmasından bir farkı kalmaz. Ancak ek olarak bize eriişilebilen uzaklıklar 
    da verilir. Eğer cluster_method parametresi "dbscan" olarak girilirse bu durumda DBSCAN algoritması kullanılacağı için 
    bizim eps parametresini de girmemiz gerekir. Aksi takdirde sanki eps=0 gibi tüm noktalar gürültü noktası biçiminde oluşacaktır. 

    OPTICS türünden nesne yaratıldıktan sonra eğitim fit metoduyla yapılmaktadır. Diğer kümeleme sınıflarfında olduğu gibi 
    kümeleme bilgisi yine nesnenin labels_ özniteliğinden elde edilmektedir. Nesnenin ordering_ özniteliği noktaların hangi 
    sırada ele alındığına ilişkin bilgi vermektedir. Nesnenin reachability_ özniteliği noktaların erişilebilir uzaklıklarını, 
    core_distances_ özniteliği ise noktaların ana uzaklıklarını bize vermeketdir. Nesnenin cluster_hierarchy_ özniteliği 
    erişilebilir uzaklıklardan hareketle bir dendgrogram çizilmesini sağlamak için bir bağlantı matrisi vermektedir. (Ancak 
    burada verilen bağlantı matrisi SciPy'da kullanmış olduumuz dendrgram fonksiyonunun kullandığı formata uygun değildir.

    Aşağıdaki örnekte daha önce üzerinde çalışmış olduğumuz "points.csv" verileri OPTICS algoritmasıyla kümelendirilmiştir. 
    Burada biz yalnızca min_samples değerini vermekteyiz. Algoritma bu örnekte iki küme oluşturmuştur. Hiçbir noktayı gürültü 
    noktası olarak işaretlememiştir.  
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('points.csv')
dataset = df.to_numpy(dtype='float32')

from sklearn.cluster import OPTICS

opt = OPTICS(min_samples=3, eps=1, cluster_method='xi')

opt.fit(dataset)
print(opt.labels_)
print(opt.reachability_)
print(opt.ordering_)
print(opt.core_distances_)
print(opt.cluster_hierarchy_)

nclusters = np.max(opt.labels_) + 1;

if nclusters == -1:
    nclusters = 0

plt.title('OPTICS Clustered Points', fontsize=12)
for i in range(nclusters):
    plt.scatter(dataset[opt.labels_ == i, 0], dataset[opt.labels_ == i, 1])     
plt.scatter(dataset[opt.labels_ == -1, 0], dataset[opt.labels_ == -1, 1], marker='x', color='black')
legends = [f'Cluster-{i}' for i in range(1, nclusters + 1)]
legends.append('Noise Points')
plt.legend(legends)
plt.show()
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte min_samples=9, xi=0.1 için zambak veri kümesi OPTICS algoritmasına göre kümelendirilmiştir. Örnekte
    bu parametrelerle 3 küme oluşturulmuştur. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('points.csv')
dataset = df.to_numpy(dtype='float32')

from sklearn.cluster import OPTICS

opt = OPTICS(min_samples=3, eps=1, cluster_method='xi')

opt.fit(dataset)
print(opt.labels_)
print(opt.reachability_)
print(opt.ordering_)
print(opt.core_distances_)
print(opt.cluster_hierarchy_)

nclusters = np.max(opt.labels_) + 1;

if nclusters == -1:
    nclusters = 0

plt.title('OPTICS Clustered Points', fontsize=12)
for i in range(nclusters):
    plt.scatter(dataset[opt.labels_ == i, 0], dataset[opt.labels_ == i, 1])     
plt.scatter(dataset[opt.labels_ == -1, 0], dataset[opt.labels_ == -1, 1], marker='x', color='black')
legends = [f'Cluster-{i}' for i in range(1, nclusters + 1)]
legends.append('Noise Points')
plt.legend(legends)
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıda iç içe eliptik veri kümesine OPTICS algoritması uygulanmıştır. Burada min_samples parametresi uygun bir biçimde 
    ayaralanarak iç ve dış eliptik noktalar birbirinden ayrılmıştır. 
#----------------------------------------------------------------------------------------------------------------------------

from sklearn.datasets import make_circles

dataset, labels = make_circles(100, factor=0.2, noise=0.02)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
plt.title('Random Points')

for i in range(2):
    plt.scatter(dataset[labels == i, 0], dataset[labels == i, 1])    
plt.show()

import numpy as np
from sklearn.cluster import OPTICS

optics = OPTICS(min_samples=10)
optics.fit(dataset)

nclusters = np.max(optics.labels_) + 1

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
plt.title('Clustered Points')

for i in range(nclusters):
    plt.scatter(dataset[optics.labels_ == i, 0], dataset[optics.labels_ == i, 1])

plt.scatter(dataset[optics.labels_ == -1, 0], dataset[optics.labels_ == -1, 1], marker='x', color='black')

legends = [f'Cluster-{i}' for i in range(1, nclusters + 1)]
legends.append('Noise Points')
plt.legend(legends)

plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Yoğunluk tabanlı DBSCAN algoritmasıyla OPTICS algoritmasını şöyle karşılaştırabiliriz:

    - OPTICS algoritması daha fazla bellek kullanmaktadır. Çünkü algoritmanın işleyişinde bir "öncelik kuyruğundan (priority 
    queue) faydalanılmaktadır.

    - OPTICS algoritması DBSCAN algoritmasına göre daha yavaş çalışma eğilimindedir. Çünkü eps değeri büyük tutulduğunda tüm 
    noktalar arasında uzaklık hesabı yapılmak zorunda kalnır.

    - OPTICS yöntemi veri kümesinde farklı yoğunluklu kümeler buulunduğu durumda daha iyi performans gösterebilir. DBSCAN 
    yönteminde farklı yoğunluklu bölgeler eps sınırları dışında kalabilir. Halbuki OPTICS yönteminde erişim uzaklıkları 
    dikkate alındığı için farklı yoğunluklu bölgeler tespit edilebilecektir. 

    - OPTICS algoritmasında biz yalnızca min_samples parametresini ve xi değerini belirleriz. Halbuki DBSCAN algoritmasında 
    biz epsilon değerini de belirlemek zorundayız. 

    - DBSCAN algortiması daha esnektir. DBSCAN'de epsilon değeri uygulamacı tarafından istenildiği gibi alınıp kümeleme üzerinde 
    daha fazla kontrol sağlanabilmektedir. 

    - Hem DBSCAN hem de OPTICS algoritmaları küresel olmayan (eliptik) verilerde K-Means ve agglomerative hiyerarşik yönteme 
    göre daha iyi sonuç vermektedir. 

    - OPTICS algoritmasındaki erişilebilir uzaklıklar hesaplandığı için bu uzaklık bilgilerinden başka amaçlarla da 
    faydalanılabilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Makine öğrenmesinde kullanılan naif yöntemlerden biri de "k-NN (k-Nearest Neighbors)" denilen yöntemdir. Bu yönteme Türkçe
    "En Yakın k Komşuluk Yöntemi" de diyeceğiz. k-NN temelde denetimli (supervised) bir yönteme benzemektedir. Ancak yöntemin
    denetimsiz (unsupervised) modellerde uygulama alanları da vardır. En yakın k komşuluk yöntemi fikir olarak makine öğrenmesinin
    başka alanlarında çeşitli süreçlerde de kullanılmaktadır. 

    k-NN yönteminin dayandığı fikir oldukça basittir. Yöntemdeki k harfi en yakın kaç komşuya bakılacağına ilişkin değeri 
    temsil eder. Bu k değeri yöntemin bir hyper parametresidir. Örneğin bu yöntemde k'nın 3 olması "en yakın 3 komşuya bak" 
    anlamına gelmektedir. k-NN yöntemi özellikle sınıflandırma problemlerinde kullanım alanı bulmaktadır. Ancak regresyon 
    problemlerinde de duruma göre kullanılabilmektedir. Yöntemde eğitim veri kümesi ile kestirilecek değerler aynı anda işleme 
    sokulmaktadır. Yani bu yöntemde önce eğitim yapılıp oradan bilgiler elde edilip kestirim sırasında o bilgilerden faydalanılmamaktadır. 
    Eğitim verileriyle kestirim verileri aynı süreçte işleme sokulmaktadır. 

    En yakın k komşuluk yönteminin dayandığı basit temel şudur: Bir kestirim yapılacaksa kestirim yapılacak noktaya en yakın 
    k tane noktanın durumuna bakılır. Örneğin bir sınıflandırma işleminde kesitirilecek noktaya en yakın k tane noktada hangi 
    sınıfsal değerler (etiketler) daha fazla ise noktanın o sınıfa ilişkin olduğu kabul edilir. Yöntemi şu sürece de benzetilebiliriz: 
    Birisinin belli bir özelliği hakkında bilgi elde etmek isteyelim. Bunun için onun en yakın k tane arkadaşını inceleyip  
    o k tane arkadaşın ilgili özelliğine bakarak yargıda bulunabiliriz. Tabii buradaki yargı oldukça naif bir temele dayanmaktadır. 
    Bu naif yargı "bana arkadaşını söyle senin kim olduğunu söyleyeyim" özdeyişini anımsatmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                        94. Ders - 18/01/2024 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıda k-NN yöntemine göre sınıflandırma yapan düz mantıkla yazılmış bir örnek verilmiştir. (Bu örnek ChatGPT'ye uygun 
    promopt'lar girilerek yazdırılmıştır.)

    import numpy as np
    from collections import Counter

    def euclidean_distance(x1, x2):
        return np.sqrt(np.sum((x1 - x2) ** 2))

    class KNN:
        def __init__(self, k=3):
            self.k = k
        def fit(self, X_train, y_train):
            self.X_train = X_train
            self.y_train = y_train

        def predict(self, X_test):
            predictions = [self._predict(x) for x in X_test]
            return np.array(predictions)

        def _predict(self, x):  
            distances = [euclidean_distance(x, x_train) for x_train in self.X_train]
            k_indices = np.argsort(distances)[:self.k]
            k_nearest_labels = [self.y_train[i] for i in k_indices]
            
            most_common = Counter(k_nearest_labels).most_common(1)
            return most_common[0][0]

    if __name__ == "__main__":
        X_train = np.array([[1, 2], [2, 3], [3, 3], [6, 5], [7, 8], [8, 8]])
        y_train = np.array([0, 0, 0, 1, 1, 1])  # 0 ve 1 sınıfları
        
        # Test verisi
        X_test = np.array([[5, 5], [3, 4]])

        model = KNN(k=3)
        model.fit(X_train, y_train)
        predictions = model.predict(X_test)
        print("Tahminler:", predictions)

    Burada düz mantıkla kestirilecek noktaların tüm noktalara uzaklıkları bir liste içlemiyle elde edilmiştir. Sonra da 
    Python'un standart Counter sınıfıyla en çok yinelenen etiket değerleri bulunmuştur. Tabii buradaki algoritma düz mantık
    (brute force) biçimde oluşturulmuştur. Algoritmayı hızlandırmak için fit işlemi sırasında ağaç yapıları oluşturulup 
    bunlardan faydalanılabilmektedir. Biz bu algoritmaları burada ele almayacağız.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    k-NN yönteminde k değeri bir hyper parametredir. Yani bunun uygulamacı tarafından algortimaya verilmesi gerekir. Pekiyi 
    bu k değerini uygulamacı nasıl tespit etmelidir? Aslında bu konuda kesin bir yöntem önermek mümkün değildir. En çok uygulanan 
    yöntem veri kümesini değişik k değerleri için sınıflandırmak ve en iyi k değerini deneme yanılma yoluyla tespit etmektir. 
    Uygulamacıların bazıları k değerini görsel ya da nümerik olarak bir çeşit dirsek grafiği eşliğinde belirlemeye çalışmaktadır.
    Eğer k değeri çok büyük seçilirse yakınlığın bir anlamı kalmaz. Ayrıca işlemler de zaman bakımından uzar. k değeri çok 
    küçük seçilirse genelleme yeteneği azalır. O halde k değerinin makul bir biçimde seçilmesi gerekir. Veri kümesi çok küçükse 
    k değerinin azaltılması, çok büyükse daha yüksek tutulması uygun olabilir. 5 gibi bir değer çoğu veri kümesi için ortalama
    makul bir değerdir. 

    k-NN yöntemi kullanılmadan önce özellik ölçeklemesi yapılmalıdır. Çünkü uzaklık hesabında belli bir sütunun diğerinden 
    daha etikili olması genellikle istenmez.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    k-NN yöntemi scikit-learn kütüphanesinde sklearn.neighbors modülünde bulunan çeşitli sınıflar yoluyla gerçekleştirilmiştir. 
    Biz burada bu kütüphanedeki bazı sınıfların kullanımları üzerinde duracağız. 

    KNeighborsClassifier sınıfı k-NN yöntemiyle sınıflandırma yapmak için kullanılmaktadır. Sınıfın __init__ metodunun parametrik 
    yapısı şöyledir:

    class sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, 
            metric='minkowski', metric_params=None, n_jobs=None)

    Burada n_neighbors parametresi kaç komşuluğa bakılacağını belirtmektedir. Yani bu parametre k değerini belirtmektedir. 
    algorithm parametresi en yakın komşuluk bulmada kullanılacak algoritmayı belirtmektedir. Algoritma için girilecek iki tipik 
    değer "ball_tree" ve "kd_tree" biçimindedir. Bu parametrenin default değerinin "auto" olduğuna dikkat ediniz. Bu durumda
    veri kümesine en uygun algoritma seçilmektedir. metric parametresi uzaklık ölçmek için kullanılmaktadır. Bu parametrenin
    default değerinin "minkowski" biçiminde girildiğine dikkat ediniz. Minkowski uzaklığı Öklit uzaklığının genel bir biçimidir. 
    Minkowski uzaklığındaki üs belirten p değeri de p parametresiyle belirlenebilmektedir. Bu p değerinin default durumda 2 
    olduğunu görüyorsunuz. Bu durumda default uzaklık olarak Öklit uzaklığı kullanılacaktır. Örneğin:

    from sklearn.neighbors import KNeighborsClassifier

    knc = KNeighborsClassifier(5)

    KNeighborsClassifier nesnesi yaratıldıktan sonra fit işlemi yapılır. fit işlemi sırasında en yakın komuşukların hızlı 
    bulunması için bazı hazırlıklar yapılmaktadır. Örneğin:

    knc.fit(dataset_x, dataset_y)

    Bundan sonra artık kestirim yapılabilir. Kestirim için yine sınıfın predict metodu kullanılmaktadır. Örneğin:

    predict_result = knc.predict(predict_dataset_x)

    Sınıfın kneighbors isimli metodu verilen noktalara en yakın k tane noktaya olan uzaklıkları ve bu nktaların indekslerini 
    bize ikili bir demet olarak vermektedir. 
    
    Aşağıda zambak (iris) veri kümesi üzerinde bir uygulama verişmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('iris.csv')
dataset_x = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')
dataset_y = df['Species'].to_numpy(dtype='str')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset_x)
scaled_dataset_x = ss.transform(dataset_x)

from sklearn.neighbors import KNeighborsClassifier

knc = KNeighborsClassifier(5)
knc.fit(scaled_dataset_x, dataset_y)

predict_df = pd.read_csv('predict-iris.csv')
predict_dataset = predict_df.to_numpy(dtype='float32')
scaled_dataset_predict = ss.transform(predict_dataset)

predict_result = knc.predict(scaled_dataset_predict)
print(predict_result)

#----------------------------------------------------------------------------------------------------------------------------
    k-NN yöntemiyle regresyon problemlerinin çözümünde tipik olarak noktaya en yakın k tane noktanın değerlerinin ortalaması 
    heaplanmaktadır. Bunun için scikit-learn içerisindeki KNeighborsRegressor sınıfı kullanılmaktadır. Sınıfın __init__ metodunun
    parametrik yapısı şöyledir:

    class sklearn.neighbors.KNeighborsRegressor(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, 
            metric='minkowski', metric_params=None, n_jobs=None)

    Yine metodun n_neighbors parametresi k değerini belirtmektedir. Bu değerin default olarak 5 alındığını görüyorsunuz. Diğer
    parametreler yine aynıdır. Sınıf benzer biçimde kullanılmaktadır. Örneğin:

    knr = KNeighborsRegressor(5)
    nr.fit(scaled_dataset_x, dataset_x)

    Kestirim yine sınıfın predict metoduyla yapılmaktadır: 

    predict_result = knr.predict(predict_dataset_x)

    Aşağıda "Boston Hosing Prices" veri kümesi üzerinde k-NN ile regresyon işleminebir örnek verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_y = df.iloc[:, -1].to_numpy()
df.drop([8, 13], axis=1, inplace=True)
dataset_x = df.to_numpy('float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset_x)
scaled_dataset_x = ss.transform(dataset_x)

from sklearn.neighbors import KNeighborsRegressor

knr = KNeighborsRegressor(5)
knr.fit(scaled_dataset_x, dataset_x)

predict_df = pd.read_csv('predict-boston-housing-prices.csv', delimiter=r'\s+', header=None)

predict_df.drop([8], axis=1, inplace=True)
predict_dataset_x = predict_df.to_numpy('float32')

scaled_predict_dataset_x = ss.transform(predict_dataset_x)

predict_result = knr.predict(scaled_predict_dataset_x)
print(predict_result)

#----------------------------------------------------------------------------------------------------------------------------
    sklearn.neigbours modülünde başka yararlı sınıflar da vardır. NearestNeighbors sınıfı sınıflandırma ya da regresyon işlemini 
    yapmaz. Denetimsiz biçimde yalnızca verilen noktalara ilişkin en yakın k komşuları tespit eder. Aynı zamanda bu noktaların 
    en yakın komşulara uazaklıklarını da vermektedir. 

    sklearn.neigbours modülündeki diğer bir faydalı sınıf da NearestCentroid isimli sınıftır. Bu sınıf denetimli (supervised)
    biçimde çalışmaktadır. Biz bu sınıfın fit metodunu dataset_x ve dataset_y değerleriyle çağırırız. Metot her sınıf için 
    ağırlık merkezini (yani orta noktasını) tespit eder. Sonra predict işlemini yaptığımızda metot verilen noktalar hangi ağırlık 
    merkezine yakınsa noktaların o sınıflara ilişkin olduğu sonucunu çıkartır. Bu sınıfı KNeighborsClassifier sınıfı ile 
    karıştırmayınız. KNeighborsClassifier sınıfı en yakın k komşuluğun y değerlerini oylayarak tespiti yapmaktadır.
        
    Modüldeki diğer sınıflar nispeten daha az kullanılmaktadır. Bunları dokümanlardan inceleyebilirsiniz.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Bu bölümde istatistike ve veri biliminde çok kullanılan "kovaryans" ve "korelasyon" kavramlarını ele alacağız. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Biz giriş derslerinde "varyans" kavramını görmüştük. Varyans standart sapmanın karesine denilmektedir. İstatistikte bazı 
    konularda varyans kavramı çok kullanılırken bazı konularda standart sapma kavramı çok kullanılmaktadır. Dolayısıyla bu iki 
    kavram birbirleriyle ilişkili olduğu halde bunlar için iki farklı terim ismi uydurulmuştur. Giriş konularında da gördüğümüz 
    gibi varyans işlemi NumPy ktüphanesinde axis temelinde yapılabilmektedir.

    Standart sapma ve varyans değerlerin ortalama etrafındaki kümelenmesi konusunda bir fikir verebilmektedir. Biribirine yakın 
    değerlerin standart sapması ve varyansı düşüktür. Birbirinden uzak değerlerin standart sapması ve varyansı yüksektir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Kovaryans (covariance) iki olgunun birlikte değişimi ya da doğrusallığı konusunda bilgi veren istatistiksel bir ölçüttür.
    Örneğin bu olgular x ve y olsun. Eğer x artarken tutarlı biçimde y de artıyorsa aralarında doğrusal bir ilişkiye benzer 
    bir ilişki vardır. Bu durumda iki değişkenin kovaryansları yüksektir. Tabii ilişki doğrusal gibi olduğu halde ters yönde 
    de olabilir. Yani örneğin x artarken y de tutarlı bir biçimde azalıyor olabilir. Burada da kovaryans ters yönde yüksektir. 
    Ancak bir değişken artarken diğeri tutarlı bir biçimde artıp azalmıyorsa bu iki değişken arasında düşük bir kovaryans vardır. 
    Kovaryans iki değişken arasında ilişkiyi belirtmektedir. İki değişkendne çok değişkenlerin kovaryasnları ancak birbirlerine 
    göre elde edilebilir. Bu durumda bir kovaryans matrisi oluşacaktır. 

    İki değişken arasındaki kovaryans hesabı şöyle hesaplanmaktadır:

    Kovaryans(x, y) = sigma((xi - xbar) * (yi - ybar)) / n

    Örneğin değerler aşağıdaki gibi olusn:

     X            Y
    ---          ---
    1             5
    2             4 
    3             3 
    4             2
    5             1

    Burada X ve Y ortalaması şöyledir:

    Xbar = 3
    Ybar = 3

    Kovaryans da şöyle hesaplanır:

    +-----+--------+--------+---------------------+---------------------+---------------------------------------------+
    |  i  | x_i    | y_i    |    x_i - x̄          |  y_i - ȳ            |   (x_i - x̄) * (y_i - ȳ)                     |
    +-----+--------+--------+---------------------+---------------------+---------------------------------------------+
    |  1  |   1    |   5    |      -2             |      2              |                 -4                          |
    |  2  |   2    |   4    |      -1             |      1              |                 -1                          |
    |  3  |   3    |   3    |       0             |      0              |                  0                          |
    |  4  |   4    |   2    |       1             |     -1              |                 -1                          |
    |  5  |   5    |   1    |       2             |     -2              |                 -4                          |
    +-----+--------+--------+---------------------+---------------------+---------------------------------------------+

    Buradan kovaryasn şöyle hesaplanır:

    Kovaryans(X, Y) = -10 / 5 = -2

    Bunu bir fonksiyon olarak da şöyle yazabiliriz:

    import numpy as np

    def cov(x, y):
        return np.sum((x - np.mean(x)) * (y - np.mean(y))) / len(x)

    Aynı değişkenin aynı değişkenle kovaryansının zaten varyans anlamına geldiğine dikkat ediniz. Yani cov(x, x) aslında 
    var(x) ile aynı anlamdadır. 

    İki değişken arasında elde edilen kovaryans başka iki değişken arasında elde edilen kovaryans ile kıyaslanamaz. Bunların
    arasında bir kıyaslama yapılabilmesi için özellik ölçeklemesi uygulanmalıdır. Zaten özellik ölçeklemesi uygulanmış olan 
    kovaryansa da korelasyon denilmektedir.
            
    NumPy kütüphanesindeki cov fonksiyonu iki boyutlu NumPy dizileriyle ya da tek boyutlu Numpy dizileriyle çalışabilmektedir. 
    cov fonksiyonu bize bir kovaryans matrisi verir. Yani her değişkenin her değişkenle kovaryasları matris halinde verilmektedir. 
    Tabii bu matris simetrik bir matrisir. Default durumda cov fonksiyonu n - 1'değerine bölme yapmaktadır. ddof=0 parametresiyle 
    n değerine bölme yaptırabiliriz. Kovaryans matrisinde köşegenler değişkenlerin varyanslarını belirtir. Çünkü cov(x, x) zaten 
    var(x) anlamındadır. Örneğin:

    x = np.array([1, 2, 3, 4, 5])
    y = np.array([3, 6, 8, 10, 12])

    result = np.cov(x, y, ddof=0)
    print(result)

    Buradan şöyle bir sonuç elde edilmiştir:

    [[2.   4.4 ]
    [4.4  9.76]]   

    Örneğimizde iki değişken bulunduğu için kovaryans matrisi de 2x2 boyuttadır. Bu matrisin köşegenleri varyasn değerlerini
    vermektedir. İki değiikenden daha fazla değişkenler için kovaryans elde etmek için değerler bir matriste toplanıp bu matris 
    birinci parametreye girilebilir. Örneğin:

    x = np.array([1, 2, 3, 4, 5])
    y = np.array([3, 6, 8, 10, 12])
    z = np.array([3, 5, 1, 6, 8])

    m = np.vstack((x, y, z))

    result = np.cov(m, ddof=0)
    print(result)
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
    
x = np.array([1, 2, 3, 4, 5])
y = np.array([3, 6, 8, 10, 12])
z = np.array([3, 5, 1, 6, 8])

m = np.vstack((x, y, z))

result = np.cov(m, ddof=0)
print(result)

m = np.cov((x, y, z), ddof=0)
print(m)

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte iki değişkenin arasındaki ilişkiyi değiştirerek doğrusallık temelinde kovaryans değerlerini inceleyiniz. 
    Değişkenlerin arasındaki ilişki doğrusallığa benzedikçe kovaryans da yükselmektedir. Tabii ters yönde doğrusal ilişki de 
    yüksek negatif bir kovaryans oluşturmaktadır.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np

def cov(x, y):
    return np.sum((x - np.mean(x)) * (y - np.mean(y))) / len(x)
            
x = np.array([1, 2, 3, 4, 5])
y = np.array([3, 5, 8, 9, 12])

result = cov(x, y)
print(result)
    
result = np.cov(x, y, ddof=0)
print(result)

import matplotlib.pyplot as plt

plt.title('Covariance')
plt.plot(x, y, marker='o')
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirttiğimiz gibi n tane değişkenin birbirlerine göre kovaryanslarını hesaplarken cov fonksiyonuna iki boyutlu 
    tek bir dizi girilir. (Tabii aslında bu parametre bir liste listesi, bir NumPy dizi dizisi ya da NumPy dizilerinden oluşan 
    bir liste olarak da girilebilir). Default durumda cov fonksiyonu satır temelinde çalışmaktadır. Yani her satırı ayrı bir 
    değişken gibi kabul etmektedir. Ancak fonksiyonunun rowvar parametresi False yapılırsa bu durumda her sütun ayrı bir değişken 
    kabul edilmektedir. Örneğin üç ayrı değişkenimiz olsun:

    a = np.array([1, 2, 3, 4, 5])
    b = np.array([2, 6, 1, 7, 4])
    c = np.array([30, 23, 45, 16, 12])

    Biz bu üç değişkenin birbirlerine göre kovaryanslarını şöyle hesaplayabiliriz:

    >>> a = np.array([1, 2, 3, 4, 5])
    >>> b = np.array([2, 6, 1, 7, 4])
    >>> c = np.array([30, 23, 45, 16, 12])
    >>> np.cov([a, b, c], ddof=0)
    array([[  2.  ,   1.  ,  -8.6 ],
           [  1.  ,   5.2 , -20.2 ],
           [ -8.6 , -20.2 , 135.76]])

    Aynı şey şöyle de yapılabilirdi:

    >>> a = np.array([[1, 2, 3, 4, 5], [2, 6, 1, 7, 4], [30, 23, 45, 16, 12]])
    >>> np.cov(a, ddof=0)
    array([[  2.  ,   1.  ,  -8.6 ],
        [  1.  ,   5.2 , -20.2 ],
        [ -8.6 , -20.2 , 135.76]])
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                                95. Ders - 19/01/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Kovaryans iki değişkenin birlikte değişimi hakkında bize bilgi vermektedir. Ancak kovaryans değerlerini karşılaştırmak 
    zordur. Yani başka bir deyişle x ile y arasındaki kovaryansı m ile z arasındaki kovaryansla karşılaştıramayız. Örneğin
    biz hava sıcaklığı ile yağış miktarı arasındaki kovaryansa baktığımızda sıcaklığı derece olmaktam çıkartıp Fahrenayt haline 
    getirirsek kovaryans değişir. İşte kovaryansların standardize edilmiş haline "Pearson Korelasyon Katsayısı (Pearson Correlation 
    Coefficient)" denilmektedir. Korelasyon katsayıları için aslında değişik hesaplama yöntemleri önerilmiştir. Ancak en çok 
    kullanılan korelasyon katsayı hesaplama yöntemi "Pearson Korelasyon Katsayısı" denilen yöntemdir. Bu yöntemde iki değişkenin 
    kovaryansları onların standart sapmalarının çarpımına bölünmektedir. Yani değişkenler x ve y olmak üzere Pearson korelasyon 
    katsayısı cov(x, y) / (std(x) * std(y)) biçiminde hesaplanmaktadır. İki değişkenin kovaryanslarının standart sapmalarına 
    bölünmesi aslında sütunların standart ölçeklemeye sokulduktan sonra kovaryanslarının hesaplanması anlamına da gelmektedir. 
    Bu işlem kovaryans değerini [-1, 1] aralığına hapsetmektedir. Dolayısıyla karşılaştırmalar bu sayede yapılabilmektedir. 
    Değişkenler ne kadar doğrusal ilişki içerisindeyse korelasyon katsayısı +1 ya da -1'e o kadar yaklaşır. Bir değişken artarken 
    diğeri de artıyorsa pozitif bir korelasyon, bir değişken artarken diğeri azalıyorsa negatif bir korelasyon söz konusudur. 
    Pozitif de olsa negatif de olsa korelasyon katsayısı yükseldikçe ilişki doğrusal olmaya yaklaşmaktadır.  Eğer iki değişken 
    arasındaki ilişki tutarsız ve doğrusal olmaktan uzak ise bu durumda korelasyon katsayısı 0'a yaklaşır. Özellikle sosyal 
    bilimlerde ve sağlık bilimlerinde araştırma yapanlar ölçükleri değişkenlerin arasında korelasyonlara bakmaktadır. Bu sayede 
    yüksek korelasyonlu değişkenler arasında bir ilişkinin olabileceği göz önüne alınmaktadır. İki değişken arasında korelasyon 
    için tipik olarak şunlar söylenebilmektedir:

    0.0-0.2 arasında ise çok zayıf korelasyon ya da korelasyon yok
    0.2-0.4 arasında ise zayıf korelasyon
    0.4-0.6 arasında ise orta şiddette korelasyon
    0.6-0.8 arasında ise yüksek korelasyon
    0.8–1 > ise çok yüksek korelasyon 

    İki olgu arasında yüksek bir korelasyon olamsı bunlar arasında bir neden-sonuç ilişkisinin olacağı anlamına gelmemektedir. 
    İki olgu arasında dolaylı birtakım ilişkiler de söz konusu olabilir ancak bu neden-sonuç ilişkisi olmayabilir. Örneğin 
    dondurma satışlarıyla boğulma vakalarının sayısı arasında yüksek bir korelasyon olabilir. Ancak biz buradan dondurma 
    yemenin boğulmaya yol açtığı gibi bir sonuç çıkartamayız. Fakat ne olursa olsun özellikle sosyal bilimlerde ve sağlık 
    bilimlerinde iki olgu arasındaki yüksek korelasyon araştırmacıya bir ipucu verebilmektedir. Araştırmacı buradan hareketle 
    çeşitli hipotezler geliştirip onları test edebilir.

    Pearson korelasyon katsayısı NumPy'da corrcoef isimli fonksiyonla hesaplanabilmektedir. corrcoef fonksiyonu tamamen cov 
    fonksiyonu gibi kullanılmaktadır. Bu fonksiyon değişkenlerin birbirlerine göre korelasyonlarından oluşan bir korelasyon 
    matrisi vermektedir. Örneğin:

    >>> a = np.array([1, 2, 3, 4, 5])
    >>> b = np.array([2, 6, 1, 7, 4])
    >>> c = np.array([30, 23, 45, 16, 12])
    >>> np.corrcoef([a, b, c])
    array([[ 1.        ,  0.31008684, -0.52191231],
        [ 0.31008684,  1.        , -0.76026287],
        [-0.52191231, -0.76026287,  1.        ]])

    Buradaki matrisin yine simetrik olduğuna dikkat ediniz. Köşegen elemanlarının 1 olmasının nedeni bir değişkenin kendisiyle 
    korelasyonunun 1 olmasından kaynaklanmaktadır. Yani corr(x, x) her zaman 1'dir. corrcoef fonksiyonunda ddof parametresi 
    gereksizdir ve kaldırılmıştır. Çünkü zaten bölme işleminde kullanılan ddof değerleri birbirini götürmektedir.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Makine öğrenmesinde ve veri biliminde veri kümesinde çok fazla sütun (yani özellik) bulunmasının bazı olumsuzlukları vardır. 
    Çok fazla sütun çok fazla işlem anlamına gelir. Dolayısıyla hesaplama zamanları göreli olarak artar. Çok fazla sütun aynı 
    zamanda bellek kullanımı üzerinde de olumsuz etkilere yol açmaktadır. Fazlaca sütun bilgisinin işlenmesi için daha fazla 
    bellek alanına gereksinim duyulmaktadır. Ancak veri kümesinde çok fazla sütunun bulumasının en önemli dezavantajı "overfitting 
    ve underfitting" eğilimini artırmasıdır. Denetimli öğrenmede karmaşık modeller öğrenmenin düşmesine ve yanşlış öğrenmelere 
    yol açabilmektedir. O halde çok fazla sütunun daha az sütuna indirgenmesi önemli önişlem faaliyetlerinden biridir. Buna 
    "boyutsal özellik indirgemesi (dimensionality feature reduction)" denilmektedir. Boyutsal özellik indirgemesi çeşitli Auto 
    ML araçları tarafından otomatik da yapılabilmektedir. Tabii bunun için verilerin iyi bir biçimde analiz edilmesi gerekir.

    Boyutsal özellik indirgemesi n tane sütundan k < n koşulunu sağlayan k tane sütunun elde edilmesi sürecidir. Bu süreç iki 
    alt gruba ayrılmaktadır:

    1) n tane sütundan bazılarını atarak ancak diğerlerini değiştirmeden k tane sütun elde etmeye çalışan yöntemler.
    2) n tane sütundan onu temsil eden (ancak bu n tane sütunun hiçbirini içermeyen) yeni k tane sütun elde etmeye çalışan 
    yöntemler.

    Biz de burada belli başlı yöntemler üzerinde duracağız.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Eksik Değerli Sütunların Atılması Yöntemi (Missing Value Ratio): Bu yöntemde eğer bir sütunda eksik veriler varsa o sütun
    veri kümesinden çıkartlır. Tabii burada sütundaki eksik verilerin oranı da önemlidir. Genellikle eksik veri bakımından 
    belli oranı aşan sütunların atılması yoluna gidilmektedir. Örneğin sütunlarda %20'nin yukarısında eksik veri varsa bu 
    sütunları atabiliriz. Çünkü zaten bu sütunların temsil yeteneği azalmıştır.  

    Düşük Varyans Filtrelemesi (Low Variance Filtering): Bir sütunun varyansı o sütundaki değişkenliği bize anlatmaktadır. Örneğin 
    veri kümesinde hep aynı değerlerden oluşan bir sütun bulunuyor olsun. Bu sütun bize bir bilgi verebilir mi? Tabii ki hayır. 
    Bu sütunun varyansı 0'dır. O halde biz n tane sütundan bazılarını atarak k tane sütun elde etmek istediğimizde seçeneklerden 
    biri de az bilgiye sahip olan sütunları atmaktır. O da değişkenliği az olan yani düşük varyansa sahip sütunlardır. O halde 
    bu yöntemde sütunların varyanslarına bakılır. n = k + m ise en düşük varyansa sahip m tane sütun atılarak k tane sütun elde 
    edilebilir. Diğer bir yöntem de m tane sütunu atmak yerine belli bir eşik değeri belirleyip o eşik değerinin aşağısında 
    kalan sütunları atmak olabilir. Ancak sütunlardaki skala farklılıkları varyansların karşılaştırılmasını engellemektedir. 
    O halde bu yöntem uygulanmadan önce sütunların aynı skalaya dönüştürülmesi uygun olur. Bunun için Min-Max ölçeklemesi 
    kullanılabilir. 

    Aşağıdaki örnekte "Boston Housing Prices (housing.csv)" veri kümesindeki 13 sütundan en düşük varyansa sahip olan 5 tanesi 
    atılarak bu veri kümesi 8 sütuna indirgenmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.preprocessing import MinMaxScaler

mms = MinMaxScaler()
mms.fit(dataset_x)
scaled_dataset_x = mms.transform(dataset_x)

import numpy as np

feature_vars = np.var(scaled_dataset_x, axis=0)
sorted_arg_vars = np.argsort(feature_vars)
reduced_dataset_x = np.delete(dataset_x, sorted_arg_vars[:5], axis=1)
print(reduced_dataset_x)

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte ise aynı yöntem kullanılarak 4 sütuna sahip "zambak (iris)" verileri en düşük varyansa ilişkin sütun 
    atılarak üç sütuna indirgenmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('iris.csv')

dataset_x = df.iloc[:, 1:-1].to_numpy(dtype='float32')

from sklearn.preprocessing import MinMaxScaler

mms = MinMaxScaler()
mms.fit(dataset_x)
scaled_dataset_x = mms.transform(dataset_x)

import numpy as np

feature_vars = np.var(scaled_dataset_x, axis=0)
sorted_arg_vars = np.argsort(feature_vars)
reduced_dataset_x = np.delete(dataset_x, sorted_arg_vars[:1], axis=1)
print(reduced_dataset_x)

#----------------------------------------------------------------------------------------------------------------------------
    scikit-learn içerisinde sklearn.feature_selection modülünde VarianceThreshold isimli bir sınıf bulunmaktadır. Bu sınıf belli 
    bir eşik değerinden küçük olan sütunların atılmasında kullanılmaktadır. Sınıfın kullanımı diğer scikit-learn sınıflarındaki 
    gibidir. Nesne yaratılırken eşik değeri verilir. Sonra fit_transform işlemiyle indirgeme yapılır. fit işleminden sonra sınıfın 
    variances_ örnek özniteliğinde sütun varyansları bulunur. Örneğin:

    from sklearn.feature_selection import VarianceThreshold

    vt = VarianceThreshold(0.04)
    reduced_dataset_x = vt.fit_transform(dataset_x)

    Bu sınıf kendi içerisinde özellik ölçeklemesi yapmamaktadır. Bu nedenle sütunların skalaları birbirinden farklıysa önce
    özellik ölçeklemesinin yapılması gerekir. 
 
    Aşağıdaki örnekte Boston Housing Prices veri kümesi üzerinde VarianceThreshold sınıfı kullanılarak belli bir eşik değeri 
    ile düşük varyans filtrelemesi yapılmıştır.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

print(dataset_x.shape)

from sklearn.preprocessing import MinMaxScaler

mms = MinMaxScaler()
mms.fit(dataset_x)
scaled_dataset_x = mms.transform(dataset_x)

from sklearn.feature_selection import VarianceThreshold

vt = VarianceThreshold(0.04)

reduced_dataset_x = vt.fit_transform(scaled_dataset_x)
print(reduced_dataset_x.shape)

#----------------------------------------------------------------------------------------------------------------------------
    Yüksek Korelasyon Filtrelemesi Yöntemi (High Correlation Filtering): İki sütun söz konusu olsun. Biri diğerinin iki katı 
    değerlere sahip olsun. Bu iki sütunun bir arada bulunmasının hiçbir yöntemde hiçbir faydası yoktur. Bu iki sütunun Pearson 
    korelasyon katsayısı 1'dir. İşte birden fazla sütun birbirleriyle yüksek derecede korelasyon içeriyorsa bu sütunların yalnızca 
    bir tanesi muhafaza edilip diğerleri atılabilir. Bu yönteme "yüksek korelasyon filtrelemesi" denilmektedir.
    
    Yüksek korelasyon filtrelemesi manuel bir biçimde yapılabilir. Anımsanacağı gibi korelasyon iki değişken arasında hesaplanmaktadır. 
    Birden fzla değişken söz konusu olduğunda bu değişkenlerin birbirlerine göre korelasyonları korelasyon matrisi oluşturmaktadır.
    İşte burada uygulamacı matirisn en büyük elemanlarını bulmaya çalışabilir. Onun satır ve sütun değerleri yüksek korelasyonu 
    olan sütunları verecektir. Korelasyon için özellik ölçeklemesi yapmaya gerek yoktur. Çünkü zaten Pearson korelasyon katsayısı
    bize standardize edilmiş bir değer vermektedir. Tabii yüksek korelasyon filtrelemesi yapılırken yüksek korelasyonun negatif 
    ya da pozitif olmasının da bir önemi yoktur. Pozitif yüksek korelasyon da negatif yüksek korelasyon da neticede aynı durumlara 
    yol açmaktadır. 

    Scikit-leran içerisinde ya da yaygın kütüphanelerin içerisinde yüksek korelasyon filtrelemesi yapan hazır bir fonksiyon 
    ya da sınıf bulunmamaktadır. Programcının bu işlemi manuel bir biçimde yapması gerekmektedir. 

    Yüksek korelasyon filtrelemesini yapmak biraz daha zahmetlidir. Çünkü korelasyon matrisi büyük olabilir. Bizim de bu büyük 
    matrisi incelememiz gerekebilir. Ayrıca yüksek korelasyona sahip olan sütunlardan hangilerinin atılacağı da bazen önemli 
    olabilmektedir. Örneğin bizim iki sütunuzmuzun korelasyonları 0.95 olsun. Bunlardan birini atmak isteriz. Ama hangisini 
    atmak daha uygun olur? İşte burada uygulamacı başka ölçütleri de göz önüne alabilir. Örneğin düşük varyansa sahip olanı 
    atmak isteyebilir. Konuya hakimse nispeten daha önemsiz kabul ettiği bir sütunu da atmak isteyebilir. 

    Yüksek korelasyonlu sütunların görsel bir biçimde tespit edilebilmesi için "heatmap" denilen grafiklerden de faydalanılabilmektedir. 
    Heapmap grafikleri matplotlib içerisinde yoktur ancak seaborn kütüphanesinde bulunmaktadır. Bu heatmap grafiğinde (grafik 
    çeşitli biçimlerde konfigüre edilebilmektedir) yüksek değerler açık renklerle düşük değerler koyu renklerle gösterilirler. 
    Böylece uygulamacı gözle bunları kontrol edebilir. Aşağıdaki örnekte Boston veri kümesinde korelasyon uygulanıp korelasyon 
    matrisi heatmap fonksiyona verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

import numpy as np

feature_corrs = np.abs(np.corrcoef(dataset_x, rowvar=False))

import seaborn as sns

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 9))
sns.heatmap(data=feature_corrs, annot=True)
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Korelasyon matrisinde yüksek olan satır ve sütun numaralarını programalama yoluyle elde etmek istebiliriz. Burada dikkat 
    edilmesi gereken nokta korelasyon matrisinin simetrik olması ve köşegen elemanlarının 1 olmasıdır. Aşağıdaki örnekte korelasyon 
    matrisi dolaşılmış yüksek korelasyonlu sütunların bir tanesi bir listede toplanmış sonra da bu sütunlar veri kümesinden 
    atılmıştır.
#----------------------------------------------------------------------------------------------------------------------------

CORR_THRESHOLD = 0.75

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

import numpy as np

feature_corrs = np.abs(np.corrcoef(dataset_x, rowvar=False))

eliminated_features = []

for i in range(feature_corrs.shape[0]):
    for k in range(i):
        if i not in eliminated_features and k not in eliminated_features and feature_corrs[i, k] > CORR_THRESHOLD:
            eliminated_features.append(k)

print(eliminated_features)

reduced_dataset_x = np.delete(dataset_x, eliminated_features, axis=1)
print(reduced_dataset_x.shape)

#----------------------------------------------------------------------------------------------------------------------------
                                        96. Ders - 25/01/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Yukarıdaki gibi yüksek korelasyon filtrelemesi yapan algoritmada bir noktaya dikkatinizi çekmek istitoruz. Örneğin A ile 
    B arasında ve B ile C arasında yüksek korelasyon olsun. Yukarıdaki algoritmada bunlardan yalnızca bir tanesi (örneğin B
    sütunu) veri kümesinden atılacaktır. Eğer bunların biri dışında hepsinin atılmasını istiyorsanız bir graf oluşturup o 
    graftaki tek sütunu alıp diğerlerini atma yoluna gidebilirsiniz. Bu durumda muhafaza edilecek sütun hedef değişkenle 
    korelasyonu en yüksek sütun olarak seçilebilir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    En çok kullanılan boyutsal özellik indirgemesi yöntemi "temel bileşenler analizi (principle component analysis)" denilen 
    yöntemdir. Bu yöntemde orijinal n tane sütuna sahip olan veri kümesi k < n olmak üzere k tane sütuna indirgenmektedir. 
    Ancak bu yöntemde elde edilen k sütunlu veri kümesinin sütunları orijinal n sütun ile aynı olmamaktadır. Yani bu yöntem 
    n tane sütunlu veri kümesini temsil eden tamamen farklı k tane sütun oluşturmaktadır. Yöntemin matematiksel temeli biraz 
    karmaşıktır. Bu yöntemde n boyutlu uzaydaki noktalar dönüştürülerek en yüksek varyans sağlanacak biçimde k < n boyutlu 
    uzaydaki noktalara dönüştürülmektedir. Şüphesiz n tane özelliğe sahip olan veri kümesini k tane özelliğe indirgediğimiz 
    zaman orijinal veri kümesinin temsili zayıflamış olur. Ancak bu yöntem bu veri kümesindeki zayıflamayı en aza indirmeye 
    çalışmaktadır. 

    Temel bileşenler analizi "denetimsiz (unsupervied)" bir özellik indirgeme yöntemidir. Yani bu yöntemde hedef değişken 
    (dataset_y) ile ilgili bir işlem yapılmamaktadır. Bu yöntemde veri kümesindeki sütunların nümerik olması gerekmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Temel Bileşenler Analizinin matemetiksel açıklamasının biraz karmaşık olduğunu belirtmiştik. Yöntemin anlaşılabilmesi için 
    "öz değerler (eigenvalues) ve öz verktörler (eigenvectors)" konusunun bilinmesi gerekir. Bu yöntemde amaç n boyutlu uzaydaki 
    noktaları k < n olacak biçimde k boyutlu uzaya indirgemektir. Bu indirgeme sırasında k boyutlu uzay için eksen kaydırması 
    ve projeksiyon yapılmaktadır. Projeksiyon n boyutlu uzaydaki noktanın k boyutlu uzaya kaydırılması anlamına gelmektedir. 
    Bu projeksiyon yapılırken projeksiyon sonucunda elde edilen noktaların toplam varyansalarının en yükske olmasına çalışılır. 
    Biz burada bu işlemin yapılabilmesi için gerekli adımları aşağıda vereceğiz. Konun matematiksel ayrıntılaır için başka 
    kaynaklara başvurabilirsiniz:

    Örneğin n tane sütuna sahip bir veri tablosundan k tane sütuna sahip (k < n) bir veri tablosunu temel bileşenler analizi 
    yöntemiyle elde etmek isteyelim. İşlem adımları şöyle gerçekleştirilir:

    1) Önce N sütunlu veriler üzerinde gerekli özellik ölçeklendirmesi uygulanır.

    2) n sütunlu matristen nxn'lik kovaryans matrisi elde edilir. 

    3) Bu kovaryans matrisinden n tane "öz vektör (eigenvector)" bulunur. 

    4) Bu n tane özvektör arasından k tanesi seçilerek (seçimin nasıl yapılacağı belirtilecektir) asıl matrisle çarpılır ve 
    böylece sonuçta k tane sütuna indirgenmiş veri tablosu elde edilir. 

    Şimdi bu işlemleri adım adım Python'da yapalım. Bu örneğimizde iki sütunlu tabloyu tek sütuna indirgemeye çalışacağız. 
    İki sutunlu tablonun bilgileri şöyle olsun:

    x1      x2
    0.72    0.13
    0.18    0.23
    2.5     2.3
    0.45    0.16
    0.04    0.44
    0.13    0.24
    0.30    0.03
    2.65    2.1
    0.91    0.91
    0.46    0.32

    Bu bilgilerin "dataset.csv" isimli dosyada bulunduğunu varsayacağız. 

    Şimdi ilk yapılacak şey sözellik ölçeklemesi uygulamaktır: 
    
    ss = StandardScaler()
    scaled_dataset = ss.fit_transform(dataset)

    Şimdi orijin noktasını değerlerin ortasına kaydıralım. Bu işlem şöyle yapılabilir: 
    
    pca_dataset = scaled_dataset - np.mean(scaled_dataset, axis=0)

    Şimdi kovaryans matrisini elde edelim:

    cmat = np.cov(pca_dataset, rowvar=False)

    Şimdi de kovaryans matrisiin özdeğerlerini ve özvektörlerini elde edelim:

    evals, evects = np.linalg.eig(cmat)

    Şimdi bizim projeksiyon işlemini yapmamız gerekir. Biz ölçeklendirilmiş asıl matrisimizi nxn'lik özvektör matrisinin k 
    tanesiyle çarptığımızda artık k tane sütunlu bir matris elde ederiz. Buradaki amacımız iki sütunu tek sütuna indirgemekti. 
    Demek ki biz tek bir özvektörle çarpma yaparak tek sütunumuzu elde edeceğiz. Pekiyi n tane öz vektör arasından hangi k 
    tane özvektörü bu çarpma işlemine sokmalıyız? İşte öz değeri yüksek vektörlerin bu işlem için seçilmesi gerekmektedir. 
    Özdeğeri yüksek olan vektörü (yani sütun indeksini) şöyle elde edebiliriz:

    max_index = np.argmax(evals)
        
    Şimdi de biz bu özvektörü asıl matrisle çarpmalıyız: 

    reduced_dataset = np.matmul(pca_dataset, evects[:, max_index].reshape((-1, 1)))

    Kod bir bütün olarak aşağıda verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv('dataset.csv')
dataset = df.to_numpy('float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
scaled_dataset = ss.fit_transform(dataset)

pca_dataset = scaled_dataset - np.mean(scaled_dataset, axis=0)

cmat = np.cov(pca_dataset, rowvar=False)

evals, evects = np.linalg.eig(cmat)

max_index = np.argmax(evals)
reduced_dataset = np.matmul(pca_dataset, evects[:, max_index].reshape((-1, 1)))
print(reduced_dataset)

#----------------------------------------------------------------------------------------------------------------------------
    Temel bileşenler analizi scikit-learn kütüphanesinde sklearn.decomposition modülü içerisindeki PCA isimli sınıfla temsil 
    edilmiştir. Sınıfın kullanımı diğer scikit-learn sınıflarında olduğu gibidir. Yani PCA sınıfı türünden bir nesne yaratılır. 
    Sonra sınıfın fit ve transform  metotları (ya da fit_transform metodu) çağrılır. PCA sınıfın __init__ metodunun parametik 
    yapısı şöyledir:

    class sklearn.decomposition.PCA(n_components=None, *, copy=True, whiten=False, 
        svd_solver='auto', tol=0.0, iterated_power='auto', n_oversamples=10, power_iteration_normalizer='auto', random_state=None)

    Burada zorunlu olan ilk parametre indirgenme sonucunda elde edilecek sütun sayısını belirtmektedir. PCA nesnesi yaratıldıktan 
    sonra önce fit işlemi yapılır. Bu işlem sırasında indirgemede kullanılacak bilgiler elde edilir. Ondan sonra gerçek indirgeme 
    transform metoduyla yapılmaktadır. Tabii fit ve transform işlemleri bir arada da fit_transform metoduyla yapılabilmektedir. 

    Yukarıda da belirttiğmiz gibi eğer veri kümesinin sütunları arasında skala farklılıkları varsa PCA işleminden önce özellik 
    ölçeklemesi uygulamak gerekir. PCA işlemi için en uygun özellik ölçeklemesi yöntemi "standart ölçekleme" yani StandardScaler 
    sınıfı ile gerçekleştirilen ölçeklemedir. 

    Yukarıda manuel olarak yaptığımız PCA işlemi aşağıda scikit-learn içerisindeki PCA sınıfıyla gerçekleştirilmiştir. Her iki
    işlem sonucunda aynı değerlerin elde edildiğine dikkat ediniz. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('dataset.csv')
dataset = df.to_numpy('float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
scaled_dataset = ss.fit_transform(dataset)

from sklearn.decomposition import PCA

pca = PCA(1)

reduced_dataset = pca.fit_transform(scaled_dataset)
print(reduced_dataset)

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "Boston Housing Prices" veri kümesi üzerinde PCA işlemi uygulanmıştır. Bu veri kümesi 13 sütun oluşmaktadır. 
    Biz aşağıdaki örnekte bu 13 sütunu 10'a indirdik.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset_x)
scaled_dataset_x = ss.transform(dataset_x)

from sklearn.decomposition import PCA

pca = PCA(10)

reduced_dataset_x = pca.fit_transform(scaled_dataset_x)
print(reduced_dataset_x)

print(dataset_x.shape)
print(reduced_dataset_x.shape)

#----------------------------------------------------------------------------------------------------------------------------
    Şüphesiz PCA işlemiyle indirginen veri kümesi ile oluşturulan modelde predict işlemini yaparken predict işlemi için 
    kullanılacak veri kümesini yine özellik indirgemesine sokarak eğitim sırasındaki veri kümesi biçimine dönüştürmemiz gerekir. 
    Yukarıdaki örnekte biz önce StandardScaler ve sonra da PCA işlemlerini uyguladık. Muhtemelen asıl modelimizde bunun sonucunda 
    elde edilen veri kümesini kullanacağız. O halde "predict" işleminde predict edilecek verileri de önce StnadardScaler ve PCA 
    işlemlerine sokmamız gerekir. Tabii predict veri kümesi eitimde kullanılan StandardScaler ve PCA bilgilertiyle transform 
    edilmelidir. 

    Aşağıdaki örnekte 13 sütundan oluşan "Boston Housing Prices" veri kümesi önce StandardScaler sınıfı ile ölçeklendirilmiştir. 
    Daha sonra standardize edilmiş veri kümesi PCA işlemine sokularak 10 sütuna indirgenmiştir. Daha sonra da yapay sinir ağı 
    yoluyla eğitim, test ve kestirim işlemleri yapılmıştır. Burada 13 sütunun 10 sütuna indirilmesinin önemli bir avantajı 
    muhtemelen olmayacaktır. Bu örnek yalnızca PCA sınıfının bu tür durumlarda nasıl kullanılacağını açıklamak verilmiştir. 

    Veri kümesinin birtakım peşi sıra işlemlere sokulması (örneğin önce normalizasyon sonra PCA gibi) bazen sıkıcı olabimektedir. 
    Bu tür peşi sıra yapılacak işlemleri daha basit ele almak için sckit-learn kütüphanesinde Pipeline isimli bir sınıf da 
    bulundurulmuştur. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(training_dataset_x)
scaled_training_dataset_x = ss.transform(training_dataset_x)
scaled_test_dataset_x = ss.transform(test_dataset_x)

from sklearn.decomposition import PCA

pca = PCA(10)

pca.fit(scaled_training_dataset_x)
reduced_training_dataset_x = pca.transform(scaled_training_dataset_x)
reduced_test_dataset_x = pca.transform(scaled_test_dataset_x)

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense

model = Sequential(name='Boston-Housing-Price')
model.add(Dense(64, activation='relu', input_dim=reduced_training_dataset_x.shape[1], name='Hidden-1'))
model.add(Dense(64, activation='relu', name='Hidden-2'))
model.add(Dense(1, activation='linear', name='Output'))

model.summary()

model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])
hist = model.fit(reduced_training_dataset_x, training_dataset_y, batch_size=32, epochs=200, validation_split=0.2)

import matplotlib.pyplot as plt

plt.figure(figsize=(15, 5))
plt.title('Epoch-Loss Graph', fontsize=14, fontweight='bold')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.xticks(range(0, 210, 10))

plt.plot(hist.epoch, hist.history['loss'])
plt.plot(hist.epoch, hist.history['val_loss'])
plt.legend(['Loss', 'Validation Loss'])
plt.show()

plt.figure(figsize=(15, 5))
plt.title('Epoch-Mean Absolute Error Graph', fontsize=14, fontweight='bold')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.xticks(range(0, 210, 10))

plt.plot(hist.epoch, hist.history['mae'])
plt.plot(hist.epoch, hist.history['val_mae'])
plt.legend(['Mean Absolute Error', 'Validation Mean Absolute Error'])
plt.show()

eval_result = model.evaluate(reduced_test_dataset_x, test_dataset_y)

for i in range(len(eval_result)):
    print(f'{model.metrics_names[i]}: {eval_result[i]}')
    
import numpy as np

predict_data = np.array([[0.11747, 12.50, 7.870, 0, 0.5240, 6.0090, 82.90, 6.2267, 5, 311.0, 15.20, 396.90, 13.27]])

scaled_predict_data = ss.transform(predict_data)
reduced_predict_data = pca.transform(scaled_predict_data)
predict_result = model.predict(reduced_predict_data)

for val in predict_result[:, 0]:
    print(val)
    
model.save('boston.h5')

import pickle

with open('boston.pickle', 'wb') as f:
    pickle.dump(ss, f)
    pickle.dump(pca, f)
    
#----------------------------------------------------------------------------------------------------------------------------
    PCA sınıfında fit işlemi sonucunda nesne üzerinde bazı öznitelikler oluşturulmaktadır. Bu öznitelikler PCA işleminin
    matematiksel temeline ilişkin bilgiler vermektedir. Burada uygulamacı için en önemli iki öznitelik explained_variance_
    ve explained_variance_ratio_ öznitelikleridir. PCA işlemi sonucunda elde edilen "açıklanan varyans (explained variance)"
    değeri dönüştürmedeki kayıp hakkında bilgi veren en önemli göstergedir. Açıklanan varyans oranları indirgenmiş sütunların
    asıl veri kümesini temsil etme kuvvetini belirtmektedir.  Örneğin bir sütunun açıklanan varyans oranı 0.4 ise bu sütun 
    tek başına tüm veri kümesindeki bilgilerin yüzde 40'ını temsil etmektedir.Açıklanan varyans oranlarının toplam 1 olmaz. 
    Çünkü indirgemede bir kayıp da söz konusudur. Açıklanan varyans oranları indirgenmiş sütunların asıl veri kümesini açıklamakta 
    ne kadar etkili olduğu konusunda da bize fikir vermektedir. Örneğin yukarıdaki "Boston Housing Prices" veri kümesini 
    10 sütuna indirgedidiğimizde bu sütunların açıklanan varyansları PCA sınıfının explained_variance_ratio_ özniteliğinden 
    şöyle elde edilmiştir:

    array([0.47011107, 0.10884895, 0.09291499, 0.06930587, 0.06372181,  0.05212396, 0.04226861, 
            0.03040597, 0.02087826, 0.01714009], dtype=float32)

    Bu değerlerin toplamı 0.9677195865660906 biçimindedir. BU açıklanan varyans oranlarına baktığımızda örneğin ilk sütunun 
    en önemli bilgiyi barındırdığı görülmektedir.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Programcı tüm sütunların açıklanan varyans oranlarını toplayarak indirgenmiş olan veri kümesinin asıl veri kümesinin yüzde 
    kaçını temsil edebildiğini görebilir. Örneğin Boston Housing Prices veri kümesi için bu işlemi 1'den başlayarak n'e kadar 
    tek tek yapalım:

    for i in range(1, dataset_x.shape[1] + 1):
        pca = PCA(i)
        pca.fit(scaled_dataset_x)
        total_ratio = np.sum(pca.explained_variance_ratio_)
        print(f'{i} ---> {total_ratio}')
      
    Programın çalıştırışması sonucunda şöyle bir çıktı elde edilmiştir:

    1 ---> 0.471296101808548
    2 ---> 0.5815482139587402
    3 ---> 0.6771341562271118
    4 ---> 0.7431014180183411
    5 ---> 0.8073177337646484
    6 ---> 0.8578882217407227
    7 ---> 0.89906907081604
    8 ---> 0.929538369178772
    9 ---> 0.9508417248725891
    10 ---> 0.9677831530570984
    11 ---> 0.9820914268493652
    12 ---> 0.9951147437095642
    13 ---> 1.0000001192092896
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset_x)
scaled_dataset_x = ss.transform(dataset_x)

import numpy as np
from sklearn.decomposition import PCA

for i in range(1, dataset_x.shape[1] + 1):
    pca = PCA(i)
    pca.fit(scaled_dataset_x)
    total_ratio = np.sum(pca.explained_variance_ratio_)
    print(f'{i} ---> {total_ratio}')
    
#----------------------------------------------------------------------------------------------------------------------------
    O halde PCA işleminde indirgenecek sütun sayısı nasıl belirlenmelidir? Bunun için temelde iki yöntem sık kullanılmaktadır. 
    Birinci yöntemde uygulamacı belli bir temsil oranını belirler. Toplam açıklanan varyans yüzdesinin o oranı kartşıladığı 
    sütun sayısını elde eder. İkinci yöntemde uygulamacı toplam açıklanan varyans yüzdelerinin grafiğini inceleyerek görsel 
    bir biçimde kararını verir. 

    Birinci yöntem özetle aşağıdaki kodda olduğu gibi uygulanabilir:

    TARGET_RATIO = 0.7

    for i in range(1, dataset_x.shape[1] + 1):
        pca = PCA(i)
        pca.fit(scaled_dataset_x)
        total_ratio = np.sum(pca.explained_variance_ratio_)
        if total_ratio >= TARGET_RATIO:
            break

    Aşağıda bu yöntemin uygulanışına bir örnek verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

TARGET_RATIO = 0.7

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset_x)
scaled_dataset_x = ss.transform(dataset_x)

import numpy as np
from sklearn.decomposition import PCA

for i in range(1, dataset_x.shape[1] + 1):
    pca = PCA(i)
    pca.fit(scaled_dataset_x)
    total_ratio = np.sum(pca.explained_variance_ratio_)
    if total_ratio >= TARGET_RATIO:
        break
    
print(f'Number of features: {i}')

#----------------------------------------------------------------------------------------------------------------------------
    İkinci yöntemde uygulamacı toplam açıklanan varyansın ya da bunun oranının grafiğini çizer. Bu grafikte yatay eksende özellik 
    sayıları düşey eksende açıklanan varyans oranları bulunur. Bu grafik önce sert bir biçimde yükselmekte ve sonra yavaş yavaş 
    yatay bir seyire doğru hareket etmektedir. İşte eğrinin yatay seyire geçtiği nokta gözle tespit edilir. Buna tıpkı kümelemede 
    olduğu gibi "dirsek noktası (elbow point)" da denilmektedir. 

    Aşağıdaki örnekte "Boston Housing Price" için böyle bir grafik çizilmiştir. Bu veri kümesinde çok az sayıda sütun vardır. 
    Dolayısıyla eğrinin yataya geçmesi açık bir biçimde görülmemektedir. Ancak yine bu grafik yorumlandığında 9 gibi bir değerin
    uygun olduğu görülmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset_x)
scaled_dataset_x = ss.transform(dataset_x)

import numpy as np
from sklearn.decomposition import PCA

total_ratios = []
for i in range(1, dataset_x.shape[1] + 1):
    pca = PCA(i)
    pca.fit(scaled_dataset_x)
    total_ratio = np.sum(pca.explained_variance_ratio_)
    total_ratios.append(total_ratio)
    
import matplotlib.pyplot as plt

plt.figure(figsize=(15, 8))
plt.title('Optimal number of Featured')
plt.plot(range(1, dataset_x.shape[1] + 1), total_ratios, color='red')
plt.plot(range(1, dataset_x.shape[1] + 1), total_ratios, 'bo', color='blue')
plt.legend(['Total explained variance ratio'])
plt.xlabel('Nuber of Features')
plt.ylabel('Ratio')
plt.xticks(range(1, dataset_x.shape[1] + 1))

plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de MNIST örneğinde (784 özellik vardı) toplam açıklanan varyans oranlarının grafiğini çizdirelim.
#----------------------------------------------------------------------------------------------------------------------------

from tensorflow.keras.datasets import mnist

(training_dataset_x, training_dataset_y), (test_dataset_x, test_dataset_y) = mnist.load_data()

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
for i in range(9):
    plt.subplot(3, 3, i + 1)
    plt.title(str(training_dataset_y[i]), fontsize=14)
    plt.imshow(training_dataset_x[i], cmap='gray')
    
plt.show()

from tensorflow.keras.utils import to_categorical

ohe_training_dataset_y = to_categorical(training_dataset_y)
ohe_test_dataset_y = to_categorical(test_dataset_y)

scaled_training_dataset_x = training_dataset_x.reshape(-1, 784) / 255
scaled_test_dataset_x = test_dataset_x.reshape(-1, 784) / 255

import numpy as np
from sklearn.decomposition import PCA

total_ratios = []
for i in range(1, 300):
    pca = PCA(i)
    pca.fit(scaled_training_dataset_x)
    total_ratio = np.sum(pca.explained_variance_ratio_)
    total_ratios.append(total_ratio)
    print(i, end=' ')
 
import pickle

with open('mnist.pickle', 'wb') as f:
    pickle.dump(total_ratios, f)
              
import matplotlib.pyplot as plt

plt.figure(figsize=(30, 8))
plt.title('Optimal number of Featured')
plt.plot(range(1, 300), total_ratios, color='red')
plt.plot(range(1, 300), total_ratios, 'bo', color='blue')
plt.legend(['Total explained variance ratio'])
plt.xlabel('Nuber of Features')
plt.ylabel('Ratio')
plt.xticks(range(1, 300, 10))

plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    PCA işlemi çok sütunlu olan veri kümelerinin iki boyutlu grafiklerinin çizilmesi için de kullanılmaktadır. Biz de zaten 
    daha önceki örneklerimizde "zambak (iris)" veri kümesini kümeledikten sonra bu yöntemle grafiğini 
    çizmiştik. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Özellik seçimi ve özellik mühendisliği için kullanılan alternatif birtakım kütüphaneler de vardır. Bu kütüphanelerin bazıları 
    zaman içerisinde hızlı bir gelişme göstermiştir. (Makine öğrenmesi ve veri bilimi çok yüksek ivmeli bir alan olduğu için 
    bir sene içerisinde bile kütüphanelerde ve yöntemlerde yeni gelişmeeler yaşanabilmektedir.) Özellik seçimi ve mühendisliği 
    için son yıllarda gelime göstermiş olan kütüphanelerden biri de "feature-engine" isimli kütüphanedir. Kütüphane şöyle 
    yüklenebilir:

    pip install feature-engine

    Feaure-engine kütüphasindeki bazı özellikler zaten scikit-learm kütüphanesinde de bulunmaktadır. Ancak bu kütüphanenin 
    asıl yoğunlaştığı alan özellik seçimi ve mühendisliği olduğu için bu bağlamda scikit-learn kütüphanesinden daha fazla 
    yeteneğe sahiptir. Biz burada kütüphanin kullanımı için bir örnek üzerinde duracağız.
    
    Kütüphanenin ana paket ismi feature_engine biçimindedir. Örneğin:

    import feature_engine import fe

    Kütüphanenin genel arayüzü scikit-learn kütüphanesine benzetilmiştir. Yani önce bir sınıf nesnesi yaratılır. Sonra fit 
    ve transform işlemleri yapılır.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
   Örneğin feature-engine kütüphanesindeki DropCorrelatedFeatures sınıfı yüksek korelasyon filtrelemesi yapmaktadır. Biz bu 
   sınıf türünden bir nesne yaratırken korelasyon için eşik değerini veririz. Korelasyon katsayısının nasıl hesaplanacağını
   (tipik olarak "pearson") fonksiyonda belirtiriz. Sonra fit ve transform işlemlerini yaparız. Örneğin:

   CORR_THRESHOLD = 0.70

   from feature_engine.selection import DropCorrelatedFeatures

    dcf = DropCorrelatedFeatures(method='pearson', threshold=CORR_THRESHOLD)
    reduced_dataset_x = dcf.fit_transform(df)

    Burada 0.70'lik bir eşik değeri seçildiğinde Boston Housing Prices veri kümesi 10 sütuna indirgenmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

CORR_THRESHOLD = 0.70

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from feature_engine.selection import DropCorrelatedFeatures

dcf = DropCorrelatedFeatures(method='pearson', threshold=CORR_THRESHOLD)
reduced_dataset_x = dcf.fit_transform(df)

print(reduced_dataset_x.shape)

#----------------------------------------------------------------------------------------------------------------------------
    Boyutsal özellik indirgemesi için kullanılan diğer bir yönteme "Doğrusal Ayırtaç Analizi (Linear Discriminant Analysis)"
    denilmektedir. Biz bu yöntemi İngilizce LDA biçiminde ifade edeceğiz. (LDA İngilizce "Linear Discriminant Analysis" 
    sözcüklerinin ilk harflerinden yapılan kısaltmadır.) LDA sınıflandırma amacıyla oluşturulmuş veri kümelerinde denetimli 
    (supervised) biçimde uygulanan bir yöntemdir. Bu yöntemde n boyutlu uzaydaki noktalar k < n olacak biçimde k boyutlu 
    uzaydaki noktalara dönüştürülmektedir. Dönüştürmede noktaların kovaryans yapısı ya da sınıf merkezleri dikkate alınmaktadır. 
    Dolayısıyla veri kümesindeki özelliklerin (sütunların) sayısal olması gerekir. 
    
    LDA yöntemi yalnızca özellik indirgemesi için değil aynı zamanda sınıflandırma amacıyla da kullanılabilmektedir. Çünkü bu 
    yöntemde aslında noktaları birbirinden ayırmak için doğrusal vektörler oluşturulmaktadır. Biz burada LDA yöntemini özellik 
    indirgemesi amacıyla kullanacağız. Yöntemin sınıflandırma amacıyla kullanılması ileride ayrı bir bölümde ele alınmaktadır.
    
    LDA işlemi tipik olarak şu adımlarla gerçekleştirilmektedir: 

    1) Önce veri kümesi üzerinde özellik ölçeklemesi yapılır. Yöntemde kovaryans hesabı kullanıldığı için standart ölçekleme 
    tercih edilmektedir. Örneğin:

    ss = StandardScaler()
    scaled_dataset_x = ss.fit_transform(dataset_x)

    2) Her sınıf için o sınıfa dahil olan noktaların (satırların) sütunsal ortalaması elde edilir. Ortalama işlemi K-Means 
    yöntemindeki ağırlık merkezinin elde edilmesinde olduğu gibi yapılmaktadır. Örneğin:
 
    nfeatures = dataset_x.shape[1]
    labels = np.unique(dataset_y)
    mean_overall = np.mean(scaled_dataset_x, axis=0)
            
    mean_list = []
    for label in labels:
        mean_list.append(np.mean(scaled_dataset_x[dataset_y == label], axis=0))

    3) Sınıf İçi Saçılım Matrisi (Within-Class Scatter Matrix) oluşturulur. Bu matrise Sw matrisi ya da S_W matrisi de
    denilmektedir. Sınıf içi saçılım matrisi, her sınıfın kendi merkezine (ortalamasına) göre ne kadar saçıldığını ölçer. 
    LDA bağlamında sembolik bir biçimde şu biçimde tanımlanır:

    S_W = sum((dataset_xi - Mi) * (dataset_xi - Mi)^T)

    Burada dataset_xi veri kümesindeki i'inci sınıfa ilişkin satırları Mi ise i'inci sınıfa ilişkin satır ortalamasını, ^T 
    ise transpoze işlemini belirtmektedir. dataset_xi - Mi işlemi veri kümesinin her satırının kendi sütun ortalamasından 
    çıkartılması anlamına gelmektedir. Bir vektörün kendi transpozesi ile çarpılmasının "dot product" anlamına geldiğine 
    dikat ediniz. Bu işlem aşağıdaki gibi bir döngüyle yapılabilir:

    S_W = np.zeros((nfeatures, nfeatures))
    for label, mvect in zip(labels, mean_list):
        scatter = np.zeros((nfeatures, nfeatures)) 
        for row in scaled_dataset_x[dataset_y == label]:
            r = row.reshape(nfeatures, 1)
            m = mvect.reshape(nfeatures, 1)
            scatter += (r - m).dot((r - m).T)
        S_W += scatter

    4) Sınıflararası Saçılım Matrisi (Between-Class Scatte Matrix) oluşturulur. Bu matris sınıf içi saçılım matrisi gibi 
    hesaplanmaktadır. Yalnız ortalamalarda sınıf ortalamaları değil tüm noktaların ortalalamaları kullanılır:

    S_B = sum(Ni (dataset_xi - M) * (dataset_xi - M)^T)

    Buradaki Ni i'inci sınıftaki nokta sayısını M ise tüm veri kümesinin ortalamasını belirtmektedir. Bu işlem aşağıdaki kodla
    yapılabilir:

    S_B = np.zeros((nfeatures, nfeatures))
    mo = mean_overall.reshape(nfeatures, 1)  
    for label, mvect in zip(labels, mean_list):
        n = scaled_dataset_x[dataset_y == label].shape[0]
        m = mvect.reshape(nfeatures, 1)  
        S_B += n * (mvect - mo).dot((mvect - mo).T) 

    5) S_W^-1 * S_B matrisi oluşturulur. Nu işlem kodla şöyle yapılabilir:

    S_W_inv = np.linalg.pinv(S_W)
    S = S_W_inv.dot(S_B)

    6) Elde edilen bu matristen hareketle özvektörler bulunur.

    7) Bulunan özvektörler o sınıftaki satırlarla (noktalarla) çarpılır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    LDA yöntemi scikit-learn içerisindeki discriminant_analysis modülü içerisinde bulunan LinearDiscrimiantAnalysis isimli 
    sınıfla yapılmaktadır. Sınıfın __init__ metodunun parametrik yapısı şöyledir:

    class sklearn.discriminant_analysis.LinearDiscriminantAnalysis(solver='svd', shrinkage=None, priors=None, 
            n_components=None, store_covariance=False, tol=0.0001, covariance_estimator=None)

    Buradaki parametreler yöntemin matematiksel işleyişi ile ilgilidir. n_components parametresi özellik indirgemesi 
    uygulanacaksa hedeflenen özellik sayısını belirtmektedir. n_components parametresi toplam sınıf sayısından küçük olmalıdır.  
    Örneğin "zambak (iris)" veri kümesinde toplam 3 tane sınıf vardır. Bu nedenle bu veri kümesinde n_components < 3 olmak 
    zorundadır. LinearDiscriminantAnalysis nesnesi oluşturulduktan sonra dataset_x ve dataset_y değerleriyle fit işlemi yapılır. 
    Sonra da transform metodu ile dönüştürme geröekleştirilir. Yukarıda da belirttiğimiz gibi yöntemi uygulamadan önce bir özellik 
    ölçeklemesinin yapılması gerekmektedir. Örneğin:

    ss = StandardScaler()
    ss.fit(dataset_x)
    scaled_dataset_x = ss.transform(dataset_x)

    lda = LinearDiscriminantAnalysis(n_components=NFEATURES)
    lda.fit(scaled_dataset_x, dataset_y)
    transformed_dataset_x = lda.transform(scaled_dataset_x)

    Aşağıda yöntemin "zambak (iris)" veri kümesi üzerinde uygulanmasına örnek verilmiştir. Burada 4 sütun, 3 sınıftan oluşan 
    zambak veri kümesi 2 sütuna indirgenmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

NFEATURES = 2

import pandas as pd

df = pd.read_csv('iris.csv')
dataset_x = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')
dataset_y = df['Species']

from sklearn.discriminant_analysis import LinearDiscriminantAnalysis

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset_x)
scaled_dataset_x = ss.transform(dataset_x)

lda = LinearDiscriminantAnalysis(n_components=NFEATURES)
lda.fit(scaled_dataset_x, dataset_y)
transformed_dataset_x = lda.transform(scaled_dataset_x)

print(transformed_dataset_x.shape)

#----------------------------------------------------------------------------------------------------------------------------
                                            97. Ders - 26/01/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Makine öğrenmesine ilişkin kütüphanelerin çoğunda "boru hattı (pipeline)" denilen bir mekanizma bulunmaktadır. Bu mekanizmada 
    programcı peşi sıra yapılacak işlemleri bu boru hattına verir, sonra tek bir metot çağırarak bu işlemlerin peşi sıra yapılmasını 
    sağlar. Bu da kodun daha sade gözeükmesini sağlamaktadır. scikit-learn kütüphanesinde de Keras kütüphanesinde de boru hattı 
    mekanizması vardır. Tabii boru hattı mekanizması için sınıfların belli metotlara sahip olması gerekir. 

    Örneğin biz bir veri kümesi üzerinde scikit-learn kullanarak K-Means kümeleme işlemini yapmak isteyelim. Ancak veri kümemizde 
    eksik veriler de bulunuyor olsun. Biz bunun için önce SimpleImputer sınıfı ile imputation yapıp bunun sonucunu StandardScaler 
    sınıfı ile standardize edebiliriz. Bunun da sonucunu KMeans sınıfına verebiliriz. Burada çıktının girdiye verildiği bir 
    dizi işlem söz konusudur. İşte bu tür durumlarda boru hattı mekanizması kodlamyı kısaltmaktadır. Biz buradaki örneği önce 
    boru hattı mekanizmasını kullanmadan aşağıdaki gibi tek tek yapalım:

    si = SimpleImputer(strategy='mean')
    si.fit(dataset)
    output = si.transform(dataset)

    ss = StandardScaler()
    ss.fit(output)
    output = si.transform(output)

    km = KMeans(3)
    km.fit(output)
    final_output = km.tranform(output)

    Zaten biz şimdiye kadar hep bu yöntemi izledik. İşte bu işlem boru hattı mekanizması yoluyla aşağıdaki gibi tek hamlede
    de yapılabilmektedir:

    pl = Pipeline([('imputation', SimpleImputer(strategy='mean')), ('scaling', StandardScaler()), ('clustering', KMeans(3))])

    pl.fit(dataset)
    output = pl.transform(dataset)
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    scikit-learn içerisindeki Pipeline sınıfı sklearn.pipeline modülü içerisinde bulunmaktadır. Sınıfın __init__ metodunun
    parametrik yapısı şöyledir:

    class sklearn.pipeline.Pipeline(steps, *, memory=None, verbose=False)

    Buradaki steps parametresi ikili demetlerden oluşan bir liste biçiminde girilir. İki elemanlı demetlerin ilk elemanı 
    uygulamacının kendi belirlediği bir isimden ikinci elemanı ise dönüştürücü nesneden oluşmalıdır. Örneğin:

    steps = [('imputation', SimpleImputer(strategy='mean')), ('scaling', StandardScaler()), ('clustering', KMeans(3))]
    pl = Pipeline(steps)
    
    Metodun memory parametresi "cache'leme" yapılıp yapılmayacağını belirtmektedir. Default durumda bir cache'leme yapılmamaktadır. 

    Pipeline sınıfı türünden nesne yaratıldıktan sonra uygulamacı fit ve transform işlemlerini yapar. Tabii yine sınıfın 
    fit_transform metodu da vardır. fit ve transform işlemlerinde aslında bir döngü içerisinde önceki nesnenin fit ve transform 
    çıktıları sonrakine verilmektedir. transform işleminden en son nesnenin çıktısı elde edilmektedir. 

    scikit-learn kütüphanesinde kullanılan terminolojide boru hattına verilen her nesneye "dönüştürücü (transformer)" denilmektedir. 
    (Buradaki "dönüştürücü (transformer)" kavramı ile LLM'lerde kullanılan "dönüştürücü (transformer)" kavramının bir ilgisi 
    yoktur.) scikit-learn kütüphanesinde son dönüştürücüye de "nihai tahminleyici (final estimator)" denilmektedir. 

    Pekiyi buradaki dönüştürü nesnelere neden isim verilmektedir? İşte isimler bu nesnelerin daha sonra elde edilmesinde kullanılmaktadır. 
    Pipeline sınıfının named_steps isimli property elemanı bize boru hattındaki dönüştürücü nesneleri isimleri ile vermektedir. 
    named_steps property'si bir sözlük biçimindedir. Bu sözlüğün anahtarları isimlerden değerleri ise dönüştürücü nesnelerden 
    oluşmaktadır. 

    Pipeline sınıfı için __getitem__ metodu da yazılmıştır. Biz herhangi bir indeksteki dönüştürücü nesneye indeks numarasını 
    vererek [] operatörü ile de erişebiliriz. 
    
    Pekiyi Pipeline sınıfının fit metodu nasıl fit işlemi yapmaktadır? Önceki dönüştürücü nesnenin çıktısı sonraki dönüştürücü 
    nesnenin argüman yapılacağına göre aslında fit işlemi transform olmadan yapılamaz. Gerçekten de biz Pipeline nesnesi üzerinde 
    fit işlemi yaparken aslında PipeLine nesnesi dönüştürücüler üzerinde fit_transform metotlarını uygulamaktadır. 

    Nesne Yönelimli Programlama Tekniğinde Pipeline sınıfında uygulanan tasarım kalıbına "bileşim (composite)" kalıbı denilmektedir. 
    Bileşim (compoiste) kalbınında bileşim işlemini uygulayan sınıf da aynı metotlara sahip olduğu için başka bir bileşim
    nesnesinde kullanılabilmektedir. Yani biz birkaç tane Pipeline nesnesini de başka Pipeline nesnelerinde dönüştürücü olarak 
    kullanabiliriz. Örneğin:

    pl1 = Pipeline(....)
    pl2 = Pipeline(....)
    pl3 = Pipeline(....)

    final_pl = Pipeline([('pl', pl1), ('pl2', pl2), ('pl3', pl3)])
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi SimpleImputer, StandardScaler ve KMeans nesnelerini bir boru hattında birleştiren bir örnek yapalım. Bunun için 
    Pipeline nesnesini şöyle oluşturulabiliriz:

    steps = [('imputation', SimpleImputer(strategy='mean')), ('scaling', StandardScaler()), ('clustering', KMeans(3))]
    pl = Pipeline(steps)

    Şimdi biz pl nesnesi ile fit işlemi yaptığımızda tüm dönüştürücüler peşi sıra fit edilecektir:

    pl.fit(dataset)

    transform işlemi yaptığımızda da tüm nesneler peşi sıra transform edilecektir:

    distances = pl.transform(dataset)
    print(distances)

    Biz burada nihai dönüştürücüyü (final estimator) named_steps property'si yoluyla elde edebiliriz:

    km = pl.named_steps['clustering']

    Sonra da onun elemanlarına erişebiliriz:

    print(km.labels_)

    Aslında Pipeline sınıfının __getitem__ metodu da yazılmış durumdadır. Yani biz bir dönüştürücüye [] operatörü ile de 
    indeks numarası vererek erişebiliriz:

    print(pl[2].labels_)

    Aşağıda kod bir bütün olarak verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('iris.csv')
dataset = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.pipeline import Pipeline

steps = [('Imputation', SimpleImputer(strategy='mean')), ('Scaling', StandardScaler()), ('Clustering', KMeans(3))]

pl = Pipeline(steps)
distance = pl.fit_transform(dataset)
print(distances)

km = pl.named_steps['Clustering']
print(km.labels_)

print(pl[2].labels_)

#----------------------------------------------------------------------------------------------------------------------------
    Pipeline sınıfının memory parametresi ve diğer bazı özellikleri olmadan basit bir gerçekleştirimi şöyle olabilir:

    class SimplePipeline:
        def __init__(self, steps):
            self._steps = steps
            self.named_steps = dict(steps) 

        def fit(self, X, y=None):
            for name, step in self._steps:
                X = step.fit_transform(X, y)
            return self

        def transform(self, X):
            for name, step in self._steps:
                X = step.transform(X)
            return X

        def fit_transform(self, X, y=None):
            for name, step in self._steps:
                X = step.fit_transform(X, y)
            return X
        
        def __getitem__(self, index):
            return self._steps[index][1]

        def predict(self, X):
            last_step = self._steps[-1][1]
            return last_step.predict(X)

    Aşağıda kendi yazdığımız sınıfın kullanılmasına ilişkin bir örnek verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

class SimplePipeline:
    def __init__(self, steps):
        self._steps = steps
        self.named_steps = dict(steps) 

    def fit(self, X, y=None):
        for name, step in self._steps:
            X = step.fit_transform(X, y)
        return self

    def transform(self, X):
        for name, step in self._steps:
            X = step.transform(X)
        return X

    def fit_transform(self, X, y=None):
        for name, step in self._steps:
            X = step.fit_transform(X, y)
        return X
    
    def __getitem__(self, index):
        return self._steps[index][1]

    def predict(self, X):
        # Son adımda tahmin yapılması varsayılır (örneğin, modelin son adımı)
        last_step = self._steps[-1][1]
        return last_step.predict(X)

import pandas as pd

df = pd.read_csv('iris.csv')
dataset = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')

from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

steps = [('Imputation', SimpleImputer(strategy='mean')), ('Scaling', StandardScaler()), ('Clustering', KMeans(3))]

pl = SimplePipeline(steps)
pl.fit(dataset)
distances = pl.transform(dataset)
print(distances)

km = pl.named_steps['Clustering']
print(km.labels_)

print(pl[2].labels_)

#----------------------------------------------------------------------------------------------------------------------------
    Pipeline nesnesindeki dönüştürücülerin parametrelerini de elde edip değiştirebiliriz. Bunun sınıfta get_params ve set_params 
    metotları kullanılmaktadır. Bu metotlarda dönüştürücü isminin yanına __ getirerek parametre ismi belirtilerek set işlemi 
    yapılabilir. Örneğin:

    steps = [('Imputation', SimpleImputer(strategy='mean')), ('Scaling', StandardScaler()), ('Clustering', KMeans(3))]

    pl = Pipeline(steps)
    ...
    pl.set_params(Clustering__n_clusters=2)

    distances = pl.fit_transform(dataset)
    print(distances)
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Pipeline nesnesini daha kolay oluşturabilmek için sklearn.pipeline modülünde make_pipeline isimli bir fonksiyon da 
    bulundurulmuştur. Fonksiyonun parametrik yapısı şöyledir:

    sklearn.pipeline.make_pipeline(*steps, memory=None, verbose=False)

    Burada programcı dönüştürücü nesnelerini ayrı parametreler biçiminde fonksiyona verir. Fonksiyon bu nesnelerin sınıf isimlerini
    küçük harfe dönüştürerek isimleri oluşturur ve Pipeline nesnesini yaratarak ona geri döner. Fonksiyonun basit gerçekletirimi 
    aşağıdaki gibi olabilir:

    def mymake_pipeline(*steps, memory=None, verbose=False):
        corrected_steps = [(type(step).__name__.lower(), step) for step in steps] 
        return Pipeline(corrected_steps, memory=memory, verbose=verbose) 

    Örneğin:

    pl = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler(), KMeans(3))
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('iris.csv')
dataset = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')

from sklearn.pipeline import make_pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

pl = make_pipeline(SimpleImputer(strategy='mean'), StandardScaler(), KMeans(3))
pl.fit(dataset)
distances = pl.transform(dataset)
print(distances)

km = pl.named_steps['kmeans']
print(km.labels_)

#----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirttiğimiz gibi eğer biz kendi sınıfımızda fit, transform, fit_transform, predict gibi metotları bulundurmuşsak
    kendi sınıfımız türünden nesneleri de scikit-learn kütüphanesindeki boru hattı mekanizmasına dahil edebiliriz. Örneğin 
    feature-engine kütüphanesindeki sınıfların da fit, transform, fit_transform, predict gibi metotları olduğu için bunlar boru 
    hattı mekanizmasına dahil edilebilmektedir:

    pl = make_pipeline(DropCorrelatedFeatures(threshold=0.7), SimpleImputer(strategy='mean'), StandardScaler(), KMeans(3))

    Aşağıda MyStandardScaler isimli sarma bir sınıf yazılmıştır. Bu sınıfın ilgili metotları StandardScaler sınıfının ilgili
    metotlarını çağrımaktadır. Biz bu sınıfı fit, transform ve fit_transform mtotları olduğu içinm boru hattı mekanizmasına 
    dahil edebiliriz:

    class MyStandardScaler:
        def __init__(self):
            self._ss = StandardScaler()
            
        def fit(self, X, y=None):
            return self._ss.fit(X, y) 
        
        def transform(self, X):
            return self._ss.transform(X) 
        
        def fit_transform(self, X, y=None):
            return self._ss.fit_transform(X, y) 

    pl = make_pipeline(SimpleImputer(strategy='mean'), MyStandardScaler(), KMeans(3))
    distances = pl.fit_transform(dataset)
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('iris.csv')
dataset = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')

from sklearn.pipeline import make_pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans

class MyStandardScaler:
    def __init__(self):
        self._ss = StandardScaler()
        
    def fit(self, X, y=None):
        return self._ss.fit(X, y) 
    
    def transform(self, X):
        return self._ss.transform(X) 
    
    def fit_transform(self, X, y=None):
        return self._ss.fit_transform(X, y) 

pl = make_pipeline(SimpleImputer(strategy='mean'), MyStandardScaler(), KMeans(3))
distances = pl.fit_transform(dataset)
print(distances)

km = pl.named_steps['kmeans']
print(km.labels_)

#----------------------------------------------------------------------------------------------------------------------------
                                            98. Ders - 01/02/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Anomalilerin tespit edilmesi (anomaly detection) makine öğrenmesinin popüler konularından biridir. Elimizde bir veri kümesi 
    olabilir. Burada bazı satırlar diğerlerinden şüphe oluşturacak biçimde farklı olabilir. Biz de bu farklı olan satırlatın 
    belirlenmesini isteyebiliriz. İngilizce "anomalilerin tespit edilmesi (anomaly detection)" terimi yerine "outliers", 
    "novelties", "noise", "deviations", "exceptions" gibi terimler de kullanılabilmektedir. 

    Anomalilerin tespit edilmesi pek çok alanda kullanılabilecek bir uygulama konusudur. Örneğin bankalardaki şüpheli işlemlerin
    tespit edilmeye çalışılması, bilgisayarlardaki zararlı unsurların tespit edilmesi (malware detection), biyomedikal görüntülerdeki
    anomalilerin otomatik tespiti gibi pek çok faydalı amaçlar sıralanabilir. Anomalilerin tespit edilmesi "denetimli (supervied)" 
    öğrenme yöntemleriyle yapılabilirse de ana olarak bu konu "denetimsiz (unsupervied)" öğrenme konularının kapsamı içerisine 
    girmektedir. Elimizde anamali içeren ve içermeyen bilgiler varsa biz denetimli yöntemlerle kestirim yapabiliriz. Ancak genellikle 
    bu tür durumlarda elimizde yeteri kadar anomali içeren veri bulunmaz. Bu nedenle bu konuda daha çok denetimsiz (unsupervised) 
    öğrenme yöntemleri kullanılmaktadır. Anomalalierin tespit edilmesi için pek çok yöntemden faydalanılabilmektedir. Örneğin:

    - Yoğunluk Tabanlı Yöntemler (Isolation Forest, K-Nearest Neighbor, vs.)
    - En Yakın Komuşuk Yöntemleri (k-Nearest Neighbors)
    - Destek Vektör Makineleri (Support Vector Machines)
    - Bayes Ağları (Bayesian Networks)
    - Saklı Markov Modelleri (Hidden Markov Models)
    - Kümeleme Esasına Dayanan Yöntemler (Culestering Based Methods)
    - Bulanık Mantık Kullanılan Yöntemler (Fuzzy Logic Methods)
    - Boyutsal Özellik İndirgemesi ve Yükseltmesi Esasına Dayanan Yöntemler

    Biz burada "kümeleme esasına dayanan yöntemler" ile "boyutsal özellik indirgemesi ve yükseltmesi esasına dayanan yöntemler" 
    üzerinde duracağız.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Anomalilerin tespit edilmesinde en çok kullanılan yöntem gruplarından biri "kümeleme tabanlı" yöntem gruplarıdır. Kümeleme 
    tabanlı anomoli tespit sürecinde veri kümesini oluşturan noktalar denetimsiz kümeleme işlemine sokulur. Kümeleme sonucunda 
    kopuk noktalar (gürültü noktaları) tespit edilir. Bunun için daha çok DBSCAN, OPTICS gibi yoğunluk tabanlı kümeleme yöntemleri 
    tercih edilmektedir. 
    
    Anımsanacağı gibi bu yöntemlerde belli bir eps ve min_samples hyper parametreleri uygulamacı tarafından veriliyor ve bunun 
    sonucunda da kümelemedeki gürültü noktaları elde edilebiliyordu. DBSCAN sınıfında fit işleminden sonra gürültü noktalarının 
    labels_ özniteliğindeki -1 değerleriyle belirtildiğini anımsayınız. Uygulamacı eps ve min_samples değerlerini belirleyerek
    anomali tespit sıkılığını ya da gevşekliğini ayarlayabilmektedir. Örneğin:

    EPS = 0.70
    MIN_SAMPLES = 5

    dbs = DBSCAN(eps=EPS, min_samples=MIN_SAMPLES)
    dbs.fit(dataset)
    anomaly_data = dataset[dbs.labels_ == -1]
    
    Aşağıdaki örnekte zambak veri kümesi üzerinde DBSCAN kümeleme algoritması uygulanmıştır ve eps ve min_samples değeri 
    ayarlanarak anomali içeren noktalar X tespit edilmiş ve grafik üzerinde X sembolüyle gösterilmiştir. Bu örnekte siz de 
    min_samples değerini sabit bırakarak eps değerini değiştirip anomalileri tespit ediniz. 
#----------------------------------------------------------------------------------------------------------------------------

EPS = 0.70
MIN_SAMPLES = 5

import pandas as pd

df = pd.read_csv('iris.csv')
dataset = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset)
transformed_dataset = ss.transform(dataset)

from sklearn.cluster import DBSCAN

dbs = DBSCAN(eps=EPS, min_samples=MIN_SAMPLES)
dbs.fit(transformed_dataset)

import numpy as np

nclusters = np.max(dbs.labels_) + 1

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
reduced_dataset = pca.fit_transform(dataset)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
plt.title('Clustered Points')

plt.title('DBSCAN Clustered Points', fontsize=12)
for i in range(nclusters):
    plt.scatter(reduced_dataset[dbs.labels_ == i, 0], reduced_dataset[dbs.labels_ == i, 1])     

plt.scatter(reduced_dataset[dbs.labels_ == -1, 0], reduced_dataset[dbs.labels_ == -1, 1], marker='x', color='black')

legends = [f'Cluster-{i}' for i in range(1, nclusters + 1)]
legends.append('Noise Points')
plt.legend(legends, loc='lower right')

plt.show()

anomaly_data = dataset[dbs.labels_ == -1]

print(f'Number of points with anomly: {len(anomaly_data)}')

#----------------------------------------------------------------------------------------------------------------------------
    Anomalilerin tespit edilmesi için K-Means kümeleme yöntemi de kullanılabilir. Bu durumda biz K-Means algoritmasını tek 
    küme oluşturacak biçimde belirleriz. Böylece noktaların bir ağırlık merkezini elde ederiz. Sonra da bu ağırlık merkezine 
    en uzak noktaları belirlemeye çalışabiliriz. Tabii aslında burada K-Means algoritması yalnızca ağırlık merkezi bulmak için 
    kullanılmaktadır. Biz bu ağırlık merkezini aslında manuel biçimde de bulabiliriz. Aşağıda zambak verileri için bu yöntem 
    kullanılmıştır. 

    Bu yöntem anomali tespiti için zayıf bir yöntemdir. DBSCAN kümeleme yöntemleri anomali tespiti için daha iyi sonuç 
    vermektedir. 
#----------------------------------------------------------------------------------------------------------------------------

NANOMALY_POINTS = 5

import numpy as np
import pandas as pd

df = pd.read_csv('iris.csv')
dataset = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset)
scaled_dataset = ss.transform(dataset)

from sklearn.cluster import KMeans

km = KMeans(n_clusters=1, n_init=10)
distances = km.fit_transform(scaled_dataset)

arg_sorted_distances = np.argsort(distances[:, 0])

anomaly_points = dataset[arg_sorted_distances[-NANOMALY_POINTS:]]
print(anomaly_points)

import matplotlib.pyplot as plt
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
pca.fit(dataset)
reduced_dataset = pca.transform(dataset)
reduced_normal_points = reduced_dataset[arg_sorted_distances[:-NANOMALY_POINTS]]
reduced_anomaly_points = reduced_dataset[arg_sorted_distances[-NANOMALY_POINTS:]]

scaled_centroids = ss.inverse_transform(km.cluster_centers_)
reduced_centroids = pca.transform(scaled_centroids)

plt.figure(figsize=(10, 8))
plt.title('K-Means Anomaly Detection')
plt.scatter(reduced_normal_points[:, 0], reduced_normal_points[:, 1], color='blue')
plt.scatter(reduced_anomaly_points[:, 0], reduced_anomaly_points[:, 1], color='red')

plt.legend(['Normal Points', 'Anomaly Points'])
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Anomali tespiti için "k En Yakın Komşuluk (k-NN) yöntemi" de kullanılabilir. Bu yöntemde her noktanın en yakın N tane 
    komşusu elde edilir. Bu komşuların ilgili noktaya uzaklarının ortalaması hesaplanır. Böylece belli bir eşik değerini aşan 
    noktalar anomali olarak belirlenir. Bunun için scikit-learn kütüphanesindeki NearestNeigbors sınıfından faydalanabiliriz. 

    class sklearn.neighbors.NearestNeighbors(*, n_neighbors=5, radius=1.0, algorithm='auto', leaf_size=30, 
            metric='minkowski', p=2, metric_params=None, n_jobs=None)

    Metodun n_neighbors parametresi en yakın kaç komuşu noktanın bulunacağını belirtmektedir. metric parametresi yine uzaklık 
    için kullanılacak metriğin ne olduğunu belirtir. Diğer parametreler en yakın komşulukların oluşturulması için kullanılan 
    veri yapısı ile ilgilidir. Bu sınıf "denetimsiz (unsupervised)" bir işlem yapmaktadır. Yani biz fit işleminde yalnızca 
    dataset_x değerlerini veririz. Sınıfın kneighbors metodu verilen noktaların en yakın k komşusunu bulmaktadır. Tabii biz 
    bu metoda aynı dataset_x noktalarını verirsek bu durumda metot bize mevcut noktaların en yakın k komşularını verecektir. 
    Örneğin:
 
    nn = NearestNeighbors(n_neighbors=NNEIGHBORS)
    nn.fit(dataset)
    distances, indices = nn.kneighbors(dataset)

    kneighbors metodu ikili bir demete geri dönmektedir. Demetin birinci elemanı verilen noktalara en yakın k tane noktaya 
    olan uzaklıkları verir. İkinci elemanı ise bu k noktanın asıl veri kümesindeki indekslarini vermektedir. 

    Pekiyi biz bu yöntemde her noktanın en yakın k komşusuna uzaklıkları elde ettikten sonra nasıl bir ölçüt kullanarak 
    noktaların anomali oluşturup oluşturmadığına karar verebiliriz? İlk akla gelen yöntem noktalara en yakın k komşusunun 
    uzaklıklarının ortalamalarını hesaplamak sonra bu ortalamaları standart normal dağılıma uydurup tek taraftan kesim 
    uygulamaktır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                            99. Ders - 02/02/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi k-NN yöntemiyle "zambak (iris)" veri kümesinde anomali tespiti yapan bir örnek üzerinde duralım. Veri kümesinin 
    dataset dizisi biçiminde okunduğunu varsayalım. Her noktanın en yakın NNEIGHBORS kadar komşusunu aşağıdaki gibi elde 
    edebiliriz:

    nn = NearestNeighbors(n_neighbors=NNEIGHBORS)
    nn.fit(dataset)
    distances, indices = nn.kneighbors(dataset)

    Tabii bu komuşuluğa noktanın kendisi de dahil edilmektedir. Her noktanın kendisine uzaklığı 0 olacaktır. Yani elde edilen
    distances matrislerinin ilk elemanları 0 olacaktır. Hesaplamalarda bu 0 olan sütun dilimlemeyle tamamen atılabilir. Şimdi
    bu her noktaya en yakın k tane noktanın ortalamalarını hesaplayabiliriz:

    mean_distances = distances[:, 1:].mean(axis=1)

    Burada 0 olan sütunun atıldığına dikkat ediniz. Tabii biz bu sütunu atmasak da aslında değişen bir şey olmayacaktır. Eşik 
    değeri belirlemek için bu ortalamaları normal dağılıma uydurabiliriz. Böylece eşik olarak ortalamadan belli bir standart 
    sapmayı alabiliriz:

    mean_mean_distances = np.mean(mean_distances)
    std_mean_distances = np.std(mean_distances, ddof=0)
    threshold = mean_mean_distances + THRESHOLD_STD * std_mean_distances

    Burada THRESHOLD_STD ortalamadan kaç standart sapma uzak olanların anomali olarak değerlendirileceğini belirtmektedir. 
    Bu değerin tamsayı olması gerekmemektedir. Anımsanacağı gibi ortalamadan iki standart sapma uzaklık çift taraflı %95 
    civarında 3 standart sapma uzaklık %99 civarında alan kaplamaktadır. Tabii biz burada iki taraflı değil tek taraflı bir 
    uzaklık uygulamaktayız. Bu işlemlerden sonra artık normal noktalar ve anomali noktaları aşağıdaki gibi elde edilebilir:

    normal_points = dataset[mean_distances <= threshold]
    anomaly_points = dataset[mean_distances > threshold]
    normal_indices = np.where(mean_distances <= threshold)
    anomaly_indices = np.where(mean_distances > threshold)

    Aşağıda kodun tamamı verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

NNEIGHBORS = 5
THRESHOLD_STD = 2

import numpy as np
import pandas as pd

df = pd.read_csv('iris.csv')
dataset = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(dataset)
scaled_dataset = ss.transform(dataset)

from sklearn.neighbors import NearestNeighbors

nn = NearestNeighbors(n_neighbors=NNEIGHBORS)
nn.fit(dataset)
distances, indices = nn.kneighbors(dataset)

mean_distances = distances[:, 1:].mean(axis=1)

mean_mean_distances = np.mean(mean_distances)
std_mean_distances = np.std(mean_distances, ddof=0)
threshold = mean_mean_distances + THRESHOLD_STD * std_mean_distances

normal_points = dataset[mean_distances <= threshold]
anomaly_points = dataset[mean_distances > threshold]
normal_indices = np.where(mean_distances <= threshold)
anomaly_indices = np.where(mean_distances > threshold)

print(f'Anomaly points:\n{anomaly_points}')
print(f'Anomaly indices: {anomaly_indices}')

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
reduced_dataset = pca.fit_transform(dataset)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
plt.title('Clustered Points')

plt.title('k-NN Anomaly Detection', fontsize=12)
plt.scatter(reduced_dataset[normal_indices, 0], reduced_dataset[normal_indices, 1])     

plt.scatter(reduced_dataset[anomaly_indices, 0], reduced_dataset[anomaly_indices, 1], marker='x', color='red')

plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de biraz daha gerçekçi bir örnek üzerinde çalışalım. Bu örnekte kredi kartı işlemlerine yönelik çeşitli bilgiler 
    toplanmıştır. Bu bilgiler PCA işlemine sokularak 29 sütuna indirilmiştir. İlk sütun işlemin göreli zamanını belirtmektedir. 
    Bu sütun veri kümesinden atılabilir. Son sütun ise işlemin anomali içerip içermediğini belirtmektedir. Bu sütun "0" ise 
    işlem anomali içermemektedir, "1" ise anomali içermektedir. Yani veri kümesi denetimli (supervised) bir biçimde oluşturulmuştur. 
    Veri kümesindeki toplam satır sayısı 284807 tanedir. Bunların yalnızca 492 tanesi anomali içermektedir. Veri kümesi aşağıdaki 
    bağlantıdan "creditcard.csv" ismiyle indirilebilir:

    https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud?resource=download

    Veri kümesi üzerinde PCA işlemi uygulanmış durumdadır. Dolayısıyla PCA işleminden önce zaten özellik ölçeklemesi yapılmıştır. 
    Bu nedenle biz bu örnekte özellik ölçeklemesi yapmayacağız. 

    Aşağıdaki örnekte min_samples=5, eps=10 alınarak 100000 tane kredi kart verisi DBSCAN işlemine sokulmuş bu parametrelerle 
    707 tane nokta anomali olarak tespit edilmiştir. DBSCAN parametreleriyle oynayarak anomali miktarını ayarlayabilirsiniz. 
    Buradaki kredi kart verilerini sayısı çok yüksektir. İşlemler yerel makinede fazlaca zaman alabilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

EPS = 10

import pandas as pd

df = pd.read_csv('creditcard.csv', dtype='float32')

dataset = df.iloc[:100000, 1:-1].to_numpy()
dataset_y = df.iloc[:100000, -1].to_numpy()

import numpy as np
from sklearn.cluster import DBSCAN

dbs = DBSCAN(eps=EPS, min_samples=5)
dbs.fit(dataset)
from sklearn.decomposition import PCA

pca = PCA(n_components=2)
reduced_dataset = pca.fit_transform(dataset)

nclusters = np.max(dbs.labels_) + 1

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
plt.title('Clustered Points')
for i in range(nclusters):
    plt.scatter(reduced_dataset[dbs.labels_ == i, 0], reduced_dataset[dbs.labels_ == i, 1])    
plt.scatter(reduced_dataset[dbs.labels_ == -1, 0], reduced_dataset[dbs.labels_ == -1, 1], marker='x', color='black')
legends = [f'Cluster-{i}' for i in range(1, nclusters + 1)]
legends.append('Noise Points')
plt.legend(legends, loc='lower right')
plt.show()

anomaly_data = dataset[dbs.labels_ == -1]
print(f'Number of points with anomly: {len(anomaly_data)}')

original_anomaly_indices = np.where(dataset_y == 1)
dbscan_anomaly_indices = np.where(dbs.labels_ == -1)
intersect_anomalies = np.intersect1d(original_anomaly_indices, dbscan_anomaly_indices)

success_ratio = len(intersect_anomalies) / (dataset_y == 1).sum()
print(f'Success ratio: {success_ratio}')        # %26

#----------------------------------------------------------------------------------------------------------------------------
    K-Means yöntemi ile kredi kart verileri üzerinde anomali tespiti de aşağıdaki gibi yapılabilir.
#----------------------------------------------------------------------------------------------------------------------------

NANOMALY_POINTS = 2000

import pandas as pd

df = pd.read_csv('creditcard.csv', dtype='float32')

dataset = df.iloc[:, 1:-1].to_numpy()
dataset_y = df['Class'].to_numpy()

import numpy as np
from sklearn.cluster import KMeans

kmeans = KMeans(n_clusters=1)
distances = kmeans.fit_transform(dataset)

arg_sorted_distances = np.argsort(distances[:, 0])

anomaly_points = dataset[arg_sorted_distances[-NANOMALY_POINTS:]]
print(anomaly_points)

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
decomposed_dataset = pca.fit_transform(dataset)

decomposed_normal_points = decomposed_dataset[arg_sorted_distances[:-NANOMALY_POINTS]]
decomposed_anomaly_points = decomposed_dataset[arg_sorted_distances[-NANOMALY_POINTS:]]

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
plt.title('K-Means Anomaly Detection')
plt.scatter(decomposed_normal_points[:, 0], decomposed_normal_points[:, 1], color='blue')
plt.scatter(decomposed_anomaly_points[:, 0], decomposed_anomaly_points[:, 1], color='red')
plt.legend(['Normal Points', 'Anomaly Points'])
plt.show()

original_anomaly_indices = np.where(dataset_y == 1)
kmeans_anomaly_indices = arg_sorted_distances[-NANOMALY_POINTS:]

intersect_anomalies = np.intersect1d(original_anomaly_indices, kmeans_anomaly_indices)

print(len(intersect_anomalies))

#----------------------------------------------------------------------------------------------------------------------------
    Özellik indirgemesi ve yükseltmesi yoluyla da anomali tespiti yapılabilmektedir. Bunun için n tane sütuna sahip olan veri 
    kümesi PCA işlemi ile k < n olmak üzere k tane sütuna indirgenir. Sonra yeniden bu noktalar n tane sütuna yükseltilir. Bu 
    işlemler sonucunda orijinal noktalarla indirgenip yükseltilmiş noktalar arasındaki uzaklıklar ne kadar fazla ise bu noktaların 
    anomali olasılığı o kadar yükselmektedir. Pekiyi bu yöntemde özellikleri kaça kadar düşürmeliyiz? Aslında bu noktada deneme 
    yanılma yöntemine gidilebilir. Ancak açıklanan varyans oranının %70'lerin aşağısına düşürülemsi uygun olabilmektedir. Bu 
    işlemi "zambak (iris)" veri kümesi üzerinde gerçekleştirelim. Veri kümesinin dataset biçiminde bir NumPy dizisine okunduğunu
    varsayıyoruz. Bunun için önce PCA işlemi ile veri kümesi üzerinde özellik indirgemesi yaparız. Örneğin zambak veri kümesi 
    için 4 özelliği 2 özelliğe indirgeyelim:

    pca = PCA(n_components=2)
    reduced_dataset = pca.fit_transform(dataset)

    Anımsanacağı gibi bu tür sınıfların inverse_transform isimli metotları da vardı. PCA sınıfının inverse_transform metodu 
    veri kümesini ters dönüşüm yaparak orijinal boyuta yükseltmektedir:

    inversed_dataset = pca.inverse_transform(reduced_dataset)

    Biz bu iki veri kümesi arasındaki farka bakarak bu farkın yüksek olduğu noktaları anomali noktaları biçiminde belirleyeceğiz. 
    Pekiyi buradaki ölçütümüz ne olabilir? Aslında burada çeşitli ölçütler kullanılabilir. Örneğin iki nokta arasında Öklit 
    uzaklığını ölçüt olarak kullanabiliriz. Tabii karekök alma işlemine gerek yoktur.

    def anomaly_scores(original_data, manipulated_data):
        return np.sum((original_data - manipulated_data) ** 2, axis=1) 

    Artık her nokta için anomali skorları tespit edilebilir:

    scores = anomaly_scores(dataset, inversed_dataset)

    Burada anomaly değerlerinin belli bir yüzdesi elde edilebilir. Bunun için NumPy'ın quantile fonksiyonunu kullanalım. Bu 
    fonksiyon veri kümesi içerisindeki değerlerin belli bir yüzdelik kısmını belirten değeri vermektedir:

    q = np.quantile(scores, 1 - ANOMALY_RATIO)
    anomalies = dataset[scores > q]
    normals = dataset[scores <= q]

    Görüldüğü gibi veri kümesinde elde skorlar arasında en kötü olan belli bir yüzdesi elde edilmiştir. Tabii bu işlem quantile
    fonksiyonu yerine dizinin sıraya dizilmesi ve belli bir yüzdelik kısmının elde edilmesi biçiminde manuel olarak da 
    yapılabilirdi. 

    Aşağıdaki örnekte zambak veri kümesindeki 4 sütundan 2 sütuna indirgenip yeniden 4'e yükseltilmiştir. Sonra da orijinal 
    noktalarla indirgenip yükselitlmiş noktalar arasındaki uzaklar hesaplmış ve en uzak belli sayıda nokta anomaly olarak 
    tespit edilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

REDUCTION_FEATURES = 2

ANOMALY_RATIO = 0.05

import numpy as np
import pandas as pd

df = pd.read_csv('iris.csv')
dataset = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']].to_numpy('float32')

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
scaled_dataset = ss.fit_transform(dataset)

from sklearn.decomposition import PCA

pca = PCA(n_components=REDUCTION_FEATURES)
reduced_dataset = pca.fit_transform(scaled_dataset)
inversed_dataset = pca.inverse_transform(reduced_dataset)

def anomaly_scores(original_data, manipulated_data):
    return np.sum((original_data - manipulated_data) ** 2, axis=1) 
    
scores = anomaly_scores(dataset, inversed_dataset)
q = np.quantile(scores, 1 - ANOMALY_RATIO)
anomalies = dataset[scores > q]
normals = dataset[scores <= q]

pca = PCA(n_components=2)

reduced_anomalies = dataset[scores > q]
reduced_normals = dataset[scores <= q]

import matplotlib.pyplot as plt

plt.title('Anomalies')
plt.legend(['Normal points', 'Anomalies'])
figure = plt.gcf()
figure.set_size_inches((10, 8))
plt.scatter(reduced_normals[:, 0], reduced_normals[:, 1], color='blue')
plt.scatter(reduced_anomalies[:, 0], reduced_anomalies[:, 1], marker='x', color='red')
plt.show()

print(f'Number of anomaly pointes: {len(anomalies)}')

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte kredi kartı işlemleri üzerinde özellik indgirmesi ve yükseltmesi yöntemi ile anomali tespiti yapılmıştır. 
#----------------------------------------------------------------------------------------------------------------------------

REDUCTION_FEATURES = 10
ANOMALY_RATIO = 0.0001

import numpy as np
import pandas as pd

df = pd.read_csv('creditcard.csv', dtype='float32')

dataset = df.iloc[:, 1:-1].to_numpy()
dataset_y = df.iloc[:, -1].to_numpy()

from sklearn.decomposition import PCA

pca = PCA(n_components=REDUCTION_FEATURES)
reduced_dataset = pca.fit_transform(dataset)
inversed_dataset = pca.inverse_transform(reduced_dataset)

def anomaly_scores(original_data, manipulated_data):
    return np.sum((original_data - manipulated_data) ** 2, axis=1) 
    
scores = anomaly_scores(dataset, inversed_dataset)
q = np.quantile(scores, 1 - ANOMALY_RATIO)
anomalies = dataset[scores > q]
normals = dataset[scores <= q]

pca = PCA(n_components=2)

reduced_anomalies = dataset[scores > q]
reduced_normals = dataset[scores <= q]

import matplotlib.pyplot as plt

plt.title('Anomalies')
plt.legend(['Normal points', 'Anomalies'])
figure = plt.gcf()
figure.set_size_inches((10, 8))
plt.scatter(reduced_normals[:, 0], reduced_normals[:, 1], color='blue')
plt.scatter(reduced_anomalies[:, 0], reduced_anomalies[:, 1], marker='x', color='red')
plt.show()

print(f'Number of anomaly pointes: {len(anomalies)}')

#----------------------------------------------------------------------------------------------------------------------------
    İstatistiksel sınıflandırma yöntemlerinin en yalınlarından biri "Naive Bayes" denilen yöntemdir. Burada "naive" sıfatı 
    yöntemde kullanılan karşılanması zor bazı varsayımların bulunuyor olmasından hareketle uydurulmuştur. Naive Bayes yöntemi 
    tamamen olasılık kurallarına göre sınıflandırma yapmaktadır. Naive Bayes "denetimli (supervised)" bir yöntemdir. Yöntemin 
    temeli ünlü olasılık kuramcısı Thomas Bayes'in "Bayes Kuralı (Bayes Rule)" olarak bilinen teoremine dayanmaktadır. İstatistikte 
    Bayes Kuralına "koşulu olasılık (conditional probablity)" kuralı da denilmektedir. 

    İstatistikte koşullu olasılık "bir olayın olduğu kabul edilerek başka bir olayın olasılığının hesaplanması" anlamına 
    gelmektedir. Koşullu olasılık genellikle P(A|B) biçiminde gösterilir. Burada P(A|B) ifadesi "B olayı olmuşken A olayının 
    olma olasılığı" anlamına gelmektedir. Yani buradaki olasılıkta zaten B'nin gerçekleştiği ön koşul olarak kabul edilmektedir. 

    P(A|B) olasılığı "B olmuşken A'nın olasılığı" anlamına geldiğine göre aşağıdaki gibi hesaplanır:

    P(A|B) = P(A, B) / P(B)
    
    Burada P(A, B) ifadesi P(A ∩ B) ile aynı anlamdadır. Koşullu olasılık bir aksiyon gibi kabul edilebilir. Ayrıca bir ispatı 
    yapılamamaktadır. Ancak Kolmogorov'un temel aksiyomlarına da uymaktadır. Koşuluu olasılık ifadesine bir kez daha bakınız:

    P(A|B) = P(A, B) / P(B)
    
    Bu eşitlikten P(A, B) olasılığını elde edebiliriz:

    P(A, B) = P(A|B) / P(B)

    Şimdi de bunun tersi olan P(B|A) olasılığını hesaplayalım:

    p(B|A) = P(B, A) / P(A)

    Buradan da P(A, B) olasılığını elde edilim:

    P(A, B) = p(B|A) / P(A)

    Kesişim işlemi değişme özelliğine sahip olduğuna göre P(A, B) olasılığı ile P(B, A) olasılığy aynı anlama gelmektedir:

    P(A, B) = P(A|B) / B
    P(B, A) = P(B|A) / A

    İki eşitliğin sol tarafı eşit olduğuna göre sağ tarafları da birbirlerine eşittir:

    P(A|B) * P(B) = P(B|A) * P(B)

    O halde aşağıdaki iki eşitlik elde edilir:

    P(A|B) = P(B|A) * P(A) / P(B)
    P(B|A) = P(A|B) * P(B) / P(A)

    Bu eşitliklere "Bayes Kuralı" denilmektedir. 

    Olasılık konusunda koşullu olasılıklara örnek oluşturan tipik sorular "bir koşul altında bir olasılığın verilmesi ve bunun 
    tersinin sorulması" biçimindedir. Örneğin:

    "Bir şirket çalışanları arasında üniversite mezunu olan 46 personelin 6'sının, üniversite mezunu olmayan 54 personelin 
    22'sinin sigara içtiği biliniyor. Buna göre şirketteki sigara odasında sigara içtiği görülen bir çalışanın üniversite mezunu 
    olma olasılığı nedir?"

    Bu soruda bize verilenler şunlardır: 
   
    P(sigara içiyor|üniversite mezunu) = 6 / 46
    P(sigara içiyor|üniversite mezunu değil) = 22 / 54

    Bizden istenen de şudur:

    P(üniversite mezunu|sigara içiyor)
   
    Bayes formülünde bunları yerlerine koyalım:

    P(üniversite mezunu|sigara içiyor)= P(sigare içiyor|üniversite mezunu) * P(üniversite mezunu) / P(sigara içiyor)

    P(üniversite mezunu|sigara içiyor) = (6 / 46) * (46 / 100)) / (28 / 100)

    Koşullu olasılıkla ilgili diğer bir soru çeşiti de "ayrık bütüne tamamlayan olaylarla" ilgilidir. Soruyu soran kişi
    ayrık bütüne tamamlayan olayları belirtir. Sonra bunların bazılarının içinde bulunduğu bir olayın olsılığını sorar. 
    Örneğin bütüne tamamlayan olaylar A, B, C, D, E olsun. Burada bir X olayının söz konuşu olduğunu düşünelim. 

    P(X) = P(X|A) + P(X|B) + P(X|C) + P(X|D) + P(X|E) 

    Burada koşulu olasılıkları da aşağıdaki gibi tersten açabiliriz:

    P(X|A) = (A|X) * P(X) / P(A) + (B|X) * P(X) / P(B) + (C|X) * P(X) / P(C)

    biçiminde yazılabilir. Örnek bir soru şöyle olabilir (KTÜ Olasılık ders notlarındna alınmış bir örnek):

    "Pense üretim firması, üç ayrı fabrikasında aynı penseleri üretmektedir. 1 no’lu fabrikada,hem 2 hemde 3 no’lu fabrikalardaki
    üretimlerin iki katı kadarpense üretilmektedir. Hem 1 hem de 2 no’lu fabrikalardaki üretimin %2’si, 3 no’lu fabrikadaki
    üretimin %4’ü kusurlu çıkmaktadır. Üretilen penselerin tümü aynı kasaya konularak bu kasadan rastgele bir penseçekiliyor.
    Bu pensenin kusurlu olma olasılığı nedir?"

    Bu sorada P(kusurlu_pense) olasılığı sorulmaktadır. Bu olasılık aşağıdaki biçimde ifade edilebilir:

    P(kusurlu_pense) = P(kusurlu_pense|A) + P(kusurlu_pense|B) + P(kusurlu_pense|C)
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                    100. Ders - 08/02/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------
    
#----------------------------------------------------------------------------------------------------------------------------
    Bir olayın gerçekleşme olasılığının diğer bir olayın gerçekleşmesi olasılığı ile hiçbir ilişkisi yoksa bu iki olaya 
    "istatistiksel bağımsız olaylar" denilmektedir. Örneğin bir oyun kartından bir kart çekilmesi ve sonra bir zar atılması 
    olaylarını düşünelim. Bu iki olay istatistiksel bakımdan bağımsızdır. Çünkü çekilen kart atılan zarı etkilememektedir. 
    Bir olay oluşsa da olmamışsa da diğer olayın oluşunu etkilemiyorsa bu iki olay istatistiksel bakımdan bağımsızıdır. 
    P(A|B) koşullu olasılığında B'nin olması ile A'nın olmasının hiçbir ilgisi yoksa bu olasılık P(A) ile gösterilebilir. 
    Yani B olsa da olmasa da A'nın olasılığı değişmiyorsa P(A|B) = P(A)'dır. Böylece 

    P(A, B) = P(A|B) * P(B) olduğuna göre A ve B istatistiksel olarak bağımsızsa bu formül şu hale gelmektedir:

    P(A, B) = P(A) * P(B)

    Buna olasılıkta "bağımsız olasılıkların çarpım kuralı" denilmektedir. Örneğin bir oyun destesinden çekilen kartın kupa 
    ası olma olasılığı ve sonra atılan zarın 6 gelme olasılığı 1/52 * 1/6'dır. 

    Ancak doğada pek çok olay istatistiksel olarak bağımsız değildir. Çünkü birbirine etki etmektedir. Örneğin bir kişinin 
    kalp hastası olması ile sigara içmesi istatistiksel bakımdan bağımsız değildir. Sigara içmek kalp hastalıklarına yatkınlığı 
    artırmaktadır. Konunun "kaos teorisi" bağlamında felsefi açılımları da vardır. 

    İkiden fazla sitatistiksel olarak bağımsız olayın birikte gerçekleşmesi de yine çarpım kuralı ile ifade edilebilir. 
    Örneğin:

    P(A, B, C, D, E) = P(A) * P(B) * P(C) * P(D) * P(E)
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Elimizde kategorik değerlerden oluşan x1, x2, x3, ..., xn sütunlarına ilişkin bir veri kümesi olsun. Veri kümesindeki her 
    satır m tane kategoriden oluşan bir Y sınıfı ile eşleştirilmiş olsun. Bu durumda biz x1, x2, x3, ..., xn değerlerinin hangi 
    sınıfa ilkişkin olduğunu koşullu olasılığa dayalı olarak belirleyebiliriz. Zira m tane Y için tek tek P(Yk|x1, x2, x3, ..., xn) 
    olasılıkları hesaplanıp bunların hangisi yüksekse o kategori kestirim için seçilebilir. P(Yk|x1, x2, x3, ..., xn) koşullu 
    olasılığı şöyledir:

    P(Yk|x1, x2, x3, ..., xn) = P(x1, x2, x3, ..., xn|Yk) * P(Yk) / P(x1, x2, x3, ..., xn)

    Burada naive bir varsayımla x1, x2, x3, ..., xn olaylarının istatistiksel bakımdan bağımsız olduğunu varsayarsak aşağıdaki 
    durumu elde ederiz. (Bu varsayımda bulunmazsak buradan faydalı bir sonuç çıkmamaktadır):

    P(Yk|x1, x2, x3, ..., xn) = (P(x1|Yk) * (x2|Yk) * P(x3|Yk) * ... * P(xn|Yk) * P(Yk)) / (P(x1) * P(x2) * P(x3) * ... * P(xn))

    Burada Yk demekle Y'nin ayrı ayrı m tane kategorisini belirtiyoruz. Bu olasılıkların en büyüğü elde edileceğine göre ve bu 
    olasılıkların hespinde paydadaki ifade olduğuna göre bu karşılaştırmada onları boşuna 
    hesaplamayız:

    argmax(k = 1, ..., m) = P(x1|Yk) * (x2|Yk) * P(x3|Yk) * ... * P(xn|Yk) * P(Yk)

    Burada eşitliğin sağ tarafı tablodaki sıklık değerleriyle elde edilebilmektedir. Buradaki koşulun sütunların istatistiksel 
    olarak birbirinden bağımsızlığı olduğuna dikkat ediniz. Yöntemi "naive" hale getiren bu koşuldur. Aslında bu koşul genellikle 
    karşılanmaz. Ancak karşılandığı varsayılır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Yukarıdaki açıklamalar veri kümesindeki tüm sütunların "kategorik" olduğu varsayımıyla yapılmıştır. Çünkü çıkardığımız 
    formüldeki olasılıkları hesaplayabilmek için sütunların kategorik olması gerekir. Tabii Naive Bayes yöntemi bir sınıflandırma 
    yöntemi olduğuna göre Y verileri de her zaman kategoriktir. Ancak tüm sütunların kategorik olduğu durumlar çok seyrektir. 
    Genellikle sütunların bazıları kategorik bazıları nümerik değerlerden oluşur. Pekiyi bu durumda ne yapılacaktır? Burada 
    iki yönteme başvurulabimektedir:

    1) Değerleri ayrık hale getirmek (discretazation)
    2) Değerleri belli bir dağılma (tipik olarak normal dağılıma) uydurmak. 

    Değerlerin ayrık hale getirilmesi farklıo değerlerin aynıymış gibi işlem görmesine yol açmaktadır. Bu nedenle genellikle 
    değerlerin normal dağılıma uydurulması yöntemi izlenmektedir. Bu yönteme "Gaussian Naive Bayes (Gaussian NB)" denilmektedir. 
    Bu yöntemde sütunların her Y kategorisi için ortalamaları ve standart sapmaları hesaplanır. Bu değerlerden hareketle Gauss 
    foksiyonu (normal dağılım fonksiyonu) oluşturulur ve olasılıklar bu Gauss fonksiyonundan hareketle elde edilir. 

    Örneğin A, B, C biçiminde 3 nümarik sütunu olan C1 ve C2 sınıflarına sahip veri kümesinde Guassian NB yöntemini uygulamak 
    isteyelim. Bizim aşağıdaki Gauss fonksiyonlarını oluşturmamız gerekir. 

    C1 sınıfına ilişkin A sütun değerleri için Gauss Fonksiyonu
    C1 sınıfına ilişkin B sütun değerleri için Gauss Fonksiyonu
    C1 sınıfına ilişkin C sütun değerleri için Gauss Fonksiyonu
    C2 sınıfına ilişkin A sütun değerleri için Gauss Fonksiyonu
    C2 sınıfına ilişkin B sütun değerleri için Gauss Fonksiyonu
    C2 sınıfına ilişkin C sütun değerleri için Gauss Fonksiyonu
    
    Tabii aslında fonksiyon oluşturmaya gerek yoktur. Zaten bu fonksiyonların değerleri ortalama ve standart sapma parametreleriyle
    elde edilebilmektedir. O halde Navive Bayes yöntemiyle örneğin verilen bir Xa, Xb, Xc değerinin hangi sınıfa ilişkin olduğu
    aşağıdaki iki olasılığın karşılaştırılması ile tespit edilebilir:

    P(C1|Xa, Xb, Xc) = P(Xa|C1) * P(Xb|C1) * P(Xc|C1) * P(C1)
    P(C2|Xa, Xb, Xc) = P(Xa|C2) * P(Xb|C2) * P(Xc|C2) * P(C2)

    İşte Gaussian NB yönteminde örneğin P(Xa|C1) olasılığı C1 sınıfına ilişkin A sütun değerleri için oluşturulan Gauss eğrisinde 
    A değerine karşılık gelen değer olarak elde edilir.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Naive Bayes yönteminde eğer sütunlar yalnızca 0 ve 1'lerden oluşuyorsa bu durumda olasılıkların Bernolli dağılımından 
    hareketle hesaplanması eğer sütunlar sıklık sayılarından oluyorsa olasılıkların Binom dağılımından hareketle hesaplanması 
    daha iyi sonuçların elde edilmesine yol açmaktadır. Bu iki durum yazısal sınıflamalarda tipik karşılaşılan durumlardır. 
    Anımsanacağı gibi vektörizasyon yapıldığında sütunlar binary ya da sözcüklerin sıklık sayılarına ilişkin değerlerden 
    oluşmaktaydı. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Naive Bayes yöntemi ile sınıflandırma için sklearn.naive_bayes modülünde çeşitli hazır sınıflar bulundurulmuştur. Bu 
    sınıfların kullanımları benzerdir. Hangi sınıfların hangi durumlarda kullanılacağı şöyle özetlenebilir:

    CategoricalNB: Bütün sütunların zaten kategorik olduğu durumlarda kullanılır. Böylesi veri kümeleri seyrek karşımıza 
    çıkmaktadır. 
    
    GaussianNB: Bütün sütunların nümerik olduğu durumlarda kullanılmaktadır. 

    BernoullyNB: Sütunların yalnızca 1 ve 0'lardan oluştuğu durumlarda kullanılmaktadır. Örneğin CountVectorizer sınıfı ile 
    yazıların vektörize edilmesi sonucunda elde edilen veri kümelerinde kullanılabilir. 

    MultinomialNB: Sütunların sıklık sayılarından oluştuğu durumlarda kullanılmaktadır. Örneğin CountVectorizer sınıfı ile 
    yazıların sıklık sayılarıyla vektörüze edilmesi sonucunda elde edilen veri kümelerinde kullanılabilir.

    Gaussian Naive Bayes yönteminde programcının ayrıca "özellik ölçeklemesi" yapmasına gerek yoktur. Zaten yöntem kendi 
    içerisinde sütunları normal dağılıma uydurmaktadır. 

    Pekiyi veri kümesindeki bazı sütunlar kategorik bazı sütunlar nümerik ise Naive Bayes uygulanabilir mi? scikit-learn içerisinde
    doğrudan bu biçimdeki veri kümeleri üzerinde çalışan bir sınıf yoktur. Bu durumda ilk akla gelen yöntem nümerik sütunlarla
    kategorik sütunları ayırmak nümerik sütunlara Gaussian NB, kategorik sütunlara Categorical NB uygulamak olabilir. Tabii 
    buradan iki ayrı sonuç elde edilecektir. Bu iki sonucun (iki sınıfın) tek bir sonuca (sınıfa) indirgenmesi gerekir. Bunun 
    işlem tipik olarak nümerik sütunlar için elde edilen olasılıkla (sınıf değil) kategorik sütunlar için elde edilen olasılığın 
    belli ağırlıklarla ilişkilendirilmesi olabilir. Örneğin nümerik sütunlardan elde edilen C1 olasılığı 0.4, C2 olasılığı 0.6
    olsun. Kategorik sütunlardan elde edilen C1 olasılığı 0.7, C2 olasılığı 0.3 olsun. Şimdi biz bunların belli ağırlıklarla 
    ağırlıklı ortalamasını hesaplayıp nihani soncu elde edebiliriz. Örneğin nümerik sütunların ağırlığı 0.4 kategrik sütunların 
    ağırlığı 0.6 olsun.  

    C1 olsalığı = (0.4 * 0.4 + 0.7 * 0.6 ) / 2 = 0.29
    C2 olsalığı = (0.6 * 0.4 + 0.3 * 0.6 ) / 2 = 0.21

    Buradan C1 sınıfı elde edilmektedir. Diğer bir yöntem de "oylama (voting)" yöntemi olabilir. Burada nümerik sütunlarla 
    kategorik sütunlar için ayrı kestirimlerde bulunulur. Eğer iki yöntemde de aynı sınıf bulunursa o sınıf alınır, iki 
    yöntemde farklı sınıflar bulunursa bunlardan biri isteğe bağlı olarak tercih edilebilir. Tabi iaslında sütunların 
    bazıları kategorik bazıları nümerik bazıları 0 ve 1'lerden oluşan bazıları da sıklık sayılarından oluşabilir. Bu durumda 
    oylama daha anlamlı uygulanabilir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                                101. Ders - 09/02/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi CatericalNB sınıfının kullanımına bir örnek verelim. Bunun için "Araba Değerlendirme (Car Evaluation)" veri kümesini
    kullanalım. Bu veri kümesini aşağıdaki bağlantıdan indirebilirsiniz:

    https://archive.ics.uci.edu/dataset/19/car+evaluation

    Veri kümesindeki sütunlar bir arabanın çeşitli özelliklerini kategorik olarak betimlemektedir. Veri kümesinde toplam 4 
    sınıf vardır:

    unacc
    acc
    good
    v-good

    Veri kümesi 6 sütuna sahiptir. Sütunların hepsi kategorik değerlerden oluşmaktadır. Sütunları oluşturan kategorik değerler
    şöyledir:

    buying       v-high, high, med, low
    maint        v-high, high, med, low
    doors        2, 3, 4, 5-more
    persons      2, 4, more
    lug_boot     small, med, big
    safety       low, med, high

    Veri kümesi "car.data" dosyasının içerisindedir ancak CSV formatındadır. Dosyada bir başlık kısmı yoktur. Görünümü 
    aşağıdaki gibidir:

    vhigh,vhigh,2,2,small,low,unacc
    vhigh,vhigh,2,2,small,med,unacc
    vhigh,vhigh,2,2,small,high,unacc
    vhigh,vhigh,2,2,med,low,unacc
    vhigh,vhigh,2,2,med,med,unacc
    vhigh,vhigh,2,2,med,high,unacc
    vhigh,vhigh,2,2,big,low,unacc
    vhigh,vhigh,2,2,big,med,unacc
    vhigh,vhigh,2,2,big,high,unacc
    vhigh,vhigh,2,4,small,low,unacc
    vhigh,vhigh,2,4,small,med,unacc
    vhigh,vhigh,2,4,small,high,unacc
    vhigh,vhigh,2,4,med,low,unacc
    .....

    Dosyayı aşağıdaki gibi okuyabiliriz:

    df = pd.read_csv('car.data', header=None)
    
    Burada dosyanın başlık kısmı olmadığı için header=None geçildiğine dikkat ediniz. DataFrame nesnesi içerisinde sütun 
    isimlerini aşağıdaki gibi oluşturabiliriz:

    df.columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']

    Bizim önce sütunlardaki etiketleri yazısal olmaktan çıkartıp sayısal hale getirmemiz gerekir. Anımsanacağı gibi kategorik 
    verileri sayısal hale çevirmek için LabelEncode ya da OrdinalEncoder sınıfları kullanılabiliyordu. Bu iki sınıf arasındaki
    fark LabelEncoder sınıfının tek hamlede tek bir sütun üzerinde işlem yapması OrdinalEncoder sınıfının ise tek hamlede birden 
    fazla sütun üzerinde işlem yapabilmesidir:
    
    oe = OrdinalEncoder()
    le = LabelEncoder()

    encoded_dataset_x = oe.fit_transform(df.iloc[:, :-1].to_numpy(dtype='str'))
    encoded_dataset_y = le.fit_transform(df.iloc[:, -1].to_numpy(dtype='str'))

    Şimdi de veri kümesini eğitim ve test biçiminde ikiye ayırabiliriz:

    training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
            train_test_split(encoded_dataset_x, encoded_dataset_y, test_size=0.2)

    Artık CategoricalNB sınıfı ile Navive Bayes sınıflandırması yapabiliriz. Sınııfn __init__ metodunun parametrik yapısı 
    şöyledir:

    class sklearn.naive_bayes.CategoricalNB(*, alpha=1.0, force_alpha=True, fit_prior=True, 
            class_prior=None, min_categories=None)[source]
    
    Buradaki parametreler algoritmanın içsel işleyişi ile ilgilidir. Nesne default değerler ile yaratılabilir:

    cnb = CategoricalNB()

    Bundan sonra fit işlemi yapılır:

    cnb.fit(training_dataset_x, training_dataset_y)

    fit işlemiyle tüm sınıflandırma bilgileri elde edilir. Sınıfın transform isminde bir metodu yoktur. Doğrudan predict 
    işlemi ile kestirim yapılabilir. Örneğin biz sınıflandırma işleminin başarısını test veri kümesi ile şöyle belirleyebiliriz:

    test_result = cnb.predict(test_dataset_x)
    score = np.sum(test_dataset_y == test_result) / len(test_dataset_y)
    print(score)

    Anımsanacağı gibi karşılıklı elemanların eşitliğine dayalı oran aynı zamanda sklearn.metrics modülündeki sccuracy_score 
    fonksiyonuyla da elde edilebiliyordu:

    score = accuracy_score(test_dataset_y, test_result)

    Kestirim işlemi de aşağıdaki gibi yapıalbilir. Kestirilecek değerlerin "predict.csv" isimli dosyada aşağıdaki gibi 
    bulunduğunu varsayalım:

    predict_dataset_x = pd.read_csv('predict.csv', header=None).to_numpy(dtype='str')
    encoded_predict_dataset_x = oe.transform(predict_dataset_x)

    predict_result = cnb.predict(encoded_predict_dataset_x)
    print(predict_result)
    predict_result_names = le.inverse_transform(predict_result).tolist()

    Kod bir bütün olarak aşağıda verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('car.data', header=None)
df.columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']

from sklearn.preprocessing import OrdinalEncoder, LabelEncoder

oe = OrdinalEncoder()
le = LabelEncoder()

encoded_dataset_x = oe.fit_transform(df.iloc[:, :-1].to_numpy(dtype='str'))
encoded_dataset_y = le.fit_transform(df.iloc[:, -1].to_numpy(dtype='str'))

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(encoded_dataset_x, encoded_dataset_y, test_size=0.2)

from sklearn.naive_bayes import CategoricalNB

cnb = CategoricalNB()

cnb.fit(training_dataset_x, training_dataset_y)

test_result = cnb.predict(test_dataset_x)

from sklearn.metrics import accuracy_score

score = accuracy_score(test_dataset_y, test_result)
print(score)

"""
import numpy as np

score = np.sum(test_dataset_y == test_result) / len(test_dataset_y)
print(score)
"""

predict_dataset_x = pd.read_csv('predict.csv', header=None).to_numpy(dtype='str')
encoded_predict_dataset_x = oe.transform(predict_dataset_x)

predict_result = cnb.predict(encoded_predict_dataset_x)
print(predict_result)
predict_result_names = le.inverse_transform(predict_result).tolist()

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de nümerik sütunlardan oluşan bir veri kümesi üzerinde Gaussian NB yöntemini uygulayalım. Bunun için "Breast Cancer 
    Wisconsin" veri kümesini kullanacağız. "Breast Cancer Winconsin" veri kümesi 30 biyomedikal veriden hareketle kitlenin 
    "iyi huylu (benign)" mu yoksa "kötü huylu mu (malign)" olduğunu tespit etmek için kullanılmaktadır. Veri kümesi CSV dosyası 
    olarak bağlantıdan indirilebilir:
    
    https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data

    Aslında bu veri kümesi zaten sklearn.datasets modülünde load_breast_cancer fonksiyonu ile yüklenebilmektedir. Bu fonksiyon 
    bize bir sınıf nesnesi verir. Sınıfın data ve target örnek öznitelikleri veri kümesine ilişkin X ve Y değerlerini vermektedir. 

    Gaussian NB yöntemini uygulamak için sklearn.naive_bayes modülündeki GaussianNB sınıfı kullanılmaktadır. Sınıfın __init__
    metodunun parametrik yapısı şöyledir:

    class sklearn.naive_bayes.GaussianNB(*, priors=None, var_smoothing=1e-09)

    Nesneyi default argümanlarla yaratabiliriz:

    gnb = GaussianNB()

    Veri kümesi üzerinde özellik ölçeklemesi yapılmasına gerek olmadığını belirtmiştik. fit işlemi aşağıdaki gibi uygulanabilir:

    Yine sınıfın predict metodu ile kestirim yapılabilir:

    test_result = gnb.predict(test_dataset_x)

    test_dataset_y verileri ile kesitirimdeki verileri sınıflandırmanın başarısını test etmek için kullanabiliriz:

    accuracy = accuracy_score(test_dataset_y, test_result)
    print(accuracy)

    Kod bir bütün olarak aşağıda verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv("data.csv")

dataset_x = df.iloc[:, 2:-1].to_numpy()
dataset_y = np.zeros(len(df))
dataset_y[df['diagnosis'] == 'M'] = 1

"""
from sklearn.datasets import load_breast_cancer

bc = load_breast_cancer()
"""

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
    train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.naive_bayes import GaussianNB

gnb = GaussianNB()

gnb.fit(training_dataset_x, training_dataset_y)
test_result = gnb.predict(test_dataset_x)

from sklearn.metrics import accuracy_score

accuracy = accuracy_score(test_dataset_y, test_result)
print(accuracy)

#----------------------------------------------------------------------------------------------------------------------------
    Naive Bayes yönteminde artırımlı eğitim işlemleri algoritmayı sıfıran yeniden çalıştırmadan sağlanabilmektedir. Yani biz 
    belli miktarda satırla eğitimi yapmış olabiliriz. Daha sonra yeni satırlar geldikçe eğitimi devam ettirebiliriz. Bunun 
    için scikit-learn sınıflarında partial_fit isimli metotlar bulunmaktadır. scikit-learn içerisindeki Naive Bayes sınıflarının 
    partial_fit metotları bukunmaktadır.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Naive Bayes yönteminin şimdiye kadar gördüğümüz ve henüz görmediğimiz yöntemlere göre avantajlarını ve dezavantajlarını 
    şöyle ifade edilebiliriz:

    - Tüm sütunları kategorik olan veri kümelerinde Naive Bayes yöntemi diğer yöntemlere göre daha iyi sonuç verme eğilimindedir. 
    Ancak karışık sütunlu ve kategorik olmayan sütunlu veri kümelerinde yöntemin etkinliği düşmektedir. 

    - Naive Bayes yöntemi az sayıda veriden (yani satırdan) oluşan veri kümelerinde oldukça etkilidir. Örneğin az sayıda satıra 
    sahip veri kümelerinde yapay sinir ağlarının iyi bir biçimde eğitilmesi mümkün olamamaktadır. 

    - Naive Bayes yöntemi basit aritmetik hesaplara dayalı olduğu için az miktarda belleğin kullanılmasına yol açmaktadır. Yine 
    hesaplama zamanı diğer yöntemlere göre çok daha hızlı olabilmektedir. Ancak sütun sayısı arttıkça algoirtmanın performansı 
    düşme eğilimindedir. 

    - Naive Bayes yöneteminin gerçekleştirimi nispeten diğer yöntemlere göre daha kolaydır. 

    - Yöntem metinsel sınıflamalarda (örneğin spam filtrelemelerinde vs) basitliğinden ve hızından dolayı tercih edilebilmektedir. 

    - Naive Bayes yöntemi artırımlı eğitimlere uygun bir yöntemdir. (Yani biz bir kez değil veri geldikçe partial_fit ile eğitime
    devam edebiliriz.)

    - Naive Bayes yöntemi sütunların istatistiksel bakımdan bağımısz olduğu varsayımına dayanmaktadır. Uygulamada bu koşulun 
    sağlanması çoğu kez mümkün olamamaktadır. Bu durumda modelin başarısı düşecektir. Örneğin bir sütunda hava durumu (normal, 
    güneşli, yağışlı gibi), diğer sütunda havadaki nem oranı bulunuyor olsun. Bu iki sütun aslında birbirinden bağımsız değildir. 
    Yöntem bunların bağımsız olduğu fikriyle uygulanmaktadır. Bu da başarının düşmesine yol açmaktadır. Sütunlar birbirlerine ne 
    kadar bağımlıysa yöntemin etkinliği de buna bağlı olarak düşmektedir. 

    - Veri kümesinde hiç bulunmayan bir sütun etiketi ile tahmin yapılmaya çalışılırsa 0 değeri elde edilmektedir. Bunun nedeni 
    Naive Bayes formülünden anlaşılabilir:

    argmax(k = 1, ..., m) = P(x1|Yk) * P(x2|Yk) * P(x3|Yk) * ... * P(xn|Yk) * P(Yk)
    
    Gerçi bunun için bazı yöntemler (smoothing methods) uygulanmaktadır. Örneğin scikit-learn sınıfları bu yöntemleri uygulamaktadır. 
    Ancak bu tür verilerin tahmini düşük bir performansla yapılabilmektedir. 

    - Naive Bayes yöntemi nümerik ve karma sütunlu veri kümelerinde alternatif yöntemlere göre daha düşük performans gösterme 
    eğilimindedir. 

    Tabii hangi durumlarda hangi yöntemin daha iyi performans göstereceği deneme yanılma yöntemine başvurulmadan çoğu 
    kez önceden belirlenememektedir. Bu durumda uygulamacı birden fazla yöntemi deneyerek kendi veri kümesi için en iyi 
    performansı gösteren yöntemi kullanabilir. Ya da başka bölümde ele alacak olduğumuz "topluluk yöntemlerinden (ensemble 
    methods) faydalanabilir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Bu bölümde istatistiksel doğrusal regresyon, polinomsal regresyon ve doğrusal sınıflandırıcılardan (linear classifiers)
    lojistik regresyon üzerinde duracağız.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Girdi ile çıktı arasında ilişki kurma sürecine istatistikte "regresyon" denilmektedir. Girdiyle çıktı arasındaki ilişki 
    bir fonksiyonla ifade edilebildiğine göre regresyon sürecini de biz aslında girdi ile çıktı arasındaki ilişkiyi belirten 
    uygun bir fonksiyonun bulunması süreci olarak ele alabiliriz. Matematiksel biçimde açıklarsak regresyon aslında y = f(x) 
    biçiminde bir f fonksiyonun bulunması sürecidir. Burada x ve y birden fazla değişkeni temsil ediyor olabilir . (Yani x bir 
    tane değil x0, x1, ... xn biçiminde n tane olabileceği gibi y de bir tane değil y0, y1, ... ym biçiminde m tane olabilir.) 
    x değerlerinin bir den fazla olduğu fonksiyonlara matematikte "çok değişkenli fonksiyonlar" denildiğini anımsayınız. 

    Pekiyi girdi ile çıktı arasında ilişki kurmanın amacı ne olabilir? Şüphesiz en önemli amaç kestirimde bulunmaktır. Örneğin 
    elimizde birtakım geçmiş veriler vardır. Biz de gelecekteki durumun ne olabileceğiyle ilgili karar vermek isteyebiliriz. 
    Bu durumda gelecekteki verileri regresyon sonucunda bulduğumuz f fonksiyonuna girdi yaparak sonucu kestirebiliriz. 

    Regresyon modelleri ve problemleri istatistikte çeşitli biçimlerde sınıflandırılabilmektedir. Maalesef herkesin hemfikir 
    olduğu bir sınıflandırma biçimi yoktur. Biz burada istatistiksel regresyon modellerini tipik olarak aşağıdaki gibi 
    sınıflandıracağız:
    
    - Doğrusal Regresyon (Linear Regression): Girdi ile çıktı arasındaki ilişkiyi parametrelerin doğrusal bileşimleriyle ifade 
    eden regresyon modelidir. Yani doğrusal regresyonla girdi ile çıktı arasında ilişkiyi belirten doğrusal bir fonksiyon 
    bulunmaya çalışılır. Doğrusal regresyonda girdi (yani bağımsız değişen) bir tane ve çıktı da (bağımlı değişken) bir tane 
    ise buna "basit doğrusal regresyon" denilmektedir. Tabii gerçek yaşama ilişkin problemlerde genellikle girdi bir tane olmaz. 
    Örneğin bizim kullandığımız veri kümelerindeki özellikler (sütunlar) girdileri oluştururlar. Böylece regresyon modelinde 
    çok sayıda girdi söz konusu olur. İşte eğer doğrusal regresyonda girdiler (yani bağımsız değişkenler) birden fazla ise buna 
    "çoklu doğrusal regresyon (multiple linear regression)" denilmektedir. Doğrusallığın değişken sayısı ile ilgili olmadığına 
    değişkenlerin dereceleri ile ilgili olduğuna dikkat ediniz. Örneğin n tane değişken içeren doğrusal bir fonksiyonun genel 
    biçimi şöyledir:

    f(x) = a1x1 + a2x2 + a3x3 + ... + anxn + b

    Biz bu doğrusal fonksiyonu vektörel biçimde şöyle de ifade edebiliriz:

    f(X) = AX + b

    Burada A bir satır vektörünü X ise bir sütun vektörünü belirtmektedir. Aslında AX işleminin bir "dot product" oluşturduğuna 
    dikkat ediniz.

    - Polinomsal Regresyon (Polynomial Regression): Verilerin grafiğini çizdiğimizde ilişkinin doğrusal olup olmadığı hemen 
    gözle görülebilmektedir. Bağımsız değişkenlerin herhangi birinin üssü 1'den büyükse bu tür regresyon modellerine polinomsal 
    regresyon modelleri denilmektedir. Başka bir deyişle polinomsal regresyon aşağıdaki gibi bir polinomsal fonksiyonun bulunması 
    sürecidir:

    f(x)= a0x^0 + a1x^1 + a2x^2 + ... + anx^n

    Aslında polinomsal regresyon eğer katsayılarla değişkenler yer değiştirirse doğrusal regresyona benzemektedir:

    f(a)= x^0a0 + x^1a1 + x^2a2 + ... + x^nan

    - Doğrusal Olmayan Regresyon (Nonlinear Regression):  Her ne kadar polinomlar doğrusal fonksiyonlar değilse de katsayılarla 
    değişkenler yer değiştirdiğinde doğrusal gibi ele alınabilmektedir. İstatistikte doğrusal olmayan regresyon denildiğinde 
    katsayılarla değişkenler değiştirildiğinde yine doğrusal olmayan fonksiyonların elde edildiği regresyonlar anlaşılmaktadır. 
    Bu tür fonksiyonalar genel olarak üstel ifadeler, logaritmik ifadeler, pay ve paydasında bağımsız değişkenlerin bulunduğu 
    oransal ifadeler içermektedir.

    - Lojistik Regresyon (Logistic/Logit Regression): Bağımlı değişkenin sürekli bir değer almadığı, kategorik değer aldığı 
    durumlarda uygulanan regresyonlara lojistik regresyon ya da logit regresyonu denilmektedir. Lojistik regresyon terimi tipik 
    olarak çıktının 0 ya da 1 gibi ikili değerlere sahip olduğu durumlar için kullanılmaktadır. (Örneğin çıktı "evli mi bekar mı", 
    "hasta mı sağlıklı mı", "film iyi mi kötü mü" gibi iki seçenekten biri olabilmektedir.) Ancak zamanla bu terim genişletilmiştir. 
    Çıktının ikiden fazla kategoriye ayrıldığı durumlar için de "çok sınıflı lojistik regresyon (multinomial logistic regression)" 
    terimi kullanılmaktadır. Ayrıca "sıralı lojistik regresyon (ordinal logistic regression)" denilen bir lojistik regresyon 
    modelinde girdi ve çıktılar kategorik değil sıralı ölçeklere ilişkin olabilmektedir. 

    Regresyonlar bağımlı ve bağımsız değişken sayılarına göre de sınıflandırılmaktadır:

    - Basit Regresyon (Simple Regression): Bağımsız değişken sayısı bir tane ise buöyle regresyonlara basit regresyonlar 
    denilmektedir. 

    - Çoklu Regresyon (multiple regression): Bağımsız değişken sayısının (yani girdilerin) birden fazla olduğu fakat bağımlı 
    değişken sayısının (yani çıktının) bir tane olduğu regresyon modelleri için kullanılan bir terimdir. Örneğin bir otomobilin 
    8 özelliğinden onun yakıt harcamasının tahmin edilmek istendiği regresyon modeli çoklu regresyon modelidir. Ya da örneğin 
    "diabestes.csv" örneğinde olduğu gibi kişinin 8 biyomedikal bilgisinden hareketle kişinin şeeker hastası olup olmadığının 
    tahmin edilmesi için oluşturulan model de çoklu lojistik regresyon modelidir. 

    - Çok Değişkenli Regresyon (Multivariate Regression): Eğer regresyon modelinde bağımlı değişkenin sayısı birden fazlaysa 
    (yani çıkktı birden fazlaysa) buna da "çok değişkenli (multivariate)" regresyon denilmektedir. Örneğin öğrencinin bazı 
    girdi bilgileri olsun (bağımsız değişkenler) biz de onun sınavda alacağı notu ve ortalama kaç saat uyuduğunu tahmin etmek 
    isteyelim. Burada tahmin etmek istediğimiz şey birden fazladır. Şüphesiz çok değişkenli regresyonlarda çıktılar birbirlerinden 
    bağımsız ve teker teker olarak da ele alınabilirler. O zaman iki farklı çoklu regresyondan söz ederdik. Fakat çok değişkenli 
    regresyonlarda aynı anda birden fazla çıktının değişiminin belirlenmesi hedeflenmektedir. Yani örneğin 15 tane biyomedikal 
    tetkike bakarak biz bir kişinin "diyabetli olup olmadığını", "kalp hastası olup olmadığını", "hipertansiyonunun olup olmadığını" 
    ayrı ayrı çoklu lojistik regresyonla anlamaya çalışabiliriz. Ancak bu üç hastalık birbirlerini de etkiliyor olabilir. O 
    halde bu üç hastalığın birlikte değerlendirilmesi gerekir. İşte bu durum çok değişkenli lojistik regresyon olarak modellenebilir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    En çok uygulanan istatistiksel regresyon modeli "doğrusal regresyon (linear regression)" denilen modeldir. Tek değişkenli 
    doğrusal regresyona "basit doğrusal regresyon (simple linear regression)" denildiğini söylemiştik. Basit doğrusal regresyon 
    yukarıda da belirttiğimiz gibi noktaları temsil eden bir doğru denkleminin elde edilmesi sürecidir. Eğer böyle bir doğru 
    denklemi elde edilebilirse bu durumda kestirim yapılabilir. Kestirim için X değerleri doğru denkleminde yerine konur ve sonuç 
    elde edilir. Pekiyi basit doğursal regresyonda noktaları temsil eden bir doğru denklemi nasıl elde edilecektir? İşte elde 
    edilecek doğru denklemi bu noktaları en iyi ortalayan bir doğrunun denklemi olmalıdır. Pekiyi noktaların en iyi biçimde 
    ortalanmasının matematiksel ifadesi nedir?

    Örneğin elimizde aşağıdaki gibi X değerleri için onlara karşı gelen Y değerleri olsun:

    x       Y
    10      12.3
    13.2    18.2
    14.3    19.8
    ...     ...

    Burada bağımısz değişken bir tane olduğu için "basit doğrusal regresyon" söz konusudur. Basit doğrusal regresyonda elde edilmek 
    istenen doğru denklemi şöyle ifade edilebilir:

    𝑦 = β₀ + β₁𝑥

    Genellikle istatistikte katsayılar için Beta sembolü kullanılmaktadır. Buradaki B'ler beta sembolü anlamında kullanılmıştır. 

    Aslında doğrusallık genel bir kavramdır. Uzayın boyutu ne olursa olsun doğrusallık durumunda yapılan işlemler benzerdir. İki 
    boyutlu uzaydaki doğru üç boyutlu uzayda bir düzlem haline gelmektedir. Her çok boyutlu uzayın kendi düzlemleri vardır. Çok 
    boyutlu uzaydaki o uzaya ilişkin düzlemlere İngilizce "hyperplane" denilmektedir. 
    
    Şimdi elimizdeki veri kümesinde iki sütun olduğunu varsayalım. Bu durumda regresyon sürecinde üç boyutlu uzayda bir düzlem 
    elde edilmeye çalışılacaktır. Üç oyutlu uzaydaki düzlem denklemi şöyledir:

    𝑦 = β₀ + β₁𝑥₁ + β₂𝑥₂

    Yukarıda da belirttiğimiz gibi her N boyutlu uzayın da bir düzlemi vardır. Buna genel olarak "hyperplane" denilmektedir. 
    Lineer cebirde doğrusallık ile ilgili işlemler iki boyutlu kartezyen koordinat sisteminde nasıl yürütülüyorsa N boyutlu 
    uzayda da benzer biçimde yürütülmektedir. Bu nedenle açıklamalar genellikle basitliği nedeniyle iki boyutlu uzayda veriliyor 
    olsa da formüller kolaylıkla genelleştirilebilmektedir. N boyutlu uzayda "hyperplane" denklemi şöyle oluşturulabilir:

    𝑦 = 𝐵₀ + 𝐵₁𝑥₁ + 𝐵₂𝑥₂ + 𝐵₃𝑥₃ + ⋯ + 𝐵ₙ𝑥ₙ 

    Genellikle bu tür doğru denklemleri basitlik sağlamak amacıyla matris formunda gösterilmektedir. Burada B katsayılarının 
    bir satır vektörü X değişkenlerinin de bir sütun vektörü olduğunu varsayarsak aynı denklemi şöyle de ifade edebiliriz:

    𝑦 = β𝐗 + 𝑏
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                        102. Ders - 15/02/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi basit doğrusal regresyonda B0 ve B1 değerlerinin elde edilmesinde kullanılan "en küçük kareler (ordinary least squares)" 
    yönteminden bahsedelim. Basit doğrusal regresyonda noktaları en iyi ortalayan doğru denklemine ilişkin B0 ve B1 değerleri 
    sırasıyla şu aşamalardan geçilerek elde edilebilmektedir:

    1) Önce minimize edilecek fonksiyon belirlenir. Minime edilecek fonksiyon noktaların gerçek y değerlerinden doğru 
    denkleminden elde edilen y değerlerinin farklarının karelerinin toplamları biçiminde oluşturulabilir. (Farklar pozitif ve 
    negatif olabileceği için farkların kareleri alınarak farkların her zaman pozitif olması sağlanmaktadır.) Örneğin veri kümesindeki 
    x0 değeri için y0 değerinin karşı geldiğini varsayalım. Bu durumda biz bu x0 değerini elde ettiğimiz doğru denkleminde yerine 
    koysaydık B0 + B1 x0 değerini elde ederdik. O halde buarada yapılan hata (y0 - (B0 + B1 x0)) ** 2 biçiminde ifade edilebilir. 
    Burada tüm x0'lar Xi ile ve tüm y0'lar da Yi ile gösterilirse yapılan toplam hatayı da şöyle ifade edebiliriz:

    Toplam hata = ∑(𝑌ᵢ − (𝐵₀ + 𝐵₁ 𝑋ᵢ))²
    
    Bunu Python ifadesi olarak şöyle yazabiliriz:
    
    total_err = np.sum((y - (B0 + B1 * x)) ** 2)

    Burada Xi ve Yi n tane gözlem değerinden oluşan vektörlerdir. Buradaki toplam hatanın daha önce kullanmış olduğumuz "mean 
    squared error" loss fonksiyonuna çok benzediğine dikkat ediniz. Biz bu değeri gözlem sayısı olan N'e bölsek iki ifade 
    aynı hale gelecektir. İstatistikte bir noktaya karşı gelen gerçek y değeri ile bu noktanın doğru denkleminde yerine konulması
    ile elde edilen değer arasındaki farka "residüel (residual)" denilmektedir.

    2) Yukarıdaki ifadenin B0 ve B1 için parçalı türevleri alınıp sıfıra eşitlenirse buradan iki denklem elde edilir. Burada 
    text ekrandan dolayı bu formülü veremiyoruz. Ancak Internet'te Bo ve B1 değerlerini veren en küçük kareler formülünü kolaylıkla 
    elde edebilirsiniz. Xi ve Yi değerlerini alarak B0 ve B1 değerlerini veren Python fonksiyonu şöyle yazılabilir:
    
    def linear_regression(x, y):
        a = np.sum((x - np.mean(x)) * (y - np.mean(y)))
        b = np.sum(((x - np.mean(x)) ** 2))
        b1 = a / b
        b0 = (np.sum(y) - b1 * np.sum(x)) / len(x)
        return b0, b1

    Aşağıdaki örnekte en küçük kareler formülü kullanılarak basit doğrusal regresyon için B0 ve B1 değerlerini elde eden yukarıdaki
    fonksiyon "points.csv" dosyasındaki noktalara uygulanmıştır. "points.csv" dosyasının içeriği şöyledir:

    x,y
    2,4
    3,5
    5,7
    7,10
    7,8
    8,12
    9.5,10.5
    9,15
    10,17
    13,18

    Örnekte biz hem noktaların saçılma diyagramını hem de regresyon doğrusunu çizdik.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv('points.csv')

dataset_x = df['x'].to_numpy()
dataset_y = df['y'].to_numpy()

def linear_regression(x, y):
    a = np.sum((x - np.mean(x)) * (y - np.mean(y)))
    b = np.sum(((x - np.mean(x)) ** 2))
    b1 = a / b
    b0 = (np.sum(y) - b1 * np.sum(x)) / len(x)
    return b0, b1

b0, b1 = linear_regression(dataset_x, dataset_y)

x = np.linspace(0, 15, 1000)
y = b0 + b1 * x

import matplotlib.pyplot as plt

plt.title('Simple Linear Regression')
plt.scatter(dataset_x, dataset_y, color='blue')
plt.plot(x, y, color='red')
plt.xticks(range(1, 15))
plt.show()

predict_data = 12.9
predict_result = b0 + predict_data * b1
print(predict_result)

#----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirtildiği gibi basit (tekli) doğrusal regresyon aslında veri biliminde ve makine öğrenmesinde gerçek bir 
    kullanıma sahip değildir. Bu alanlarda kullanılan veri kümelerinin çok fazla sütunu vardır. Dolayısıyla bu alanlarda 
    "çoklu doğrusal regresyon (multiple linear regression)" ile karşılaşılmaktadır. X değerlerinin birden fazla olduğu (yani 
    sütun sayısının birden fazla olduğu) doğrusal regresyon modellerine istatistikte "çoklu doğrusal regresyon (multiple 
    linear regression)" denildiğini anımsayınız. Yukarıda da belirttiğimiz gibi çoklu doğrusal regresyon aslında N boyutlu 
    uzayda noktaları en iyi ortalayan bir "hyperplane" denkleminin elde edilmesi sürecidir. Çoklu doğrusal regresyonda elde 
    edilecek Beta değerleri boyut sayısı N olmak üzere N + 1 tanedir. Örneğin sütun sayısının 5 olduğunu varsayalım. Bu durumda 
    hyperplane denklemi şöyle olacaktır:

     𝑦 = β₀ + β₁𝑥₁ + β₂𝑥₂ + β₃𝑥₃ + β₄𝑥₄ + β₅𝑥₅

    Çoklu doğrusal regresyon için Beta katsayılarının parçalı türevlerle nasıl elde edildiğinin anlaşılması biraz lineer cebir 
    ve parçalı türev bilgisini gerektirmektedir. Aşağıdaki dokümandan bu bilgileri edinebilirsiniz:

    https://eli.thegreenplace.net/2014/derivation-of-the-normal-equation-for-linear-regression

    Çoklu doğrusal regresyonun matrisel formülünün nasıl oluşturulduğunu "ChatGPT" gibi büyük dil modellerinden de elde 
    edebilirsiniz. Bunun için örnek bir prompt şöyle olabilir:

    "Bana çoklu doğrusal regresyonda en küçük kareler yönteminin matrisel denkleminin nasıl elde edildiğini adım adım açıklar 
    mısın? Veri kümesi X ile ve hedef değişken de y ile temsil ediliyor olsun. Matyris çarpımlarını @ sembolü ile göstermelisin."

    ChatGPT Pro versiyonunun verdiği bir yanıt aşağıdaki gibidir:

    ************************************************

    Tabii! Aşağıda çoklu doğrusal regresyonda **en küçük kareler yönteminin (OLS)** matris çözümünü Unicode karakterlerle 
    düzgün biçimlenmiş bir şekilde adım adım açıklıyorum:

    ## 🧮 Problem Tanımı

    Veri kümesi:

    * 𝐗 ∈ ℝⁿˣᵖ → Girdi (özellik) matrisi
    * 𝐲 ∈ ℝⁿˣ¹ → Hedef değişken (çıktı) vektörü
    * 𝛽 ∈ ℝᵖˣ¹ → Öğrenilecek regresyon katsayıları

    Amaç:  𝐗 @ 𝛽  ≈ 𝐲  olacak şekilde 𝛽'yi bulmak.

    ## 🎯 1. Hata Fonksiyonu (Kare Hatalar Toplamı)

    Amaç fonksiyonu:
    ‖𝐲 − 𝐗 @ 𝛽‖² = (𝐲 − 𝐗 @ 𝛽)ᵀ @ (𝐲 − 𝐗 @ 𝛽)

    ## 🔍 2. Türev Alma (∇𝛽 L(𝛽))

    Amaç fonksiyonunun türevi:

    ∇𝛽‖𝐲 − 𝐗 @ 𝛽‖²
    \= −2 · 𝐗ᵀ @ (𝐲 − 𝐗 @ 𝛽)
    \= −2𝐗ᵀ𝐲 + 2𝐗ᵀ𝐗 @ 𝛽

    ## 🟰 3. Türevi Sıfıra Eşitleme

    −2𝐗ᵀ𝐲 + 2𝐗ᵀ𝐗 @ 𝛽 = 0
    ⇒ 𝐗ᵀ𝐗 @ 𝛽 = 𝐗ᵀ𝐲

    Bu denklem **normal denklem** olarak adlandırılır.

    ## ✅ 4. Kapalı Formda Çözüm

    Eğer 𝐗ᵀ𝐗 terslenebilirse:

    𝛽 = (𝐗ᵀ𝐗)⁻¹ @ 𝐗ᵀ @ 𝐲

    ## ℹ️ Not

    * Eğer 𝐗ᵀ𝐗 terslenemezse (singular), çözüm için Moore–Penrose pseudotersi kullanılır:
    𝛽 = 𝐗⁺ @ 𝐲

    Burada 𝐗⁺, 𝐗'in pseudoinverse'idir.

    ************************************************

    Çoklu doğrusal regresyonun en küçük kareler yöntemiyle çözümünden elde edilen formüle dikkat ediniz:

    B = (X.T @ X)^-1 @ X.T @ y

    Burada X veri kümesindeki dataset_x değerlerini (izleyen paragraflarda ayrıntılarını göreceksiniz) y ise dataset_y değerlerini 
    belirtiyor. Eğer veri kümesinde toplam n tane satır ve k tane sütun varsa X matrisi (n, k) boyutunda, y matrisi ise (n, 1) 
    boyutundadır. Gösterimimizdeki X.T ise X matrisinin transpozesini belirtiyor. X.T matrisinin (k, n) boyutunda olduğuna dikkat 
    ediniz. Bu durumda (k, n) boyutlu bir matris (n, k) boyutlu bir matrisle çarpılırsa (k, k) boyutlu bir kare matris elde edilir. 
    Bunun tersi de yine (k, k) boyutlu bir matristir. Sonra (k, k) boyutlu bir matris (k, n) boyutlu bit matrisle çarpılırsa (k, n) 
    boyutunda bir matris elde edilir. Bu da (n, 1) boyutunda bir matrisle çarpılırsa (k, 1) boyutunda bir matris elde edilecektir. 
    Çarpım boyutlarını aşama aşama şöyle de belirtebiliriz:

    1) X.T @ X işleminde (n, k) boyutlu bir matrisle (k, n) boyutlu matris çarpılıyor ve (k, k) boyutlu matris elde ediliyor.
    2) (X.T @ X)^-1 işleminde (k, k) boyutlu matrisin tersi alınıyor ve (k, k) boyutlu bir matris elde ediliyor.
    3) (X.T @ X)^-1 @ X.T işleminde (k, k) boyutlu matrisle (k, n) boyutlu matris çarpılıyor ve (k, n) boyutlu matris elde 
    ediliyor.
    4) (k, n) boyutlu bir matrisle (n, 1) boyutlu bir matris çarpılıyor ve (k, 1) boyutlu bir matris elde ediliyor.

    Bu formüldeki X matrisinin birinci sütununun 1'lerden oluşması gerekmektedir. Bu 1 değerleri aslında B0 katsayısını (intercept) 
    belirtiyor. Bu formül kullanılarak Beta katsayalarını elde eden bir fonksiyon şöyle yazılabilir:

    def multiple_linear_regression(x, y):
        ones = np.ones((x.shape[0], 1))
        x = np.concatenate((ones, x), axis=1)
        betas = (np.linalg.inv(x.T @ x) @ x.T @ y).reshape(-1)
        return betas[0], betas[1:]
    
    Fonksiyon iki elemanlı bir demete geri dönmektedir. Demetin birinci elemanı B0 değerinden ("intercept"), ikinci elemanı 
    ise X katsayılaından oluşmaktadır. Fonksiyon şöyle çağrılabilir:

    intercept, coeffs = multiple_linear_regression(dataset_x, dataset_y)

    Aşağıdaki örnekte biz 3 sütunlu "data.csv" isimli bir dosya oluşturup bu dosyadaki değerlerle yukarıda yazmış olduğumuz 
    fonksiyonun test işlemini yaptık. Örnekte kullandığımız "data.csv" dosyasının içeriği şöyledir:

    X1,X2,X3,Y
    2,0,2,469
    0,-7,9,390
    0,24,0,1604
    -4,-11,-1,-1278
    15,-4,7,1698
    -5,-11,1,-1136
    -3,6,-6,-477
    -10,-9,4,-1162
    5,-4,-4,-180
    -9,0,-5,-1256
    2,-19,0,-1062
    -5,0,-15,-1612
    2,-12,7,45
    3,5,-5,207
    -1,0,3,42
    -11,7,11,337
    2,-17,-19,-2383
    -6,0,18,902
    -2,-4,-14,-1581
    -5,3,-10,-1085
    3,-2,-6,-323
    7,14,-9,893
    3,3,-17,-863
    0,-2,-19,-1610
    -13,2,5,-572
    13,1,-16,25
    15,-3,-7,557
    10,-8,9,1102
    -11,13,8,443
    8,2,-12,-91
    -3,-14,-3,-1535
    15,-2,-2,1018
    3,-5,14,1137
    -1,-14,-3,-1287
    0,3,10,953
    -10,-12,8,-1079
    1,1,7,861
    -7,10,-4,-318
    -2,-14,0,-1063
    4,6,-1,748
    -3,9,3,610
    4,1,18,1941
    -9,14,-14,-965
    2,-13,-19,-2195
    -6,15,3,697
    0,-26,15,-494
    -3,-1,-8,-1032
    8,-2,0,604
    -14,21,5,622
    -8,9,-5,-520
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

def multiple_linear_regression(x, y):
    ones = np.ones((x.shape[0], 1))
    x = np.concatenate((ones, x), axis=1)
    betas = (np.linalg.inv(x.T @ x) @ x.T @ y).reshape(-1)
    return betas[0], betas[1:]
    
df = pd.read_csv('data.csv')
dataset_x = df.iloc[:, :-1].to_numpy()
dataset_y = df.iloc[:, -1].to_numpy().reshape(-1, 1)

intercept, coeffs = multiple_linear_regression(dataset_x, dataset_y)

predict_data = np.array([3, 3, -17])

"""
total = intercept
for i in range(len(coeffs)):
    total += coeffs[i] * predict_data[i]
print(total)
"""

result = np.dot(coeffs, predict_data) + intercept
print(result)

#----------------------------------------------------------------------------------------------------------------------------
    Tabii çoklu doğrusal regresyon için oluşturulan genel matrisel formül basit doğrusal regresyon için de kullanılabilir. 
    Aşağıdaki örnekte daha önce yapmış olduğumuz "points.csv" verileri ile basit doğrusal regresyon uygulanmıştır. Ancak bu 
    uygulamada çoklu doğrusal regresyon formülü kullanılmıştır. Örneğimizdeki "points.csv" dosyasının içeriği şöyledir:

    x,y
    2,4
    3,5
    5,7
    7,10
    7,8
    8,12
    9.5,10.5
    9,15
    10,17
    13,18
#----------------------------------------------------------------------------------------------------------------------------  

import numpy as np
import pandas as pd

def multiple_linear_regression(x, y):
    ones = np.ones((x.shape[0], 1))
    x = np.concatenate((ones, x), axis=1)
    betas = (np.linalg.inv(x.T @ x) @ x.T @ y).reshape(-1)
    return betas[0], betas[1:]
    
df = pd.read_csv('points.csv')
dataset_x = df.iloc[:, :-1].to_numpy()
dataset_y = df.iloc[:, -1].to_numpy().reshape(-1, 1)

intercept, coeffs = multiple_linear_regression(dataset_x, dataset_y)

x = np.linspace(0, 15, 1000)
y = intercept + coeffs[0] * x

import matplotlib.pyplot as plt

plt.title('Simple Linear Regression')
plt.scatter(dataset_x, dataset_y, color='blue')
plt.plot(x, y, color='red')
plt.xticks(range(1, 15))
plt.show()

predict_data = np.array([3])
result = np.dot(coeffs, predict_data) + intercept
print(result)

#----------------------------------------------------------------------------------------------------------------------------
    Çoklu doğrusal regresyon ile aktivasyon fonksiyonunun "linear" olduğu tek nörondan oluşan "perceptron" modeli birbirine 
    çok benzemektedir. Nörondaki "bias" değeri de aslında doğru denklemindeki "intercept" değeri gibi işlev görmektedir. 
    Perceptron'un n tane girişi olduğunu kabul edersek nöronda oluşacak dot product şöyle olur:

    𝑤₁𝑥₁ + 𝑤₂𝑥₂ + 𝑤₃𝑥₃ + ⋯ + 𝑤ₙ𝑥ₙ + 𝑏

    Bu da zaten n boyutlu uzaydaki hyperplane denklemidir. Tabii biz perceptron ile çözüm yaparken aslında arka planda en 
    küçük kareler yöntemini değil "gradient descent" nümerik optimizasyon yöntemini kullanmış olmaktayız. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    En küçük kareler yöntemiyle doğrusal regresyon için özellik ölçeklemesi yapmaya gerek yoktur. Çünkü kapalı çözümü olan 
    problemlerde özellik ölçekleme gerekmemektedir. Fakat eğer çözüm "gredient descent" gibi nümerik yöntemlerle yapılıyorsa 
    özellik ölçeklemesi yapılmalıdır. (Tabii kapalı çözümü olan bir problemi iteratif bir biçimde çözmeye çalışmanın genellikle 
    (ama her zaman değil) bir faydası olmaz.) 
    
    Veri kümsinde uç değerlerin olması (outliers) doğrusal regresyonu oldukça kötü etkilemektedir. Bu nedenle doğrusal regresyon 
    işleminden önce veri kümesinin bu uç değerlerden arındırılması gerekir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aslında scikit-learn içerisinde zaten en küçük kareler yöntemini kullanarak doğrusal regresyon işlemini yapan sklearn.linear_model 
    modülünde LinearRegression isimli bir sınıf bulunmaktadır. Yani bizim yukarıdaki gibi fonksiyonları yazmamıza gerek kalmamaktadır. 
    Sınıfın genel kullanımı diğer scikit-learn sınıflarında olduğu gibidir. Sınıfın __init__ metodunun parametrik yapısı şöyledir:

    sklearn.linear_model.LinearRegression(*, fit_intercept=True, copy_x=True, n_jobs=None, positive=False)

    Sınıf nesnesi herhangi bir argüman verilmeden default argümanlarla yaratılabilir. Örneğin:

    lr = LinearRegression()

    Nesne yaratıldıktan sonra beta katsayılarının elde edilmesi için yine fit işlemi yapılır:

    lr.fit(dataset_x, dataset_y)

    fit işleminden sonra nesnenin coef_ özniteliği beta katsayılarını (B1, B2, B3, ..., Bn) intercept_ örnek özniteliği 
    ise B0 değerini verir. Kestirim işlemi de manuel bir biçimde intercept_ ve coef_ özniteikleri kullanılarak yapılabilir. 
    Ancak zaten sınıfta bu işlemi yapan predict metodu da bulunmaktadır. 

    Aşağıdaki örnekte daha önce vermiş olduğumuz "points.csv" dosyası üzerinde LinearRegression sınıfıyla kestirim yapılmıştır.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv('points.csv')

dataset_x = df['x'].to_numpy()
dataset_y = df['y'].to_numpy()

from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(dataset_x.reshape(-1, 1), dataset_y)

x = np.linspace(0, 15, 1000)
y = lr.intercept_ + lr.coef_[0] * x

import matplotlib.pyplot as plt

plt.title('Simple Linear Regression')
plt.scatter(dataset_x, dataset_y, color='blue')
plt.plot(x, y, color='red')
plt.xticks(range(1, 15))
plt.show()

predict_data = 12.9
predict_result = lr.intercept_ + predict_data * lr.coef_[0]
print(predict_result)

predict_data = np.array([[12.9], [4.7], [6.9]])
predict_result = lr.predict(predict_data)
print(predict_result)

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi bir doğrusal regresyon uygulandığı zaman bu regresyonun başarısı hakkında bir şey söylenebilir mi? İşte bunun için 
    bazı ölçütler kullanılmaktadır. En yaygın kullanılan ölçüt R^2 (R kare) denilen ölçüttür. R^2 değeri ne kadar büyük olursa 
    elde edilen doğrunun noktaları temsil gücü o kadar iyi olur. R^2 değerine İngilizce "coefficient of determination" da 
    denilmektedir. R^2 [0, 1] aralığında değer belirtmetedir. R^2 değeri "açıklanan (explained) varyans değerinin toplam varyansa 
    oranıdır." Matematiksel olarak "kestirilen değerlerle gerçek değerlerin arasındaki farkların karelerinin toplamının, gerçek 
    değerlerle gerçek değerlerin ortalamasının farklarının karelerinin toplamına oranının 1'den çıkartılmasıyla hesaplanmaktadır:
    R^2 değerini şöyle ifade edebiliriz:

    rsquare = 1 - ((y_true - y_pred)** 2).sum() / ((y_true - y_true.mean()) ** 2).sum())

    Burada y_true gerçek y değerlerini y_pred ise doğru denkleminden elde edilen y değerlerini temsil etmektedir. 

    Yukarıda da belirttiğimiz gibi R^2 ne kadar büyük olursa doğrunun noktaları temsil etme özelliği o kadar fazla olmaktadır. 
    Ancak R^2 değeri kestirimin gücü konusunda mutlak bir belirlemeye sahip değildir. Yani R^2 değeri yüksek olduğu halde
    kestirim beklenen kadar güçlü olmayabilir ya da R^2 değeri yüksek olmadığı halde kestirim daha isabetli de olabilir. 
    Bunun çeşitli nedenleri vardır.  

    R^2 değeri LinearRegression sınıfının score isimli metodu ile elde edilebilmektedir. score metodunu çağırmadan önce bizim 
    fit işlemini yapmış olmamız gerekmektedir. score metodu bizden gerçek X ve Y değerlerini alır. X değerleriyle predict 
    işlemi yapıp R^2 değerini hesaplayarak bize verir. Örneğin:

    rsquare = lr.score(dataset_x.reshape(-1, 1), dataset_y)

     R^2 için 0.7'nin yukarısı "iyi", 0.9'un yukarısı "çok iyi" kabul edilmektedir.

    Her ne kadar istatistikte doğrusal regresyonun başarısı için genellikle R^2 değerine önem veriliyorsa da aslında daha 
    önce gördüğümüz diğer metrikler de kullanılabilmektedir. Örneğin gerçek değerlerle doğru denkleminden elde edilen değerler
    arasında "mean squared error" ya da "mean_absolute_error" metrikleri uygulanabilir. R^2 değerinin bir alternatifi olarak 
    sütun sayılarını da dikkate alan "düzeltilmiş R^2 (adjusted R^2)" ölçütü de sıkça kullanılmaktadır. Düzeltilmiş R^2 değeri 
    şöyle hesaplanmaktadır:

    Düzeltilmiş R² = 1 - ((1 - R²) * (n - 1)) / (n - p - 1)
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                            102. Ders - 16/02/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "Boston Hausing Prices" veri kümesi üzerinde çoklu doğrusal regresyon ile yapay sinir modeli uygulanmıştır. 
    Genel olarak bu haliyle yapay sinir ağı modelinin test verileri ile yapılan ölçümde (mean absolute error) her zaman daha 
    iyi sonuç verdiği görülmektedir. Ancak çoklu doğrusal regresyon da bu veri kümesi için kötü bir sonuç vermemektedir. Örnekte 
    çoklu doğrusal regresyonun R^2 değeri de yazdırılmıştır. Bu R^2 değerinin yüksekliği ile "mean absolute error" sonuçları 
    her zaman örtüşmemektedir.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(training_dataset_x, training_dataset_y)

predict_result = lr.predict(test_dataset_x)

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(predict_result, test_dataset_y)
print(f'Mean Absolute Error: {mae}')

r2 = lr.score(test_dataset_x, test_dataset_y)
print(f'R^2 = {r2}')
print()

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(training_dataset_x)
scaled_training_dataset_x = ss.transform(training_dataset_x)
scaled_test_dataset_x = ss.transform(test_dataset_x)

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense

model = Sequential(name='Boston-Housing-Price')
model.add(Dense(64, activation='relu', input_dim=training_dataset_x.shape[1], name='Hidden-1'))
model.add(Dense(64, activation='relu', name='Hidden-2'))
model.add(Dense(1, activation='linear', name='Output'))
model.summary()

model.compile(optimizer='rmsprop', loss='mse', metrics=['mae'])
hist = model.fit(scaled_training_dataset_x, training_dataset_y, batch_size=32, epochs=200, validation_split=0.2)

import matplotlib.pyplot as plt

plt.figure(figsize=(15, 5))
plt.title('Epoch-Loss Graph', fontsize=14, fontweight='bold')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.xticks(range(0, 210, 10))

plt.plot(hist.epoch, hist.history['loss'])
plt.plot(hist.epoch, hist.history['val_loss'])
plt.legend(['Loss', 'Validation Loss'])
plt.show()

plt.figure(figsize=(15, 5))
plt.title('Epoch-Mean Absolute Error Graph', fontsize=14, fontweight='bold')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.xticks(range(0, 210, 10))

plt.plot(hist.epoch, hist.history['mae'])
plt.plot(hist.epoch, hist.history['val_mae'])
plt.legend(['Mean Absolute Error', 'Validation Mean Absolute Error'])
plt.show()

eval_result = model.evaluate(scaled_test_dataset_x, test_dataset_y)

for i in range(len(eval_result)):
    print(f'{model.metrics_names[i]}: {eval_result[i]}')
    
#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi her türlü veri kümesine doğrusal regresyon uygulayabilir miyiz? Bunun yanıtı hayır olacaktır. Doğrusal regresyon 
    veri kümesinin sütunları ile (bağımsız değişkenlerle) kestirilecek nicelik (bağımlı değişken) arasında doğrusal bir ilişkiye
    benzer bir ilişki varsa iyi bir yöntem olabilmektedir. Eğer veri kümesinin sütunları ile kestirilecek nicelik arasında 
    doğrusal bir ilişki yoksa bu yöntemin başarısı düşmektedir. 

    Noktaların doğrusallığının korelasyon katsayısı ile ölçüldüğünü anımsayınız. Dolayısıyla biz önce X ve Y değerleri arasındaki 
    korelasyona bakıp ondan sonra doğrusal regresyon uygulayabiliriz. Eğer bu korelasyon çok zayıf çıkarsa doğrusal regresyon 
    uygulamamalıyız. Ancak diğer bir seçenek de veri kümesinde hedef değişken ile düşük korelasyona sahip sütunların atılması
    yalnızca yüksek korelasyona sahip sütunların doğrusal regresyona sokulmasıdır. Böyle bir yaklaşım tüm sütunların doğrusal
    regresyona sokulmasındna daha iyi sonuçlar vermektedir. 

    Çoklu doğrusal regresyonda X değişkenlerinin sayısı arttıkça (yani veri kümesindeki sütunların sayısı arttıkça) regresyonun
    temsil yeteneği azalmaktadır. Bu nedenle bu yöntem çok sayıda sütuna sahip veri kümelerinde dikkatlice uygulanmalıdır. Bu
    tür durumlarda yukarıda da belirttiğimiz gibi hedef değişken ile düşük korelasyona sahip sütunların atılmasıyla bir özellik 
    seçimi yapılabilir. 

    Aşağıdaki örnekte make_blobs fonksiyonu ile küresel noktalar üretilip bu noktalar üzerinde doğrusal regresyon uygulanmıştır. 
    Tabii R^2 değeri çok düşük çıkmıştır. X ve Y verileri arasında doğrusal bir ilişkiye benzeyen bir ilişki yoksa doğrusal 
    regresyon uygulamaya çalışmamalısınız ya da düşük korelasyonlu sütunları atarak yalnızca yüksek korelasyona sahip sütunları 
    doğrusal regresyona sokmalısınız. Doğrusal regresyonun uygulanamadığı bu tür durumlarda yapay sinir ağları ya da "destek 
    vektör makineleri (support vector machines)" gibi diğer yöntemleri tercih edebilirsiniz. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
from sklearn.datasets import make_blobs

dataset, _ = make_blobs(n_samples=100, centers=1, center_box=(0, 0))

dataset_x = dataset[:, 0].reshape(-1, 1)
dataset_y = dataset[:, 1]

from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(dataset_x, dataset_y)

x = np.linspace(-5, 5, 100)
y = lr.predict(x.reshape(-1, 1))

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
plt.title('Linear Regression with Circuler Data')
plt.scatter(dataset_x, dataset_y, color='blue')
plt.plot(x, y, color='red')
plt.show()

r2 = lr.score(dataset_x, dataset_y)
print(f'R^2 = {r2}')

cor = np.corrcoef(dataset_x.flatten(), dataset_y)
print(cor)

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi doğrusal regresyon uygulayacağımız veri kümemizde kategorik (nominal) sütunlar varsa ne yapmalıyız? Bu sütunları 
    doğrudan LabelEncoder ile sayısal hale getirip doğrusal regresyona sokmak iyi bir fikir değildir. Örneğin bir sütunda 
    "Kırmızı", "Yeşil", "Mavi" gibi etketler bulunuyor olsun. Burada Kırmızı = 0, Mavi = 1, Yeşil = 2 ilişkisinin doğrusal 
    regresyon için hiçbir anlamı yoktur. Bu tür durumlarda "one-hot-encoding" dönüştürmesinin uygulandığını anımsayınız. O 
    halde biz de kategorik sütunları önce "one-hot-encoding" dönüştürmesine sokup sonra doğrusal regresyon uygulayabiliriz. 
    Tabii aslında doğrusal regresyon tipik olarak nümerik sütunların söz konusu olduğu veri kümeleri için uygun yöntem olmaktadır. 
    Kategorik sütunlara sahip veri kümelerinde bu kategorik sütunlar doğrusal regresyon uygulamadan önce tamamen de atılabilir. 
    Ancak bu da regresyonun sonucunu etkileyebilecektir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi veri kümemiz için doğrusal regresyonun uygun olup olmadığına nasıl karar verebiliriz? Örneğin elimizde x1, x2, x3 
    ve x4 sütunlarına sahip bir veri kümesi olsun bunlar da Y değerleriyle eşleşsinler. Biz bu veri kümesinin doğrusal regresyona
    uygunluğunu nasıl belirleyebiliriz? İşte bunun için iki yöntem uygulanabilir:

    1) Biz önce doğrusal regresyonu uygulayıp R^2 değerine bakabiliriz. Eğer R^2 değeri düşük çıkarsa doğrusal regresyon uygulamanın
    iyi bir fikir olmadığına karar veririz. 
    
    2) Veri kümesinin sütunlarıyla Y sütunu arasında tek tek ikili korelasyonlara bakarız. Eğer bu korelasyonlar yüksek değilse 
    doğrusal regresyonun iyi sonuç vermeyeceğini düşünürüz. Bu durumda ya doğrusal regresyon uygulamaktan vazgeçeriz ya da 
    yalnızca Y değerleriyle yüksek korelasyona sahip sütunları doğrusal regresyona sokarak duruma bakabiliriz.

    Örneğin x1, x2, x3, x4 sütunlarından x1 ve x3'ün Y ile korelasyonları yüsek ancak x2 ile x4'ün Y ile korelasyonları düşük 
    olsun. Bu durumda uygulamacı ne yapabilir? İşte bu tür durumlarda yukarıda da belirttiğimiz gibi uygulamacı düşük korelasyonu 
    olan sütunları atarak "özellik seçimi (feature selection)" uygulayabilir. Yani uygulamacı burada x1 ve x3 sütunlarını alıp 
    x2 ve x4 sütunlarını atarak doğrusal regresyon uygulayabilir. Doğrusal regresyonda tüm sütunların kullanılması zorunlu 
    değildir. Bu tekniği uygulamak için Y verileri X verilerine katılıp np.corrcoef fonksiyonu uygulanabilir. Bu fonksiyon 
    uygulanarak heatmap grafiğinin çizilmesi de görsel olarak tespitin yapılmasını kolaylaştıracaktır.

    Çoklu doğrusal regresyonda eğer sütun sayısı fazla ise veri kümesindeki satır sayısı da fazla olmaldıdır. Başka bir deyişle
    sütun sayısının satır sayısına oranı yüksek olmamalıdır. Eğer özellik seçimi yapıldıktan sonra hala bu oran yüksek kalıyorsa
    doğrusal regresyon uygulamaktan vazgeçilebilir. 

    Aşağıdaki örnekte "Boston Housing Prices" veri kümesinde X sütunlarıyla Y arasındaki korelasyonlar incelenmiş ve 0.45'ten 
    büyük olan sütunlar alınarak onlarla doğrusal regresyon uygulanmıştır. Bu sonuç tüm sütunların alınmasıyla elde edilen 
    sonuçtan biraz daha iyi olmaktadır.
#----------------------------------------------------------------------------------------------------------------------------

CORR_THREASHOLD = 0.45

import numpy as np
import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')
from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=1234)

from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(training_dataset_x, training_dataset_y)

predict_result = lr.predict(test_dataset_x)

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(predict_result, test_dataset_y)
print(f'Mean Absolute Error: {mae}')
r2 = lr.score(test_dataset_x, test_dataset_y)
print(f'R^2 = {r2}')
print()

concat_dataset = np.concatenate((training_dataset_x, training_dataset_y.reshape(-1, 1)), axis=1)
corr = np.abs(np.corrcoef(concat_dataset, rowvar=False))

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(15, 8))
sns.heatmap(data=corr, annot=True)
plt.show()

selected_cols, = np.where(corr[:-1, -1] > CORR_THREASHOLD)

selected_training_dataset_x = training_dataset_x[:, selected_cols] 
selected_test_dataset_x = test_dataset_x[:, selected_cols] 

from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(selected_training_dataset_x, training_dataset_y)

predict_result = lr.predict(selected_test_dataset_x)
mae = mean_absolute_error(predict_result, test_dataset_y)
print(f'Mean Absolute Error: {mae}')

r2 = lr.score(selected_test_dataset_x, test_dataset_y)
print(f'R^2 = {r2}')

#----------------------------------------------------------------------------------------------------------------------------
    Doğrusal regresyonun diğer önemli bir problemi de "multi-collinearity" denilen problemdir. Eğer doğrusal regresyon için 
    kullanılan X veri kümesindeki bazı sütunların kendi aralarında yüksek bir korelasyonu varsa yüksek korelasyonu olan sütunların 
    birlikte regresyona sokulması regresyonu kötüleştirmektedir. Bu durumda uygulamacı kendi aralarında yüksek korelasyona 
    sahip olan sütunların yalnızca bir tanesini alıp regresyon uygulamalıdır. İşte X sütunlarıyla Y arasında yüksek korelasyon 
    olanları seçtikten sonra ayrıca seçilenlerin arasındaki korelasyonlara da bakmalıyız. Eğer seçilenler arasında yüksek korelsyona 
    sahip olanlar varsa onların da bir tanesini muhafaza ederek diğerlerini atabiliriz. 

    Pekiyi aralarında yüksek korelasyon olan sütunları nasıl tespit edebiliriz? İlk akla gelen yöntem korelasyon matrisini elde 
    edip matrisin hücrelerine bakmak, yüksek değerli hücrelerin bulunduğu sütunlardan birini atıp diğerini seçmek olabilir. Bu 
    durumda seçilecek sütun hedef değişkenle korelasyonu daha yüksek olan sütun olabilir. Tabii C1 sütunu ile C2 sütunu arasında,  
    C2 sütunu ile de C3 sütunu arasında yüksek bir korelasyon olabilir. Bu durumda eğer biz C1 sütununu atacaksak C2 ile C3 
    arasında da yüksek korelasyon olduğu için C2 ya da C3'ten birini de atmak isteyebiliriz. 

    Aralarında yüksek korelasyonun bulunduğu sütunları tespit etmek için nümerik yöntemler de geliştirilmiştir. Bunlardan en 
    çok kullanılanı "Variance Inflation Factor (VIF)" denilen yöntemdir. Bu yöntemde veri kümesinin sütunları tek tek bu bakımdan 
    değerlendirilir. Yüksek skor alan sütunların diğer sütunlarla korelasyonu olduğu sonucuna varılır. Bu yöntemin matematiksel 
    açıklamasını burada yapmayacağız. Bu yöntemi uygulayan scikit-learn ya da SciPy içerisinde hazır bir fonksiyon yoktur. Ancak 
    "statsmodels" kütüphanesinde statsmodels.stats.outliers_influence modülünde variance_inflation_factor isimli bir fonksiyon 
    bulunmaktadır. Kütüphane Anaconda dağıtımında default olarak bulunmamaktadır. Kütüphaneyi pip programı ile şöyle kurabilirsiniz.

    pip install statsmodels

    variance_inflation_factor fonksiyonun iki parametresi vardır. Birinci parametre X verilerinin bulunduğu matrisi, ikinci 
    parametre sütun numarasını alır. Uygulamacının bir döngü içerisinde tüm sütunlar için bu fonksiyonu çağırması gerekir. 
    Pekiyi fonksiyonun geri döndürdüğü VIF değeri nasıl yorumlanacaktır? Yorumu tipik olarak şöyle yapılmaktadır:

    - Eğer 1 ise sütunun diğerleri ile korelasyonu yoktur.
    - Eğer 1 ile 5 arasında ise sütunun diğer sütunlarla orta derecede bir korelasyonu vardır.
    - 5'ten büyük ise sütun diğer sütunlarla yüksek bir korelasyon içerisindedir.

    O halde biz iki yöntemi karma edebiliriz. Yani biz hem Y ile yüksek korelasyonu olan X sütunlarını alabiliriz hem de kendi 
    aralarında yüksek korelasyonu olan X sütunlarını atabiliriz. Bu tür durumlarda hedef değişkenle yüksek korelasyonu olan 
    sütunların seçilmesi genel olarak doğrusal regresyon için daha etkilidir. (Yani önce hedef değişkenle yüksek korelasyonlu 
    sütunları belirleyip sonra onların arasında yüksek korelasyon olan sütunları elimine etmek uygun olabilir.) 

    Aşağıdaki örnekte VIF değerlerine bakılarak aralarında yüksek korelasyon bulunan sütunlardan birisi atılmıştır. Ancak bu 
    örnekte önemli bir sorun vardır. Yukarıda da belirttiğimiz gibi eğer biz yalnızca sütunların kendi aralarındaki korelasyonlarına 
    bakarsak hiç hedef değişkenle olan koreleasyonlara bakmazsak VIF yöntemiyle seçilen sütunların hedef değişkenle korelasyonu 
    düşük olabilir. Bu da kötü bir sonucun elnde edilmesine yol açacaktır. Aşağıda yalnızca yüksek korelasyonu olan sütunların 
    atılmasıyla doğrusal regresyon uygulanmıştır. Bu da kötü bir sonucun elde edilmesine yol açmıştır. 
#----------------------------------------------------------------------------------------------------------------------------

CORR_THREASHOLD = 0.45

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=1234)

import numpy as np

concat_dataset = np.concatenate((training_dataset_x, training_dataset_y.reshape(-1, 1)), axis=1)
corr = np.abs(np.corrcoef(concat_dataset, rowvar=False))

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(15, 8))
sns.heatmap(data=corr, annot=True)
plt.show()

selected_cols, = np.where(corr[:-1, -1] > CORR_THREASHOLD)
print(selected_cols)

from statsmodels.stats.outliers_influence import variance_inflation_factor

vifs =  np.array([variance_inflation_factor(training_dataset_x, i) for i in range(training_dataset_x.shape[1])])

for i, vif in enumerate(vifs):
    print(f'{i} ---> {vif}')

selected_cols, = np.where(vifs < 5)
print(selected_cols)

selected_training_dataset_x = training_dataset_x[:, selected_cols]
selected_test_dataset_x = test_dataset_x[:, selected_cols]

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error

lr = LinearRegression()
lr.fit(selected_training_dataset_x, training_dataset_y)

predict_result = lr.predict(selected_test_dataset_x)
mae = mean_absolute_error(predict_result, test_dataset_y)
print(f'Mean Absolute Error: {mae}')

r2 = lr.score(selected_test_dataset_x, test_dataset_y)
print(f'R^2 = {r2}')

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de "Boston Housing Prices" veri kümesinde hem hedef değişkenle yüksek korelasyonu olan sütunları alalım hem de 
    bunların arasında yüksek korelasyonu olan sütunları elimine edelim. Ancak bu iki yöntemi uygularken elimizde hiç sütun da 
    kalmayabilir. Çünkü hedef değişkenle yüksek korelasyonu olan sütunlar elde edildikten sonra bunlar arasındaki korelasyonlar 
    da yüksek olabilir. Bu durumda eşik değerlerini yükseltebilirsiniz. 
    
    Aşağıdaki örnekte önce hedef değişkenle yüksek korelasyona sahip sütunlar alınıp sonra da kendi aralarında yüksek korelasyona 
    sahip olan sütunlar VIF değerlerinden hareketle atılmıştır. Biz burada VIF için eşik değerini 10 olarak aldık. Bunun sonucunda 
    örneğimizde yalnızca iki sütun seçildi. Ancak regresyonumuzun başarısı iyi olmadı. Çünkü iki sütunun seçilmesi önemli bir 
    bilgi kaybı oluşturdu. Tabii bu örnekte eşik değerlerini değiştirerek daha iyi sonuçlar oluşturabilirsiniz. 
#----------------------------------------------------------------------------------------------------------------------------

CORR_THREASHOLD = 0.45

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

import numpy as np
from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=1234)

concat_dataset = np.concatenate((training_dataset_x, training_dataset_y.reshape(-1, 1)), axis=1)
corr = np.abs(np.corrcoef(concat_dataset, rowvar=False))

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(15, 8))
sns.heatmap(data=corr, annot=True)
plt.show()

corr_selected_cols, = np.where(corr[:-1, -1] > CORR_THREASHOLD)
print(corr_selected_cols)

from statsmodels.stats.outliers_influence import variance_inflation_factor

vifs =  np.array([variance_inflation_factor(training_dataset_x[:, corr_selected_cols], i) for i in range(len(corr_selected_cols))])
for i, vif in enumerate(vifs):
    print(f'{corr_selected_cols[i]} ---> {vif}')
    
final_selected_indexes, = np.where(vifs < 10)
print(corr_selected_cols[final_selected_indexes])

final_selected_training_dataset_x = training_dataset_x[:, corr_selected_cols[final_selected_indexes]]
final_selected_test_dataset_x = test_dataset_x[:,corr_selected_cols[final_selected_indexes]]

from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error

lr = LinearRegression()
lr.fit(final_selected_training_dataset_x, training_dataset_y)

predict_result = lr.predict(final_selected_test_dataset_x)
mae = mean_absolute_error(predict_result, test_dataset_y)
print(f'Mean Absolute Error: {mae}')

r2 = lr.score(final_selected_test_dataset_x, test_dataset_y)
print(f'R^2 = {r2}')

#----------------------------------------------------------------------------------------------------------------------------
    Matematiksel optimizasyon problemlerinin çözümü temelde iki yöntemle yapılmaktadır:

    1) Kapalı (closed) yöntemle (buna sembolik ya da analitik yöntem de denilmektedir).
    2) Nümerik yöntemle.

    Çözümün eşitlikler ya da formüllerle sembolik bir biçimde oluşturulmasına "kapalı çözüm" denilmektedir. Kapalı çözüm 
    oluşturulduğunda belli değerler için sonuçlar bu değerlerin formülde yerine konulmasıyla elde edilir. Yani kapalı çözüm 
    genel bir biçimde yapılır ve bu çözümden genel bir eşitlik ya da formül elde edilir. Örneğin f(x) = 3x^2 - 5x + 7 fonksiyonun 
    türevi kapalı yöntemle f'(x) = 6x - 5 biçiminde bir fonksiyon olarak elde edilmektedir. Biz de asıl fonksiyonun belli bir 
    noktasındaki türevini bu noktayı türev fonksiyonunda yerine koyarak elde ederiz. Örneğin çoklu doğrusal regresyonun çözümünde 
    kullanılan en küçük kareler yöntemi bir kapalı çözüm vermektedir. Anımsanacağı gibi biz bu kapalı çözümden 
    (X.T @ X)^-1 @ X.T @ y biçiminde bir formül elde etmiştik. Sonra da somut bir problemi çözmek için değerleri bu formülde 
    yerine koymuştuk. Ancak maalesef her türlü problemin bu biçimde formülsel bir kapalı çözümü oluşturulamamaktadır. Bazı 
    problemlerin kapalı çözümleri bir biçimde yapılabilse bile bunlar artık uygulanabilirlikten uzaklaşabilmektedir. İşte bu
    tür problemlerde diğer bir çözüm yöntemi "nümerik analiz" yöntemi ya da kısaca "nümerik" yöntemdir. Nümerik yöntemlerde 
    problemi çözecek bir formül bulmak yerine çözüm iteratif bir biçimde gittikçe iyileştirerek elde edilmektedir. Tabii 
    nümerik yöntemlerin etkin kullanılabilmesi ancak programalama yoluyla mümkündür. 

    Şüphesiz kapalı çözümler daha kesin bir sonuca varılmasını sağlamaktadır. Kapalı çözüm çoğu durumda çok daha hızlı olma 
    eğilimindedir. (Ancak seyrek de olsa bazı durumlarda kapalı yöntemler nümerik analiz yöntemlerine göre daha yavaş da 
    kalabilmektedir.) Nümerik çözümler iteratif olduğu için hedeflenen sonuca yavaş yavaş yaklaşmayı sağlarlar. Dolayısıyla 
    gerçek sonuç ile elde edilen sonuç arasında farklar oluşabilmektedir. Yukarıda da belirttiğimiz gibi pek çok problemin 
    kapalı çözümünün mümkün olmaması nümerik çözümlerin kullanılmasını zorunlu hale getirmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    scikit-learn içerisindeki LinearRegression sınıfı yukarıda bizim benzerini yazdığımız "en küçük kareler" yöntemini kullanmaktadır. 
    Bu sınıf ile çoklu doğrusal regresyon yaparken uygun sütunların seçilmesi uygulamacının sorumluluğundadır. İşte bu konuda 
    uygulamacıya yardımcı olan üç önemli regresyon modeli daha bulunmaktadır: Lasso Regresyonu, Ridge Regresyonu ve Eleastic Net 
    Regresyonu. Bu regresyon modelleri aslında birbirine benzemektedir. Birbirlerinin çeşitli versiyonları gibidir. Bu regresyon 
    modelleri sembolik biçimde çözülmemekte, iteratif nümerik analiz yöntemleriyle "gradient descent" optimizasyon tekniği ile 
    çözülmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Lasso regresyonu en küçük kareler yöntemine mutlak değer içeren bir ceza puanının eklenmesiyle oluşturulmuştur. Böylece 
    regresyon modelinin nümerik analiz yöntemiyle iteratif çözülmesinde kullanılan en küçüklenecek amaç fonksiyonu (loss 
    fonksiyonu) bu ceza puanı nedeniyle aralarında yüksek korelasyon olan sütunları ve Y değerleriyle düşük korelasyon olan 
    sütunları elimine etmektedir. Yani Lasso regresyonu kendi içerisinde zaten yukarıda manuel biçimde yapmaya çalıştığımız 
    "özellik seçimlerini" kendisi yapmaktadır. Lasso regresyonunda en küçük kareler yöntemine eklenen bu ceza puanına "L1 
    Düzenlemesi (L1 regulation)" denilmektedir. Lasso regresyonundaki en küçüklenecek amaç fonksiyonu (ya da "loss" fonksiyonu) 
    aşağıdaki biçimde ifade edilebilir:

    J(β) = Σ(yᵢ - ŷᵢ)² + λ * Σ|βⱼ|

    Burada aslında ifadenin baş tarafı en küçük kareler formülüdür. Bu formüle L1 düzenlemesi (L1 Regulation) denilen aşağıdaki 
    terim eklenmiştir:

    λ * Σ|βⱼ|

    Burada Σ|βⱼ| ifadesi katsayıların mutlak değerlerinin toplamını belirtmektedir. λ ise bir hyper parametredir. Eğer λ = 0 
    olursa Lasso regresyonunun en küçük kareler regrsyonundan bir farkı kalmaz. λ parametresinin değeri artırıldıkça daha fazla 
    sütun elimine edilecektir. Uygulamacı çeşitli λ değerleri içinmodeli deneyip deneme yanılma yöntemiyle uygun λ değerini 
    belirlemeye çalışabilir. 
    
    Lasso regresyonunda "özellik ölçeklemesi" gerekmektedir. Genel olarak "standart ölçekleme (standard scaling)" tercih 
    edilmektedir. Ancak "Min-Max ölçeklemesi" de benzer sonuçları verebilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Lasso regeresyonu için sklearn.linear_model modülü içerisindi Lasso isimli bir sınıf bulundurulmuştur. Sınıfın kullanımı 
    diğer scikit-learn sınıflarında olduğu gibidir. Lasso sınıfının __init__ metodunun  parametrik yapısı şöyledir:

    class sklearn.linear_model.Lasso(alpha=1.0, *, fit_intercept=True, precompute=False, copy_X=True, 
            max_iter=1000, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')
    
    Metodun en önemli parametresi L1 düzenlemesinde söz konusu olan bizim lamda dediğimiz parametredir. Bizim lamda dediğimiz
    bu parametreye scikit-learn içerisinde alpha denilmektedir. Bu parametrenin default değerinin 1 olduğuna dikkat ediniz.
    Daha sonra yaratılan nesne ile sınıfın fit metodu X ve Y değerleiyle çağrılır. Yine tahminleme için predict metodu 
    kullanılmaktadır. Oluşturulan hyperplane'in katsayı değerleri coef_ ve intercept_ örnek özniteliklerinden elde edilebilmektedir.

    Lasso regresyonu kendi içerisinde özellik seçimi de yaptığından sınıfın coef_ ile elde edilen katsayılarının bazıları sıfır 
    olacaktır. Bu katsayılırın sıfır olması aslında o sütunun tamamen atıldığı anlamına gelmektedir. 

    Lasso sınıfında alpha değerini 0 verdiğinizde bir uyarı mesajıyla karşılaşabilirisiniz. Çünkü bu durumda Lasso regresyonunun 
    en küçük kareler yönteminden yaklaşımsal olarak bir farkı kalmamaktadır. 

    Aşağıdaki örnekte "Boston Housing Prices" veri kümesi üzerinde Lasso regresyonu uygulanmıştır. Burada alpha parametresi 
    0.2 seçilmiştir. Bu seçim soncunda dört sütun atılmıştır. Bu örnekte veriler üzerinde standart ölçekleme de uygulanmıştır. 
    Tabii kestirimde bulunulurken kestirilmek istenen X değerlerinin de yine aynı standart ölçeklemeye sokulması gerekmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

ALPHA = 0.05

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
    train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=12345)

from sklearn.preprocessing import StandardScaler 

ss = StandardScaler()
ss.fit(training_dataset_x)
scaled_training_dataset_x = ss.transform(training_dataset_x)
scaled_test_dataset_x = ss.transform(test_dataset_x)

from sklearn.linear_model import Lasso
from sklearn.metrics import mean_absolute_error

lasso = Lasso(ALPHA)
lasso.fit(scaled_training_dataset_x, training_dataset_y)

print(f'Intercept: {lasso.intercept_}')
print(f'Coefficients: {lasso.coef_}')

test_predict_result = lasso.predict(scaled_test_dataset_x)
r2 = lasso.score(scaled_training_dataset_x, training_dataset_y)
print(f'R^2: {r2}')

mae = mean_absolute_error(test_predict_result, test_dataset_y)
print(f'Mean Absolute Error: {mae}')

import numpy as np

predict_data = np.array([[0.98843, 0.00, 8.140, 0, 0.5380, 5.813, 100.00, 4.0952, 4, 307.0, 21.0, 394.54,  19.88], 
[0.75026, 0.00, 8.140, 0, 0.5380, 5.9240, 94.10, 4.3996, 4, 307.0, 21.00, 394.33, 16.30]])

scaled_predict_data = ss.transform(predict_data)

predict_result = lasso.predict(scaled_predict_data)
print(f'Predict Result: {predict_result}')

#----------------------------------------------------------------------------------------------------------------------------
    Lasso regresyonundaki alpha parametresini otomatik ayarlamanın bir yolu yoktur. Uygulamacı değişik alpha değerlerini deneyip
    uygun bir değeri seçebilir. Bunun "grid search" gibi sistematik yöntemler de kullanılmaktadır. Biz ileride "grid search" 
    yönteminin üzerinde duracağız. 

    Aşağıdaki örnekte "Boston Housing Prices" veri kümesi üzerinde alpha 0'dan başlatılarak 0.05 artırımla Lasso regresyonu 
    çok defalar uygulanıp "mean absolute error" değerinin en düşük olduğu alpha değeri tespit edilmeye çalışılmıştır. Burada 
    R^2 değerinin yükselmesini önemsemeyiniz. Daha önceden de belirttiğimiz gibi R^2 değeri doğrusal regresyonun iyiiğine ilişkin 
    genel bir ölçüt olmasına karşın spesifik bir veri kümesi için mutlak anlamda bir belirleme için kullanılamamaktadır. Yukarıda 
    da belirttiğimiz gibi alpha = 0 değeri için Lasso sınıfı bir uyarı vermektedir. Bu uyarı mesajını dikkate almayınız. Programın 
    çalıştırılmasıyla aşağıdaki gibi bir çıktı elde edilmiştir:

    Alpha: 0, MAE: 3.427549362182617, R^2: 0.7427978515625
    Alpha: 0.05, MAE: 3.337947368621826, R^2: 0.7414087057113647
    Alpha: 0.1, MAE: 3.295764684677124, R^2: 0.7375916838645935
    Alpha: 0.15000000000000002, MAE: 3.2998266220092773, R^2: 0.7311793565750122
    Alpha: 0.2, MAE: 3.33180832862854, R^2: 0.7246889472007751
    Alpha: 0.25, MAE: 3.3882341384887695, R^2: 0.7197294235229492
    Alpha: 0.3, MAE: 3.444835662841797, R^2: 0.7149202823638916
    Alpha: 0.35, MAE: 3.4982802867889404, R^2: 0.7100659608840942
    Alpha: 0.39999999999999997, MAE: 3.547013521194458, R^2: 0.7054669857025146
    Alpha: 0.44999999999999996, MAE: 3.564919948577881, R^2: 0.7023859620094299
    Alpha: 0.49999999999999994, MAE: 3.58282732963562, R^2: 0.6989423036575317
    Alpha: 0.5499999999999999, MAE: 3.600729465484619, R^2: 0.6951364278793335
    Alpha: 0.6, MAE: 3.6019318103790283, R^2: 0.6927566528320312
    Alpha: 0.65, MAE: 3.598907470703125, R^2: 0.6906068325042725
    Alpha: 0.7000000000000001, MAE: 3.5949909687042236, R^2: 0.6883739233016968
    Alpha: 0.7500000000000001, MAE: 3.5910913944244385, R^2: 0.6859737634658813
    Alpha: 0.8000000000000002, MAE: 3.587191104888916, R^2: 0.6834081411361694
    Alpha: 0.8500000000000002, MAE: 3.583289861679077, R^2: 0.6806771755218506
    Alpha: 0.9000000000000002, MAE: 3.579387903213501, R^2: 0.6777805685997009
    Alpha: 0.9500000000000003, MAE: 3.5754871368408203, R^2: 0.67471843957901
    Alpha: 1.0000000000000002, MAE: 3.572746992111206, R^2: 0.6714907884597778
    Alpha: 1.0500000000000003, MAE: 3.570899248123169, R^2: 0.6680976152420044
    Alpha: 1.1000000000000003, MAE: 3.57242488861084, R^2: 0.6645389199256897
    Alpha: 1.1500000000000004, MAE: 3.576953649520874, R^2: 0.660814642906189
    Alpha: 1.2000000000000004, MAE: 3.5821940898895264, R^2: 0.6569249629974365
    Alpha: 1.2500000000000004, MAE: 3.58744215965271, R^2: 0.6528698205947876
    Alpha: 1.3000000000000005, MAE: 3.5923964977264404, R^2: 0.6496732234954834
    Alpha: 1.3500000000000005, MAE: 3.5976717472076416, R^2: 0.646392822265625
    Alpha: 1.4000000000000006, MAE: 3.602947950363159, R^2: 0.6429885625839233
    Alpha: 1.4500000000000006, MAE: 3.6082236766815186, R^2: 0.639460563659668
    Alpha: 1.5000000000000007, MAE: 3.614792823791504, R^2: 0.6363101601600647
    Alpha: 1.5500000000000007, MAE: 3.6226513385772705, R^2: 0.633413553237915
    Alpha: 1.6000000000000008, MAE: 3.6321372985839844, R^2: 0.6304188966751099
    Alpha: 1.6500000000000008, MAE: 3.642801284790039, R^2: 0.6273297071456909
    Alpha: 1.7000000000000008, MAE: 3.653465747833252, R^2: 0.6241455078125
    Alpha: 1.7500000000000009, MAE: 3.665154457092285, R^2: 0.6208661794662476
    Alpha: 1.800000000000001, MAE: 3.677025318145752, R^2: 0.6174920797348022
    Alpha: 1.850000000000001, MAE: 3.689149856567383, R^2: 0.6140228509902954
    Alpha: 1.900000000000001, MAE: 3.703413963317871, R^2: 0.6104587316513062
    Alpha: 1.950000000000001, MAE: 3.7179884910583496, R^2: 0.6067994832992554

    Bu örnek programda "mean absolute error" değerinin en küçük olduğu alpha değerinin 0.1 olduğu görülmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=54321)

from sklearn.preprocessing import StandardScaler 

ss = StandardScaler()
ss.fit(training_dataset_x)
scaled_training_dataset_x = ss.transform(training_dataset_x)
scaled_test_dataset_x = ss.transform(test_dataset_x)

from sklearn.linear_model import Lasso
from sklearn.metrics import mean_absolute_error

alpha = 0

while alpha < 2:
    lasso = Lasso(alpha)
    lasso.fit(scaled_training_dataset_x, training_dataset_y)
    test_predict_result = lasso.predict(scaled_test_dataset_x)
    r2 = lasso.score(scaled_training_dataset_x, training_dataset_y)
    mae = mean_absolute_error(test_predict_result, test_dataset_y)
    print(f'Alpha: {alpha}, MAE: {mae}, R^2: {r2}')
    alpha += 0.05
  
 #----------------------------------------------------------------------------------------------------------------------------
    Lasso regresyonunun bir benzerine "Ridge Regresyonu" denilmektedir. Ridge regresyonu da tıpkı Lasso regresyonunda olduğu 
    gibi özellik seçimi yapmaktadır. Ancak Ridge regresyonu sütunları tam olarak atmaz (aynı sütunların Beta katsayılarını 
    sıfırlamaz), onların etkisini zayıflatır. Dolayısıyla Ridge regresyonunda coef_ katsayı örnek özniteliklerinin bazıları 
    sıfır değil sıfıra yakın değerler olacaktır. 

    Ridge regresyonun temel mantığı Lasso regresyonunda olduğu gibidir. Ancak bu regresyonda ceza terimi mutlak değer değil 
    kare içermektedir. Bu ceza terimine "L2 Düzenlemesi (L2 Regulation)" de denilmektedir. Ridge regresyonundaki ceza teriminde 
    de bir lambda parametresi vardır. Yine bu lambda parametresi yükseltilirse daha fazla sütunun etkisi azaltılmaktadır. Yani 
    lambda değeri yükseltilirse daha fazla sütunun katsayı değeri 0'a yaklaştırılmakta, düşürülürse daha az sütunun katsayı 
    değeri 0'a yaklaştırılmaktadır. Ridge regresyonunun amaç fonksiyonu (ya da "loss" fonksiyonu) şöyledir:

    J(β) = ∑(yᵢ - ŷᵢ)² + λ * ∑(βⱼ²)

    Burada L2 regülasyonu denilezn ceza terimi aşağıdaki gibidir:

    λ * ∑(βⱼ²)

    Burada mutlak değer yerine kare alma işlemi optimizasyon sırasında sütunun katsayısını sıfırlamak yerine onun etkisini 
    düşürmektedir. 

    Ridge regresyonunda da yine özellik ölçeklemesi yapılmalıdır. Genel olarak uygulamacılar standart ölçeklemyi tercih 
    ederler. Ancak Min-Max ölçeklemesi de benzer sonuçları vermektedir. 

    Ridge regresyonunda L2 regülasyon teriminde kare alma ifadesi olduğu çin lamda değeri Lasso regresyonuna göre daha büyük 
    tutulabilir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Ridge regresyonu için scikit-learn kütüphanesinde sklearn.linear_model modülünde Ridge isimli bir sınıf bulundurulmuştur. 
    Sınıfın __init__ metidonun parametrik yapısı şöyledir:

    class sklearn.linear_model.Ridge(alpha=1.0, *, fit_intercept=True, copy_X=True, max_iter=None, tol=0.0001, 
        solver='auto', positive=False, random_state=None)
    
    Sınıfının genel kullanımı Lasso sınıfı ile aynıdır. 

    Aşağıdaki örnekte "Boston Hosuing Prices" veri kümesi üzerinde üzerinde Ridge regresyonu uygulanmıştır. Bu örnekte alpha 
    parametresi değişik değerlerle deneyiniz. alpha parametresi yükseltildikçe daha fazla sütun değeri sıfıra yaklaştırılacaktır.
#----------------------------------------------------------------------------------------------------------------------------

ALPHA = 5

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=54321)

from sklearn.preprocessing import StandardScaler 

ss = StandardScaler()
ss.fit(training_dataset_x)
scaled_training_dataset_x = ss.transform(training_dataset_x)
scaled_test_dataset_x = ss.transform(test_dataset_x)

from sklearn.linear_model import Ridge
from sklearn.metrics import mean_absolute_error

ridge = Ridge(ALPHA)
ridge.fit(scaled_training_dataset_x, training_dataset_y)

print(f'Intercept: {ridge.intercept_}')
print(f'Coefficients: {ridge.coef_}')

test_predict_result = ridge.predict(scaled_test_dataset_x)
r2 = ridge.score(scaled_training_dataset_x, training_dataset_y)
print(f'R^2: {r2}')

mae = mean_absolute_error(test_predict_result, test_dataset_y)
print(f'Mean Absolute Error: {mae}')

import numpy as np

predict_data = np.array([[0.98843, 0.00, 8.140, 0, 0.5380, 5.813, 100.00, 4.0952, 4, 307.0, 21.0, 394.54,  19.88], 
        [0.75026, 0.00, 8.140, 0, 0.5380, 5.9240, 94.10, 4.3996, 4, 307.0, 21.00, 394.33, 16.30]])

scaled_predict_data = ss.transform(predict_data)

predict_result = ridge.predict(scaled_predict_data)
print(f'Predict Result: {predict_result}')

#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Elastic Net regresyonu denilen regresyon modeli de aslında Lasso ve Ridge regresyonlarının ceza terimlerinin birleştirilmiş 
    bir biçimidir. Yani ceza terimi içerisinde hem L1 regülayonu hem de L2 regülasyon terimi bulunmaktadır. Dolayısıyla modelin 
    lambda1 ve lambda2 biçiminde iki heyper parametresi vardır. Modelin isminin "elastic" olarak isimlendirilmesi daha esnek 
    bir kullanıma izin vermesindendir. Burada hem bazı sütunlar elimine edilirken bazılarının etkileri de düşürülmektedir. Tabii 
    heyper parametrelerin fazla olması daha fazla ayarlama yapma gereksinimini doğurmaktadır. Elastic Net regresyon modelinin
    amaç fonksiyonu (ya da "loss" fonksiyonu) şöyle ifade edilebilir:

    Loss(β) = ∑(yᵢ - ŷᵢ)² + λ1 * Σ|βⱼ| + λ2 * ∑(βⱼ²)
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Elistic Net regresyon modeli scikit-learn kütüphanesinde linear_model modülündeki ElasticNet isimli sınıfla temsil edilmiştir. 
    Sınıfın __init__ metodunun parametrik yapısı şöyledir:

    class sklearn.linear_model.ElasticNet(alpha=1.0, *, l1_ratio=0.5, fit_intercept=True, precompute=False, max_iter=1000, 
            copy_X=True, tol=0.0001, warm_start=False, positive=False, random_state=None, selection='cyclic')

    Burada alpha parametresi yine temel bir hyper parametredir. Hem L1 regülasyonu üzerinde hem de L2 regülasyonu üzerinde 
    etkili olmaktadır. l1_ratio parametresi ise L1 regülasyonunun L2 düzenlemesine göre etkisini belirlemektedir. l1_ratio 
    default olarak 0.5 değerindedir. Yani bu durumda L1 regülasyonu da L2 regülasyonu da aynı oranda etkiye sahiptir. Uygulamacı 
    alpha değerini sabit tutarak l1_ratio değerini değiştirip bunları ayarlayabilir. Ya da tam tersini yapabilir. 
    
    ElasticNet sınıfının kullanımı tamamen diğer sınıflarda olduğu gibidir. 

    Aşağıdaki örnekte "Boston Housing Prices" veri kümesinde Elastic Net regresyon modeli uygulanmıştır. Parametreler doğru 
    ayarlanırsa Elstic Net diğerlerinden daha iyi sonuç verebilmektedir. Ancak parametrelerin ayarlanması daha zahmetlidir. 
    Bunun için pek çok deneme yanılmanın yapılması gerekebilmektedir.
#----------------------------------------------------------------------------------------------------------------------------

ALPHA = 0.1

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=54321)

from sklearn.preprocessing import StandardScaler 

ss = StandardScaler()
ss.fit(training_dataset_x)
scaled_training_dataset_x = ss.transform(training_dataset_x)
scaled_test_dataset_x = ss.transform(test_dataset_x)

import numpy as np
from sklearn.linear_model import ElasticNet

for ratio in np.arange(0.1, 1, 0.05):
    print(f'Alpha: 0.5, L1 Ratio: {ratio}')
    elastic = ElasticNet(alpha=0.1, l1_ratio=ratio)
    elastic.fit(scaled_training_dataset_x, training_dataset_y)

    test_predict_result = elastic.predict(scaled_test_dataset_x)
    
    from sklearn.metrics import mean_absolute_error
    
    mae = mean_absolute_error(test_predict_result, test_dataset_y)

    print(f'Mean Absolute Error: {mae}')

    r2 = elastic.score(scaled_training_dataset_x, training_dataset_y)
    print(f'R^2: {r2}')
    print('-' * 20)
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                            105. Ders - 01/03/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Biz şimdiye kadar doğrusal regresyon gördük. Doğrusal regresyon noktaları ortalayan bir doğru denkleminin elde edilmesi 
    süreci idi. Tabii "doğru" sözcüğü iki boyutlu uzaya ilişkin bir terimdir. Çok bouyutlu uzayda doğru yerine o uzayın düzlemi 
    söz konusu olur ki buna da biz "hyperplane" demiştik. Tek özelliğe sahip veri kümelerinin belirttiği iki boyutlu uzayla 
    çok özelliğe sahip veri kümelerinin belirttiği çok boyutlu uzaydaki işlemler genel itibari ile benzerdir. Bu bölümde ise 
    polinomsal regresyonlar üzerinde duracağız.

    n'inci dereceden tek değişkenli bir polinomun genel biçimi şöyledir:

    𝑃(𝑥) = 𝑎₀ + 𝑎₁𝑥 + 𝑎₂𝑥² + 𝑎₃𝑥³ + ⋯ + 𝑎ₙ𝑥ⁿ

    Bunu toplam sembolüyle şöyle de ifad edebiliriz:

    𝑃(𝑥) = ∑ⁿᵢ₌₀ 𝑎ᵢ𝑥ⁱ

    Tabii değişken sayısı (yani veri kümesindeki sütun sayısı) birden fazla olduğunda polinomun genel biçimi daha çok terim
    içeren daha karmaşık bir hale gelmektedir. Örneğin iki değişkenli 3'üncü dereceden bir polinomun genel biçimi şöyledir:

    𝑃(𝑥₁, 𝑥₂) = 𝑎₀₀ + 𝑎₁₀𝑥₁ + 𝑎₀₁𝑥₂ + 𝑎₁₁𝑥₁𝑥₂ + 𝑎₂₀𝑥₁² + 𝑎₀₂𝑥₂² + 𝑎₂₁𝑥₁²𝑥₂ + 𝑎₁₂𝑥₁𝑥₂²

    n'inci dereceden iki değişkenli bir polinomun genel biçimini daha sembolik olarak şöyle de ifade edebiliriz:

    𝑃(𝑥₁, 𝑥₂) = ∑ 𝑎ᵢⱼ 𝑥₁ⁱ 𝑥₂ʲ

    Burada i + j <= n olmalıdır. m tane değişkene sahip n'inci dereceden polinomun genel biçimini de sembolik olarak şöyle 
    ifade edebiliriz:
    
    𝑃(𝑥₁, 𝑥₂, …, 𝑥ₘ) = ∑ 𝑎ₖ₁,ₖ₂,ₖ₃,…,ₖₘ 𝑥₁ᵏ¹ 𝑥₂ᵏ² … 𝑥ₘᵏᵐ

    Ya da şöyle de ifade edebiliriz:

    𝑃(𝑥₁, 𝑥₂, …, 𝑥ₘ) = ∑ₖ 𝑎ₖ 𝑥¹ᵏ¹ 𝑥²ᵏ² … 𝑥ᵐᵏᵐ
 
    Burada üslerin toplamı olan k1 + k2 + k3 + ... + km değeri <= n'dir.

    Görüldüğü gibi polinomsal regresyonda veri kümesindeki özellikler arttıkça tahmin edilmesi gereken parametrelerin sayısı 
    da artmaktadır. 

    Her ne kadar noktaları ortalayan doğru yerine eğri geçirmek daha uygun gibi gözüküyorsa da yukarıdaki polinomların genel 
    biçimlerinde görüldüğü üzere bu durum tahmin edilmesi gereken parametrelerin sayısını artırmaktadır. Yani modeli daha 
    karmaşık hale getirmektedir. Biz eğri geçirmenin avantajından faydalanırken o eğrinin parametrelerinin tahmini zorlaşmaktadır. 

    Bir polinomun derecesi onun en yüksek üssüyle belirtilmektedir. Pekiyi biz noktalarımızı kaçıncı dereceden bir polinomla 
    temsil etmeliyiz? Şüphesiz derece arttıkça eğri daha fazla dalgalanacağı için daha uygun bir eğrinin bulunma olasılığı 
    artmaktadır. Ancak yukarıda da belirtitğimiz gibi polinomun derecesi yüksek tutulursa bu durumda tahmin edilecek parametrelerin 
    sayısı da artmaktadır. Bu da uygun bir polinomun bulunmasını zorlaştırabilmektedir. Polinomsal regresyon yaparken polinomun 
    derecesinin yüksek tutulması genellikle uygun olmaz. İkinci derece, üçüncü derece polinomlar modeli çok karmaşık hale 
    getirmediği için tercih edilmektedir. Yüksek dereceli polinomlar overfitting durumuna da yol açabilmektedir. Bu nedenle 
    polinomun derecesi 2 ile başlatılıp 3 ve 4 değerleri de dikkate alınanbilir. Ancak daha yüksek derecelere çıkmak pek çok 
    durumda kestirimin başarısını yükseltmeyecek bilakis düşürebilecektir. Tabii uygulamacının önce noktaları inceleyip doğrusal 
    regresyonun uygun olup olmadığına bakması önerilir. Eğer bağımsız değişkenlerle bağımlı değişken arasında doğrusal ilişki 
    varsa doğrusal regresyon uygulanmalıdır. (Tabii doğrusal regresyonu derecesi 1 olan polinomsal regresyon gibi de düşünebilirsiniz.)
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi polinomsal regresyonun katsayı değerleri nasıl elde edilmektedir? Örneğin iki sütunumuzun olduğu bir veri kümesindeki
    noktaları biz üçüncü derece bir polinomla temsil etmek iteyelim. Böyle bir polinomu şöyle ifade edebiliriz:

    P(x1, x2) = a0 + a1 x1 + a2 x2 + a3 x1 x2 + a4 x1^2 + a5 x2^2 + a6 x1^2 x2 + a6 x1 x^2+ a8 x1^3 + a9 X2^3

    Burada görüldüğü gibi 7 tane katsayı değerinin tahmin edilmesi gerekmektedir. Pekiyi bu değerler matematiksel olarak nasıl 
    tahmin edilecektir?

    İşte aslında polinomsal regresyon doğrusal regresyona dönüştürülerek çözüm gerçekleştirilmektedir. Polinomsal regresyonun 
    doğrusal regresyona dönüştürülmesine "polinomsal dönüştürme (polynomial transformation)" denilmektedir. Polinomsal dönüştürmede
    temel mantık değişkenlerin katsayı gibi ele alınması katsayıların ise değişken gibi ele alınmasıdır. örneğin yukarıdaki 
    polinom aşağıdaki doğru denklemine dönüştürülmektedir:

    P(x1, x2) = a0 + x1 a1 +  x2 a2 + x1 x2 a3 + x1^2 a4 + x2^2 a5  + x1 x2^2 a6  +x1^2 x2 a7  + x1^3 a8 + x2^3 a9  
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Polinomsal dönüştürmenin nasıl yapıldığını basit örnekle açıklayalım. Tek değişken için elimizde şöyle veri kümesi olsun:

      X          Y
    -----      ----
    2           4
    4           32
    7           72
    9           102
    ...         ...

    Burada biz bu değerlerin grafiğini çizdiğimizde bu noktaların bir doğru ile temsil edilemeyeceğini görmüş olalım. Bunun 
    için ikinci derece bir polinom oluşturmaya çalışalım. Bu ikinci derece polinomun genel biçimi şöyle olacaktır:

    a0 + a1 x + a2 x^2

    Şimdi biz bu polinomda katsayılarla değişkenleri yer değiştirelim:

    a0 + x a1 + x^2 a2

    Artık burada çoklu doğrusal regresyon söz konusudur. Bu durumda yukarıdaki X katsayıları çoklu doğrusal regresyonda şu
    biçime dönüşecektir:

    A0   A1  A2
    1    2   4
    1    4   16
    1    7   49
    1    9   81
    .....

    Görüldüğü gibi tek değişkenli 2'inci dereden polinom 2 değişkenli çoklu doğrusal regresyon haline dönüştürülmüştür. Şimdi 
    bu doğrusal regresyon çözülürse biz aslında buradan a0, a1, a2 değerlerini elde etmiş olacağız. Burada ilk sütunun 1'lerden
    oluşması size biraz tuhaf gelebilir. Biz modeli bu katsayılarla doğrusal regresyona dönüştürdüğümüzde aslında polinomsal
    regresyondaki a0 değerini tahmin etmiş oluruz. Tabii doğrusal regresyonun ayrı bir intercept değeri olacaktır. Ancak bu 
    intercept bizim bütün bu A0, A1, A2 değerlerini tahmin etmemiz için gerekmektedir. 

    Pekiyi polinom 2 değişkenli olsaydı 2'inci derece polinomsal transformasyondönüştürme nasıl yapılacaktı? 2 değişkenli 
    2'inci derece polinomun genel biçimi şöyledir:

    a0 + a1 x1 + a2 x2 + a3 x1 x2 + a4 x1^2 + a5 x2^2

    Buradaki X1 ve X2 gözlemlerinin şöyle olduğunu varsayalım:

    X1     X2    Y
    ---   ---   ---
    1      2     8
    3      3    12
    4      1    11
    6      2    23
    .....

    Yukarıdaki 2 dğişkenli polinomu katsayılarla değişkenleri ters çevirirsek şöyle yazabiliriz:

    a0 + x1 a1 + x2 a2 + x1 x2 a3 + x1^2 a4 + x2^2 a5 

    Bu durumda polinomsal dönüştürme şöyle yapılacaktır:

    A0   A1   A2   A3   A4   A5
    ---------------------------
    1    1    2    2    1    4
    1    3    3    9    9    9
    1    4    1    4    16   1 
    1    6    2    12   36   4

    İşte görüldüğü gibi aslında polinomsal regresyon çoklu doğursal regresyona dönünüştürülerek çözülebilmektedir. Genel olarak 
    m değişkene sahip n'inci dereceden polinomsal regresyon doğrusal regresyona dönüştürüldüğünde C(m + n, n) kadar tahmin 
    edilecek katsayı oluşaaktadır. Örneğin 2 değişkenli 2'inci dereceden bir polinom doğrusal regresyona dönüştürüldüğünde 
    C(2 + 2, 2) = 6'dır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Polinomsal regresyon sckit-learn kütüphanesinde iki aşamada çözülür. Birinci aşamada X katsayı matrisi "polinomsal dönüştürmeye"
    sokularak doğrusal regresyon için kullanılacak katsayı değerleri elde edilir. İkinci aşamada ise doğrusal regresyon çözümü 
    yapılır. Polinomsal regresyon için polinomsal dönüştürme sklearn.preprocessing modülündeki PolynomialFeatures sınıfıyla 
    yapılmaktadır. Sınıfın __init__ metodunun parametrik yapısı şöyledir:

    class sklearn.preprocessing.PolynomialFeatures(degree=2, interaction_only=False, include_bias=True)

    Metodun ilk parametresi noktaların kaçıncı dereceden bir polinom için dönüştürüleceğini belirtmektedir. Metodun include_bias
    parametresi dönüştürme sonucunda elde edilecek matrisin ilk sütununun 1 olup olmayacağını belirtmektedir. Bu parametrenin 
    default değeri True ise (default değerin True olduğuna dikkat ediniz) bu durumda elde edilen matrisin ilk sütunu 1 olur. 
    Daha sonra işlemler diğer scikit-learn sınıflarında olduğu gibi yapılmaktadır. Yani önce fit işlemi sonra transform işlemi 
    ya da doğrudan fit_transform işlemi yapılabilir. Bu işlemin sonucunda biz aslında polinomsal regresyon için kullanacağımız 
    orijinal veri kümesini doğrusal regresyon için kullanılabilecek bir veri kümesine dönüştürmüş oluruz. Bundan sonra elde edilen 
    bu veri kümesine LinearRegresson ya da Lasso, Ridge, ElasticNet gibi sınıflarla doğrusal regresyon uygulanır. 

    Orijinal verilerin m satırdan ve n sütun oluştuğunu vasayalım. PolynomialFeatures işleminden elde edilen matris yine m tane 
    satıra sahip olacaktır. Ancak sütunları polinomun terim sayısı kadar olacaktır. Yukarıda bu sayının C(n + m, n) tane olduğunu 
    belirtmiştik. Örneğin 6 tane satırdan oluşan 2 değişkenli bir veri kümesini 2'inci derece bir polinom için dönüştürmek isteyelim. 
    Bu durumda PolinomialFetures işleminden sonra biz 6x6'lık bir matris elde ederiz. Elde ettiğimiz matrisin ilk sütununun default 
    durumda 1 olacağını anımsayınız. Örneğin veri kümemizdeki X değerlerinin "points.csv" dosyası içerisinde aşağıdaki gibi olduğunu 
    varsayalım:

    X1,X2
    1,2   
    3,3
    4,1
    6,2
    9,4
    11,3

    Bu veri kümesini aşağıdaki gibi PolynomialFeatures sınıfına sokalım:

    dataset_x = pd.read_csv('points.csv')
    pf = PolynomialFeatures(2)
    transformed_dataset_x = pf.fit_transform(dataset_x)
    print(transformed_dataset_x )

    Elde edilen matris şu biçimdedir:

    [[  1.   1.   2.   1.   2.   4.]
    [  1.   3.   3.   9.   9.   9.]
    [  1.   4.   1.  16.   4.   1.]
    [  1.   6.   2.  36.  12.   4.]
    [  1.   9.   4.  81.  36.  16.]
    [  1.  11.   3. 121.  33.   9.]]  
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd
from sklearn.preprocessing import PolynomialFeatures

dataset_x = pd.read_csv('points.csv')
pf = PolynomialFeatures(2)
transformed_dataset_x = pf.fit_transform(dataset_x)
print(transformed_dataset_x )

#----------------------------------------------------------------------------------------------------------------------------
    PolynomialFeatures sınıfından elde eedilen dönüştürülmüş matris ile doğrusal regresyon ugulandığında elde edilen coef_ 
    değerleri aslında polinomsal regresyondaki katsayıları belirtmektedir. Ancak eğer LinearRegression işlemine verilen 
    matrisin ilk sütunu 1 ise bu durumda coef_[0] değeri yerine intercept_ değeri kullanılmalıdır. İzleten paragraflarda
    bu konu üzerinde duracağız. Doğrusal regresyon sonucunda elde edilen R^2 değeri yine bize polinomsal regresyonun uygunluğu 
    konusunda bilgi verebilecektir.

    Şimdi tek değişkenli bir veri kümesi için polinomsal regresyona örnek verelim. Örneğimizdeki "points.csv" dosyasının içeriği 
    şöyle olsun:

    X,Y
    4,-200
    -3,-51
    -2,-19
    -1,-6
    0,-5
    1,-5
    2,1
    3,22
    4,56
    5,78
    6,176
    7,271
    8,401
    9,572
    10,713
    11,1042
    12,1333
    13,1623
    14,2015
    15,215

    Burada ilk sütun X verileri ikinci sütun Y verileridir. Dolayısıyla tek değişkenli bir veri kümesi söz konusudur. Buradan 
    elde edilen R^2 değeri 0.58 civarındadır.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv('points.csv')

dataset_x = df['X'].to_numpy()
dataset_y = df['Y'].to_numpy()

from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(dataset_x.reshape(-1, 1), dataset_y)

x = np.linspace(0, 18, 1000)
y = lr.intercept_ + lr.coef_[0] * x

import matplotlib.pyplot as plt

plt.title('Simple Linear Regression')
plt.scatter(dataset_x, dataset_y, color='blue')
plt.plot(x, y, color='red')
plt.show()

predict_data = 12.9
predict_result = lr.intercept_ + predict_data * lr.coef_[0]
print(predict_result)

predict_data = np.array([[12.9], [4.7], [6.9]])
predict_result = lr.predict(predict_data)
print(predict_result)

rsquare = lr.score(dataset_x.reshape(-1, 1), dataset_y)
print(f'R^2: {rsquare}')

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de yukarıdaki verileri 3'üncü derece bir polinomla temsil etmeye çalışalım . Tek değişkenli 3'üncü derece polinomun 
    genel biçimi şöyledir:

    P(x) = a0 + a1 x + a2 x^2 + a3 x^3 

    Burada toplam 4 tane katsayı vardır. Bu durumda biz polinomsal dönüştürme yaptığımızda 4 sütunlu bir veri kümesi elde ederiz. 
    O halde aslında uygulayacağımız doğrusal regresyon sanki 4 sütunlu doğrusal regresyon gibidir. Örneğin:

    df = pd.read_csv('points.csv')

    dataset_x = df['X'].to_numpy()
    dataset_y = df['Y'].to_numpy()

    from sklearn.preprocessing import PolynomialFeatures

    pf = PolynomialFeatures(degree=3)
    transformed_dataset_x = pf.fit_transform(dataset_x.reshape(-1, 1))

    from sklearn.linear_model import LinearRegression

    lr = LinearRegression()
    lr.fit(transformed_dataset_x, dataset_y)

    Burada doğrusal regresyondan elde ettiğimiz katsayılar (yani coef_ dizisi) dört elemanlı olmalıdır. Bu 4 eleman aslında 
    polinomun katsayılarını bize vermektedir. Yani polinom aslında şöyle olacaktır:

    P(x) = lr.intercept_ + lr.coef_[1] * x + lr.coef_[2] * x ** 2 + lr.coef_[3] * x ** 3

    Tabii kestirim yapmak için x değerlerini yukarıdaki gibi bir polinoma sokmak zahmetlidir. Sütun sayısı fazla olduğunda 
    polinomun genel biçimi çok daha fazla terim içerecektir. Burada tahminleme için yine aynı yol izlenebilir. Yani tahminlenecek 
    değerler önce PolynomialFeatures sınıfının transform metoduna sokulur, sonra oradan elde edilen değerler doğrusal regresyonun 
    predict metoduna sokulabilir. Örneğin:

    predict_data = np.array([4, 14, 67])
    transformed_predict_data = pf.transform(predict_data.reshape(-1, 1))
    predict_result = lr.predict(transformed_predict_data)
    print(predict_result)

    Aşağıdaki örnekte yukarıda kullanmış olduğumuz noktalardan üçüncü derece bir polinom geçirilmeltedir. "points.csv" 
    noktaları şöyledir:

    X,Y
    4,-200
    -3,-51
    -2,-19
    -1,-6
    0,-5
    1,-5
    2,1
    3,22
    4,56
    5,45
    6,176
    7,271
    8,401
    9,572
    10,713
    11,1042
    12,1333
    13,1623
    14,2015
    
    Örneğimizde kestirim işlemi iki biçimde de yapılmıştır. Birinci biçimde kestirilecek noktalar doğrudan elde edilen 
    katsayı değerleriyle polinoma sokulmuştr:

    predict_data = np.array([12.9, 4.7, 6.9])
    predict_result = lr.intercpt_ + lr.coef_[1] * predict_data  + lr.coef_[2] * predict_data ** 2 + 
            lr.coef_[3] * predict_data ** 3
    print(predict_result)

    İkinci biçimde de kestirilecek değerler önce polinomsal dönüştürmeyle doğrusal regresyona uygun hale getirilmiş sonra 
    LinearRegression sınıfının predict metodu kullanılmıştır:

    predict_data = np.array([[12.9], [4.7], [6.9]])
    transformed_predict_data = pf.transform(predict_data)
    predict_result = lr.predict(transformed_predict_data)
    print(predict_result)
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv('points.csv')

dataset_x = df['X'].to_numpy()
dataset_y = df['Y'].to_numpy()

from sklearn.preprocessing import PolynomialFeatures

pf = PolynomialFeatures(degree=3)

transformed_dataset_x = pf.fit_transform(dataset_x.reshape(-1, 1))

from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(transformed_dataset_x, dataset_y)

rsquare = lr.score(transformed_dataset_x, dataset_y)
print(f'R^2: {rsquare}')

x = np.linspace(-5, 20, 1000)
transformed_x = pf.transform(x.reshape(-1, 1))
y = lr.predict(transformed_x)

import matplotlib.pyplot as plt

plt.title('Polynomial Regression')
plt.scatter(dataset_x, dataset_y, color='blue')
plt.plot(x, y, color='red')
plt.show()

predict_data = np.array([12.9, 4.7, 6.9])
predict_result = lr.intercept_ + lr.coef_[1] * predict_data  + lr.coef_[2] * predict_data ** 2 + lr.coef_[3] * predict_data ** 3
print(predict_result)

predict_data = np.array([[12.9], [4.7], [6.9]])
transformed_predict_data = pf.transform(predict_data)
predict_result = lr.predict(transformed_predict_data)
print(predict_result)

#----------------------------------------------------------------------------------------------------------------------------
    Burada LinearRegression sınıfının fit metoduna soktuğumuz matrisin ilk sütununun 1 olması üzerinde durmak istiyoruz. 
    Bu bağlamda birkaç durum söz konusudur:

    1) fit metoduna verilen matrisin ilk sütunu 1 ise bu durumda elde edilen coef_ katsayılarının 0'ıncı indeksli elemanı 
    her zaman 0 olur. Dolayısıyla sabit terim sınıfın intercept_ elemanından elde edilmelidir. 

    2) fit metoduna verilen matrisin ilk sütunu 1 ise fakat LinearRegression nesnesi yaratılırken fit_intercept parametresi 
    False girilirse bu durumda sabit terim (yani intercept_ değeri) coef_[0]'da bulunacaktır. Tabii bu durumda nesnenin de 
    intercept_ özniteliği 0 olur.

    3) fit metoduna verilen matrisin ilk sütunu 1 değilse ve fit_intercept parametresi default değer olan True biçimindeyse 
    bu durumda sabit terim (yani intercept) nesnenin intercept_ özniteliğinden alınır. Ancak coef_ dizisinin 0'ıncı indeksi 
    artık sabit terimi (yani intercept'i) belirtmez. Sabit olmayan ilk terimin katsayısını belirtir. 
    
    4) fit metoduna verilen matrisin ilk sütunu 1 değilse ve fit_intercept parametresi False olarak girilirse bu durum
    anlamlı değildir.

    Yukarıdaki örneğimizde PolynomialFeatures sınıfı bize ilk sütunu 1 olan bir matris vermiştir. Default durumda LinearRegression
    sınıfının fit_intercept parametresi True olduğu için sabit terin nesnenin coef_[0] elemanındna değil intercept_ özniteliğinden 
    alınmıştır. 

    LinearRegression sınıfında predcit metodu zaten ilgili değerleri fit_intercept parametresini dikkate alarak doğru 
    denkleminde yerine koyup sonucu vermektedir. Tabii bizim predcit yaparken verdiğimiz veri kümesinin fit yaparken verdiğimiz 
    veri kümesi ile aynı biçimde oluşturulmuş olması gerekir. Örneğin biz LinearRegression sınıfının fit metodunu ilk sütunu 
    1 olan bir matris ile yapmışsak predict işleminde de yine ilk sütunu 1 olan bir matris kullanmalıyız. Zaten yukarıdaki 
    örneğimizde biz predict işlemini yapmadan önce yine değerleri PolynomialFeatures sınıfının transform fonksiyonuna soktuğumuz 
    için bir sorun oluşmamaktadır.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte çeşitli dereceler için polinamsal regresyon uygulanıp bunların grafikleri aynı eksende gösterilmiştir. 
    Polinomun derecesi yükseltildikçe noktaları temsil eden daha iyi bir eğri elde edildiğini göreceksiniz. Ancak bu durum 
    yanıltıcıdır. Derece yükseltildikçe söz konusu noktalara ilişkin daha iyi bir eğri elde ediliyor olsa da aslında "overfitting"
    oluşmaktadır. Yani elde edilen eğri bu noktalara özgü hale gelir ve kestirimin gücü azalır. R^2 değeri de bu bağlamda 
    iyi gösterge oluşturmamaktadır. Polinomun derecesi gerektiğinden fazla yükseltildikçe test veri kümesi üzerinde uygulanan 
    "mean squared error" gibi "mean absolute error" gibi metrikler düşmeye başlayacaktır. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv('points.csv')

dataset_x = df['X'].to_numpy()
dataset_y = df['Y'].to_numpy()

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

degrees = [2, 3, 4, 5]
rsquares = []

plt.figure(figsize=(10, 8))
plt.title('Polynomial Regression')
plt.scatter(dataset_x, dataset_y, color='blue')
plt.ylim(-500, 3000)

for i in degrees:  
    pf = PolynomialFeatures(degree=i)
    transformed_dataset_x = pf.fit_transform(dataset_x.reshape(-1, 1))
    lr = LinearRegression()
    lr.fit(transformed_dataset_x, dataset_y)
    
    x = np.linspace(-5, 20, 1000)
    transformed_x = pf.transform(x.reshape(-1, 1))
    y = lr.predict(transformed_x)
    plt.plot(x, y)
    
    rsquares.append(lr.score(transformed_dataset_x, dataset_y))
    
plt.legend( ['points'] + [f'{degree} ({rs:.2f})' for degree, rs in zip(degrees, rsquares)])
plt.show()
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Veri kümesindeki sütunların sayısının 1 artırılması doğrusal polinomsal regresyondaki terim sayısının misliyle artmasına 
    yol açmaktadır. Bir de derece yükseltildiğinde artış çok daha büyük olmaktadır. (Polinomsal regresondaki toplam terim sayısının
    n'nci dereceden m değişkenli polinom için C(n + m, n) olduğunu anımsayınız.) 
    
    Aşağıdaki örnekte veri kümesindeki sütun sayısının artmasıyla 3'üncü derece polinomun genel biçimindeki terim sayısının ne 
    kadar hızlı arttığına yönelik bir örnek verilmiştir. Şu değerler elde edilmiştir:

    Sütun Sayısı ---> Terim Sayısı
    2  --> 10
    3  --> 20
    4  --> 35
    5  --> 56
    6  --> 84
    7  --> 120
    8  --> 165
    9  --> 220
    10  --> 286
    11  --> 364
    12  --> 455
    13  --> 560
    14  --> 680
    15  --> 816
    16  --> 969
    17  --> 1140
    18  --> 1330
    19  --> 1540
    20  --> 1771
    21  --> 2024
    22  --> 2300
    23  --> 2600
    24  --> 2925
    25  --> 3276
    26  --> 3654
    27  --> 4060
    28  --> 4495
    29  --> 4960

    Görüldüğü gibi polinomsal regresyon doğrusal regresyona dönüştürüldüğünde veri kümesinin sütun sayısı çok artabilmektedir. 
    İşte bunun doğal sonucu da "overfitting" durumudur. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
from sklearn.preprocessing import PolynomialFeatures

print('Sütun Sayısı ---> Terim Sayısı')
for i in range(2, 30):
    dataset_x = np.random.random((100, i))
    dataset_y = np.random.random(100)

    pf = PolynomialFeatures(degree=3)
    transformed_dataset_x = pf.fit_transform(dataset_x)
    print(f'{i}  --> {transformed_dataset_x.shape[1]}')

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "Boston Housing Prices" veri kümesi üzerinde şu üç model denenmiştir:

    1) LinearRegression
    2) 2'inci Dereceden PolynomialFeatures --> LinearRegresson
    3) 2'inci Dereceden PolynomialFeatures --> Lasso

    Elde edilen sonuçlar şöyle olmuştur:

    Mean Absolute Error: 3.5789294242858887
    R^2 = 0.7665384411811829

    Mean Absolute Error: 5.021183967590332
    R^2 = 0.5885621309280396

    Mean Absolute Error: 2.180431842803955
    R^2 = 0.8993322253227234

    Bu denemelerden en iyi sonuç ikinci derece polinomun Lasso regresyonu ile uygulanması olmuştur. Burada alpha değeri 
    ile değişik performanslar elde edilmiştir. İyi bir alpha değeri 0.005 biçimindedir. Bu tür durumlarda çeşitli modellerin 
    denenip en iyi sonucun kullanılması yoluna gidilebilir.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Lasso

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=1234)

from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(training_dataset_x, training_dataset_y)
predict_result = lr.predict(test_dataset_x)

mae = mean_absolute_error(predict_result, test_dataset_y)
print(f'Mean Absolute Error: {mae}')
r2 = lr.score(test_dataset_x, test_dataset_y)
print(f'R^2 = {r2}')
print()

from sklearn.preprocessing import PolynomialFeatures

pf = PolynomialFeatures(degree=2)
transformed_training_dataset_x = pf.fit_transform(training_dataset_x)

lr = LinearRegression()
lr.fit(transformed_training_dataset_x , training_dataset_y)
transformed_test_dataset_x = pf.transform(test_dataset_x)
predict_result = lr.predict(transformed_test_dataset_x)

mae = mean_absolute_error(predict_result, test_dataset_y)
print(f'Mean Absolute Error: {mae}')
r2 = lr.score(transformed_test_dataset_x, test_dataset_y)
print(f'R^2 = {r2}')
print()

ss = StandardScaler()
scaled_transformed_training_dataset_x = ss.fit_transform(transformed_training_dataset_x)
scaled_transformed_test_dataset_x = ss.transform(transformed_test_dataset_x)

lasso = Lasso(alpha=0.005, max_iter=100000)
lasso.fit(scaled_transformed_training_dataset_x , training_dataset_y)
predict_result = lasso.predict(scaled_transformed_test_dataset_x)

mae = mean_absolute_error(predict_result, test_dataset_y)
print(f'Mean Absolute Error: {mae}')
r2 = lasso.score(scaled_transformed_test_dataset_x, test_dataset_y)
print(f'R^2 = {r2}')
print()

#----------------------------------------------------------------------------------------------------------------------------
    Polinomsal regresyon için önce PolynomialFeatures sınıfı sonra da regresyon sınıflarından birini kullanıyorduk. Aslında 
    bu işlemleri daha önce görmüş olduğumuz boru hattı (pipeline) mekanizmasıyla birleştirirsek daha sade bir kod elde edebiliriz. 
    Aşağıdaki örnekte "Boston Housing Prices" veri kümesi üzerinde önce PolynomialFeatures işlemi sonra StandardScaler işlemi 
    sonra da Lasso regresyon işlemi bir boru hattı içerisinde uygulnamıştır.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import PolynomialFeatures
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Lasso
from sklearn.pipeline import Pipeline
from sklearn.metrics import mean_absolute_error

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=1234)

pipeline = Pipeline(steps=[("pf", PolynomialFeatures(degree=2)), ('ss', StandardScaler()), 
        ("lasso", Lasso(alpha=0.005, max_iter=100000))])
pipeline.fit(training_dataset_x, training_dataset_y)
predict_result = pipeline.predict(test_dataset_x)

mae = mean_absolute_error(predict_result, test_dataset_y)
print(f'Mean Absolute Error: {mae}')
r2 = pipeline.score(test_dataset_x, test_dataset_y)
print(f'R^2 = {r2}')
print()

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi sonuç olarak ne zaman polinomsal regresyon uygulamalıyız? Aslında yukarıda da belirttiğimiz gibi veri kümesi için 
    çeşitli modellerin denemesi ve en iyi modelin uygulanması yani deneme yanılma yöntemi uygulamada esastır. Önce doğrusal 
    regresyon üzerinde durulmalıdır. Eğer X sütunları ile bağımsız değişken arasında doğrusala benzer bir ilişki varsa doğrusal 
    regresyon tercih edilmelidir. Eğer X değişkenin sütunları ile bağımsız değişken arasında doğrusal bir ilişki yoksa bu durumda
    polinomsal regresyon üzerinde durulabilir. Polinomsal regresyon için önce 2'inci derece sonra 3'üncü derece ve sonra da 
    4'üncü derece için denemeler yapılabilir. Derecenin 4'ün yukarısına çıkartılması "overfitting" yüzünden genellikle iyi 
    sonuç vermeme eğilimindedir. Ayrıca derecenin 4'ün yukarısına çıkartılması gürültü noktalarının bulunduğu durumda eğrinin 
    bu gürültü noktalarını da dikkate alacak biçim kıvrılmasına yol açabilir. Bunun sonucu oalrak da "overfitting" durumu yine 
    oluşabilir. Ancak yukarıda da belirttiğimiz gibi nasıl bir regresyonun uygulanacağı kararının hiç deneme yanılma yoluna 
    başvurmadan isabetli bir biçimde verilmesi de genellikle mümkün değildir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Makine öğrenmesinde sınıflandırma amacıyla uygulanan bir grup yönteme "doğrusal sınıflandırıcılar (linear classifiers)" 
    denilmektedir. Doğrusal sınıflandırıcılar iki farklı sınıf içeren kümeyi (yani ikili sınıflandırmaya ilişkin kümeyi) bir 
    doğru ile ayrıştırmayı sağlamaktadır. Tabii iki boyutlu uzaydaki doğruların üç boyutlu uzayda bir düzlem olduğunu ve her 
    n boyutlu uzayın da bir düzleminin söz konusu olduğunu belirtmiştik. N boyutlu uzayın düzlemine genel olarak "hyperplane"
    denildiğini anımsayınız. O halde doğrusal sınıflandırıcılar genel olarak bir hyperplane ile veri kümesini birbirinden 
    ayırmaya çalışmaktadır. Tabii bu tür sınıflandırıcıların iyi işlev görebilmesi için veri kümesinin de "doğrusal olarak 
    ayrıştırılabilir (linearly separable) biçimde olması gerekir. Aksi takdirde ayrıştırmada kusurlar ortaya çıkacaktır bu da 
    sınıflandırıcının performansını düşürecektir. 

    Makine öğrenmesinde çok kullanılan iki doğrusal sınıflandırıcı vardır:
    
    1) İstatstikte "lojistik regresyon (logistic regression)" ya da "logit regresyonu" denilen doğrusal sınıflandırıcı.
    2) Destek Vektör Makineleri (Support Vector Machines)" denilen doğrusal sınıflandırıcı.
    
    Biz bu bölümde istatistiksel lojistik regresyon üzerinde duracağız.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    İstatistiksel lojistik regresyonda bağımsız değişken (yani Y değerleri) 0 ve 1 ile temsil edilmektedir. Burada 1 sınıflardan 
    birini 0 ise diğer sınıfı temsil eder. Bu durumda örneğin iki boyutlu uzayda (yani 2 sütunlu bir veri kümesi) aşağıdakine
    benzer bir görünümde olacaktır:

     X1          X2          Sınıf
    ----        ----        ------
    10          7             1
    7           4             0
    2           6             1
    1           9             0
    ......

    Lojistik regresyonda kestirim sırasında kestirilecek noktanın 1 olma olasılığı elde edilmektedir. Örneğin biz bir noktayı 
    vererek kestirim yaptığımızda eğer kestirim sonucunda 0.7 gibi bir değer elde ediyorsak bu noktanın 1 olma olasılığı 0.7'dir, 
    0 olma olasılığı ise 0.3'tür. Biz bu noktayı sınıflandıracaksak 1'e daha yakın olduğu için 1 olarak sınıflandırırız. Verdiğimiz 
    başka bir nokta için kestirilen olasılık örneğin 0.1 ise bu noktanın 1 olma olasılığı 0.1'dir. Bu durumda aslında 0 olma 
    olasılığı da 0.9'dur. İşte kestirim yapılırken elde edilen olsalık 1'e daha yakınsa (yani > 0.5 ise) bunu 1 olarak, 0'a 
    daha yakınsa (yani < 0.5 ise) bunu da 0 olarak kabul ederiz. 

    İstatistikte (özellik şans oyunlarında) bir olayın gerçekleşme olasılığının gerçekleşmeme olasılığına oranına İngilizce
    "odds ratio" denilmektedir. Odds Ratio şöyle ifade edilebilir:

    Odds Ratio = p / (1 - p)

    Odds Ratio özellikle ikili bahislerde yaygın uygulanan bir yöntemdir. Örneğin bir karşılaşmada bahis için A takımına para 
    yatıranlarla B takımına para yatıranların oranlarına bakılır. Bahis komisyon çıkartılarak bu oranda dağıtılır.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                        107. Ders - 08/03/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    İstatistiksel lojistik regresyonun anlaşılması biraz zor olabilmektedir. Biz burada bu yöntemin adım adım nasıl uygulandığını 
    açıklayacağız. Lojistik regresyonda aslında yine bir doğru denkleminin bulunması hedeflenir. Yani bu bakımdan biraz doğrusal 
    regresyona benzemektedir. Ancak belli bir noktanın x değerlerinin 1 olma olasılığı x değerlerinin bu doğru denklemine sokulmasıyla 
    elde edilmez. Çünkü doğru denklemleri 0 ile 1 arasında bir değer vermemektedir. İşte belli bir noktaya ilişkin x değerlerinin 
    1 olma olasılığına dönüştürülmesi bu x değerlerinin doğru denklemine sokulup oradan elde edilen değerin sigmoid fonksiyonuna 
    sokulmasıyla elde edilmektedir. Bizim BX + b biçiminde bir doğru denklemini bir biçimde elde etmiş olduğumuzu düşünelim. 
    (Buradaki B ve X bir vektördür dolayısıyla buradaki BX + b aslında N değişkenli genel bir doğru denklemini belirtmektedir.) 
    İşte eğer bizim elimizde böyle bir doğru denklemi varsa bir noktaya ilişkin X değerlerinin 1 olma olasılığı şöyle elde 
    edilecektir:

    p(x) = 1 / (1 + e^-(BX + b)) 

    Bu aslında X noktasına ilişkin değerlerin sigmoid fonksiyonuna sokulmasıyla elde edilen değerdir. Sigmoid fonksiyonunun 0 
    ile 1 arasında bir değer verdiğini anımsayınız. Tabii buradaki asıl sorun böyle bir doğru denkleminin nasıl elde edileceğidir. 
    Bunu izleyen paragraflarda açıklayacağız. Ancak yukarıdaki eşitlikte BX + b değerini (yani noktaya ilişkin x değerlerinin 
    doğru denklemine sokulmasıyla elde edilen değeri) içler dışlar çarpımıyla yalnız bırakmaya çalışalım:

    p(x) * (1 + e^-(BX + b)) = 1
    (1 + e^-(BX + b)) = 1 / p(x)
    e^-(BX + b) = (1 - p(x))/p(x)

    Her iki tarfın logaritmasını alalım:

    log(e^-(BX + b)) = log((1 - p(x))/p(x))
    -(BX + b) = log((1 - p(x))/p(x))
    BX + b = -log((1 - p(x))/p(x))
    BX + b = log(p(x) / (1 - p(x)))

    Buradan ilginç bir sonuç çıkmaktadır. Eğer biz böyle bir doğru denklemi bulursak aslında noktaya ilişkin x değerlerini 
    bu doğru denkleminde yerine koyduğumuzda x'e ilişkin "odds ratio" değerinin logaritmasını elde ederiz. İşte lojistik 
    regresyonda "odds ratio" değerinin logaritmasına "logit" de denilmektedir. Aslında lojistik regresyondaki "log" önekinin 
    kaynağı da buradaki logaritma işlemidir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi BX + b doğru denklemi nasıl elde edilmektedir? Biz yukarıda bunun elde edilmiş olduğunu varsaydık. İşte bu doğru 
    denklemi aslında toplam olasılıkların maksimizasyonu ya da bunun negatifinin minimizasyonu yoluyla oluşturulmaktadır. 
    Toplam olasılıkların maksimize edilmesine istatistikte "maximum likelihood" yöntemi denilmektedir. Bu yöntemi açıklamadan 
    önce sigmoid fonksiyonunu yeniden vermek istiyoruz:

    p(x) = 1 / (1 + e^-(BX + b))

    Biz noktalara ilişkin x değerlerini bu fonksiyona sokup bir p(x) değerleri elde ediyoruz. Bu p(x) değerlerinin de gerçek 
    y değerleri olan 1 ya da 0'a ne kadar yakınsa bu doğru denkleminin o kadar iyi oluşturulacağını söyleyebiliriz. İşte tersten 
    gidersek bizim amacımız yukarıdaki sigmoid çıktısı ile gerçek değerler arasındaki farkı minimize edecek doğru denkleminin 
    bulunmasıdır. Örneğin bir nokta için p(x) değeri 0.8 olsun bu noktanın da gerçek sınıfı 1 olsun. Bu durumda biz bu p(x) 
    değerini daha fazla 1'e yaklaştırmak isteriz. Örneğin bir nokta için p(x) değeri 0.2 olsun. Bu noktanın da gerçek sınıfı 
    0 olsun. Bu durumda biz bu p(x) değerini daha fazla 0'a yaklaştırmak isteriz. Tabii burada bir noktaya dikkat etmek gerekir. 
    Örneğin biz yukarıdaki sigmoid çıktısından 0.1 değeri elde etmiş olalım. Eğer bu noktanın gerçek y değeri 1 ise buradaki hata 
    büyük olur ancak 0 ise buradaki hata küçük olur. O halde böyle bir amaç fonksiyonunu (ya da loss fonksiyonunu) maksimize 
    ederken bu durumu dikkate almalıyız. İşte maksimize edilecek amaç fonksiyonu (yani loss fonksiyonu) aşağıdaki gibi 
    oluşturulmaktadır:

    L(x) = ∏(p(x)^y * (1 - p(x))^(1 - y))

    Burada neden terimlerin çarpımının oluşturulduğunu izleyen paragrafta açıklayacağız. Bu fonksiyonda eğer y = 0 ise çarpımın 
    sağ tarafı 1, y = 1 ise çarpımın sol tarafı 1 olur. Buradaki çarpım ne kadar yükseltilirse elde edilecek doğru denklemi 
    o kadar iyi olacaktır. Yukarıda da belirttiğimiz gibi lojistik regresyonun bu biçimde bir maksimizasyon problemi biçiminde 
    çözülmesine İstatistikte "maximum likelihood" yöntemi denilmektedir. Ancak makine öğrenmesinde biz genel olarak maksimizasyon 
    yerine minimizasyon yapmayı tercih ederiz. Yukarıdaki fonksiyonun maksimize edilmesiyle onun negatifinin minimize edilmesi aynı 
    anlama gelmektedir:

    L(x) = - ∏(p(x)^y * (1 - p(x))^(1 - y))
    
    Fonksiyonun başındaki negatif işlemi problemi maksimizasyon yerine minimizasyon haline getirmektedir. Yukarıdaki fonksiyonda 
    üslü ifadelerden kurtulmak için fonksiyonun logaritmasını alabiliriz. Eğer f fonksiyonu her zaman pozitif değer veriyorsa 
    ve üstel biçimdeyse (fog)(x)fonksiyonunun minimize edilmesiyle log(fog(x)) fonksiyonunun minimize edilmesi aynı g(x) değerlerini 
    verecektir. Bu durumda işlemleri kolaylaştırmak fonksiyonun logaritmasını alabiliriz:

    L(x) = - ∏log((1 - p(x))^(1 - y) * p(x)^y)

    Değerlerin çarpımşarının logaritması logaritmalarının toplamına eşittir:

    L(x) = -∑[(log((1 - p(x))^(1 - y))  + log(p(x)^y))]

    Logaritma işleminde üst başa düşürülebilir:

    L(x) = -∑[(1 - y) * log(1 - p(x)) + y * log(p(x))]

    Zaten bu da aslında daha görmüş olduğumuz "binary cross-entropy" loss fonksiyonu ile aynıdır. Eğer ortalama bir değer 
    bulunmak isteniyorsa buradaki toplam değeri noktalarının sayısına bölünebilir. Böylece noktaların toplam sayısı N olmak
    üzere fonksiyon şu biçimde de ifade edilebilir:

    L(x) = -(1 / N) * ∑[(1 - y) * log(1 - p(x)) + y * log(p(x))]

    Tabii buradaki N sabit bir sayı olduğu için aslında minimizasyon işleminde genel olarak ihmal de edilebilmektedir. 

    Yukarıdaki minimizasyon işlemi kapalı biçimde (sembolik biçimde) yapılamaz. Ancak nümerik yöntemlerle ("gradient descent" 
    ya da "Newton-Raphson" gibi yöntemlerle) yapılabilir. Bu tür optimizasyonların nasıl yapıldığı ileride ele alınacaktır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de yukarıdaki amaç fonksiyonunda  terimlerin çarpımlarının kullanıldığını açıklayalım. Yukarıda da belirttiğimiz 
    gibi istatistikte BX + b doğru denkleminin elde edilmesi için kullanılan amaç fonksiyonuna istatistikte "maximum likelihood" 
    denilmektedir. İsminden de anlaşılacağı gibi "maximum likelihood" yönteminde amaç fonksiyonu maksimizasyon için oluşturulmaktadır. 
    Maximum likelihood amaç fonksiyonun dayandığı fikir veri kümesindeki satırların olasılıklarının çarpımının en büyüklenmesidir. 
    Satırların istatistiksel olarak bağımsız olduğunu varsayarsak satırların sigmoid çıktılarının çarpımı aslında toplam veri 
    kümesinin olasılığını vermektedir. (İstatistiksel bağımsız olayların birlikte gerçekleşme olasılığının onların gerçekleşme 
    olasılıklarının çarpımına eşit olduğunu anımsayınız.) İşte bu olasılığın maksimize edilmesi de aslında kaybın minimize 
    edilmesiyle aynı anlama gelmeketedir. Önceki paragrafta da belirttiğimiz gibi maximum likelihood amaç fonksiyonunu şöyle 
    oluşturulmaktadır:

    ∏[p(x)^y * (1 - p(x))^(1-y)]

    Bu ifadenin logaritmasını alıp toplam nokta sayısına bölelim:

    (1 / N) * ∑[y * log(p(x)) + (1 - y) * log(1 - p(x))]

    Buradan da görüldüğü gibi aslında maximum likelihood amaç fonksiyonu aslında binary cross entropy-fonksiyonunun pozitiflisidir. 
    Bir fonksiyonun negatifinin minimize edilmesiyle pozitifinin maksimize edilmesi aynı anlamdadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aslında istatistiksel lojistik regresyonun tek bir nöronda oluşan ve bizim "perceptron" dediğimiz sinir ağı birimiyle 
    yakın bir ilişkisi vardır. Şöyle ki: Aslında aktivasyon fonksiyonu "sigmoid" olan loss fonksiyonu "binary cross-entropy" 
    olan perceptron tamamen yukarıda açıkladığımız lojistik regresyon modelinin aynısıdır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Biz konuya girişte lojistik regresyon modelinin bir "doğrusal sınıflandırıcı (linear classifier)" olduğunu belirtmiştik.
    Yani bu model aynı zamanda bir hyperplane ile iki sınıfı birbirinden ayrıştırmaya çalışmaktadır. Şimdi bunun ispatını 
    yapalım. BX + b doğru denkleminin aynı zamanda "odds ratio" değerinin logaritması olduğunu belirtmiştik:

    BX + b = log(p(x) / (1 - p(x)))

    Burada p(x) = 0.5 alırsak eşitlik şu hale gelir:

    BX + b = log(1)
    BX + b = 0

    Bu durumda bizim elde ettiğimiz doğru denklemini 0'a eşitleyerek bir doğru (genel olarak hyperplane) çizersek aslında 0.5 
    olasılıkla noktaları ikiye ayırmış oluruz. Yukarıda kalanlar bir sınıf aşağıda kalanlar bir sınıf olur. Başka bir deyişle 
    aslında lojistik regresyondan elde edilen doğru denklemi 0'a eşitlenirse bir doğrusal sınıflandırıcı haline gelmektedir. 
    Örneğin X1 ve X2'den oluşan iki özellikli bir veri kümesi için ayırıcı doğru şöyle çizilecektir:

    B0 + B1x1 + B2x2 = 0
    B2X2 = -B0 - B1X1
    X2 = (-B0 - B1X1) / B2

    Burada biz X1'e değer vererek X2 değerlerini elde edip doğruyu çizebiliriz. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                        108. Ders - 09/03/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Loojistik regresyon işlemi için scikit-learn kütüphanesinde sklearn.linear_model modülünde LogisticRegression isimli 
    bir sınıf bulunurulmuştur. Sınıfın __init__ metodunun parametrik yapısı şöyledir:

    class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, 
            intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, 
            multi_class='deprecated', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)

    Metodun birinci parametresi doğru denkleminin elde edilmesinde kullanılacak olan regresyon yöntemini belirtmektedir. Bu 
    parametre None geçilirse bir regülasyon yapılmaz, 'l1' geçilirse L1 regülasyonu (Lasso regülasyonu), 'l2' geçilirde L2 
    regülasyonu (Ridge regülasyonu) uygulanır. Eğer bu parametreye 'elasticnet' geçilirse Hem L1 regülasyonu hem de L2 regülasyonu
    (Elastic Net regülasyonu) uygulanmaktadır. Metodun C parametresi L1 ve L2 regülasyonundaki çarpanı ayarlamak için kullanılmaktadır. 
    L1 ve L2 regülasyonunda da l1_ratio parametresi bu regülasyonlar arasındaki oranı belirtmektedir. Tabii uygulamacı genellikle 
    tüm parametreleri default değerle geçerek nesneyi yaratır. Örneğin:

    lr = LogisticRegression()

    LogisticRegression nesnesi yaratıldıktan sonra yine fit işlemi yapılır. Tüm lojistik regresyon işlemleri bu fit metodunda 
    yapılmaktadır. Sınıfın transform isimli bir metodu yoktur. fit işleminden sonra artık predict işlemi ile kestirim yapılabilir. 
    predict metodu bize doğrudan sınıf numaralarını vermektedir. Yani predict fonksiyonu verdiğimiz noktanın x değerlerini yukarıda
    belirttiğimiz sigmoid fonksiyonuna sokar, eğer bu değeri > 0.5 ise noktanın sınıfını 1 olarak < 0.5 ise 0 olarak belirler. 
    Sınıfın  predict_proba isimli metodu bize her noktanın sınıfsal olasıklarını vermektedir. Yani bu metot bize noktaya ilişkin 
    x değerlerinin sigmoid fonksiyonuna sokulmasından elde edilen değeri verir. Ancak bu metot her noktanın 0 olma olasılığı ve 
    1 olma olasılığını iki sütun halinde vermektedir. Dolayısıyla bu metodun verdiği matrisin sütun toplamları 1 olur. Sınıfın 
    score metodu bizden test verileri için x ve y değerlerini alır. Bu x değerleri için y değerlerini tahmin ederek gerçek y 
    değerleriyle oranını hesaplar ve bize "accuracy" skorunu verir. 

    Sınıfın coef_ ve intercept_ örnek öznitelikleri bize ayrıştırmayı yapan doğru denklemini vermektedir. Buradaki doğru denklemi, 
    her zaman B0 + B1x1 + B2x2 + ... + Bnxn biçiminde verilmektedir. Dolayısıyla buradan hareketle doğru çizerken uygun dönüştürmeyi 
    yapmak gerekir. 

    Normal olarak lojistik regresyon işlemlerinde özellik  öl.eklemesinin yapılması gerekir. Çünkü nümerik optimizasyon problmeleri 
    çözülürken sütunlar arasındaki skala farklılıkları nümerik çözümü olumsuz etkilemektedir. Genel olarak nümerik optimizasyonun 
    yapıldığı durumlarda özellik ölçeklemesi uygulanmalıdır.   
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıda iki boyutlu X1 ve X2 özelliklerinden oluşan "logistic-points.csv" dosyasındaki noktalar üzerinde lojistik regresyon 
    uygulaayan bir örnek verilmiştir. Bu örnekte önce StandardScaler işlemi yapılıp oradan elde edilen noktalar LogisticRegression 
    sınıfına verilmiştir. predict metodu ile kestirim de yapılmıştır.
    
    Buradaki kullanılan "logistic-points.csv" dosyasının içeriği şöyledir:

    x1,x2,class
    -0.017612,14.053064,0
    -1.395634,4.662541,1
    -0.752157,6.538620,0
    -1.322371,7.152853,0
    0.423363,11.054677,0
    0.406704,7.067335,1
    0.667394,12.741452,0
    -2.460150,6.866805,1
    0.569411,9.548755,0
    -0.026632,10.427743,0
    0.850433,6.920334,1
    1.347183,13.175500,0
    1.176813,3.167020,1
    -1.781871,9.097953,0
    -0.566606,5.749003,1
    0.931635,1.589505,1
    -0.024205,6.151823,1
    -1.693453,-0.557540,1
    -0.576525,11.778922,0
    -0.346811,-1.678730,1
    -2.124484,2.672471,1
    1.217916,9.597015,0
    -0.733928,9.098687,0
    -3.642001,-1.618087,1
    0.315985,3.523953,1
    1.416614,9.619232,0
    -0.386323,3.989286,1
    0.556921,8.294984,1
    1.224863,11.587360,0
    -1.347803,-2.406051,1
    1.196604,4.951851,1
    0.275221,9.543647,0
    0.470575,9.332488,0
    -1.889567,9.542662,0
    -1.527893,12.150579,0
    -1.185247,11.309318,0
    -0.445678,3.297303,1
    1.042222,6.105155,1
    -0.618787,10.320986,0
    1.152083,0.548467,1
    0.828534,2.676045,1
    -1.237728,10.549033,0
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
from sklearn.preprocessing import StandardScaler
import pandas as pd

df = pd.read_csv('logistic-points.csv')

dataset_x = df.iloc[:, :-1].to_numpy()
dataset_y = df.iloc[:, -1].to_numpy()

ss = StandardScaler()
scaled_dataset_x = ss.fit_transform(dataset_x)

scaled_dataset_x = np.append(scaled_dataset_x, np.ones((dataset_x.shape[0], 1)), axis=1)

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.title('Points for Logistic Regression')
plt.scatter(dataset_x[dataset_y == 0, 0], dataset_x[dataset_y == 0, 1], color='blue', marker='o')
plt.scatter(dataset_x[dataset_y == 1, 0], dataset_x[dataset_y == 1, 1], color='green', marker='^')
plt.xlabel('x1')
plt.ylabel('x2')
plt.legend(['class 0', 'class 1'])

plt.show()

def sigmoid(x):
    return 1.0 / (1 + np.exp(-x))

def gradient_descent_logistic(dataset_x, dataset_y, learning_rate=0.001, niter=50000):
        b = np.zeros((dataset_x.shape[1], 1))
        for k in range(niter):
            h = sigmoid(dataset_x @ b)
            error = h - dataset_y
            grad = dataset_x.T @ error
            b = b - learning_rate * grad
        return b

b = gradient_descent_logistic(scaled_dataset_x, dataset_y.reshape(-1, 1))

x1 = np.linspace(-5, 5, 1000)
x2 = (-b[2] - b[0] * x1) / b[1]

points = np.vstack((x1, x2)).T
transformed_points = ss.inverse_transform(points)

plt.figure(figsize=(10, 8))
plt.title('Points for Logistic Regression')
plt.scatter(dataset_x[dataset_y == 0, 0], dataset_x[dataset_y == 0, 1], color='blue', marker='o')
plt.scatter(dataset_x[dataset_y == 1, 0], dataset_x[dataset_y == 1, 1], color='green', marker='^')
plt.plot(transformed_points[:, 0], transformed_points[:, 1], color='red')
plt.xlabel('x1')
plt.ylabel('x2')
plt.legend(['class 0', 'class 1', 'regression line'])
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi istatistiksel lojistik regresyon ile yapay sinir ağlarıyla uygulanan lojistik regresyon ve naive Bayes yöntemiyle
    gerçekleştirilen lojistik regresyon arasındaki farklılıklar nelerdir? Yani bunların hangisi hangi durumlarda kullanılmalıdır?
    Bu konuda şunlar söylenebilir:

    - Yukarıda da belirttiğimiz gibi aslında lojistik regresyon aktivasyon fonksiyonu sigmoid olan ve loss fonksiyonu "binary 
    cross-entropy" olan perceptron ile eşdeğerdir. Tabii biz sinir ağı demekle perceptron'u kastetmiyoruz, çok nörondan oluşan 
    en az iki katmanlı ağları kastediyoruz.

    - Çeşitli yöntemlerin hangisinin daha iyi sonuç vereceğini verilerin dağılımını bilmeden öngörmek çok zor bazen imkansızdır. 
    Dolayısyla uygulamacının çeşitli yöntemleri deneyip kendi veri kümesi için en iyi olanı tercih etmesi tavsiye edilmektedir. 
    Zaten "otomatik makine öğrenmesi araçları" aslında bunu yapmaktadır. 

    - İstatistiksel lojistik regresyon yukarıda da belirttiğimiz gibi "doğrusal olarak arıştırılabien (linearly seperable)" 
    veri kümeleri için çok uygun bir yöntemdir. Veri kümesindeki noktalar bir doğru ile ayrıştırılabilir olmaktan çıktığında 
    bu yöntemin performansı düşmeye başlamaktadır. 

    - Yapay sinir ağları için "doğrusal olarak ayrıştırılabilirlik" biçiminde bir koşul yoktur. Yapay sinir ağları doğrusal 
    olarak ayrıştırılabilir olmayan veri kümelerinde de kullanılabilmektedir. 

    - Az sayıda veri olduğunda ve bunlar doğrusal olarak ayrıştırılabilir durumdaysa lojistik regresyon yapay sinir ağlarına 
    tercih edilir. Yapay sinir ağlarının az veriyle eğitilmesi problemlidir. 
    
    - Naive Bayes yöntemi ön koşulları olan bir yöntemdir. Sütunların çoğunun kategorik olduğu durumlarda diğerlerine göre 
    daha iyi sonuç verme eğilimindedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Tabii biz StandardScaler ve LogisticRegression nesnelerini bir boru hattına da verebiliriz. Ancak her durumda boru hattı 
    istediğimiz esnekliği sunmamaktadır. Örneğin burada boru hattı grafik çizimlerinde bize zorluk çıkartacaktır. Aşağıda
    böyle bir hattı örneği verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('logistic-points.csv')

dataset_x = df.iloc[:, :-1].to_numpy()
dataset_y = df.iloc[:, -1].to_numpy()

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 8))
plt.title('Points for Logistic Regression')
plt.scatter(dataset_x[dataset_y == 0, 0], dataset_x[dataset_y == 0, 1], color='blue', marker='o')
plt.scatter(dataset_x[dataset_y == 1, 0], dataset_x[dataset_y == 1, 1], color='green', marker='^')
plt.xlabel('x1')
plt.ylabel('x2')
plt.legend(['class 0', 'class 1'])
plt.show()

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline

pl = Pipeline([('scaling', StandardScaler()), ('logistic-regression', LogisticRegression())])

pl.fit(dataset_x, dataset_y)

predict_data = [(-0.733928, 9.098687) , (0-3.642001, -1.618087), (0.556921, 8.294984)]
predict_result = pl.predict(predict_data)
print(predict_result)

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "Breast Cancer Winconsin" veri kümesi üzerinde LogisticRegression, GaussianNB ve Yapay Sinir Ağları 
    yöntemleri uygulanmıştır. Bu veri kümesinde LogisticRegression ve yapay sinir ağları aynı sonucu vermiştir. Ancak Naive 
    Bayes daha düşük bir sonuç vermiştir. Üç yöntemden elde edilen değerler şunlardır:

    LogisticRegression accuracy score: 0.9649122807017544
    GaussianNB accuracy score: 0.9210526315789473
    NeuralNet accuracy score: 0.9649122807017544
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv("data.csv")

dataset_x = df.iloc[:, 2:-1].to_numpy()
dataset_y = np.zeros(len(df))
dataset_y[df['diagnosis'] == 'M'] = 1

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=12345)

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score
from sklearn.naive_bayes import GaussianNB
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense

ss = StandardScaler()
ss.fit(training_dataset_x)
scaled_training_dataset_x = ss.transform(training_dataset_x)
scaled_test_dataset_x = ss.transform(test_dataset_x)

# LogisticRegression Solution

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(max_iter=1000000)
lr.fit(scaled_training_dataset_x, training_dataset_y)
predict_result = lr.predict(scaled_test_dataset_x)
score = accuracy_score(test_dataset_y, predict_result)
print(f'LogisticRegression accuracy score: {score}')

# Naive Bayes Solution

gnb = GaussianNB()
gnb.fit(training_dataset_x, training_dataset_y)
predict_result = gnb.predict(test_dataset_x)
score = accuracy_score(predict_result, test_dataset_y)
print(f'GaussianNB accuracy score: {score}')

# Neural Net Solution

model = Sequential(name='BreastCancer')
model.add(Dense(64, activation='relu', input_dim=dataset_x.shape[1], name='Hidden-1'))
model.add(Dense(64, activation='relu', name='Hidden-2'))
model.add(Dense(1, activation='sigmoid', name='Output'))

model.summary()

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['binary_accuracy'])
hist = model.fit(scaled_training_dataset_x, training_dataset_y, batch_size=32, epochs=200, verbose=0)
predict_result = (model.predict(scaled_test_dataset_x) > 0.5).astype(int)
score = accuracy_score(predict_result, test_dataset_y)
print(f'NeuralNet accuracy score: {score}')

#----------------------------------------------------------------------------------------------------------------------------
                                        109. Ders - 15/03/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Biz yukarıda iki sınıflı (binary) lojistik regresyon üzerinde durduk. Zaten istatistikte lojistik regresyon denildiğinde 
    default olarak iki sınıflı lojistik regresyon anlaşılmaktadır. Çok sınıflı (multinomial/multiclass) lojistik regresyon 
    problemleri de aslında genel yapı itibari ile iki sınıflı lojistik regresyon problemlerine benzemektedir. 

    Çok sınıflı lojistik regresyon problemlerinin çözümü için üç farklı yöntem kullanılabilmektedir. Bunlardan birine "OvR 
    (One versus Rest)" yöntemi denir. Bu yöntemde her sınıfı diğerlerinden ayırmak için bir doğru denklemi elde edilmeye çalışılır. 
    Dolayısıyla K tane sınıf söz konusuysa K tane doğru denklemi elde edilecektir. İstatistikte daha çok bu yöntem kullanılmaktadır. 
    Böylece sanki çok sınıflı lojistik regresyon birden fazla iki sınıflı lojistik regresyon gibi ele alınmaktadır. Örneğin 
    bu yöntemde C1, C2 ve C3 biçiminde 3 sınıflı lojistik resgresyon probleminde C1'i diğerlerinden ayıran, C2'yi diğerlerinden 
    ayıran ve C3'ü diğerlerinden ayıran üç farklı iki sınıflı lojistik regresyon uygulanmaktadır. Dolayısıyla üç farklı doğru 
    denklemi elde edilmektedir. Burada kestirim, kestirilecek noktanın üç ayrı iki sınıflı lojistik regresyona sokulması ve 
    hangi olasılık değeri yüksekse o sınıfa atanması biçiminde yapılmaktadır. Ancak bu yöntemin bazı dezavantjları da vardır. 

    Çok sınıflı lojistik regresyon problemlerinin çözümü için kullanılan ikinci yönteme "OvO (One versus One)" denilmektedir. 
    Burada her sınıf her sınıfla ikili lojistik regresyona sokulur. Kestirim işlemi de oylama (voting) yoluyla yapılır. Örneğin
    elimizde C1, C2, C3, C4 biçiminde dört sınıflı bir veri kümesi olsun. Biz burada her sınıfı her sınıfla ikili jojistik 
    regresyona sokarız:

    C1 ile C2
    C1 ile C3
    C1 ile C4
    C2 ile C3
    C2 ile C4
    C3 ile C4

    Kestirim sırasında kestirilecek noktayı buradaki tüm regresyonlara sokup oylama yaparız. Bu yöntemde aşağıdaki gibi bir 
    sonucun elde edidiğini varsayalım:

    C1 ile C2   => C2
    C1 ile C3   => C1
    C1 ile C4   => C1
    C2 ile C3   => C3
    C2 ile C4   => C2
    C3 ile C4   => C4

    Burada oylamada C1 en iyi puanı elde ettiği için noktayı C1 sınıfına atarız. Bu yöntemde sınıf sayısı K olmak üzere 
    oluşturulacak ikili lojistik regresyon sayısının C(K, 2) olduğuna dikkat ediniz. Örneğin K = 4 olduğu durumda C(4, 2) = 6 
    farklı ikili lojistik regresyon oluşturulacaktır. Pekiyi bu yöntemde aynı oyu alan birden fazla sınıf olursa ne seçim
    nasıl yapılacaktır? İşte burada seçim birkaç biçimde yapılabilir. Aynı oyu alan sınıflardan biri rastgele seçilebilir, 
    aynı oyu alan sınıfların oylamadan elde ettikleri toplam olasılığa (sigmoid fonksiyonlarının verdiği olasılıkların toplamına)
    bakılabilir ya da aynı oyu alan sınıflardan birisine öncelik tanınabilir.

    Üçüncü yönteme "multinomial" yöntem de denilmektedir. Bu yöntemde sınıf sayısı kadar doğru denklemi ayrı ayrı oluşturmak 
    yerine tek hamlede softmax fonksiyonu uygulanarak oluşturulmaktadır. Softmax fonksiyonunu anımsatmak istiyoruz:

    Softmax(zi) = e^(zi) / Σ(e^(zj))
    
    Burada zi doğru denkleminden elde edilen değeri belirtmektedir. Bu değerlerin e tabanına göre kuvvetlerinin alındığını 
    görüyorsunuz. Paydadaki toplam da tüm doğru denklemlerinden elde edilen değerlerin üstel toplamlarını belirtmektedir. 
    Örneğin üç sınıflı bir lojistik regresyon probleminde üç ayrı doğru denklemi beraber bulunmaya çalışılır. Buradaki zi 
    ve zj değerleri x değerlerinin bu doğru denklemlerine sokulmasıyla elde edilen değerleri temsil etmektedir. Örneğin biz 
    C1, C2 ve C3 biçiminde üç sınıflı iki özellikli bir lojistik regresyonda doğru denklemlerini aşağıdaki gibi temsil etmiş 
    olalım:

    z1 ---> B10 + B11X1 + B12X2
    z2 ---> B20 + B21X1 + B22X2
    z3 ---> B30 + B31X1 + B32X2

    Elimizde bir noktaya ilişkin x değerleri olsun. Biz de yukarıda softmax fonksiyonu ile bu x değerlerinin C1 sınıfına, 
    C2 sınıfına ve C3 sınıfına ilişkin olma olasılıklarını elde edebiliriz:

    x noktasının C1 olma olasılığı = e^(z1) / (e^(z1) + e^(z2) + e^(z3))
    x noktasının C2 olma olasılığı = e^(z2) / (e^(z1) + e^(z2) + e^(z3))
    x noktasının C3 olma olasılığı = e^(z3) / (e^(z1) + e^(z2) + e^(z3))

    Burada elde edilen bu üç olasılığın toplamının 1 olduğuna dikkat ediniz. 
        
    Pekiyi buradaki doğru denklemleri nasıl elde edilmektedir? Anımsayacağınız gibi biz 2 sınıflı lojistik regresyon 
    problemlerinde "binary cross-entropy" isimli amaç fonksiyonunu (loss fonkisyonunu) kullandık. Bu da zaten "maximum 
    likelihood" amaç fonksiyonunun negatifiydi. Pekiyi örneğin üç sınıflı bir lojistik regresyon probleminde biz nasıl 
    bir amaç fonksiyonu kullanmalıyız? İşte yapay sinir ağları konusunda da gördüğümz gibi buradaki amaç fonksiyonuna 
    (loss fonksiyonuna) "categoricalcross- entropy" denilmektedir. "categorical cross-entropy" fonksiyonu yeniden anımsatmak 
    istiyoruz:

    L = -∑(c=1 to C) y_ic × log(p_ic)

    Burada p_ic değeri softmax fonksiyonundan elde edilen değerdir. Dolayısıyla aslında bu loss fonksiyonu eşliğinde doğru 
    denklemleri güncellenmektedir. Buradaki y_i değerleri ilgili satırın gerçek değerlerini belirtmektedir. Ancak bu değer
    one-hot-encoding biçimindedir. Dolayısıyla buradaki toplamda yalnızca tek bir sınıf için değer oluşacaktır. Örneğin üç 
    sınıflı bir lojistik regresyonda bir satırın gerçek sınıfı 2 olsun. Bu durumda y_ic aslında 0 1 0 biçimindedir. Dolayısıyla 
    bu toplamdan yalnızca -log(p_i2) elde edilir. Bu da ikinci sınıfa ilişkin softmak değerinin logaritmasının negatif değeridir. 
    Burada örneğin üç sınıflı lojistik regresyonda eğitim sonucunda üç doğru denkleminin oluşacağına dikkat ediniz. Bu doğru 
    denklemlerinin geometrik yorumlaması zor yapılamayabilir. Çünkü buradaki doğru denklemleri sınıfları ayıran bir karakterde 
    değildir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    scikit-learn kütüphanesindeki LogisticRegression sınıfı çok sınıflı lojistik regresyonlarda da kullanılabilmektedir. 
    Sınıfın __init__ metodunu yeniden anımsatmak istiyoruz:

    class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, 
            intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, 
            multi_class='deprecated', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)
    
    Metotta lojistik regresyonun iki sınıflı mı çok sınıflı mı olduğuna yönelik bir parametrenin olmadığına dikkat ediniz. Çok 
    sınıflı lojistik regresyonda fit işlemi sırasında fit metodu zaten y değerlerinden hareketle sınıf sayısını kendisi elde 
    edebilmektedir. 

    Pekiyi sınıf yukarıda açıkladığımız üç yöntemden hangisini kullanmaktadır? İşte bir süre önceye kadar çok sınıflı lojistik
    regresyon için sınıfın kullanacağı yöntem metodun multi_class parametresiyle nispeten ayarlanabiliyordu. Ancak gördüğünüz
    gibi bu parametre "deprecated" yapılmış durumdadır. Yani kütüphanenin sonraki versyonlarında bu parametre tümden kaldırılacaktır. 
    Bu parametreye üç değer girilebilmektedir:

    auto 
    ovr 
    mutinomial

    "ovr" yukarıdaki açıkladığımız OvR yöntemini, "multinomial" ise multinomial yöntemin kullanılacağı anlamına gelmektedir. 
    auto iki sınıf için "binary lojistik regresyon", ikiden fazla sınıf için "multinomial" anlamına gelir. Bu parametrenin
    halen default değeri "auto" biçimdedir. Tabii bu parametre kaldırılınca default durum çok sınıflı lojistik regreasyon 
    için "multinomial" olacaktır. Pekiyi biz OvR ya da OvO kullanmak istersek ne yapmalıyız? İşte bunun için sklearn.multiclass
    modülünde iki ayrı adaptör sınıf da bulundurulmuştur:

    OneVsOneClassifier
    OneVsRestClassifier

    Bu iki sınıf aslında ikili sınıflandırıcaları parametre olarak alıp işlemini yapmaktadır. Biz bu sınıfların estimator 
    parametrelerine konu bağlamında LogisticRegression nesnesi vermeliyiz. Örneğin:

    ovo = OneVsOneClassifier(LogisticRegression())
    ovr = OneVsRestClassifier(LogisticRegression())
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıda zambak veri kümesi ("iris.csv") üzerinde çok sınıflı lojistik regresyon işlemi uygulanmıştır. Zambak verilerinin 
    üç sınıfa ayrıldığını anımsayınız. Bu örnekte ayrıca zambak verileri üzerinde yapay sinir ağı modeli de uygulanmıştır. 
    İki yöntemden de genel olarak aynı sonuçlar elde edilmiştir. Bunun nedeni şüphesiz kümlerin birbirlerinden oldukça ayrık 
    durumda olmasındandır. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd
    
df = pd.read_csv('iris.csv')

dataset_x = df.iloc[:, 1:-1].to_numpy()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
dataset_y = le.fit_transform(df.iloc[:, -1])

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=12345)

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(training_dataset_x)
scaled_training_dataset_x = ss.transform(training_dataset_x)
scaled_test_dataset_x = ss.transform(test_dataset_x)

# LogisticRegression Solution

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

lr = LogisticRegression()
lr.fit(scaled_training_dataset_x, training_dataset_y)

predict_result = lr.predict(scaled_test_dataset_x)
score = accuracy_score(test_dataset_y, predict_result)
print(f'Multinomial LogisticRegression score: {score}')

# Neural Net Solution

from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)
ohe_training_dataset_y = ohe.fit_transform(training_dataset_y.reshape(-1, 1))
ohe_test_dataset_y = ohe.fit_transform(test_dataset_y.reshape(-1, 1))

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense

model = Sequential(name='Iris')
model.add(Dense(64, activation='relu', input_dim=dataset_x.shape[1], name='Hidden-1'))
model.add(Dense(64, activation='relu', name='Hidden-2'))
model.add(Dense(3, activation='softmax', name='Output'))

model.summary()

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])
hist = model.fit(scaled_training_dataset_x, ohe_training_dataset_y, batch_size=32, epochs=200)
predict_result_softmax = model.predict(scaled_test_dataset_x)

import numpy as np

predict_result = np.argmax(predict_result_softmax, axis=1)
score = accuracy_score(test_dataset_y, predict_result)
print(f'Neural Net score: {score}')
    
#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de MNIST örneğini istatistiksel çok sınıflı (multinomial) lojistik regresyonla çözmeye çalışalım. MNIST aslında 
    istatistiksel lojistik  regresyona uygun bir veri kümesi değildir. Çünkü veri kümesinde 784 tane sütun vardır. Bu biçimdeki 
    lojistik regresyonun başarılı olması zordur. Aşağıdaki programda MNIST veri kümesine hem çok sınıflı lojistik regresyon 
    hem de sinir ağı uygulanmıştır. Buradan accuracy değerleri şöyle elde edilmiştir:

    LogisticRegresson accuracy score: 0.9203
    Simple Neural Net accuracy score: 0.9808
    
    Görüldüğü gibi resim tanıma gibi işlemlerde yapay sinir ağları alternatif yöntemlere göre çok daha iyi sonuç vermektedir. 
    Tabii biz burada yapay sinir ağında derin bir ağ kullanmadık. Önceden eğitilmiş RestNet gibi modeller çok daha iyi sonucun
    elde edilmesine olanak sağlamaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

from tensorflow.keras.datasets import mnist

(training_dataset_x, training_dataset_y), (test_dataset_x, test_dataset_y) = mnist.load_data()

training_dataset_x = training_dataset_x.reshape(-1, 28 * 28)
test_dataset_x = test_dataset_x.reshape(-1, 28 * 28)

# one hot encoding for y data

from tensorflow.keras.utils import to_categorical
from sklearn.metrics import accuracy_score

ohe_training_dataset_y = to_categorical(training_dataset_y)
ohe_test_dataset_y = to_categorical(test_dataset_y)

# minmax scaling

scaled_training_dataset_x = training_dataset_x / 255
scaled_test_dataset_x = test_dataset_x / 255

# LogisticRegression Solution

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(max_iter=1000)
lr.fit(training_dataset_x, training_dataset_y)
predict_result = lr.predict(test_dataset_x)
score = accuracy_score(test_dataset_y, predict_result)
print(f'LogisticRegresson accuracy score: {score}')

# Simple Neural Net Solution

from tensorflow.keras.utils import to_categorical

ohe_training_dataset_y = to_categorical(training_dataset_y)
ohe_test_dataset_y = to_categorical(test_dataset_y)

training_dataset_x = training_dataset_x / 255
test_dataset_x = test_dataset_x / 255

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense

model = Sequential(name='MNIST') 
model.add(Dense(256, activation='relu', input_dim=784, name='Hidden-1'))
model.add(Dense(128, activation='relu', name='Hidden-2'))
model.add(Dense(10, activation='softmax', name='Output'))

model.summary()

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])
hist = model.fit(training_dataset_x, ohe_training_dataset_y, epochs=20, batch_size=32)

import numpy as np

softmax_predict_result = model.predict(test_dataset_x)
predict_result = np.argmax(softmax_predict_result, axis=1)
score = accuracy_score(test_dataset_y, predict_result)
print(f'Simple Neural Net accuracy score: {score}')

#----------------------------------------------------------------------------------------------------------------------------
    Saklı katmanı tek nörondan oluşan çıktı katmanı 4 nörondan oluşan, çıktı aktivasyon fonksiyonu "softmax" ve loss fonksiyonu
    "categorical cross-entropy" olan bir sinir ağı modeli ile "multinomial" yöntem kullanan lojistik regresyon modeli çalışma
    biçimi olarak birbirine çok benzemektedir. Çünkü her iki modelde de aslında aynı amaç fonksiyonu nümerik yöntemlerle 
    minimize edilmeye çalışılmaktadır. Tabii lojistik regresyonun bize aynı zamanda doğru denklemi verdeğine de dikkat ediniz. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Çok sınıflı lojistik regresyonlarda örneğin özellik sayısı iki ise biz regresyon doğrularını çizerek belli bir noktayı
    gözle kestirebilit miyiz? İşte "multinomial" yöntemde gözle kestirim yapmak mümkün olmayabilir. OvR yönteminde gözle kestirim
    yapmak nispteten daha kolaydır. Çünkü bu yöntemde sınıf sayısı K olmak üzere K tane regresyon doğrusu bazı uzayı çeşitl
    bölgeler ayırmaktadır. Her sınıfın bir bölgesi olur. Ancak bazı bölgeler birden fazla sınııfn içerisine girebilmektedir. 
    İşte bu bölgelerdeki noktaların hangi sınıfa ilişkin olduğu regresyon doğrularına olan uzaklıkla belirlenebilir. Bir 
    nokta hangi regresyon doğrusuna daha uzaksa o sınıfa girmektedir. 

    Aşağıdaki örnekte 3 sınıflı bir veri kümesi oluşturup "multinomial" ve "OvR" kullanılarak lojistik regresyon doğruları 
    çizdirilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------
    
import numpy as np
from sklearn.datasets import make_blobs

dataset_x, dataset_y = make_blobs(n_features=2, centers=3, cluster_std=2, random_state=100)

colors = ['red', 'green', 'blue']

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))

for i in range(3):
    plt.scatter(dataset_x[dataset_y == i, 0], dataset_x[dataset_y == i, 1], color=colors[i])
plt.show()

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(dataset_x, dataset_y)

x = np.linspace(-15, 15, 300)
plt.figure(figsize=(12, 8))
plt.xlim(-20, 20)
plt.ylim(-20, 20)
for i in range(len(lr.coef_)):
    plt.scatter(dataset_x[dataset_y == i, 0], dataset_x[dataset_y == i, 1], color=colors[i])
    y = (-lr.intercept_[i] - lr.coef_[i, 0] * x) / lr.coef_[i, 1]
    plt.plot(x, y, color=colors[i])
plt.show()

print(lr.score(dataset_x, dataset_y))

lr = LogisticRegression(multi_class='ovr')
lr.fit(dataset_x, dataset_y)

x = np.linspace(-15, 15, 300)
plt.figure(figsize=(12, 8))
plt.xlim(-20, 20)
plt.ylim(-20, 20)
for i in range(len(lr.coef_)):
    plt.scatter(dataset_x[dataset_y == i, 0], dataset_x[dataset_y == i, 1], color=colors[i])
    y = (-lr.intercept_[i] - lr.coef_[i, 0] * x) / lr.coef_[i, 1]
    plt.plot(x, y, color=colors[i])
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
                                                110. Ders - 16/03/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Makine öğrenmesinde sık kullanılan doğrusal sınıflandırıcılardan (linear classifiers) biri de "Destek Vektör Mekineleri 
    (Support Vector Machine)" denilen sınıflandırıcıdır. Bu yöntem 1992'de ilk kez ortaya konmuş ve zaman içerisinde bazı 
    yeteneklerinden dolayı gittikçe popülerlik kazanmıştır. Biz kursumuzda "Destek Vektör Makineleri" yerine kısaca "SVM (Support
    Vector Machine)" de diyeceğiz. Aslında temel olarak ele alındığında SVM'ler istatistiksel lojistik regresyonlara benzemektedir. 
    SVM'ler temel olarak sınıflandırma problemleri için kullanılıyor olsa da regresyon problemleri için de kullanılabilmektedir. 
    SVM'lerin regresyon problemleri için kullanılan biçimlerine SVR (Support Vector Regression) da denilmektedir. 
    
    İstatistiksel lojistik regresyonda gerçek sınıflarla regresyon doğrusundan elde edilen sınıflar arasındaki farklar minimize 
    edilmeye çalışılmaktadır. (Ya da bunun tersi maksimize edilmeye çalışılmaktadır ki buna "maximum likelihood" denildiğini 
    anımsayınız.) Oysa SVM'lerin dayandığı fikir daha farklıdır. SVM'lerde de yine iki sınıfı ayıran bir hyperplane elde edilmeye 
    çalışılır. Ancak bu hyperplane kendisine en yakın farklı sınıflardaki noktalar arasındaki toplam uzaklığı en büyüklemek 
    amacıyla olşturulmaktadır. Burada noktanın SVM heyperplane'ine uzaklığı için "dikme uzaklığı" kullanlmaktadır. İki kümeyi 
    ayırma iddiasında olan sonsuz sayıda hyperplane oluşturulabilir. Ancak destek vektör makinelerinde kendisine en yakın 
    iki noktanın uzaklıkları toplamına bakılmaktadır. Bir doğrunun iki sınıftan da (çok sınıf da söz konusu olabilir) kendisine 
    en yakın noktalarına "destek vektörleri (support vectors)" denilmektedir. Amaç destek vektörlerinin hyperplane'e toplam 
    uzaklıklarını maksimize etmektir. Terminolojide en yakın noktaların (destek vektörlerinin) hyperplane'a olan dikme 
    uzaklıklarının toplamına "marjin (margin)" denilmektedir. Amaç bu marjinin en yüksek olduğu hyperplane'nin elde edilmesidir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    SVM'lerin matematiksel temeli optimizasyon bağlamında biraz karışıktır. Bir noktanın bir doğruya dikme uzaklığı şöyledir:
    
    |w·x + b| / ||w||
    
    Burada w vektörü x değerlerinin katsayılarını belirtmektedir. ||w|| ise bu katsayaların karelerinin toplamının karekökünü 
    belirtir. Buradaki doğru denklemi w·x + b = 0 biçimindedir. Örneğin iki boyutlu kartezyen koordinat sisteminde doğru denklemini 
    w1x1 + w2x2 + b = 0 biçiminde de ifade edebiliriz. Bu durumda ||w|| ifadesi de sqrt(w1^2 + w2^2) biçiminde olur. Bu durumda 
    iki noktanın uygun doğruya dikme uzaklıkları şu hale gelir:

    d₁ = |w·x1 + b| / ||w|| 
    d₂ = |w·x2 + b| / ||w|| 
    
    Burada x1 noktalardan birini x2 ise diğerini temsil etmektedir. Noktalardan biri doğrunun bir tarafında diğeri de diğer 
    tarafında kalacaktır. Dolayısıyla doğru denkleminin kısıtları şöyle olur:

    yi(w·xi + b) ≥ 1,  i = 1, 2, ..., n

    Burada eğitim sırasında sınıflardan birini +1, diğerine -1 olarak etiketlendirdiğimizi varsayıyoruz. Bu kısıttaki yi değeri 
    eğitim sırasında -1 ya da +1 olabilmektedir. Bu durumda minimal olarak karar sınırında yukarıdaki uzaklıklar şu hale gelecektir:

    d₁ = |w·x1 + b| / ||w|| = 1 / ||w||
    d₂ = |w·x2 + b| / ||w|| = 1 / ||w||

    Böylece maksimize edilecek amaç fonksiyonu şöyle olşturulur:

    Zmax = 2 / ||w||

    Burada payda küçültülürse kesir büyütülmüş olur. Bu durumda optimizasyon aslında paydanın küçültülmesi biçimine dönüştürülebilir. 
    Paydanın kısıtlar altında minimize edilmesi için "lagrange çarpanları" denilen bir yöntemden faydalanılmaktadır. Ancak 
    çözüm nihayetinde nümerik optimizasyon yöntemleriyle (yani örneğin "gradient descent" ya da "Newton-Raphson" gibi yöntemlerle) 
    yapılabilir. Sonuç olarak bu minimizasyondan probleminden w değerleri elde edielcektir. Bu w değerleri (b (bias) değerinin 
    buna dahil edilmediğine dikkat ediniz) aslında doğru denkleminin katsayı değerlerini belirtmektedir. 

    Aslında SVM'de destek vektörleri iki sınıftan bir tane yani toplamda 2 tane olmak zorunda değildir. Daha fazla destek vektörü 
    kullanılarak daha iyi marjinler elde edilebilmektedir. Eğer noktalar tamamen doğrusal olarak ayrıştırılabilir biçimdeyse
    iki destek vektörü yetebilmektedir. Ancak noktalar tamamen doğrusal olarak ayrıştırılabilir değilse optimizasyonda birden 
    fazla destek verktörü kullanılarak daha iyi bir destek vektör doğrusu (hyperplane) elde edilebilmektedir. Genellikle bu 
    tür algoritmalar bu destek vektörleerinin sayısı ya da marjini üzerinde etkili olabilecek hyper parametreler bulundurmaktadır. 
    Destek vektörlerinin sayısı kernel trick" uygulandığında da artabilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Noktalar doğrusal olarak ayrıştırılabilir (linearly separable) ise istatistiksel lojistik regresyonla destek vektör makineleri 
    benzer sonuçları verme eğilimindedir. Ancak bu durumda da destek vektör makinelerinin daha adil bir hyperplane oluşturduğu 
    söylenebilir. Yani destek vektör makineleri bu durumda da sınıfları birbirinden daha iyi ayırabilmektedir. Büyük ölçüde 
    doğrusal olarak ayrıştırılabilir veri kümelerinde lojistik regresyon ile SVM yöntemleri karşılaştırıldığında şunlar 
    söylenebilir:

    - Lojistik regresyonda overfitting oluşma riski daha fazladır. SVM bu bakımdan daha dirençlidir. 
    - Lojistik regresyon SVM yöntemine göre daha hızlı olma eğilimindedir. Özellikle veri kümesi büyüdüğünde ve özellik sayısı 
    arttığında SVM lojistik regresyona göre daha yavaş olma eğilimindedir. 
    - Lojistik regresyon bize bir olasılık değeri vermektedir. Halbuki SVM'den böyle bir olasılık değeri elde edilmemektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aslında SVM'lerin popüler olmasının en önemli nedeni bu yöntemin "kernel trick" denilen bir transformasyonla doğrusal olarak 
    ayrıştırılabilir olmayan veri kümelelerine de uygulanabilmesidir. Kernel trick özellik yükseltmesi yaparak noktaları doğrusal 
    olarak ayrıştırılabilir hale getirmektedir. Örneğin iki boyutlu uzayda doğrusal olarak ayrıştırılamayan noktalar bir projeksiyonla
    üç boyutlu uzayda doğrusal olarak ayrıştırılabilir hale getirilebilmektedir. Burada bu projeksiyonu yapan fonksiyona "kernel 
    fonksiyonu" denilmektedir. Kernel trick noktaları gerçek anlamda transpoze etmeden transpoze edilmiş gibi işlemlere sokulmasını
    sağlamaktadır.
    
    Kernel değiştirme işleminin nasıl yapıldığının matematiksel açıklaması biraz ayrıntılıdır. Biz burada bunun nasıl yapıldığı 
    üzerinde durmayacağız. İstatistiksel lojistik regresyonda böyle bir "kernel trick" yapılamamaktadır. 

    Daha önceden de belirttiğimiz gibi nümerik optimizasyonların söz konusu olduğu durumlarda genel olarak özellik ölçeklemesi 
    uygulanmalıdır. Dolayısıyla SVM işlemlerinin öncesinde eğer sütunlarda skala farklılıkları varsa özellik ölçeklemesinin
    uygulanması gerekir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Destek vektör makineleri için scikit-learn kütüphanesinde sklearn.svm modülü içerisinde SVC (Support Vector Classifier) 
    isimli bir sınıf bulundurulmuştur. Sınıfın __init__ metodunun parametrik yapısı şöyledir:

    class sklearn.svm.SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, 
            tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', 
            break_ties=False, random_state=None)

    Buradaki en önemli, parametre "kernel" parametresidir. Değişik veri kümeleri için değişik kernel fonksiyonları yöntemleri 
    uygulanabilmektedir. scikit-learn şu kernel fonksiyonlarını desteklemektedir: "linear", "poly", "rbf", "sigmoid", "precomputed". 
    Bu parametrenin default değeri "rbf" biçimindedir. "rbf" kernel doğrusal olarak ayrıştırılamayan veri kümelerini de kapsayan 
    genel bir kernel'dır. Örneğin veri kümesi küresel biçimde iç içe geçmiş noktalardan oluşsa bile bu "rbf" kernel bu noktaları 
    daha yüksek boyutlu uzayda birbirinden ayırabilmektedir. "linear" kernel istatistiksel lojistik regresyonda olduğu gibi 
    kernel kullanmadan ayrıştırma yapar. "poly" kernel polinomsal transformasyon yapmaktadır. Başka bir deyişle "poly" kernel 
    polinomsal bir fonksiyonla boyut yükseltmesi yaparak ayrıştırma sağlar. "poly" kernel'daki yüksek boyut polinomun derecesiyle
    artırılabilmektedir. Metottaki degree parametresi "poly" kernel kullanıldığında polinomun derecesi belirtmektedir. "rbf" ekrnel 
    için bu parametre dikkate alınmamaktadır. Metodun probablity parametresi default durumda False biçimdedir. Bu parametre 
    True yapılırsa noktaların ilgili sınıfta olma olasılıkları da hesaplanmaktadır. Bu parametre True yapılmazsa predict_proba
    metodu uygulanamamaktadır. 
    
    SVC nesnesi yaratıldıktan sonra diğer scikit-learn sınıflarında olduğu gibi fit işlemi yapılır. fit işleminden sonra doğrudan 
    predict işlemi yapılabilir. Yine sınıfın predict_proba isimli metodu bize noktaların sınıflar içerisine düşme olasılıklarını 
    vermektedir. score metodu önce predict işlemi yapıp sonra accuracy değerini hesaplamaktadır. 

    Sınıfın intercept_ ve coef_ örnek öznitelikleri yine doğru denkleminin katsayılarını bize vermektedir. Burada bize verilen 
    katsayılar a0 + a1x1 + a2x2 + ... + anxn = 0 denkleminin katsayılarıdır. Burada verilen değerler yalnızca "linear" kernel 
    için geçerlidir. Sınıfın support_ ve support_vectors_ isimli örnek öznitelikleri sırasıyla destek vektörlerinin indislerini 
    ve değerlerini vermektedir. 

    Aşağıda örnekte "logistic-points.csv" dosyası ile temsil ettiğimiz noktalar üzerinde "linear kernel" kullanılarak SVM 
    uygulaması yapımıştır. Elde edilen doğru ve destek vektörleri grafikle gösterilmiştir. "logistic-points.csv" dosyasının
    içeriğini yukarıda daha önce vermişik.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv('logistic-points.csv')

dataset_x = df.iloc[:, :-1].to_numpy()
dataset_y = df.iloc[:, -1].to_numpy()

import matplotlib.pyplot as plt

plt.figure(figsize=(9, 7))
plt.title('Points for Logistic Regression')
plt.scatter(dataset_x[dataset_y == 0, 0], dataset_x[dataset_y == 0, 1], color='blue', marker='o')
plt.scatter(dataset_x[dataset_y == 1, 0], dataset_x[dataset_y == 1, 1], color='green', marker='^')
plt.xlabel('x1')
plt.ylabel('x2')
plt.legend(['class 0', 'class 1'])

plt.show()

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
scaled_dataset_x = ss.fit_transform(dataset_x)

from sklearn.svm import SVC

svc = SVC(kernel='linear')
svc.fit(scaled_dataset_x, dataset_y)

x = np.linspace(-3, 2, 1000)
y = -(svc.intercept_ + svc.coef_[0, 0] * x) / svc.coef_[0, 1]

points = np.vstack((x, x)).T
transformed_points = ss.inverse_transform(points)

support_x = dataset_x[svc.support_]
support_y = dataset_y[svc.support_]

import matplotlib.pyplot as plt

plt.figure(figsize=(9, 7))
plt.scatter(dataset_x[dataset_y == 0, 0], dataset_x[dataset_y == 0, 1], marker='o')
plt.scatter(dataset_x[dataset_y == 1, 0], dataset_x[dataset_y == 1, 1], marker='^')
plt.plot(transformed_points[:, 0], transformed_points[:, 1], color='red')
plt.scatter(support_x[support_y == 0, 0], support_x[support_y == 0, 1], marker='o', color='red')
plt.scatter(support_x[support_y == 1, 0], support_x[support_y == 1, 1], marker='^', color='red')
plt.legend(['Class-1', 'Class-2', 'Support Vector Line', 'Support Vectors Class1', 'Support Vectors Class2'])
plt.show()
     
print(svc.support_)      
print(svc.support_vectors_)      

predict_data = [(-0.733928, 9.098687) , (0-3.642001, -1.618087), (0.556921, 8.294984)]
scaled_predict_data = ss.transform(predict_data)

predict_result = svc.predict(scaled_predict_data)
print(predict_result)

#----------------------------------------------------------------------------------------------------------------------------
                                        111. Ders - 22/03/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte daha önce kullanmış olduğumuz "logistic-points.csv" dosyasındaki noktalarla "linear kernel" kullanarak 
    SVC işlemi ve LogisticRegression işlemi yapılıp elde edilen regresyon doğruları çizilmiştir. Sonra da accuracy skorları 
    elde hesaplanmıştır. Bu örnekte skor olarak şunlar elde edilmiştir:

    SVC score: 0.96
    Logistic score: 0.95

    Görüldüğü gibi destek vektör makineleri %1 oranında daha iyi sonuç vermiştir. Zaten çizieln doğruları da gözle incelediğinizde
    SVC'nin "linear kernel" kullanılmış olsa da noktaları ayrıştırmak için daha iyi bir doğru elde ettiğini göreceksiniz. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv('logistic-points.csv')

dataset_x = df.iloc[:, :-1].to_numpy()
dataset_y = df.iloc[:, -1].to_numpy()

from sklearn.svm import SVC

svc = SVC(kernel='linear')
svc.fit(dataset_x, dataset_y)

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(dataset_x, dataset_y)

x = np.linspace(-4, 4, 1000)
y_svc = -(svc.intercept_ + svc.coef_[0, 0] * x) / svc.coef_[0, 1]
y_logistic = -(lr.intercept_ + lr.coef_[0, 0] * x) / lr.coef_[0, 1]

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.scatter(dataset_x[dataset_y == 0, 0], dataset_x[dataset_y == 0, 1], marker='o')
plt.scatter(dataset_x[dataset_y == 1, 0], dataset_x[dataset_y == 1, 1], marker='^')
plt.plot(x, y_svc)
plt.plot(x, y_logistic)

plt.legend(['Class-1', 'Class-2', 'Support Vector Machine', 'Logistic Regression', "Support Vectors"])
plt.show()
           
svc_score = svc.score(dataset_x, dataset_y)
logistic_score = lr.score(dataset_x, dataset_y)

print(f'SVC score: {svc_score}')
print(f'Logistic score: {logistic_score}')

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte yine "linear" kernel kullanlarak scikit-learn içerisindeki make_blobs fonksiyonu ile üretilen veriler 
    üzerinde SVC ve LogisticRegression işlemleri yapılmıştır. Burada da yine "linear kernel" kullanılan SVC'nin lojistik 
    regresyondan çok az daha iyi performans gösterdiğine dikkat ediniz. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np

from sklearn.datasets import make_blobs

dataset_x, dataset_y = make_blobs(n_samples=100, n_features=2, centers=2, cluster_std=2, random_state=1234)

from sklearn.svm import SVC

svc = SVC(kernel='linear')
svc.fit(dataset_x, dataset_y)

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(dataset_x, dataset_y)

x = np.linspace(np.min(dataset_x[:, 0]), np.max(dataset_x[:, 0]), 1000)
y_svc = -(svc.intercept_ + svc.coef_[0, 0] * x) / svc.coef_[0, 1]
y_logistic = -(lr.intercept_ + lr.coef_[0, 0] * x) / lr.coef_[0, 1]

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.scatter(dataset_x[dataset_y == 0, 0], dataset_x[dataset_y == 0, 1], marker='o')
plt.scatter(dataset_x[dataset_y == 1, 0], dataset_x[dataset_y == 1, 1], marker='^')
plt.plot(x, y_svc)
plt.plot(x, y_logistic)
plt.legend(['Class-1', 'Class-2', 'Support Vector Machine', 'Logistic Regression', "Support Vectors"])
plt.show()
           
svc_score = svc.score(dataset_x, dataset_y)
logistic_score = lr.score(dataset_x, dataset_y)

print(f'SVC score: {svc_score}')
print(f'Logistic score: {logistic_score}')

#----------------------------------------------------------------------------------------------------------------------------
    İç içe dairesel noktalarda lojistik regresyon ve "linear kernel" ile destek vektör makineleri başarısız olmaktadır. 
    Aşağıdaki örnekte iç içe dairesel noktalar make_cirles fonksiyonuyla oluşturulmuş sonra bu noktalar üzerinde SVC "linear 
    kernel" ve LogisticRegression işlemleri uygulanmıştır. Buradaki accuracy değerleri her iki yöntemde de %50 elde edilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
from sklearn.datasets import make_circles

dataset_x, dataset_y = make_circles(n_samples=100, noise=0.01)

from sklearn.svm import SVC

svc = SVC(kernel='linear')
svc.fit(dataset_x, dataset_y)

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(dataset_x, dataset_y)

x = np.linspace(np.min(dataset_x[:, 0]), np.max(dataset_x[:, 0]), 1000)
y_svc = -(svc.intercept_ + svc.coef_[0, 0] * x) / svc.coef_[0, 1]
y_logistic = -(lr.intercept_ + lr.coef_[0, 0] * x) / lr.coef_[0, 1]

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.scatter(dataset_x[dataset_y == 0, 0], dataset_x[dataset_y == 0, 1], marker='o')
plt.scatter(dataset_x[dataset_y == 1, 0], dataset_x[dataset_y == 1, 1], marker='^')
plt.plot(x, y_svc)
plt.plot(x, y_logistic)
plt.legend(['Class-1', 'Class-2', 'Support Vector Machine', 'Logistic Regression'])
plt.show()
           
svc_score = svc.score(dataset_x, dataset_y)
logistic_score = lr.score(dataset_x, dataset_y)

print(f'SVC score: {svc_score}')
print(f'Logistic score: {logistic_score}')

#----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirttiğimiz gibi SVC'nin lojistik regresyona göre en önemli üstünlüğü kernel değiştirerek doğrusal olarak 
    ayrıştırılamayan noktaları özellik yükseltmesi ile doğrusal olarak ayrıştırılabilir hale getirmesidir. Yukarıda vermiş 
    olduğumuz örneği bu kez SVC'de "linear kernel" yerine "rbf kernel" kullanarak aşağıda yeniden veriyoruz. Burada artık 
    lojistik regresyonun performansı %50 iken, SVC'nin performası %100'e çıkmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

from sklearn.datasets import make_circles

dataset_x, dataset_y = make_circles(n_samples=100, noise=0.01)

from sklearn.svm import SVC

svc = SVC(kernel='rbf')
svc.fit(dataset_x, dataset_y)

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(dataset_x, dataset_y)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 6))
plt.scatter(dataset_x[dataset_y == 0, 0], dataset_x[dataset_y == 0, 1], marker='o')
plt.scatter(dataset_x[dataset_y == 1, 0], dataset_x[dataset_y == 1, 1], marker='^')
plt.legend(['Class-1', 'Class-2', 'Support Vector Machine', 'Logistic Regression'])
plt.show()
           
svc_score = svc.score(dataset_x, dataset_y)
logistic_score = lr.score(dataset_x, dataset_y)

print(f'SVC score: {svc_score}')
print(f'Logistic score: {logistic_score}')

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi biz destek vektör makinelerinde hangi kernel'ı kullanacağınızı nereden bileceğiz? Aslında eğer veri kümesinin 
    genel dağılımı biliniyorsa uygun kernel seçilebilir. Ancak genellikle bu dağılım da bilinmemektedir. Bu durumda noktalar 
    hakkında hiçbir bilgimiz yoksa "rbf kernel'ı (radial kernel)" seçebiliriz. Zaten SVC sınıfında "rbf" kernel default durumdur. 
    "rbf kernel" doğrusal olarak ayrıştırılabilir noktalar söz konusu olduğunda da yeterli performansı gösterebilmektedir. Tabii
    eğer noktalar doğrusal olarak ayrıştırılabilir durumdaysa "rbf kernel" yerine "linear kernel" daha iyi bir performans
    gösterebilecektir. SVC yöntemini "rbf kernel" ile kullandığımızda hemen her zaman lojistik regresyondan elde ettiğimiz 
    sonuçlardan daha iyi ya da onunla yaklaşık eşdeğer sonuç elde ederiz. Yapay Sinir ağları daha genel bir yöntemdir ve 
    pek çok durumda diğer alternatif yöntemlere göre daha iyi sonuçlar verebilmektedir. Ancak ne olursa olsun uygulanacak yöntem 
    verilerin dağılımına ve biçimine göre farklılıklar gösterebilmektedir. Veri bilimcisinin kümesine ilişkin alternatif 
    yöntemleri deneyip en iyi sonucu veren yöntemi tercih etmesi önerilmektedir.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    SVM tıpkı lojistik regresyonda olduğu gibi temelde iki sınıflı sınıflandırma problemleri için uygulanan bir yöntemdir. 
    Ancak lojistik regresyonda gördüğümüz gibi çok sınıflı sınıflandırma problemleri iki sınıflı sınıflandırma problemlerine
    indirgenerek SVM ile de çözülebilmektedir. Bunun için yine lojistik regresyonda gördüğümüz "OvR (One versus Rest)" ve 
    "OvO (One versus One)" yöntemleri kullanılmaktadır. Bu ayarlama SVC sınıfının __init__ metodundaki decision_function_shape
    parametresi ile ayarlanmaktadır. Bu parametrenin default değeri "ovr (one versus rest)" biçimindedir. 

    Aşağıdaki örnekte make_blobs fonksiyonu ile iki özelliğe sahip üç sınıflı rastgele noktalar üretilip bu noktalar üzerinde
    "rbf kernel" ile SVC ve lojistik regresyon yöntemleri uygulanmıştır. Elde edilen sonuçlar şöyledir:

    SVC score: 0.78
    Logistic score: 0.75
#----------------------------------------------------------------------------------------------------------------------------

from sklearn.datasets import make_blobs

dataset_x, dataset_y = make_blobs(n_samples=100, n_features=2, centers=3, cluster_std=5, random_state=12345)

from sklearn.svm import SVC

svc = SVC(kernel='rbf')
svc.fit(dataset_x, dataset_y)

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression()
lr.fit(dataset_x, dataset_y)

import matplotlib.pyplot as plt

plt.figure(figsize=(12, 10))
plt.scatter(dataset_x[dataset_y == 0, 0], dataset_x[dataset_y == 0, 1], marker='o')
plt.scatter(dataset_x[dataset_y == 1, 0], dataset_x[dataset_y == 1, 1], marker='^')
plt.scatter(dataset_x[dataset_y == 2, 0], dataset_x[dataset_y == 2, 1], marker='v')
plt.legend(['Class-1', 'Class-2', 'Class-3'])
plt.show()
           
svc_score = svc.score(dataset_x, dataset_y)
logistic_score = lr.score(dataset_x, dataset_y)

print(f'SVC score: {svc_score}')
print(f'Logistic score: {logistic_score}')

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte MNIST veri kümesi üzerinde lojistik regresyon, yapay sinir ağları ve destek vektör makineleri yöntemleri
    uygulanmıştır. Burada en iyi sonuç yapay sinir ağlarıyla elde edilmiştir. Destek vektör makinelerinin "rbf kernel" ile 
    kullanımı lojistik regresyona göre daha iyi performans göstermiştir. Aşağıda yaptığımız deneme için accuracy skorlarını 
    görüyorsunuz:

    LogisticRegression accuracy: 0.9195 
    Neural Net accuracy: 0.9798
    SVC accuracy: 0.9792  
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df_training = pd.read_csv('mnist_train.csv')
df_test = pd.read_csv('mnist_test.csv')

training_dataset_x = df_training.iloc[:, 1:].to_numpy()
training_dataset_y = df_training.iloc[:, 0].to_numpy()

test_dataset_x = df_test.iloc[:, 1:].to_numpy()
test_dataset_y = df_test.iloc[:, 0].to_numpy()

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(max_iter=1000)
lr.fit(training_dataset_x, training_dataset_y)
predict_result = lr.predict(test_dataset_x)

from sklearn.metrics import accuracy_score

score = accuracy_score(test_dataset_y, predict_result)
print(f'LogisticRegresson accuracy score: {score}')

from tensorflow.keras.utils import to_categorical

ohe_training_dataset_y = to_categorical(training_dataset_y)
ohe_test_dataset_y = to_categorical(test_dataset_y)

training_dataset_x = training_dataset_x / 255
test_dataset_x = test_dataset_x / 255

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Input, Dense

model = Sequential(name='MNIST') 
model.add(Input((training_dataset_x.shape[1],)))
model.add(Dense(256, activation='relu', name='Hidden-1'))
model.add(Dense(128, activation='relu', name='Hidden-2'))
model.add(Dense(10, activation='softmax', name='Output'))
model.summary()

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])
hist = model.fit(training_dataset_x, ohe_training_dataset_y, epochs=20, batch_size=32)

import numpy as np

softmax_predict_result = model.predict(test_dataset_x)
predict_result = np.argmax(softmax_predict_result, axis=1)

score = accuracy_score(test_dataset_y, predict_result)
print(f'Simple Neural Net accuracy score: {score}')

from sklearn.svm import SVC

svc = SVC(kernel='rbf')
svc.fit(training_dataset_x, training_dataset_y)

predict_result = svc.predict(test_dataset_x)
score = accuracy_score(test_dataset_y, predict_result)
print(f'SVC accuracy score: {score}')

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "breast cancer Winconsin" (meme kanseri)" veri kümesi üzerinde çeşitli yöntemler denenip  bunlar 
    karşılaştırılmıştır. Denenen yöntemler şunlardır:

    - "rbf kernel" ile SVC 
    - Lojistik Regresyon
    - Naive Bayes
    - Sinir Ağı Modeli

    Elde edilen sonuçlar şöyledir:

    SVC accuracy score: 0.956140350877193
    LogisticRegression accuracy score: 0.9649122807017544
    GaussianNB accuracy score: 0.9210526315789473
    NeuralNet accuracy score: 0.9649122807017544

    Burada lojistik regresyon ve sinir ağı modeli aynı sonucu vermiştir ve bu sonuç diğerlerinden daha iyidir. Sonuçları 
    şöyle özetleyebiliriz:

    Lojistik Regresyon = Sinir Ağı  > SVC ("rbf" kernel) > Naive Bayes
    
    Pekiyi neden lojistik regresyon modeli SVC modelinden daha iyi sonuç vermiştir? Bunun nedeni noktaların doğrusal olarak 
    ayrıştırılabilir olmasından kaynaklanmaktadır. Yukarıda da belirttiğimiz gibi böyle bir bilgi eşliğinde SVC'yi "linear 
    kernel" ile kullanmak daha iyi bir sonucun elde edilmesine yol açacaktır. SVC "linear kernel" ile kullanıldığında
    şu sonuçlar elde edilmiştir:
    
    SVC accuracy score: 0.9649122807017544
    LogisticRegression accuracy score: 0.9649122807017544
    GaussianNB accuracy score: 0.9210526315789473
    NeuralNet accuracy score: 0.9736842105263158

    Buradaki sonucu şöyle özetleyebiliriz:

    Sinir Ağı  > Lojistik Regresyon  = SVC ("linear" kernel) > Naive Bayes

    Tabii sinir modelinde her defasında aynı sonuçlar elde edilmemektedir. Çünkü başlangıçtaki ağırlık değerlerinin ve sınama 
    verilerinin belirlenmesinde rassallık vardır. Bu nedenle programı her çalıştırdığınızda sinir ağı modelinin performansı 
    değişebilecektir. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv("data.csv")

dataset_x = df.iloc[:, 2:-1].to_numpy()
dataset_y = np.zeros(len(df))
dataset_y[df['diagnosis'] == 'M'] = 1

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
    train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=12345)

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(training_dataset_x)
scaled_training_dataset_x = ss.transform(training_dataset_x)
scaled_test_dataset_x = ss.transform(test_dataset_x)

# SVC Solution

from sklearn.svm import SVC

svc = SVC(kernel='linear')
svc.fit(scaled_training_dataset_x, training_dataset_y)

# LogisticRegression Solution

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(max_iter=1000000)
lr.fit(scaled_training_dataset_x, training_dataset_y)

# Naive Bayes Solution

from sklearn.naive_bayes import GaussianNB

gnb = GaussianNB()
gnb.fit(training_dataset_x, training_dataset_y)

# Neural Net Solution

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Input, Dense

model = Sequential(name='BreastCancer')
model.add(Input((training_dataset_x.shape[1],)))
model.add(Dense(64, activation='relu', name='Hidden-1'))
model.add(Dense(64, activation='relu', name='Hidden-2'))
model.add(Dense(1, activation='sigmoid', name='Output'))
model.summary()

model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['binary_accuracy'])
hist = model.fit(scaled_training_dataset_x, training_dataset_y, batch_size=32, epochs=200, verbose=0)

from sklearn.metrics import accuracy_score

predict_result_svc = svc.predict(scaled_test_dataset_x)
score_svc = accuracy_score(test_dataset_y, predict_result_svc)

predict_result_lr = lr.predict(scaled_test_dataset_x)
score_lr = accuracy_score(test_dataset_y, predict_result_lr)

predict_result_gnb = gnb.predict(test_dataset_x)
score_gnb = accuracy_score(test_dataset_y, predict_result_gnb)

predict_result_nn = (model.predict(scaled_test_dataset_x) > 0.5).astype(int)
score_nn = accuracy_score(test_dataset_y, predict_result_nn)

print(f'SVC accuracy score: {score_svc}')
print(f'LogisticRegression accuracy score: {score_lr}')
print(f'GaussianNB accuracy score: {score_gnb}')
print(f'NeuralNet accuracy score: {score_nn}')

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "zambak (iris)" veri kümesine "rbf kernel" ile SVC, lojistik regresyon, Naive Bayes ve sinir ağı modelleri 
    uygulanmıştır. Aşağıdaki gibi bir sonuç elde edilmiştir:

    SVC accuracy score: 0.9666666666666667
    LogisticRegression accuracy score: 0.9666666666666667
    GaussianNB accuracy score: 0.9333333333333333
    NeuralNet accuracy score: 0.9666666666666667

    Tabii programın her çalıştırılmasında yapay sinir ağı modeli ile elde edilen sonuçlar değişiklik gösterebilecektir. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv("iris.csv")

dataset_x = df.iloc[:, 1:-1].to_numpy()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
dataset_y = le.fit_transform(df.iloc[:, -1])

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
    train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=12345)

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(training_dataset_x)
scaled_training_dataset_x = ss.transform(training_dataset_x)
scaled_test_dataset_x = ss.transform(test_dataset_x)

from sklearn.svm import SVC

svc = SVC(kernel='rbf')
svc.fit(scaled_training_dataset_x, training_dataset_y)

# LogisticRegression Solution

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(max_iter=1000000)
lr.fit(scaled_training_dataset_x, training_dataset_y)

# Naive Bayes Solution

from sklearn.naive_bayes import GaussianNB

gnb = GaussianNB()
gnb.fit(training_dataset_x, training_dataset_y)

# Neural Net Solution

from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)
ohe_training_dataset_y = ohe.fit_transform(training_dataset_y.reshape(-1, 1))
ohe_test_dataset_y = ohe.fit_transform(test_dataset_y.reshape(-1, 1))

from tensorflow.keras import Sequential
from tensorflow.keras.layers import Input, Dense

model = Sequential(name='Iris')
model.add(Input((training_dataset_x.shape[1],)))
model.add(Dense(64, activation='relu',  name='Hidden-1'))
model.add(Dense(64, activation='relu', name='Hidden-2'))
model.add(Dense(3, activation='softmax', name='Output'))

model.summary()

model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])
hist = model.fit(scaled_training_dataset_x, ohe_training_dataset_y, batch_size=32, epochs=200, verbose=0)

from sklearn.metrics import accuracy_score

predict_result_svc = svc.predict(scaled_test_dataset_x)
score_svc = accuracy_score(test_dataset_y, predict_result_svc)

predict_result_lr = lr.predict(scaled_test_dataset_x)
score_lr = accuracy_score(test_dataset_y, predict_result_lr)

predict_result_gnb = gnb.predict(test_dataset_x)
score_gnb = accuracy_score(test_dataset_y, predict_result_gnb)

predict_result_softmax = model.predict(scaled_test_dataset_x)
predict_result_nn = np.argmax(predict_result_softmax, axis=1)
score_nn = accuracy_score(test_dataset_y, predict_result_nn)

print(f'SVC accuracy score: {score_svc}')
print(f'LogisticRegression accuracy score: {score_lr}')
print(f'GaussianNB accuracy score: {score_gnb}')
print(f'NeuralNet accuracy score: {score_nn}')

#----------------------------------------------------------------------------------------------------------------------------
    Destek vektör makineleri yanızca sınıflandırma problemlerinde değil regresyon problemlerinde de kullanılabilmektedir. 
    Buna "destek vektör makineleri regresyonu (support vector machine regression)" denilmektedir. Destek vektör nakineleri 
    regresyonu (kısaca "SVR" de denilmektedir) destek vektör makineleri ile doğrusal regresyonun birleşimi gibidir. Model 
    noktaların dikme uzaklıklarının (residüellerin değil) minimize edilmesi esasına dayanmaktadır. SVR modelin hatalarını 
    belirli bir marjin içinde tutmayı hedeflemektedir. Yani model yalnızca belirli bir tolerans seviyesindeki hatalarla kabul 
    edilen veri noktalarıyla çalışır. Diğer veri noktaları için, modelin hataları belirli bir sınırdan fazla oluyorsa hata 
    cezası uygulanmaktadır.
    
    scikit-learn içerisindeki sklearn.svm modülünde bulunan SVR sınıfı regresyon problemleri için destek vektör makinelerinin 
    kullanılması amacıyla bulundurulmuştur. SVR sınıfının __init__ metodunun parametrik yapısı şöyledir:

    class sklearn.svm.SVR(*, kernel='rbf', degree=3, gamma='scale', coef0=0.0, tol=0.001, C=1.0, epsilon=0.1, 
        shrinking=True, cache_size=200, verbose=False, max_iter=-1)

    Buradaki kernel parametresinin yine default durumdu "rbf" biçimindedir. Ancak "linear", "poly", "sigmoid" kernel'lar da 
    kullanılabilmektedir. Sınıfın genel kullanımı diğer scikit-learn sınıflarıyla benzer biçimdedir. SVR işleminden de yine 
    bir heyperplane elde edilmektedir. Nesnenin coef_ özniteliği değişkenlerin katsayı vektörünü, intercept_ özniteliği ise 
    eksen kesim noktasını vermektedir. Tabii yine bu öznitelikler yalnızca "linear kernel" kullanıldığında oluşmaktadır. Destek 
    vektör makineleri regresyon problemlerine uygulanırken yine özellik ölçeklemesi yapılmalıdır. 

    Aşağıda "Boston Housing Prices" veri kümesi üzerinde "rbf kernel" ile SVR kullanılarak bir regresyon oluşturulmuştur. 
    Bu sonuçlar LinearRegression ve polinomsal Lasso regresyonu sonuçlarıyla karşılaştırılmıştır. Şu değerler elde edilmiştir:

    SVR Mean Absolute Error: 3.7860139251590907
    LinearRegression Mean Absolute Error: 3.5789291858673096
    Lasso Polynomial Mean Absolute Error: 3.5663928985595703

    Aynı programda SVR için "linear" kernel kullanıldığında ise şu sonuçlar elde edilmiştir:

    SVR Mean Absolute Error: 3.312319479985529
    LinearRegression Mean Absolute Error: 3.5789294242858887
    Lasso Polynomial Mean Absolute Error: 3.5663931369781494

    Bu veri kümesi için "linear" kernel kullanımının daha iyi sonuç verdiği görülmektedir.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=1234)

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(training_dataset_x)

scaled_training_dataset_x = ss.transform(training_dataset_x)
scaled_test_dataset_x = ss.transform(test_dataset_x)

from sklearn.svm import SVR

svr = SVR(kernel='linear')
svr.fit(scaled_training_dataset_x, training_dataset_y)
predict_result = svr.predict(scaled_test_dataset_x)

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(predict_result, test_dataset_y)
print(f'SVR Mean Absolute Error: {mae}')

from sklearn.linear_model import LinearRegression

lr = LinearRegression()
lr.fit(training_dataset_x, training_dataset_y)
predict_result = lr.predict(test_dataset_x)

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(predict_result, test_dataset_y)
print(f'LinearRegression Mean Absolute Error: {mae}')

from sklearn.preprocessing import PolynomialFeatures

pf = PolynomialFeatures(degree=2)
transformed_training_dataset_x = pf.fit_transform(training_dataset_x)

from sklearn.linear_model import Lasso

lasso = Lasso(alpha=0.005, max_iter=100000)
lasso.fit(scaled_training_dataset_x , training_dataset_y)
predict_result = lasso.predict(scaled_test_dataset_x)

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(predict_result, test_dataset_y)
print(f'Lasso Polynomial Mean Absolute Error: {mae}')

#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Makine öğrenmesindeki bazı yöntemler sonunda bir optimizasyon problemine evrilmektedir. Çözüm de bir fonksiyonun minimum 
    değerinin elde edilmesiyle sağlanmaktadır. Örneğin yapay sinir ağlarında biz her batch işleminde loss fonksiyonu diye 
    isimlendirdiğimiz bir fonksiyonu minimize etmek için w derlerini ayarlıyorduk. Benzer biçimde istatistiksel lojistik 
    regresyon, Lasso ve Ridge regresyonları bir minimizasyon problemine evrilmektedir. Biz de bu bölümde matematiksel optimizasyon
    üzerinde duracağız. Böylece pek çok makine öğrenmesi yönteminde sonuca nasıl varıldığı daha iyi anlaşılacaktır. 

    Optimizasyon bağlamında minimizasyon ve maksimizasyon süreci aynı biçimde uygulanmaktadır. Ancak makine öğrenmesinde problemler
    daha çok minimizasyon biçimine dönüştürülüp çözülmektedir.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Bir f(x) fonksiyonun değerini minimum yapan x değerleri nasıl elde edilmektedir? Bazı fonksiyonlarda minimizasyon işleminin
    bir kapalı çözümü (yani sembolik çözümü) söz konusu olsa da çoğu kez pratik bir kapalı çözüm oluşturulamamaktadır. Bu nedenle
    minimizasyon problemleri iteratif biçimde nümerik analiz yöntemleriyle gerçekleştirilmektedir. Her ne kadar lise ve üniversite 
    matenatiğinde daha çok tek değişkenli fonksiyonlar üzerinde duruluyorsa da makine öğrenmesinde değişkenler özellikleri (yani 
    sütunları) belirttiği için çok değişkenli fonksiyonlar söz konusu olmaktadır. Dolayısıyla y = f(x) gösteriminde x tek bir 
    değerden (tek değişkenli fonksiyon) oluşabileceği gibi f((x1, x2, x2, ..., xn)) biçiminde birden fazla değerden de  
    oluşabilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Fonksiyonları minimum yapan x değerlerinin elde edilmesi için çeşitli yöntem grupları kullanılabilmektedir. Bazı yöntem 
    gruplarında fonksiyonun türevinden faydalanılır bunlara "tüeev kullanan yöntemler" diyebiliriz. Tabii bu yöntemleri 
    uygulayabilmek için fonksiyonun türevlendirilebilir olması gerekir. İşte "türev kullanmayan" diğer bir yöntem grubu da vardır. 
    Diğer bir yöntem grubuna da "stokastik (ya da probabilistic) yöntemler" de denilmektedir. Örneğin genetik algoritmalar 
    bu sınıfa sokulabilir. Bazı yöntemlerde minimum bulunurken bazı kısıtlara da uyulmaya çalışılır. Yöneylem araştırmasındaki
    optimizasyon problemleri bu biçimdedir. Örneğin lagrange çarpımları, doğrusal programlama, kuadratik programlama gibi 
    yöntemleri bu gruba dahil edebiliriz. Makine öğrenmesinde genellikle "türev kullanan yöntemler" tercih edilmektedir. 
    Türev kullanan iki önemli yöntem "Newton-Raphson" ve "Gradient Descent" denilen yöntemlerdir. Newton-Raphson yöntemi daha
    hızlı bir yakınsama sağlıyor olsa da denetimli öğrenme için "Greadient Descent" yöntem çoğu kez daha uygun olmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                            112. Ders - 23/03/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Newton-Raphson özünde bir "nümerik kök bulma" yöntemidir. Bir fonksiyonun minimum değeri f'(x) değerini 0 yapan x değerleri
    olduğu için f'(x) = 0 fonksiyonun kökleri Newton-Raphson yöntemiyle bulunursa aslında fonksiyonu minimum yapan x değerleri
    de bulunmuş olur. 

    Newton-Raphson kök bulma yönteminin çalışma mekanizması oldukça basittir. Belli bir x0 değerinden işlemlere başlanır. 
    Bu x0 değeri için fonksiyonun türevi yani f'(x0) değeri fonksiyonun x0 noktasındaki teğetinin eğimine eşittir. Bir doğrunun 
    eğiminin onun yatayla yaptığı açının tanjantına eşit olduğunu biliyoruz. O halde f'(x0) değeri aslında teğet doğrusunun 
    tanyantına eşittir. Tanjantın dik üçgenlerde "karşı dik kenar / komşu dik kenar" oranı olduğunu anımsayınız. Burada karşı 
    dik kenar f(x) komşu dik kenar ise x0 - x1 olduğuna göre aşağıdaki eşitlik elde edilecektir: 
    eşitlik elde edilir:

    f'(x0) = f(x0) / (x0 - x1)

    Biz aslında burada x1 değerini elde etmek istiyoruz, x1 yalnız bırakılırsak aşağıdaki eşitliği elde ederiz:

    x1 = x0 - f(x0) / f'(x0)

    Böylece x0 verildiğinde artık köke daha yakın yeni bir x1 değeri elde edilmiş olur. Sonra x0 = x1 yapılıp aynı işlemler 
    bir döngü içerisinde yinelenir. Pekiyi bu döngü ne zaman sonlandırılacaktır? İşte bunun için birbirinin yerini tutabilen 
    çeşitli ölçütler kullanılabilmektedir. Örneğin:

    1) |xo - x1| < epsilon oluştuğunda döngü sonlandırılabilir.
    2) f(xo) < epsilon oluştuğunda döngü sonlandırılabilir.
    3) f'(x0) < epsilon olduğunda döngü sonlandırılabilir.
    4) Belli bir iterasyon sonra döngü sonlandırılabilir. 

    Burada epsilon değeri ne kadar küçültülürse köke o kadar yaklaşılır. Ancak epsilon küçültüldükçe köke yaklaşma süresi de 
    göreli biçimde uzayacaktır. Yaygın kullanılan epsilon değerleri 10^-6, 10^-8, 10^-10 gibi değerlerdir. Tabii bugün kullandığımız 
    kayan noktalı float formatında yuvarlama hattaları da söz konusu olabilecektir. Yuvarlama hatalarından dolayı iterasyonlar 
    devam ettirildiğinde tam 0 değeri de elde edilemeyebilir. 

    Newton-Raphson yöntemi ile kök bulan bir fonksiyonu basit bir biçimde aşağıdaki gibi yazabiliriz:

    def newton_raphson(f, df, x0, epsilon=1e-10):
        while True:
            x1 = x0 - f(x0) / df(x0)
            if abs(x0 - x1) < epsilon:
                break
            x0 = x1 
        return x1

    Tabii fonksiyonun birden fazla kökü varsa burada başlangıçtaki x0 değerinin seçimine göre köklerin hepsi değil köklerden 
    herhangi biri bulunacaktır. Ancak yukarıda yazdığımız fonksiyonda önemli bir kusur vardır. Eğer fonksiyonun kökü yoksa sonsuz
    döngü oluşur. Bu nedenle belli bir iterasyona kadar kök bulunamazsa kökün olmadığı sonucu çıkartılarak döngü sonlandırılmalıdır. 
    Fonksiyonu şöyle düzeltebiliriz:

    def newton_raphson(f, df, x0, epsilon=1e-10):
        for _ in range(MAX_ITER):
            x1 = x0 - f(x0) / df(x0)
            if abs(x0 - x1) < epsilon:
                return x1
            x0 = x1  
        return None
#----------------------------------------------------------------------------------------------------------------------------

MAX_ITER = 1000

def newton_raphson(f, df, x0, epsilon=1e-10):
    for _ in range(MAX_ITER):
        x1 = x0 - f(x0) / df(x0)
        if abs(x0 - x1) < epsilon:
            return x1
        x0 = x1  
    return None

def f(x):
    return x ** 2 - x - 6;


def df(x):
    return 2 * x - 1;

result = newton_raphson(f, df, 10)
print(result)

#----------------------------------------------------------------------------------------------------------------------------
    Newton-Raphson yöntemi başlangıç noktasına göre tek bir kök bulmaktadır. Eğer birden fazla kök bulunmak isteniyorsa başlangıç 
    noktalarının değiştirilmesi gerekir. Burada çeşitli yaklaşımlar söz konusu olabilir. Örneğin programcı belli x0 noktalarını 
    oluşturup bunlar için kök bulmaya çalışabilir ya da bir kökü bulduktan sonra o noktadan biraz kayarak ilerleyebilir. Ancak 
    her durumda Newton-Raphson aslında tek bir kök bulmaktadır. Biz birden fazla kök bulacak biçimde bir sarma fonksiyonu aşağıdaki 
    gibi yazabiliriz:

    def find_all_roots(f, df, low, high, epsilon=1e-10):
        roots = []
        xs = np.linspace(low, high, 10000)
        for x0 in xs: 
            if root := newton_raphson(f, df, x0):
                flag = True
                for val in roots:
                    if abs(val - root) < epsilon:
                        flag = False
                        break
                if flag:
                    roots.append(root)
        return roots

    Burada low ve high arasında 10000 tane noktayı başlangıç noktası kabul ederek aynı denklemin kökleri bulunmaktadır. Tabii
    bu köklerin çoğu aynı olacaktır. Bu nedenle biz fonksiyon içerisinde kökleri roots isimli listede toplarken onun daha 
    önce listede olup olmadığına baktık:

    for x0 in xs: 
        if root := newton_raphson(f, df, x0):
            flag = True
            for val in roots:
                if abs(val - root) < epsilon:
                    flag = False
                    break
            if flag:
                roots.append(root)
    
    Noktalı sayılar üzerinde yuvarlama hataları oluşabileceğine dikkat ediniz. Bu nedenle biz burada bulunan köklerin gerçekten
    farklı olup olmadığı kontrolünü farkların mutlak değerini epsilon ile karşılaştrarak tespit etmeye çalıştık.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np

MAX_ITER = 1000

def newton_raphson(f, df, x0, epsilon=1e-10):
    for _ in range(MAX_ITER):
        x1 = x0 - f(x0) / df(x0)
        if abs(x0 - x1) < epsilon:
            return x1
        x0 = x1  
    return None

def find_all_roots(f, df, low, high, epsilon=1e-10):
    roots = []
    xs = np.linspace(low, high, 10000)
    for x0 in xs: 
        if root := newton_raphson(f, df, x0):
            flag = True
            for val in roots:
                if abs(val - root) < epsilon:
                    flag = False
                    break
            if flag:
                roots.append(root)
    return roots

def f(x):
    return x ** 2 - x - 6;

def df(x):
    return 2 * x - 1;

roots = find_all_roots(f, df, -100, 100)
print(roots)

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte  x^8 - 5x^7 + 4x^2 - 8x + 2 biçiminde 8'inci dereceden bir polinomun kökleri bulunmuştur. Matematikte 
    5'inci dereceden sonra (5'inci derece de dahil olmak üzere) artık polinom kökleri için bir kapalı çözüm oluşturulamadığını 
    anımsayınız. (Buna ilişkin teoreme Abel-Ruffini teoremi denilmektedir.)
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np

MAX_ITER = 1000

def newton_raphson(f, df, x0, epsilon=1e-10):
    for _ in range(MAX_ITER)
        x1 = x0 - f(x0) / df(x0)
        if abs(x0 - x1) < epsilon:
            return x1
        x0 = x1  
    return None

def find_all_roots(f, df, low, high, epsilon=1e-10):
    roots = []
    xs = np.linspace(low, high, 10000)
    for x0 in xs: 
        if root := newton_raphson(f, df, x0):
            flag = True
            for val in roots:
                if abs(val - root) < epsilon:
                    flag = False
                    break
            if flag:
                roots.append(root)
    return roots

def f(x):
    return x ** 8 - 5 * x ** 7 + 4 * x ** 2 - 8 * x + 2

def df(x):
    return 8 * x ** 7 - 35 * x ** 6 + 8 * x - 8

roots = find_all_roots(f, df, -1000, 1000)
print(roots)

#----------------------------------------------------------------------------------------------------------------------------
    Newton-Raphson gibi türev kullanan yöntemlerde fonksiyonun türevini de oluşturmamız gerekir. Kapalı türev almak ise her 
    zaman mümkün değildir. Mümkün olsa da çok zor olabilmektedir. Pekiyi bu durumda ne yapabiliriz? İşte bir fonksiyonun belli 
    bir noktasındaki türevi için de nümerik yöntemler uygulanabilmektedir.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Newton-Raphson yöntemiyle fonksiyonun minimum noktası f'(x) = 0 denklemiyle bulunabilir. Bu durumda iterasyonlar şöyle 
    yapılacaktır:

    x1 = x0 - f'(x0) / f''(x0)

    Minimum noktaları bulan fonksiyon da şöyle oluşturulabilir:

    import numpy as np

    MAX_ITER = 1000

    def newton_raphson(df, d2f, x0, epsilon=1e-10):
        for _ in range(MAX_ITER):
            x1 = x0 - df(x0) / d2f(x0)
            if abs(x0 - x1) < epsilon:
                return x1
            x0 = x1  
            
        return None

    def newton_raphson_minimize(df, d2f, low, high, epsilon=1e-10):
        minimums = []
        xs = np.linspace(low, high, 10000)
        for x0 in xs: 
            if minimum := newton_raphson(df, d2f, x0):
                flag = True
                for val in minimums:
                    if abs(val - minimum) < epsilon:
                        flag = False
                        break
                if flag:
                    minimums.append(minimum)

        return minimums 

    Nasıl bir fonksiyonun birden fazla kökü varsa birinci türevin sıfır olduğu birden fazla noktası da olabilir. Matematikte
    bu noktalara "yerel minimum (local minima)" denilmektedir. Yukarıdaki fonksiyon tüm yerel minimumları bulmaktadır. Bunların
    arasındaki en küçük değer ise global minimumdur. Bu nedenle yukarıdaki fonksiyonu ulacak global minimumu bşöyle düzeltebiliriz:

    def newton_raphson_minimize(df, d2f, low, high, epsilon=1e-10):
        global_minimum = None
        xs = np.linspace(low, high, 10000)
        for x0 in xs: 
            if minimum := newton_raphson(df, d2f, x0):
                if global_minimum is None:
                    global_minimum = minimum
                    continue
            if abs(minimum - global_minimum) < epsilon:
                global_minimum = minimum
                
        return global_minimum

    Burada biz değişik x değerlerinden hareketle minimumlar bulmaya çalıştık. Bunlar arasında en küçük olanını elde ettik.
    Global minimum bulmak için daha gelişkin yöntemler de kullanılabilmektedir. Ancak biz kurusumuzda bunun üzerinde durmayacağız.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
MAX_ITER = 1000

def newton_raphson(df, d2f, x0, epsilon=1e-10):
    for _ in range(MAX_ITER):
        x1 = x0 - df(x0) / d2f(x0)
        if abs(x0 - x1) < epsilon:
            return x1
        x0 = x1  
    return None

def newton_raphson_minimize(df, d2f, low, high, epsilon=1e-10):
    global_minimum = None
    xs = np.linspace(low, high, 10000)
    for x0 in xs: 
        if minimum := newton_raphson(df, d2f, x0):
            if global_minimum is None:
                global_minimum = minimum
                continue
        if abs(minimum - global_minimum) < epsilon:
            global_minimum = minimum
            
    return global_minimum

def f(x):
    return 3 * x ** 2 - 3 * x + 6

def df(x):
    return 6 * x - 3

def d2f(x):
    return 6

minimum = newton_raphson_minimize(df, d2f, -1000, 1000)
print(minimum)

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi Newton-Raphson yönteminde birden fazla değişken varsa çözüm nasıl yapılmaktadır? Makine öğrenmesinde ve veri biliminde
    değişken sayısı sütun sayısı anlamına geldiği için çok değişkenli fonksiyonlar söz konusu olmaktadır. İşte çok değişkenli 
    fonksiyonların minimum noktalarının tespit edilmesi için parçalı türevler kullanılmaktadır. Çok değişkenli bir fonksiyonun 
    her değişken için türevi ayrı ayrı alınabilir. Bir değişken için türev alınırken diğer değişkenler sanki sabitmiş gibi 
    işleme sokulmaktadır. Örneğin:

    f(x1, x2) = 3x1^2 + 2x1x2 - 6x2^2 + 3x1 - 2x2 + 8

    Bu fonksiyonun x1 ve x2 için parçalı türevleri şöyle alınmaktadır:

    ∂f/∂x1 = 6x1 + 2x2 + 3
    ∂f/∂x2 = -12x2 + 2x1 - 2

    Buradan gördüğünüz gibi her değişken için bir parçalı türev elde edilmektedir. İşte matematikte parçalı türevlerden oluşan 
    bu vektöre "radyan vektör (gradient vector)" denilmektedir. Gradyan vektör ters üçgenle (nabla) temsil edilir ve genel olarak 
    bir sütun vektörü biçiminde ifade edilmektedir. Örneğin yukarıdaki fonksiyona ilişkin gradyen vektör şöyle gösterilebilir:

    ∇f = [
        6x1 + 2x2 + 3
        -12x2 + 2x1 - 2
    ]

    Bir fonksiyonun ikinci türevlerden oluşan matrise de matematike "Hessian Matrisi (Hessian Matrix)" denilmektedir. Hessian
    matrisi H sembolüyle temsil edilmektedir. Hesian matrisin genel biçimi şöyledir:

    H(f) = [
        [∂²f/∂x₁², ∂²f/∂x₁∂x₂, ..., ∂²f/∂x₁∂xₙ],
        [∂²f/∂x₂∂x₁, ∂²f/∂x₂², ..., ∂²f/∂x₂∂xₙ],
        [⋮, ⋮, ⋱, ⋮],
        [∂²f/∂xₙ∂x₁, ∂²f/∂xₙ∂x₂, ..., ∂²f/∂xₙ²]
    ]

    Buradaki ∂²f/∂x₁∂x₂ gibi bir ikinci türev "önce x1'e göre parçalı türev al sonra da onun yeniden x2'ye göre parçalı türevini 
    al" anlamına gelmektedir. Tabii ∂²f/∂x₁² türevi de aslında ∂²f/∂x₁∂x₁ türevi ile eşdeğerdir. Hessian matrisinin köşegenlerinin
    bu biçimde olduğuna dikkat ediniz. 

    Biz daha önce Newton-Raphson yönteminde minimum noktayı aşağıdaki iterasyon ifadesiyle bulmuştuk:

    x_next = x_prev - f'(x_prev) / f''(x_prev)

    Eğer çok değişkenli bir fonksiyon söz konusuysa tabii xprev ve xnext değişken sayısı kadar bir vektör biçiminde olacaktır. 
    İşte çok değişkenli fonksiyonlarda Newton-Raphson yöntemini uygularken birinci türev yerine gradyen vektör ikinci türev 
    yerine de Hessian matrisi kullanılmaktadır:

    x_next = x_prev - transpose(H^-1(x_prev) @ ∇f(x_prev))

    Tabii her iterasyonda x değerleri güncellendiğinde aslında elimizde değişken sayısı kadar x değeri olur. Pekiyi çok 
    değişkenli fonksiyonlarda durdurma koşulu nasıl oluşturulabilir? Aslında durdurma için yukarıda belirttiğimiz yöntemlerin 
    hepsi kullanılabilir. Örneğin |x_prev - x_next|< epsilon kuşuluna bakılabilir. Burada |x_prev - x_next| vektörün karşılıklı 
    elemanlarının çıkartılmasıyla elde edilen vektörün uzaklığını (tipik olarak Öklit uzaklığını) temsil etmektedir. Biz bu iki 
    vektörün çıkarımını x vektörü ile temsil edersek (yani x = |x_prev - x_next| dersek) bu uzaklık √(x₁² + x₂² + ... + xₙ²) 
    biçiminde hesaplanmaktadır. Yukarıdaki iterasyon ifadesinde eğer ∇f bir sütun vektörü olduğuna göre  H^-1(x_prev) @ ∇f(x_prev)
    matris çarpımından bir sütun vektörü elde edilir. x_prev bir satır vektörü olduüu için siz bu H^-1(x_prev) @ ∇f(x_prev) 
    sütun vektörünün transpozesini almalısınız.

    Çok değişkenli fonksiyonların Newton-Raphson yöntemi ile minimum değerleri bulunurken yine rastgele bir noktadan başlanabilir. 
    Ancak bu rastgele noktanın tek bir değer içermeyeceğine değişken sayısı kadar değere sahip olan bir satır vektörü olacağına
    dikkat ediniz.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                            113. Ders - 06/04/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Bu noktada kısaca bir fonksiyonun belli bir noktasındaki türevinin nümerik analiz yöntemleriyle nasıl elde edileceği 
    üzerinde de durmak istiyoruz. Nümerik türev işlemleri genellikle iteratif biçimde yapılmamaktadır. Türevin tanımını 
    anımsayınız:

    lim   (f(x + h) - f(x) ) / h
    h-> 0

    Türev bir fonksiyonun belli bir noktadaki anlık değişimini belirtmektedir. Yukarıdaki ifadede h çok bir değer olarak alınırsa
    fonksiyonun x noktasındaki türevi elde edilebilir. Tabii burada h'nın aşırı küçük alınmaması gerekir. Çünkü bilgisayarlarımızda 
    kullandığımız float türünün (C'nin, Java ve C#'ın double türünün) noktadan sonra belli bir duyarlılığı vardır. Bu duyarlılık 
    yaklaşık 10^-16 civarındadır. Örneğin biz h değerini 10^-10 alabiliriz. Bu biçimde nümerik türev elde etmeye "ileri fark 
    yöntemi (forward difference method)" denilmektedir. Bu yöntemde türev işlemi aşağıdaki gibi bir fonksiyonla yapılabilir:

    def derivative(f, x, h=1e-10):
        return (f(x + h) - f(x)) / h

    def f(x):
        return 3 * x ** 2 - 5 * x + 2

    result = derivative(f, 2)
    print(result)               # 7.000000579182597

    Buradaki türevi alınacak fonksiyon 3x^2 - 5x + 2 fonksiyonudur. Biz bu fonksiyonun x = 2 noktasındaki türevini elde 
    etmeye çalışık. Bu fonksiyonun x = 2 noktasındaki türevi 7'dir. Ancak biz burada tam 7 değerini elde edemedik. Çünkü 
    yukarıda da belirttiğimiz gibi h değeri 0'a çok yakın değil 10^-10 olarak alınmıştır. Tabii bu tür durumlarda Python'un
    standart kütüphanesindeki Decimal sınıfını da kullanabiliriz. Bu sınıf işlemleri yapay bir biçimde fakat yüksek duyarlılıkta 
    ve yuvarlama hatasına maruz kalmadan yapabilmektedir. Örneğin:

    import decimal

    def derivative(f, x, h=decimal.Decimal('0.'+'0' * 25 + '1')):
        return (f(x + h) - f(x)) / h

    def f(x):
        return 3 * x ** 2 - 5 * x + 2

    decimal.getcontext().prec = 28
    d = decimal.Decimal('2')
    result = derivative(f, d)
    print(result)                   # 7
    
    Ancak Decimal sınıfı ile işlemlerin göreli biçimde yavaş olduğunu belirtmek istiyoruz. Yoğun hesap gerektiren durumlarda 
    bu sınıfı kullanmayınız.

    Tabii fonkiyonun belli bir noktasında türevi tam ters bir biçimde x noktasından h kadar geriye gidilerek de elde edilebilir:

    lim    (f(x) - f(x - h) ) / h
    h-> 0

    Bu yönteme de "geri fark yöntemi (backward difference method)" denilmektedir. Genellikle bu iki yöntemin karma hali tercih 
    edilmektedir. Buna da "merkezi fark yöntemi (central difference method)" denilmeketdir:

    lim    (f(x + h) - f(x - h) ) /  (2 * h)
    h-> 0

    Bu yöntem Python'da şöyle uygulanabilir:

    def derivative(f, x, h=1e-10):
        return (f(x + h) - f(x - h)) / (2 * h)

    def f(x):
        return 3 * x ** 2 - 5 * x + 2

    result = derivative(f, 2)
    print(result)               # 7.000000579182597

    Nümerik türev için başka yöntemler de kullanılabilmektedir. Ancak en yaygın kullanılan yöntem "merkezi fark" yöntemidir. 

    SciPy kütüphanesinde merkezi fark yöntemi ile nümerik türev elde etmek için scipy.misc modülündeki derivative fonksiyonu
    bulundurulmuştur. Örneğin:

    from scipy.misc import derivative

    result = derivative(f, 2)
    print(result)

    Ancak SciPy'ın son versiyonlarında misc modülü "deprecated" yapılmış ve bu fonksiyon scipy.differentiate isimli bir modül 
    oluşturularak oraya taşınmıştır. Kullandığınız SciPy versiyonuna ve bu fonksiyonun nerede bulunduğuna dikkat ediniz. 
#----------------------------------------------------------------------------------------------------------------------------

def derivative(f, x, h=1e-10):
    return (f(x + h) - f(x - h)) / (2 * h)

def f(x):
    return 3 * x ** 2 - 5 * x + 2

result = derivative(f, 2)
print(result)               # 7.000000579182597

import decimal

def derivative(f, x, h=decimal.Decimal('0.'+'0' * 25 + '1')):
    return (f(x + h) - f(x)) / h

def f(x):
    return 3 * x ** 2 - 5 * x + 2

decimal.getcontext().prec = 28

d = decimal.Decimal('2')
result = derivative(f, d)
print(result)

from scipy.misc import derivative

result = derivative(f, 2)
print(result)

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi nümerik biçimde parçalı türev nasıl elde edilmektedir? Aslında işlemler benzer bir biçimde yürütülmektedir. 
    Örneğin fonkisyonumuz şöyle olsun:

    f(x1, x2, x3) = 3x1^2 + 2x1^2 x3^2 2x1 x2 x3 + 2x2 - x3 + 8

    Burada bu fonksiyonun x1 = a, x2 = b, x3 = c için x3'e göre parçalı türevini elde etmek isteyelim. Yapılacak şey aynıdır:

    ∂f/∂x3 = lim     (f(x1, x2, x3 + h) - f(x1, x2, x3)) / h
            h -> 0

    Görüldüğü gibi burada biz yalnızca parçalı türevini elde edeceğimiz değişkene küçük bir artım verdik.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Biz yukarıda Newton-Raphson yöntemini açıkladık. Aslında makine öğrenmesinde Newton-Raphson yerine daha çok "gradient descent" 
    denilen yöntem tercih edilmektedir. Newton Rapson yöntemindeki ikinci türevler yakınsamayı hızlandırmakla birlikte denetimli 
    yöntemlerde karmaşıklığa yol açmaktadır. Gradient descent yöntem bir kök bulma yöntemi değildir, minimum bulma yöntemidir. 
    Gradient descent yöntemde ikinci türevler kullanılmadığı için yakınsama Newton-Raphson yöntemine göre daha geç gerçekleşmektedir. 
    Ancak ikinci türevlerin ortadan kaldırılması yöntemin uygulanabilirliğini oldukça artırmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Gradient descent de türev kullanan bir yöntemdir. Ancak bu yöntemde fonksiyonun ikinci türevi değil birinci türevi kullanılır.
    Fonksiyonun birinci türevi bize bir doğrultu verir. Biz de o doğrultuda yavaş yavaş ilerleyerek hedefe ulaşırız. Gradient 
    descent yöntem Newton-Raphson yöntemine göre hedefe daha geç ulaşmaktadır ancak makine öğrenmesi uygulamaları için daha 
    elverişli bir yöntemdir. Bu yöntemle yakınsama aşağıdaki iterasyon ifadesi ile yapılır:

    x_new = x_old - α * ∇f(x_old)

    Burada f fonksiyonu çok değişkenli bir fonksiyon olduğu için f'in türevi parçalı bir biçimde gradient vektör olarak elde 
    edilmelidir. Tabii eğer f fonksiyonu tek değişkenli ise bu iterasyonu şöyle de temsil edebiliriz:

    x_new = x_old - α * f'(x_old)

    Burada alpha değerine "öğrenme hızı (learning rate)" denilmektedir. Bu öğrenme hızı uygulamacı tarafından belirlenir. 
    Yukarıda da belirttiğimiz gibi fonksiyonun birinci türevi bize bir doğrultu verir. Biz de o doğrultuda adım adım ilerleriz. 
    Ancak adım büyüklüğünü istediğimşz gibi ayarlayabiliriz. Buradaki öğrenme hızı bu adım büyüklüğünü ayarlamkta kullanılmaktadır.
    Gradient descent yöntemi şuna benzetebiliriz. Biz bir dağın tepesinde olalım ve hızlı bir biçimde aşağıya yani ovaya inmek 
    isteyelim. Bunu nasıl yapabiliriz? Tabii ki en yüksek irtifa kaybettiren yolu, yani daha dik yolu seçeriz. İşte bu benzetmede 
    birinci türev aslında bize en yüksek irtifayı kaybettirecek doğrultuyu vermektedir. Tabi biz o doğrultuda büyük adımlarla 
    ya da küçük adımlarla ilerleyebiliriz. Daha önceden de belirttiğimiz gibi büyük adımlarla ilerlerken hedefi biraz kaçırabiliriz. 
    Ancak büyük adımlar hedefe daha kolay yaklaşmamızı sağlar. İşte yukarıdaki iterasyon ifadesindeki alpha değeri bu adımı 
    ayarlamakta kullanılmaktadır. 

    Burada alpha parametresi kullanıldıktan sonra türev ifadesinin değerinin önemsizleştiğini sanabilirsiniz. Gerçekten de biz 
    türevden yalnızca bir doğrultu elde edip bir büyüklük elde etmesek de algoritma yine çalışacaktır. Ancak yukarıdaki dağ
    örneğinde belirttiğimiz gibi aslında bu türev ifadesi bizim adımlarımızı da ayarlamaktadır. Eğer türev değeri yüksekse 
    biz daha büyük adımlarla, düşükse daha düşük adımlarla ilerleriz. Buradaki alfa değeri aslında bir hyper parametredir. 
    Yani duruma bizim müdahale etmeemizi sağlayan bir üst parametredir. 

    Gradient descent yöntemde alpha ile temsil ettiğimiz "öğrenme hızı (learning rate)" sabit bir değer olarak (örneğin 10^-5 
    gibi) alınabilir. Ancak bu değer ne kadar küçültülürse hedefe varmak için gereken iterasyon sayısı artacaktır. Bu nedenle 
    öğrenme hızını sabit almayıp onu dinamik bir biçimde de değiştirebiliriz. Örneğin önce büyük adımlarla hedefin yanına yaklaşıp 
    orada adımlarımızı küçültebiliriz. Genellikle bu tür yöntemler tercih edilmektedir. 

    Pekiyi bu yöntemde iterasyonlar ne zaman sonlandırılmaktadır? Aslıda sonlandırmalar daha önce görmüş olduğumuz Newton-Raphson 
    yöntemindeki gibi yapılabilir. Bazı sonlandırma stratejileri şöyle olabilir:

    1) |x_new - x_old| < epsilon oluştuğunda iterasyonlar sonlandırılabilir.
    1) |f(x_new) - f(x_old)| < epsilon oluştuğunda iterasyonlar sonlandırılabilir.
    3) |∇f(x_new)| < epsilon olduğunda iterasyonlar sonlandırılabilir.
    4) Belli bir iterasyon aypıldıktan sonra iterasyonlar sonlandırılabilir. 

    Gradient descent yöntemle tek değişkenli bir fonksiyonun minimum noktasını bulan bir fonksiyon aşağıdaki gibi yazılabilir:

    def gradient_descent(f, f_d, x,  *, niter=None, alpha=1e-5, maxiter=10_000_000):
        if niter != None and niter > maxiter:
            raise ValueError(f'niter must be less than max_iter. Your max_iter is = {maxiter}')
        x_old = x
        count = 0
        for _ in range(maxiter):
            x_new = x_old - alpha * f_d(x_old)       
            if niter != None:
                if count >= niter:
                    return x_new, f(x_new)
                count += 1
            else:
                if abs(f(x_new) - f(x_old)) < 1e-15:
                    return x_new, f(x_new)
            x_old = x_new
            
        return None

    Burada f parametresi minimize edilecek fonksiyonu f_d parametresi ise bu fonksiyonun türev fonksiyonunu belirtmektedir. 
    Bitiş koşulu iki biçimde ayarlanabilmektedir. Eğer niter parametresi için bir argüman girilmemişse bitiş koşulu için iki 
    değer arasındaki fark kullanılmaktadır. Eğer niter parametresi için argüman girilmişse bitiş koşulu iterasyon miktarıyla
    belirlenmektedir. Fonksiyonun ikili bir demete geri döndüğüne dikkat ediniz. Fonksiyonun maxiter parametresi minimuma sahip 
    olmayan fonksiyonlarda iterasyonları durdurmak için bulundurulmuştur. Örnek bir kullanım şöyle olabilir:

    def f(x):
        return 3 * x ** 2 - 6 * x + 2

    def f_d(x):
        return 6 * x - 6;
    
    t = gradient_descent(f, f_d, 10, niter=1000000)
    if t != None:
        x, minval = t
        print(x, minval)
    else:
        print('no minimum')
#----------------------------------------------------------------------------------------------------------------------------

def f(x):
    return 3 * x ** 2 - 6 * x + 2

def f_d(x):
    return 6 * x - 6

def gradient_descent(f, f_d, x,  *, niter=None, alpha=1e-5, maxiter=10_000_000):
    if niter != None and niter > maxiter:
        raise ValueError(f'niter must be less than max_iter. Your max_iter is = {maxiter}')
    x_old = x
    count = 0
    for _ in range(maxiter):
        x_new = x_old - alpha * f_d(x_old)       
        if niter != None:
            if count >= niter:
                return x_new, f(x_new)
            count += 1
            
        else:
            if abs(f(x_new) - f(x_old)) < 1e-15:
                return x_new, f(x_new)
        x_old = x_new
         
    return None

t = gradient_descent(f, f_d, 10, niter=1000000)
if t != None:
    x, minval = t
    print(x, minval)
else:
    print('no minimum')

#----------------------------------------------------------------------------------------------------------------------------
    Gradient descent yöntemde de başlangıç noktasına bağlı olarak biz yerel minimumlara yakalanabiliriz. Global minimum değerin
    elde edilmesi için yine Newton-Raphson yönteminde sözünü ettiğimiz yöntemler kullanılabilmektedir. Anımsayacağınız gibi en 
    basit yöntem buradaki başlangıç x değerini değiştirip global minimumu yakalamaya çallışmaktır. Aşağıda örnekte yöntem 
    uygulanmıştır. Ancak aslında global minimumu daha az denemede belirlemek için daha gelişmiş yöntemler de kullanılabilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np

def f(x):
    return 3 * x ** 2 - 6 * x + 2

def f_d(x):
    return 6 * x - 6

def gradient_descent(f, f_d, x,  *, niter=None, alpha=1e-5, maxiter=10_000_000):
    if niter != None and niter > maxiter:
        raise ValueError(f'niter must be less than max_iter. Your max_iter is = {maxiter}')
    x_old = x
    count = 0
    for _ in range(maxiter):
        x_new = x_old - alpha * f_d(x_old)       
        if niter != None:
            if count >= niter:
                return x_new, f(x_new)
            count += 1      
        else:
            if abs(f(x_new) - f(x_old)) < 1e-15:
                return x_new, f(x_new)
        x_old = x_new
         
    return None

def gradient_descent_minimize(df, d2f, low, high, epsilon=1e-1, **kwargs):
    global_minimum = None
    xs = np.linspace(low, high, 100)
    for x0 in xs: 
        t = gradient_descent(df, d2f, x0, **kwargs)
        if t:
            x, minimum = t
            if global_minimum is None:
                global_minimum = minimum
                continue
        if abs(minimum - global_minimum) < epsilon:
            global_minimum = minimum
            
    return x, global_minimum

x, minval = gradient_descent_minimize(f, f_d, -10000, 1000, niter=1000000)
print(x, minval)

#----------------------------------------------------------------------------------------------------------------------------
    Tabii biz aslında yukarıdaki fonksiyonlara yalnızca asıl fonksiyonu parametre olarak geçirebiliriz, türev işlemini de 
    nümerik yöntemle gerçekleştirebiliriz. Aşağıda böyle bir örnek veriyoruz. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np

def derivative(f, x, h=1e-10):
    return (f(x + h) - f(x - h)) / (2 * h)

def f(x):
    return 3 * x ** 2 - 6 * x + 2

def gradient_descent(f, x,  *, niter=None, alpha=1e-5, maxiter=10_000_000):
    if niter != None and niter > maxiter:
        raise ValueError(f'niter must be less than max_iter. Your max_iter is = {maxiter}')
    x_old = x
    count = 0
    for _ in range(maxiter):
        x_new = x_old - alpha * derivative(f, x_old)       
        if niter != None:
            if count >= niter:
                return x_new, f(x_new)
            count += 1      
        else:
            if abs(f(x_new) - f(x_old)) < 1e-15:
                return x_new, f(x_new)
        x_old = x_new
         
    return None

def gradient_descent_minimize(df, low, high, epsilon=1e-1, **kwargs):
    global_minimum = None
    xs = np.linspace(low, high, 10)
    for x0 in xs: 
        t = gradient_descent(df, x0, **kwargs)
        if t:
            x, minimum = t
            if global_minimum is None:
                global_minimum = minimum
                continue
        if abs(minimum - global_minimum) < epsilon:
            global_minimum = minimum
            
    return x, global_minimum

x, minval = gradient_descent_minimize(f, -10, 100, niter=1000000)
print(x, minval)

#----------------------------------------------------------------------------------------------------------------------------
    Daha önce de belirttiğimiz gibi çok değişkenli fonksiyonlarda gradient descent yönteminde parçalı türevler kullanılmaktadır. 
    Parçalı türevlerden oluşan vektöre de gradyan vektör dendiğini anımsayınız. Örneğin bu gradient descent yöntemiyle iki 
    değişkenli bir fonksiyonun minimum noktasını bulmaya çalışalım. Fonksiyonumuz şöyle olsun:

    f(x1, x2) = 3x1^2 + 2x2^2 - 3x1x2 + 2x1 + x2 + 7

    Bu fonksiyonun x1 ve x2 için parçalı türevlerini elde edelim:

    ∂f/∂x1 = 6x1 -  3x2 + 2
    ∂f/∂x2 = 4x2 -  3x1 + 1

    Böylece gradyan vektör şöyle oluşturulur:

    ∇f = [
            6x1 -  3x2 + 2
            4x2 -  3x1 + 1
         ]

    Gradient descent iterasyon ifadesi şöyleydi:

    x_new = x_old - α * ∇f(x_old)

    Burada artık x_old ve x_new bir sütun vektörü olacaktır. Tabii biz bunları tek boyutlu dizi olarak oluşturup karşılıklı 
    elemanla üzerinde de işlem yapabiliriz. Tabii artık burada başlangıç noktası tek bir x değeri değil x1 ve x2 değerlerinden 
    oluşan bir vektör olacaktır. İzleyen paragraflarda buna ilişkin örnekler vereceğiz.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                        114. Ders - 12/04/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Amaç fonksiyonlarının (loss fonksiyonlarının) parçalı türevlerinin alınması konusunun iyi anlaşılması için bileşke 
    fonksiyonların türevlerinin nasıl alındığının bilinmesi gerekmektedir. Bir fonksiyonun çıktısının başka bir fonksiyona
    girdi yapılması durumuna matematikte "bileşke fonsiyon (composite function)" denilmektedir. Örneğin biz g(x) fonksiyonundan
    elde edilen değeri f(x) fonksiyonuna sakup bir değer elde etmek isteyelim. Bu durum programlamada f(g(x)) biçiminde bir 
    çağırma ile yapılmaktadır. Matematikte ise bu işlem (fog)(x) ile gösterilmektedir. (fog)(x) tamamen f(g(x)) ile aynı 
    anlamdadır. Tabii bileşke fonksiyonlar da birbirini izleyebilir. Örneğin biz h(x) fonksiyonun çıktısını g(x) fonksiyonuna 
    girdi yapabiliriz, g(x) fonksiyonunun çıktısını da f(x) fonksiyonuna girdi yapabiliriz. Bu durum matematikte (fogoh)(x)
    biçiminde gösterilmektedir. Bu ifade de f(g(h(x))) ile eşdeğerdir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Bir fonksiyon matematikte iki biçimde gösterilmektedir:

    1) Fonksiyonel biçimde (functional form) yani f(x) = ... biçiminde.
    2) Denklemsel biçimde (equation form) yani y = ... biçiminde.

    Eğer fonksiyon fonksiyonel biçimde belirtiyorsa bunun türevi de f'(x) = ... biçiminde gösterilmektedir. Bu gösterime 
    "Lagrange Notasyonu" da denilmektedir Eğer fonksiyon denklemsel biçimde belirtilmişse bunun türevi de dy/dx = ... biçiminde 
    gösterilmektedir. Buna da "Leibniz Notayonu" denilmektedir. Ayrıca d/dx (x^2 - 1) biçimindeki ifadeler de "x^2 - 1'in 
    türevinib al" anlamına gelmektedir. Çok değişkenli fonksiyonlarda parçalı türevler söz konusu olduğu için türev ifadesi 
    de genel olarak ∂f/∂x ile gösterilmektedir. Burada ∂x parçalı türevi alınacak değişkeni belirtmektedir.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Bileşke fonksiyonun türevi şöyle oluşturulmaktadır:

    (fog)'(x) = f'(g(x)) * g'(x)

    Bileşke fonksiyonun bu türev ifadesine "türevde zincir kuralı (chain rule)" da denilmektedir. Bu ifade şöyle de yazılabilir:

    (fog)'(x) = df/dg * dg/dx

    Örneğin biz y = (x - 2)^2 fonksiyonunun türevini almak isteylim. Bu türevi almanın bir yolu karesel ifadeyi açıp 
    elde edilen ifadenin türevini almaktadır. Karesel ifadeyi açalım:

    y = x^2 - 4x + 4

    Şimdi türev alalım:

    dy/dx = 2x - 4

    Şimdi y = (x - 2)^2 fonksiyonunu bileşke fonksiyon olarak ele alıp zincir kuralıyla türev alalım. x - 2 fonksiyonuna
    denkelmsel biçimde u diyelim:

    u = x - 2
    y = u^2

    Şimdi zincir kuaralını uygulayalı.ç

    dy/dx = dy/du * du/dx = 2u * 1

    Şimdi u yerine x - 2 ifadesini yerleştirelim:

    dy/dx = 2 * (x - 2) = 2x - 4
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de doğrusal regresyonu gradient descent yöntemle çözmeye çalışalım. Tabii aslında doğrusal regresyonun gradient 
    descent yöntemle çözülmesine gerek yoktur. Zaten doğrusal regresyonun kapalı çözümü vardır. Bu kapalı çözüme "en küçük 
    kareler (ordinary least squares)" yöntemi dendiğini anımsayınız. Ancak biz burada gradient descent yöntemin doğrusal regresyon 
    üzerinde bir uygulamasını yapmak istiyoruz. Bunun için önce en küçüklemeye çalıştığımız loss fonksiyonun (amaç fonksiyonu) 
    her değişken için türevlerini alarak gradyan vektörü elde ederiz. Sonra da adım adım hedefe varmaya çalışırız. Doğrusal 
    regresyonda amaç fonksiyonu "doğru denkleminden elde edilen değerle (yi_hat) gerçek değerlerin (yi) farklarının karelerinin 
    toplamının ortalaması biçiminde" ifade edilebilir. 

    L = Σ(yi_hat - yi)² / N

    Şimdi burada biz L'nin b0 ve b1 için parçalı türevlerini elde edeceğiz. Buradaki y_hat teriminin aslında b0 + b1x1 + b2x2 + 
    ... + bnxn anlamına geldiğine dikkat ediniz. Önce bu karesel açımı yapalım:

    L = Σ(yi_hat^2 - 2yi_hatyi + yi^2) / N
    
    Burada türevde zincir kuralını uygulayarak b0'a göre parçalı türevi elde edelim:

    ∂L/∂b0 = (Σ(2yi_hat - 2yi) / N) * 1
    ∂L/∂b0 = (2 / N) * Σ(yi_hat - yi) 

    Şimdi yine zincir kuralı ile bj'lere göre parçalı türevi elde edelim:

    ∂L/∂bj = Σ[(2yi_hat - 2yi) / N * xi]
    ∂L/∂bj = (2 / N) * Σ[(yi_hat - yi) * xi]

    Şimdi her iki parçalı türev ifadesini yeniden alt alta yazalım:

    ∂L/∂b0 = (2 / N) Σ(yi_hat - yi) 
    ∂L/∂bj = (2 / N) Σ[(yi_hat - yi) * xj]

    Minimizasyon problemlerinde aslında sabit çarpanların temelde önemi yoktur. Yani örneğin x^2 değerini minimize etmekle 3x^2 
    değerini minimize etmek arasında ya da (1/3)X^2 minimize etmek arasında bizim için bir fark yoktur. (Burada yanlış anlamayın 
    bu fonksiyonların minimum değerleri farklıdır ancak minimize etmek için yapılacak türev işlemleri arasında bir farklılık 
    yoktur.) Bu nedenle kolaylık sağlamak amacıyla bu tür çarpanları tamamen atabiliriz:

    ∂L/∂b0 = Σ(yi_hat - yi) 
    ∂L/∂bj = Σ[(yi_hat - yi) * xj]

    Bu tür minimizasyon işlemlerinde sabit çarpanları muhafaza etmenin bazen minimizasyona bir stabilite kazandırmakta faydası 
    olabilmektedir. Ancak bu stabilite gradyan işleminde alpha katsayısı ile de ayarlanabilmektedir.

    Biz yukarıda belli bir bj değerini bulduk. Tüm bj değerlerini matrisel biçimde de ifade edebliriz:

    ∂L/∂b = X.T @ (y_hat - y)

    Buradan da gradient için iterasyon ifadesi şöyle oluşturulabilir:

    b0_new = b0_old - alpha * Σ(yi_hat - yi)
    b_new = b_old = alpha * X.T @ (y_hat - y)

    Burada y_hat x değerlerinin b0 + b1x1 + b2x2 + b3x3 + ... + bnxn doğru denkleminde yerine konularak elde edilen değeri 
    belirtmektedir. 

    Tabii aslında yukarıdaki iki türev ifadesini tek bir ifade haline de getirebiliriz. İki türev ifadesine bir daha dikkat 
    ediniz:

    ∂L/∂b0 = Σ(yi_hat - yi) 
    ∂L/∂b = X.T @ (y_hat - y)

    Eğer biz X'e 1'lerle dolu bir sütun eklersek bu sütun zaten b0'ı temsil eder hale gelir:

    ∂L/∂b = X.T @ (y_hat - y)

    Bu durumda iterasyon ifadesi de şöyle olur:

    b_new = b_old = alpha * X.T @ (y_hat - y)

    Şimdi de yukarıdaki genel formülü basit doğrusal regresyona uygun hale getirelim. Basit doğrusal regresyon için elde edilecek 
    doğru denkleminin b0 + b1x olduğunu anımsayınız.

    ∂L/∂b0 = Σ(yi_hat - yi) 
    ∂L/∂b1 = Σ[(yi_hat - yi) * xi]

    Aşağıda basit doğrusal regresyon için bu işlemlerin nasıl yapıldığı gösterilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv('points.csv')
dataset_x = df['x']
dataset_y = df['y']

def loss(y_hat, y):
    return np.sum((y_hat - y) **2)

def linear_regression_gradient(x, y, *, niter = None, epsilon=1e-10, learning_rate):
    b0 = 0
    b1 = 0
    
    prevloss = 0
    count = 0

    while True:
        y_hat = b0 + b1 * x     
        df_b0 = np.sum(y_hat - y)
        df_b1 = np.sum((y_hat - y) * x)
        
        b0 = b0 - df_b0 * learning_rate
        b1 = b1 - df_b1 * learning_rate
        
        if niter != None:
           if count >= niter:
              break
           count += 1      
        
        nextloss = loss(b0 + b1 * x, y)
        if np.abs(prevloss - nextloss) < epsilon:
            break
        prevloss = nextloss
        
    return b0, b1

b0, b1 = linear_regression_gradient(dataset_x, dataset_y,  niter=100, learning_rate=0.001)

x = np.linspace(1, 15, 100)
y = b0 + b1 * x

import matplotlib.pyplot as plt

plt.title('Linear Regression with Gradient Descent')
plt.xlabel('x')
plt.ylabel('y')
plt.scatter(dataset_x, dataset_y, color='blue')
plt.plot(x, y, color='red')
plt.show()

print(f'Slope = {b1}, Intercept={b0}')

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de lojistik regresyon problemini gradient descent yöntemle çözelim. Anımsanacağı gibi lojistik regresyon için 
    "maximum liklihood" denilen amaç fonksiyonu kullanılıyordu. Ancak "maximum likelihood" maksimizasyon amacıyla oluşturulmuş 
    bir fonksiyon olduğundan biz minimizasyon için bunun negatiflisini kullanıyorduk. Buna da "binary cross-entropy" fonksiyonu 
    diyorduk. 
    
    Lojistik regresyondan nihai amaç aslında aşağıdaki gibi bir z doğru denklemini gradient descent yöntemiyle elde etmektir:

    z = b0 + b1x1 + b2x2 + b3x3 + .... + bnxn 

    Binary-crossentropy loss fonksiyonunu aşağıdaki gibi lojistik regresyona uygun hale getirebiliriz:

    L = -1/N * ∑[(1 - yi) * log(1 - σ(z(xi))) + yi * log(σ(z(xi)))]

    Burada z(xi) ifadesi xi satır değerlerinin doğru denklemine sokulmasıyla elde edilen değeri, σ(z(xi)) ifadesi ise xi satır
    değerlerinin doğru denklemine sokulmasıyla elde edilen değerin sigmoid fonksiyonuna sokulmasıyla elde edilen değeri belirtiyor.
    
    Bizim buradaki L fonksiyonunun b0 ve bj'ler için (burada bj b0 dışındaki b katsayılarını temsil ediyor) parçalı türevlerini 
    elde etmemiz gerekiyor. Bunu türevde zincir kuralını (chain rule) uygulayarak başarabiliriz. Bileşke fonksiyonlarımızı şöyle 
    ifade edelim:
  
    z(x) = b0 + b1x1 + b2x2 + b3x3 + .... + bnxn 
    σ(z) = 1 / (1 + e^-z)
    L(σ) = (1 - y) * log(1 - σ) + y * log(σ)

    Burada y satırların gerçek değerlerini temsil ediyor. L fonksiyonundan toplam ifadesini ve -1/N çarpanını çıkardığımıza 
    dikkat ediniz. Bunları en sonunda yerleştireceğiz. Şimdi ∂L/∂b0 türevi için zincir kuralını uygulayalım:
    
    ∂L/∂b0 = ∂L/∂σ * ∂σ/∂z * ∂z/∂b0

    Burada z'nin doğru denklemini ve σ'nın ise sigmoid fonksiyonunu belirttiğine dikkat ediniz. Önce ∂z/∂b0 parçalı türevini 
    bulalım:

    z = b0 + b1x1 + ... + bnxn 
    ∂z/∂b0 = 1'dir.
    
    ∂σ/∂z parçalı türevi şöyledir: 

    ∂σ/∂z = σ * (1 - σ)

    ∂L/∂σ parçalı türevi de şöyledir:

    ∂L/∂σ =  (-y / σ) + (1 - y) / (1 - σ)
  
    Elde ettiklerimizi zincir kuralında yerine koyarsak hedefimize ulaşırız: 

    ∂L/∂b0 =  (-y / σ) + (1 - y) / (1 - σ) * σ * (1 - σ) * 1
    = σ - y

    Burada y "gerçek değerleri", σ ise "xi'lerin önce doğru denklemine sonra da sigmoid fonksiyonuna sokulmasıyla elde edilen 
    değerleri" belirtiyor. Bu sonucu şöyle de ifade edebiliriz:

    ∂L/∂b0 = 1 / (1 + e^-(b0 + b1x1 + b2x2 + b3x3 + .... + bnxn)) - y
    
    Toplama işlemini ve çarpan değerini de dahil ettiğimizde ∂L/∂b0 parçalı türevi şu hale gelecektir:

    ∂L/∂b0 = -1/N * ∑(σ(z(i)) - yi)

    Bunu matrisel biçimde şöyle ifade edebiliriz:

    ∂L/∂b0 = -1/N * (σ(z(X)) - Y)

    Burada σ(z(X) ifadesi X matrisinin satırlarının önce doğru denklemine sonra da sigmoid fonksiyonuna sokulmasıyla elde edilen 
    değerleri belirtmektedir.

    Diğer bj katsayıları için parçalı türevler de benzer biçimde zincir kuralı uygulanarak elde edilebilir:

    ∂L/∂bj = ∂L/∂σ * ∂σ/∂z * ∂z/∂bj
       
    ∂z/∂b1 = x1
    ∂z/∂b2 = x2
    ...
    ∂z/∂bj = xj

    ∂L/∂σ * ∂σ/∂z çarpımı σ - y biçiminde elde edilmişti. Hepsini yerine koyarak şu sonucu elde ederiz:

    ∂L/∂bj = (σ - y) * x

    Buradaki x j'inci b değeri için j'inci sütun değerlerini temsil ediyor. Toplama işlemini de dahil edersek parçalı türev şöyle 
    son haline gelecektir:

    ∂L/∂bj = -1/N * ∑[(σ(z(xi)) - yi) * xij]

    Biz bu sonucu şöyle de ifade edebiliriz:

    ∂L/∂bj = -1/N * ∑[(1 + e^-(b0 + b1x1 + b2x2 + b3x3 + .... + bnxn)) * xij]

    Burada xij i'inci satırın j'inci sütununu temsil ediyor. Yani veri kümesindeki sütunlar (özellikler) ((σ(z(xi)) - yi) ile 
    çarpılıp toplanmaktadır. Veri kümesinde n tane satır k tane sütun olduğunu varsayalım. Buradaki toplam ifadesi i'ler üzerinde 
    yürütülmektedir. Yani buradaki toplam i = 1'den n'e kadar gitmektedir. Bu ifadeyi matrisel biçimde şöyle de yazabiliriz:

    ∂L/∂bj = -1/N * X.T @ (σ(z(X)) - Y)

    Burada X.T X matrisinin tranpoz matrisidir. σ(z(X)) ise satırların önce doğru denklemine sonra da sigmoid fonksiyonuna 
    sokulmasıyla elde edilen değeri belirtmektedir.

    ∂L/∂b0 ve ∂L/∂bj ifadelerine dikkat ediniz:

    ∂L/∂b0 = -1/N * (σ(z(X)) - Y)
    ∂L/∂bj = -1/N * X.T @ (σ(z(X)) - Y)

    Aslında yine X matrisine 1'lerden oluşan bir sütun ekleyerek bu iki ifadeyi tek bir matris ifadesi olarak da birleştirebiliriz.
    Bu durumda gradiyent ifademiz tek parça haline gelecektir:

    ∂L/∂b = -1/N * X.T @ (σ(z(X)) - Y)

    Buradaki σ(z(X)) satırın önce doğru denklemine sonra da sigmoid fonksiyonuna sokulmasıyla elde edilen değerleri, Y ise gerçek 
    değerleri belirtiyor.İfadeyi bu biçimde tek bir matris ifadesine dönüştürdüğümüzü varsayarsak gradient descent iterasyon ifadesi 
    şöyle kodlanabilir:

    h = sigmoid(dataset_x @ b)
    error = h - dataset_y
    grad = -1 / len(dataset_x) * dataset_x.T @ error
    b = b + learning_rate * grad
   
    Buradaki -1/N çarpımını gradient descent işleminde sabit terim olduğu gerekçesiyle atabiliriz:

    h = sigmoid(dataset_x @ b)
    error = h - dataset_y
    grad = dataset_x.T @ error
    b = b - learning_rate * grad

    -1/N çarpqanının atılmadığı durumda b değerinin güncellenmesinin çıkartma yerine toplama işlemi ile yapıldığına dikkat ediniz. 
    Çünkü -1/N ifadesi işareti terslemektedir.

    Aşağıda bu yöntemle lojistik regresyon probleminin çözümüne ilişkin bir örnek verilmiştir. Gradeint descent yönteminin uygulandığı 
    fonksiyon şöyledir:

    def gradient_descent_logistic(dataset_x, dataset_y, learning_rate=0.001, niter=50000):
        b = np.zeros((dataset_x.shape[1], 1))
        for k in range(niter):
            h = sigmoid(dataset_x @ b)
            error = h - dataset_y
            grad = -1 / len(dataset_x) * dataset_x.T @ error
            b = b + learning_rate * grad
        return b

    Örneğimizde kullanılan "logistic-points.csv" dosyasının içeriği şöyledir:

    x1,x2,class
    -0.017612,14.053064,0
    -1.395634,4.662541,1
    -0.752157,6.538620,0
    -1.322371,7.152853,0
    0.423363,11.054677,0
    0.406704,7.067335,1
    0.667394,12.741452,0
    -2.460150,6.866805,1
    0.569411,9.548755,0
    -0.026632,10.427743,0
    0.850433,6.920334,1
    1.347183,13.175500,0
    1.176813,3.167020,1
    -1.781871,9.097953,0
    -0.566606,5.749003,1
    0.931635,1.589505,1
    -0.024205,6.151823,1
    -1.693453,-0.557540,1
    -0.576525,11.778922,0
    -0.346811,-1.678730,1
    -2.124484,2.672471,1
    1.217916,9.597015,0
    -0.733928,9.098687,0
    -3.642001,-1.618087,1
    0.315985,3.523953,1
    1.416614,9.619232,0
    -0.386323,3.989286,1
    0.556921,8.294984,1
    1.224863,11.587360,0
    -1.347803,-2.406051,1
    1.196604,4.951851,1
    0.275221,9.543647,0
    0.470575,9.332488,0
    -1.889567,9.542662,0
    -1.527893,12.150579,0
    -1.185247,11.309318,0
    -0.445678,3.297303,1
    1.042222,6.105155,1
    -0.618787,10.320986,0
    1.152083,0.548467,1
    0.828534,2.676045,1
    -1.237728,10.549033,0
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
from sklearn.preprocessing import StandardScaler
import pandas as pd

df = pd.read_csv('logistic-points.csv')

dataset_x = df.iloc[:, :-1].to_numpy()
dataset_y = df.iloc[:, -1].to_numpy()

ss = StandardScaler()
scaled_dataset_x = ss.fit_transform(dataset_x)

scaled_dataset_x = np.append(scaled_dataset_x, np.ones((dataset_x.shape[0], 1)), axis=1)

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.title('Points for Logistic Regression')
plt.scatter(dataset_x[dataset_y == 0, 0], dataset_x[dataset_y == 0, 1], color='blue', marker='o')
plt.scatter(dataset_x[dataset_y == 1, 0], dataset_x[dataset_y == 1, 1], color='green', marker='^')
plt.xlabel('x1')
plt.ylabel('x2')
plt.legend(['class 0', 'class 1'])

plt.show()

def sigmoid(x):
    return 1.0 / (1 + np.exp(-x))

def gradient_descent_logistic(dataset_x, dataset_y, learning_rate=0.001, niter=50000):
        b = np.zeros((dataset_x.shape[1], 1))
        for k in range(niter):
            h = sigmoid(dataset_x @ b)
            error = h - dataset_y
            grad =  -1 / len(dataset_x) * dataset_x.T @ error
            b = b + learning_rate * grad
        return b

b = gradient_descent_logistic(scaled_dataset_x, dataset_y.reshape(-1, 1))

x1 = np.linspace(-5, 5, 1000)
x2 = (-b[2] - b[0] * x1) / b[1]

points = np.vstack((x1, x2)).T
transformed_points = ss.inverse_transform(points)

plt.figure(figsize=(10, 8))
plt.title('Points for Logistic Regression')
plt.scatter(dataset_x[dataset_y == 0, 0], dataset_x[dataset_y == 0, 1], color='blue', marker='o')
plt.scatter(dataset_x[dataset_y == 1, 0], dataset_x[dataset_y == 1, 1], color='green', marker='^')
plt.plot(transformed_points[:, 0], transformed_points[:, 1], color='red')
plt.xlabel('x1')
plt.ylabel('x2')
plt.legend(['class 0', 'class 1', 'regression line'])
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
                                        115. Ders - 13/04/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Biz yukarıdaki örneklerde tüm veri kümesini tek hamlede işleme soktuk. Aslında gradient descent yöntemin önemli bir avantajı 
    veri kümesini parçalara ayırarak parçalar halinde eğitime daha iyi olanak sağlamasıdır. Böylece bir döngü içerisinde eğitim 
    parça parça yapılabilmektedir. 
    
    Gradient descent yöntemde eğitimin parça parça yapılmasına yönelik birkaç teknik kullanılabilmektedir. Bu tekniklere "batch 
    gradient descent", "stochastic gradient descent" ve "mini batch gradient descent" denilmektedir. "Batch gradient descent" 
    her iterasyonda tüm veri kümesinin bir bütün olarak işleme sokulması anlamına gelmektedir. Örneğin elimizde 1000 satırlık 
    bir veri kümesi olsun. Biz her iterasyonda bu 1000 satırın hepsini işleme sokarsak "batch gradient descent" tekniğini kullanmış 
    oluruz. Yukarıda ilk yaptığımız örnek bu biçimdeydi. "Stochastic gradient descent" her defasında rastgele bir satır seçilerek 
    iterasyonunun satır satır yapılması anlamına gelmektedir. Örneğin 1000 satırlık veri kümesinde bir döngü içerisinde biz her 
    iterasyonda rastgele bir satırı seçip iterayonu yalnızca bu satırla yaparsak "stochastic gradient descent" tekniğini kullanmış 
    oluruz. "Mini-batch gradient descent" ise her defasında tüm satırları değil, tek bir satırı da değil, bir grup satırı kullanarak 
    iterasyon yapmak anlamına gelmektedir. Örneğin biz 1000 satırlık veri kümesinde her iterasyonda 100 satırı tek hamlede işleme 
    sokarsak "mini-batch gradient descent" tekniğini kullanmış oluruz. Tabii aslında "mini-batch gradient descent" yönteminde de 
    iterasyona sokulacak bir grup satır rastgele seçilebilir. Yani aslında bu yöntem de "stochastic" biçimde kullanılabilmektedir. 
    Bizim yapay sinir ağlarında aslında "mini-batch gradient descent" kullanmış olduğumuza dikkat ediniz. Gerçekten de en çok 
    tercih edilen yöntem "mini-batch gradient descent" yöntemidir. Bu yöntemde genellikle uygulamacı önce veri kümesini karıştırır 
    sonra onu batch batch işleme sokar. 

    Aşağıdak "mini-batch-gradient descent" lojistik regresyona bir örnek verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
from sklearn.preprocessing import StandardScaler
import pandas as pd

df = pd.read_csv('logistic-points.csv')

dataset_x = df.iloc[:, :-1].to_numpy()
dataset_y = df.iloc[:, -1].to_numpy()

ss = StandardScaler()
scaled_dataset_x = ss.fit_transform(dataset_x)

scaled_dataset_x = np.append(scaled_dataset_x, np.ones((dataset_x.shape[0], 1)), axis=1)

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 6))
plt.title('Points for Logistic Regression')
plt.scatter(dataset_x[dataset_y == 0, 0], dataset_x[dataset_y == 0, 1], color='blue', marker='o')
plt.scatter(dataset_x[dataset_y == 1, 0], dataset_x[dataset_y == 1, 1], color='green', marker='^')
plt.xlabel('x1')
plt.ylabel('x2')
plt.legend(['class 0', 'class 1'])

plt.show()

def sigmoid(x):
    return 1.0 / (1 + np.exp(-x))

def gradient_descent_logistic(dataset_x, dataset_y, batch_size, learning_rate=0.001, niter=50000):
        b = np.zeros((dataset_x.shape[1], 1))
        nbatches = dataset_x.shape[0] // batch_size
        
        for batch_no in range (nbatches):
            x = dataset_x[batch_no * batch_size:batch_no * batch_size + batch_size]
            y = dataset_y[batch_no * batch_size:batch_no * batch_size + batch_size]
            for k in range(niter):
                h = sigmoid(x @ b)
                error = h - y
                grad = x.T @ error
                b = b - learning_rate * grad
        return b

b = gradient_descent_logistic(scaled_dataset_x, dataset_y.reshape(-1, 1), batch_size=10)

x1 = np.linspace(-5, 5, 1000)
x2 = (-b[2] - b[0] * x1) / b[1]

points = np.vstack((x1, x2)).T
transformed_points = ss.inverse_transform(points)

plt.figure(figsize=(10, 8))
plt.title('Points for Logistic Regression')
plt.scatter(dataset_x[dataset_y == 0, 0], dataset_x[dataset_y == 0, 1], color='blue', marker='o')
plt.scatter(dataset_x[dataset_y == 1, 0], dataset_x[dataset_y == 1, 1], color='green', marker='^')
plt.plot(transformed_points[:, 0], transformed_points[:, 1], color='red')
plt.xlabel('x1')
plt.ylabel('x2')
plt.legend(['class 0', 'class 1', 'regression line'])
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de sinir ağlarında w ve bias değerlerinin gradient descent yöntemde nasıl güncellendiği üzerinde duralım. Yukarıda 
    da belirttiğimiz gibi sinir ağlarında genellikle "mini batch gradient descent" yöntem kullanılmaktadır. Yani bir batch veri 
    ağa girdi olarak verilir. Bu batch veriden bir çıktı elde edilir. Sonra bu çıktıdan hareketle gradyanlar hesaplanır ve 
    bu gradyanlar tüm nörünların w ve bias değerlerini güncellemekte kullanılır. 
    
    Sinir ağlarında bir batch bilginin ağa verilip bundan çıktı elde edilmesine "ileri yayılım (forward propagation)", geriye
    doğru gidilerek nöronların w ve bias değerlerinin güncellenmesine de "geriye doğru yayılım (back propagation)" denilmektedir. 
    İleriye doğru yayılımın nasıl yapıldığını zaten biliyoruz. Burada geri doğru yayılımın nasıl yapıldığı üzerinde duracağız.

    Geriye doğru yaylımı açıklamak için şöyle bir sinir ağını kullanabiliriz:
    
    - Sinir ağımızda x1 ve x2 biçiminde iki girdi (özellik) vardır. 
    - Sinir ağımızda iki saklı katman bir çıkış katmanı vardır. Bu katmanlarda tek bir nöron bulunmaktadır.
    - Saklı katmanlarda "RELU" aktivasyon fonksiyonu çıktı katmanında da "linear" "aktivasyon fonksiyonu kullanılmaktadır. 
    - Bir regresyon ağı olduğu için loss fonksiyonu "mean squared error" biçimindedir:

    L = (y_hat - y)^2 / N

    Ağın görünümü şöyledir: 

    x1 -------> 
                    Nöron --------> (h1) ---------> Nöron (h2) --------> Nöron -------> y_hat
    x2 ------->  

    Burada ilk katmandaki nöronda bulunan w değerlerini w11 ve w12 olarak, bias değerini de b1 olarak ifade edersek birinci 
    nöronun çıktısı şöyle olur:

    h1 = relu1(w11x1 + w12 x2 + b1)

    İkinci nöronun tek girdisi olduğuna göre bu nöronda bir tane w değeri olacaktır. Bu w değerini de w21 ile ve bu 
    nörondaki bias değerini de b2 temsil edersek ikinci nöronun çıktısı şöyle olur:

    h2 = relu2(w21h1 + b2)

    Aynı durum çıktı nöronu için de uygulanırsa çıktı değeri (y_hat) şöyle olacaktır:

    y_hat = w31h2 + b3

    Loss fonksiyonunu anımsayınız:

    L = (y_hat - y)^2 

    Bu karesel ifadeyi açalım:

    L = (y_hat^2 - 2y_haty + y^2)^2 

    Şimdi bizim amacağımız her w değerinin ve bias değerinin gradyanını bulmaktır. Bunun için parçalı türevler alınmalıdır.
    Gradient descent yöntemi anımsayınız:

    xnew = xold - grad(xold)

    Burada örneğin biz w11 için parçalı türev almak isteyelim. Yani ∂L/∂w11 parçalı türevini hesaplamak isteyelim. Bu parçalı 
    türev aslında nümerik olarak hesaplanabilir. Ancak w ve bias değerlerinin bu biçimde nümerik hesaplanması oldukça işlem 
    yükü gerektirmektedir. Nümerik hesabın işlem yükü fazla olsa da aslında mantıksal bakımdan daha kolay anlaşılmaktadır. 
    Örneğin biz w11'e göre parçalı türev alacaksak aslında ağda yalnızca w11'de çok küçük bir değişim yaratıp loss fonksiyonun 
    değerine bakabiliriz:

    ∂L/∂w11 = (L(x1, x2, w11, w12, w21, w31, b1, b2, b3) - L(x1, x2, w11 + h, w12, w21, w31, b1, b2, b3)) / h

    Tabii biz aslında NumPy'ın vektörel işlem yapma yeteneğini kullanarak tüm gradyenleri tek hamlede bulabiliriz. Aşağıda 
    "claude.ai" tarafından uygun prompt girilerek yzılmış olan programı veriyoruz. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import matplotlib.pyplot as plt

class SimpleNeuralNetwork:
    def __init__(self):
        # Parametreleri başlat (rastgele değerlerle)
        # [w1_1, w1_2, b1, w2, b2, w3, b3]
        # İlk katman: 2 giriş, 1 çıkış (w1_1, w1_2, b1)
        # İkinci katman: 1 giriş, 1 çıkış (w2, b2)
        # Çıkış katmanı: 1 giriş, 1 çıkış (w3, b3)

        self.params = np.random.randn(7) * 0.1
        self.param_names = ['w1_1', 'w1_2', 'b1', 'w2', 'b2', 'w3', 'b3']
    
    def relu(self, x):
        return np.maximum(0, x)
    
    def forward(self, x):
        z1 = self.params[0] * x[0] + self.params[1] * x[1] + self.params[2]  
        a1 = self.relu(z1)
        
        z2 = self.params[3] * a1 + self.params[4] 
        a2 = self.relu(z2)
        
        z3 = self.params[5] * a2 + self.params[6]  
        
        return z3
    
    def loss(self, x, y_true):
        y_pred = self.forward(x)
        return (y_pred - y_true) ** 2 
    
    def compute_numeric_gradients(self, x, y_true, epsilon=1e-6):
        gradients = np.zeros_like(self.params)
        original_loss = self.loss(x, y_true)
        
        for i in range(len(self.params)):
            # Parametreyi küçük bir değer kadar artır
            self.params[i] += epsilon
            new_loss = self.loss(x, y_true)
            
            gradients[i] = (new_loss - original_loss) / epsilon
            self.params[i] -= epsilon
        
        return gradients
    
    def train(self, X, y, learning_rate=0.01, epochs=1000):
        loss_history = []
        
        for epoch in range(epochs):
            epoch_loss = 0
            
            for i in range(len(X)):
                x = X[i]
                y_true = y[i]
                
                gradients = self.compute_numeric_gradients(x, y_true)     
                self.params -= learning_rate * gradients
                epoch_loss += self.loss(x, y_true)
            
            avg_loss = epoch_loss / len(X)
            loss_history.append(avg_loss)
            
            if epoch % 100 == 0:
                print(f"Epoch {epoch}, Loss: {avg_loss:.4f}")
        
        return loss_history

np.random.seed(42)
n_samples = 100
X = np.random.randn(n_samples, 2) 
y = 2 * X[:, 0] - 3 * X[:, 1] + np.random.randn(n_samples) * 0.5

nn = SimpleNeuralNetwork()
loss_history = nn.train(X, y, learning_rate=0.0001, epochs=1000)

plt.figure(figsize=(10, 6))
plt.plot(loss_history)
plt.title('Eğitim İlerlemesi')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.grid(True)

print("\nEğitilmiş Parametreler:")
for name, value in zip(nn.param_names, nn.params):
    print(f"{name}: {value:.4f}")

test_samples = 5
test_indices = np.random.choice(len(X), test_samples, replace=False)
print("\nTest Tahminleri:")
for i in test_indices:
    pred = nn.forward(X[i])
    actual = y[i]
    print(f"Girdi: {X[i]}, Tahmin: {pred:.4f}, Gerçek: {actual:.4f}")

#----------------------------------------------------------------------------------------------------------------------------
    Sinir ağındaki w ve bias değerlerinin yukarıdaki yöntemle güncellenmesi eğitimi yavaşlatmaktadır. Bu nedenle w ve bias bias 
    değerlerinin gradyenleri bileşke fonksiyonların türevlerinden faydalanılarak kapalı biçimde hesaplanıp işleme sokulmaktadır.
    Yukarıdaki küçük ağımızda girdiden itibaren loss değerinin elde edilmesine kadar geçen aşamaları yeniden aşağıda vermek 
    istiyoruz. Ancak burada dot product değerleri ile (h'lar), aktivasyon fonksiyonunun çıktı değerlerini (o'lar) birbirinden 
    ayırıyoruz:

    x1 -----> 
                Nöron ----> h1 ----> o1 ----> Nöron ----> h2 ----> o2 ----> Nöron -----> h3 -----> o3 = y_hat
    x2 ----->  

    Buradaki h'lar dot-product değerini o'lar ise aktivasyon fonksiyonunun çıktısını belirtiyor. y_hat ağın nihai çıktısını
    temsil ediyor. o3 değerinin y_hat değeri ile aynı anlama geldiğine dikkat ediniz.

    h1 = w11 * x1 + w12 x2 + b1
    o1 = relu(h1)
    h2 = w21 * o1 + b2
    o2 = relu(h2)
    h3 = w31 * o2 + b3
    o3 = y_hat = linear(h3)

    Loss fonkiyonunu şöyle ifade edebiliriz:

    L = (y_hat - y)^2 / N
    L = (y_hat^2 - 2 * y_hat * y + y^2) / N

    Önce ∂L/∂y_hat parçalı türevini elde edelim:

    ∂L/∂y_hat = (2 * y_hat - 2 * y) / N
    ∂L/∂y_hat = 2 / N * (y_hat - y)

    Burada 2 / N sabit bir değer olduğu için kolaylık sağlamak aamcıyla bunu atabiliriz:

    ∂L/∂y_hat = y_hat - y

    Şimdi geriye doğru giderek gerekli parçalı türevleri hesaplayalım. ∂L/∂w31 parçalı türevi şöyledir:

    ∂L/∂w31 = ∂L/∂y_hat * ∂y_hat/∂h3 * ∂h3/∂w31
    ∂L/∂w31 = (y_hat - y) * 1 * o2
    ∂L/∂w31 = (y_hat - y) * o2
    
    ∂y_hat/∂h3 parçalı türevi 1'dir. (y = x fonksiyonunun türevinin 1 olduğuna dikkat ediniz.)

    ∂L/∂wb3 parçalı türevi şöyledir:

    ∂L/∂b3 = ∂L/∂y_hat * ∂y_hat/∂h3 * ∂h3/∂b3
    ∂L/∂b3 = (y_hat - y) * 1 * 1
    ∂L/∂b3 = y_hat - y 

    Şimdi ∂L/∂w21 parçalı türevini bulalım:

    ∂L/∂w21 = ∂L/∂y_hat * ∂y_hat/∂h3 * ∂h3/o2 * ∂o2/h2 * ∂h2/w21
    ∂L/∂w21 = (y_hat - y) * 1 *  w31  *  (h2 > 0 ise 1, h2 < 0 ise 0) * o1
    ∂L/∂w21 = (y_hat - y) * w31  *  (h2 > 0 ise 1 h2 < 0 ise 0) * o1
    
    Burada ∂h3/o2 türevinin w31 olduğuna, ∂h2/w21 türevinin de o1 olduğuna dikkat ediniz. ∂L/∂b2 türevi de şöyledir:

    ∂L/∂b2 = ∂L/∂y_hat * ∂y_hat/∂h3 * ∂h3/o2 * ∂o2/h2 * ∂h2/∂b2
    ∂L/∂b2 = (y_hat - y) * 1 *  w31  *  (h2 > 0 ise 1, h2 < 0 ise 0) * 1
    ∂L/∂b2 = (y_hat - y) * w31  *  (h2 > 0 ise 1 h2 < 0 ise 0)

    Şimdi ∂L/∂w11 türevini bulalım:
    
    ∂L/∂w11 = ∂L/∂y_hat * ∂y_hat/∂h3 * ∂h3/o2 * ∂o2/h2 * ∂h2/∂o1 * ∂o1/∂h1 * ∂h1/∂w1
    ∂L/∂w11 = (y_hat - y) * 1 *  w31 * (h2 > 0 ise, 1 h2 < 0 ise 0) * w21 * (h1 > 0 ise 1, h1 < 0 ise 0) * x1
    ∂L/∂w11 = (y_hat - y) * w31 * (h2 > 0 ise, 1 h2 < 0 ise 0) * w21 * (h1 > 0 ise 1, h1 < 0 ise 0) * x1

    Şimdi ∂L/∂w12 türevini bulalım:

    ∂L/∂w12 = ∂L/∂y_hat * ∂y_hat/∂h3 * ∂h3/o2 * ∂o2/h2 * ∂h2/∂o1 * ∂o1/∂h1 * ∂h1/∂w12
    ∂L/∂w11 = (y_hat - y) * 1 *  w31 * (h2 > 0 ise, 1 h2 < 0 ise 0) * w21 * (h1 > 0 ise 1, h1 < 0 ise 0) * x2
    ∂L/∂w11 = (y_hat - y) * w31 * (h2 > 0 ise, 1 h2 < 0 ise 0) * w21 * (h1 > 0 ise 1, h1 < 0 ise 0) * x2

    Şimdi ∂L/∂b1 türevini bulalım:

    ∂L/∂w12 = ∂L/∂y_hat * ∂y_hat/∂h3 * ∂h3/o2 * ∂o2/h2 * ∂h2/∂o1 * ∂o1/∂h1 * ∂h1/∂b1
    ∂L/∂b1 =  (y_hat - y) * 1 *  w31 * (h2 > 0 ise 1 h2 < 0 ise 0) * w21 * (h1 > 0 ise 1 h1 < 0 ise 0) * 1
    ∂L/∂b1 =  (y_hat - y) * w31 * (h2 > 0 ise 1 h2 < 0 ise 0) * w21 * (h1 > 0 ise 1 h1 < 0 ise 0)

    Şimdi bu parçalı türevlerin hepsini sondurumuyla alt alta yazalım:

    ∂L/∂w31 = (y_hat - y) * o2
    ∂L/∂b3 = y_hat - y 
    ∂L/∂w21 = (y_hat - y) * w31  *  (h2 > 0 ise 1 h2 < 0 ise 0) * o1
    ∂L/∂b2 = (y_hat - y) * w31  *  (h2 > 0 ise 1 h2 < 0 ise 0)
    ∂L/∂w11 = (y_hat - y) *  w31 * (h2 > 0 ise 1 h2 < 0 ise 0) * w21 * (h1 > 0 ise 1 h1 < 0 ise 0) * x1
    ∂L/∂w12 = (y_hat - y) *  w31 * (h2 > 0 ise 1 h2 < 0 ise 0) * w21 * (h1 > 0 ise 1 h1 < 0 ise 0) * x2
    ∂L/∂b1 =  (y_hat - y) *   w31 * (h2 > 0 ise 1 h2 < 0 ise 0) * w21 * (h1 > 0 ise 1 h1 < 0 ise 0)

    Pekiyi burada eşitliğin sol tarafındaki gradyen değerleri nasıl hesaplanacaktır? İşte bu değerler hesapnaırken yukarıdaki 
    türev ifadelerinde ileri yayılımdaki değerler kullanılır. Örneğin ∂L/∂w31 gradyenine dikkat ediniz:

    ∂L/∂w31 = (y_hat - y) * o2

    Buradaki y_hat değeri aslında x1 ve x2 değerleri ağa uygulandığında ağın çıktısını belirtmektedir. O halde bu değer ileri 
    yayılım sırasında zaten elde edilmiş olacaktır. y değeri x1 ve x2'nin bulunduğu satırın gerçek değerini belirtmektedir. 
    Yine ileri yayılım yapıldıktan sonra zaten o2 değeri de elde edilmiş olacaktır. O halde bu ifadede aslında y_hat, y ve o2 
    değerlerinin hepsi bellidir. y_hat ve o2 ileri yayılım sırasında elde edilmektedir. Şimdi de örnek olarak ∂L/∂w11 grasyeninin 
    nasıl elde edildiğine bakalım:

    ∂L/∂w11 = (y_hat - y) *  w31 * (h2 > 0 ise 1 h2 < 0 ise 0) * w21 * (h1 > 0 ise 1 h1 < 0 ise 0) * x1

    Burada da aslında ileri yayılım sırasında gerekli bütün değerler elde edilmiş olacaktır. w31 ve w21 değerleri zaten elimizde
    vardır. x1 değeri de elimizde olduğuna göre bu gradyen hesaplanabilir.

    Bu durumda gradyenler şöyle hesaplanmaktadır: 
    
    1) Önce parçalı türevlerin kapalı ifadeleri elde edilir. Burada türevde zincir kuralı kuralı uygulanır.
    2) İleri yayılım uygulanır ve gradyenler için gereken değerler not alınır. 
    3) Elde edilen değerler parçalı türevlerdeki formüllere yerleştirielrek gradyen değerleri elde edilir. 

    Artık gradyenler elde edildiğine göre her değişken için gradient descent iterasyonu uygulanabilir. Örneğin w11 için şu 
    iterasyon uygulanacaktır:

    w11_new = w11_old - grad(w11)

    Tabii tüm bu işlemlere önce w ve bias değerlerine rastgele ilkdeğerler verilerek başlanmalıdır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Bu bölümde doğrudan yapay zeka ve makine öğrenmesinin bir konusu olmamakla birlikte optimizasyon işlemlerinde sıkça 
    karşılaşılan ve "kısıtlar altında maksimizasyon ve minimizasyon bulmayı hedefleyen" bazı yöntemlerden bahsedeceğiz. Bu yöntemler 
    kendi aralarında çeşitli alt gruplara ayrılmaktadır. Eğer kısıtlar ve amaç fonksiyonu (maksimum a da minimum değerin elde 
    edileceği fonksiyon) doğrusalsa buna "doğrusal programlama (linear programming)", doğrusal değilse buna "doğrusal olmayan 
    programlama (non-linear programming"), eğer değişkenler yalnızca tamsayı değerler alabiliyorsa bunlara da "tamsayılı programlama 
    (integer programming)" denilmektedir. Buradaki programlama teriminin yazılımsal programlama terimiyle bir ilgisi yoktur. Bu 
    konular genel olarak ismine "yöneylem araştırması (operations research)" denilen bir bilim dalı içerisinde ele alınmaktadır. 
    Yöneylem araştırması "optimizasyon problemleriyle ilgili olan disiplinler arası" bir bilim dalıdır. Bu tür problemler özellikle 
    "endüstri ve işletme mühendisliğinde", "ekonometri" ve "matematik" alanında uygulama bulmaktadır. Dolayısıyla yöneylem araştırması 
    üniversitelerde "endüstri mühendisliği", "ekonometri" ve "matematik" bölümlerindeki ders programlarında yer almaktadır. 

    Yöneylem araştırmasının ve doğrusal programlamanın teorisi İkinci Dünya Savaşı yıllarında kısıtlı kaynakların verimli kullanılmasının 
    önemli olduğu bir süreç içerisinde geliştirilmiştir. Yöneylem araştırmasının bazı alt alanları şunlardır:

   - Doğrusal programalama
   - Doğrusal olmayan programlama
   - Tamsayılı programlama
   - Graflar üzerinde optimizasyon işlemleri
   - Ulaştırma problemleri
   - İş sıralama ve çizelgeleme
   - Oyun teorisi (game theory)
   - Karar analizi
   - Çok amaçlı programalama

    Ancak alanın en çok bilinen ve en yaygın karşılaşılan alt alanı doğrusal programlamadır. Doğrusal programalama "doğrusal 
    kısıtlar altında doprusal bir fonksiyonun maximum ve minimum değerlerinin" araştırılması ile ilgilenmektedir. Buradaki 
    doğrusallık kısıtların ve amaç fonksiyonunun birinci dereceden doğrusal fonksiyonlar olduğunu belirtmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Doğrusal programalamada doğrusal kısıtlar "konveks" bir küme oluşturmaktadır. (Konveks küme demek kümenin herhangi iki 
    noktasını birleştiren doğrunun her noktasının o küme içerisinde kalması" demektir.) Konveks kümeleree doğruların kesişimlerinden 
    oluşan "uç mokta (extreme point)" denilen özel noktalar vardır. İşte amaç fonksiyonunu en büyük yapan ya da en küçük yapan 
    noktalar bu uç noktaların birindedir. Böylece sonsuz sayıda noktayı gözden geçirmek yerine yalnızca uç noktaları gözden geçiren 
    algoritmalar geliştirilmiştir. Bu algoritmaların en çok tercih edileni "Simplex" denilen algoritmadır. Simplex algoritmasının 
    iyileştirilmiş biçimine ise "Revised Simplex" denilmektedir. Bugün doğrusal karar modelleri genellikle "Revised Simplex" 
    ve bunların türevleri ile çözülmektedir. Simplex algoritması tüm uç noktaları dolaşmaz, yalnızca çözüme ilişkin olabilecek 
    uç noktalarda gezinir
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Doğrusal programalama problemleri genellikle gerçek yaşamdan hareketle sözel bir biçimde ortaya konmaktadır. Sonra problemin 
    bu sözel anlatımından hareketle "matematiksel modeli" oluşturulur ve çözüm matematiksel model üzerinde uygulanır. Problemin 
    matematiksel modeli demekle onun "matematiksel terimlerle biçimsel ifadesi" kastedilmektedir. 

    Doğrusal programlamada ayarlanması gereken değişkenlere (bunlara karar değişkenleri de denilmektedir) genellikle x1, x2, x3, 
    ..., xn biçiminde isimler verilir. Kısıtlar ise doğru denklemleriyle oluşturulmaktadır. Örneğin n tane değişkene ve m tane 
    kısıta ilişkin bir doğrusal programlama modelinin kısıtları aşağıdaki gibi bir görünümde olabilir:

    a11 x1 + a12 x2 + a13 x3 + ... + a1n xn <= b1
    a21 x1 + a22 x2 + a23 x3 + ... + a2n xn <= b2
    a31 x1 + a32 x2 + a33 x3 + ... + a3n xn <= b3
    ...
    am1 x1 + am2 x2 + am3 x3 + ... + amn xn <= bm

    Burada toplam n değişken ve m tane kısıt vardır. Tabii bu kısıtlar pratik bir biçimde matris çarpımıyla da ifade edilebilmektedir:

    Ax <= b

    Burada A katsayı matrisidir ve şu biçimdedir:

    a11 a12 a13 ... a1n
    a21 a22 a23 ... a2n
    a31 a32 a33 ... a3n
    ...
    am1 am2 am3 ... amn

    x ise aşağıdaki gibi bir sütun vektörüdür:

    x1
    x2
    x3
    ...
    xm

    b de bir sütun vektörüdür:

    b1
    b2
    b3
    ...
    bm

    Doğrusal programlamada Ax <= b gibi bir kısıtlar altında belli bir fonksiyon en büyüklenmeye ya da en küçüklenmeye çalışılır. 
    Genellikle bu fonksiyon Z biçiminde isimlendirilmektedir. Buna "amaç fonksiyonu (objective function)" denilmektedir. O halde 
    amaç fonksiyonun genel biçimi şöyledir:

    Zmin ya da Zmax = c1 x1 + c2 x2 + c3 x3 + ... + cn xn

    Bu amaç fonksiyonu da matrisel biçimde şöyle ifade edilebilir:

    Zmin, Zmax = Cx

    Burada C bir satır vektörü x yine yukarıdaki gibi bir sütub vektörüdür:

    c1 c2 c3 ... cn

    Kısıtların dışında doğrusal karar modellerinde değişkenler üzerinde de aralık temelli kısıtlar bulunabilmektedir. En çok 
    karşılaşılan değişken kısıtları değişkenin 0'dan büyük ya da sıfıra eşit olma kısıtıdır. Bu kısıt şöyle ifade edilebilir:

    x >= 0

    Bir doğrusal karar modelinde kısıtlar genellikle aynı biçime dönüşürülür. Örneğin bütün kısıtlar <= biçimine, >= biçimine
    ya da = biçimine dönüştürülmektedir. Bu biçimde dönüştürme Simplez algortimasının daha kolay yürütülmesini sağlamaktadır 
    
    Doğrusal karar modellerinin matematiksel gösterimi iki biçimde yapılmaktadır: Kanonik biçimde ve standart biçimde. Kanonik 
    biçimde tüm kısıtlar <= ya da >= biçiminde, standart biçimde ise tüm kısıtlar = biçiminde oluşturulur. 
    Kanonik biçim şöyldir:

    Ax <= b
    x >= 0
    Zmax = Cx

    ya da

    Ax >= b
    x >= 0
    Zmin = Cx

    Standart biçim ise şöyledir:

    Ax = b
    x >= 0
    Zmin ya da Zmax = Cx

    Genellikle kanonik biçim karşımıza çıkar. 

    >= olan kısıtların <= biçimine, <= olan kısıtların >= biçimine dönüştürülmesi her iki tarafın -1 ile çarpılmasıyla 
    sağlanabilmektedir. = kısıtları <= ve >= biçimine ya da  <= ve >= kısıtları = kısıtına iki kısıt eklenerek dönüştürülebilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                            117. Ders - 20/04/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirttiğimiz gibi doğrusal karar modelleri genellikle endüstriyel bir problem biçiminde sözel anlatımla karşımıza 
    çıkar. Örnek bir doğrusal programalama problemi şöyle olabilir:

    Bir çiftçinin buğday, mısır ve arpa ürünlerinin ekimi için 300 hektarlık arazisi vardır. Çiftçi hektar başına buğdaydan 
    150 TL, mısırdan 220 TL, arpadan da 180 TL kar beklemektedir. İşgücü yüzünden çiftçi buğday için 150 hektardan ve arpa için 
    120 hektardan daha fazla yer ayırmamalıdır. Verimlilik yönünden ise en az 80 hektar buğday için yer ayırmalı ve mısır ekimi 
    için de toplam arazinin %30'undan daha fazla yer ayırmamalıdır. Çiftçi karını en büyüklemek istemektedir. Çiftçinin hangi 
    ürün için ne kadar alan ayırması gerekir?

    Şimdi problemin matematriksel modelini oluşturalım. Önce değişkenlere isimler verelim:

    x1: Ekilecek buğdayın hektar büyülüğü
    x2: Ekilecek mısırın hektar büyülüğü
    x3: Ekilecek arpanın hektar büyülüğü

    Sourda bir en büyükleme yapılması istenmiştir. Amaç fonksiyonu şöyledir:

    Zmax = 150 x1 + 220 x2 + 180 x3

    Eğer problemin kısıtları olmasaydı biz 300 hektarın hepsine mısır ekerdik. Ancak problemin uyulması gereken kısıtları 
    vardır:

    x1 <= 150 (buğday için en fazla 150 hektar yer ayrılmalıdır)
    x3 <= 120 (arpa için en fazla 120 hektar yer ayrılmalıdır)
    x1 >= 80 (buğday için en az 80 hektar yer ayrılmalıdır)
    x2 <= 90 (mısır için toplam arazinin %30'undan daha fazla yer ayrılmamalıdır)

    x1, x2, x3 >= 0 (negatif üretim yapılmaz)

    Buradaki matematiksel model ne kanonik ne de standart biçime uygundur. Çünkü kısıtların bazıları <= biçiminde bazıları 
    >= biçimindedir. Biz kısıtları -1 ile çarparak onların yönünü değiştirebiliriz. Örneğin:

    x1 >= 80

    ile

    -x1 <= -80

    aynı anlamdadır. O halde yukarıdaki matemetiksel modeli kanonik biçimde şöyle de ifade edebiliriz:

    x1 <= 150 
    x3 <= 120 
    x1 <= -80 
    x2 <= 90 

    x1, x2, x3 >= 0 (negatif üretim yapılmaz)
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                                117. Ders - 19/04/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Beslenme ya da diyet tarzı problemlerde doğrusal programalama teknikleri yaygın kullanılmaktadır. Buna şöyle bir örnek 
    verilebilir:

    Bir kişi sadece et, süt ve yumurta yiyerek diyet yapmaktadır. Bu kişinin günde en az 15 mg A vitamini, 30 mg C vitamini 
    ve 10 mg D vitamini alması gerekmektedir. Buna karşılık besinlerle aldığı kolesterol 80 br/günü geçmemelidir. 1 litre sütte 
    1 mg A, 100 mg C, 10 mg D ve 70 birim kolesterol vardır ve sütün litresi 800 TL dir. 1 kg ette 1 mg A, 10 mg C, 100 mg D 
    vitamini ve 50 br kolesterol vardır. Etin kilosu 3700 TL dir. Yumurtanın düzinesinde 10 mg A, 10 mg C ve 10 mg D vitamini 
    ile 120 birim kolesterol bulunmakta olup, yumurtanın düzinesi 275 TL'dir. Kişinin istediği, bu diyeti en ucuz yolla 
    gerçekleştirmektir. Buna göre problemin doğrusal programlama modelini oluşturunuz.

    Burada yine önce değişkenleri isimlendirmek gerekir:

    x1: Kilogram olarak tüketilecek et miktarı 
    x2: Litre olarak tüketilecek süt miktarı
    x3: Düzine olarak tüketilecek yumurta miktarı

    Problemde istenen en az para harcayarak diyet yapmaktır:

    Zmin = 800 x1 + 3700 x2 + 275 x3

    Tabii hiçbir şey tüketmezsek para da harcamayız. Ancak bu udurm mümkün değildir. Çünkü uymamız gereken bazı sağlık 
    kısıtları vardır:

    x1 + x2 + 10 x3 >= 15                (A vitamini kısıtı)
    100 x1 + 10 x2 + 10 x3 >= 30         (C vitamini, kısıtı) 
    10 x1 + 100 x2 + 10 x3 >= 10        (D vitamini kısıtı)
    70 x1 + 50 x2 + 120 <= 80            (Kolesterol kısıtı)

    Bu değerlerin hiçbiri negatif olamamaktadır:

    x1, x2, x3 >= 0
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Python kullanarak doğrusal karar modellerinin çözümü için çeşitli kütüphaneler oluşturulmuştur. Bunlardan en yaygın 
    kullanılanları SciPy'ın linprog modülü, PuLP kütüphanesi ve Pyomo kütüphanesidir. Biz burada linprog ve PuLP kütüphanelerinin 
    kullanımları üzerinde duracağız. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    SciPy kütüphanesinin scipy.optimize paketinde bulunan linprog fonksiyonu doğrusal karar modelleri için yaygın biçimde 
    kullanılmaktadır. linprog fonksiyonunun parametrik yapısı şöyledir:

    scipy.optimize.linprog(c, A_ub=None, b_ub=None, A_eq=None, b_eq=None, bounds=None, method='highs', 
            allback=None, options=None, x0=None, integrality=None)

    linprog fonksiyonunu kullanabilmek için modelin aşağıdaki biçime dönüştürülmüş olması gerekir:

    Zmin = Cx

    Ax <= b ya da Ax = b

    Yani modelin bir minimizasyon biçiminde olması ve kısıtların da "<=" biçiminde olması ya da modelin minimizasyon ya da 
    maksimizasyon biçiminde olması ve kısıtların "=" biçiminde olması gerekir. Eğer problem bir maksimizasyon problemi ise amaç 
    fonksiyonunun negatifi alınıp problem minimizasyon problemine dönüştürülmelidir. Yukarıda da belirttiğimiz gibi kısıtların 
    bazıları ">=" biçimindeyse eşitsizliğin iki tarafı -1 ile çarpılarak kısıtlar <= biçimine dönüştürülebilir. 

    Fonksiyonun parametreleri NumPy dizisi olmak zorundadır. c parametresi amaç fonksiyonun katsayı vektörünü belirtir. A_ub
    parametresi "<=" kısıtlarının katsayı matirisidir. b_ub kısıtların sağ tarafındaki b katsayılarını belirtmektedir. (Buradaki 
    "ub" eki "upper bound" sözcüklerinden kısaltılmıştır.) A_eq parametresi = kısıtlarının katsayı matrisini b_eq parametresi de 
    "=" kısıtlarının b değerlerini belirtmektedir. Fonksiyonun method parametresi kullanılacak çözüm yöntemini belirtmektedir. 
    Yukarıda da belirttiğimiz gibi genel olarak Simplex algoritması ve bunun türevleri yaygın kullanılmaktadır. Buradaki "highs" 
    değeri "highs" isimli optimizasyon kütüphanesinin kullanılacağını belirtmektedir. Fonksiyonun bounds parametresi değişkenler 
    üzerindeki kısıtları belirtir. Değişken kısıtları bir aralık biçiminde belirtilebilmektedir. Bu parametrenin default değeri 
    bounds=(0, None) biçimindedir, bu da "x >= 0" kısıtı anlamına gelmektedir. Bu parametreye iki elemanlı demet listesi geçilebilir. 
    Demetlerin ilk elemanları minimum değeri, ikinci elemanları maksimum değeri belirtir. Eğer tek bir demet geçirilirse bu 
    durumda bu kısıt tüm değişkenler için geçerli olur. Örneğin:

    [(0, 100), (10, None), (None, None)] 

    Buradaki None değerleri minimum için eksi sonnsuz, maksimum için artı sonsuz anlamına gelmektedir. 

    linprog fonksiyonu çağrıldığında çözüm gerçekleştirilir. Fonksiyonun geri dönüş değeri bir sınıf nesnesi olarak bize 
    verilir. Bu nesnenin fun özniteliği amaç fonksiyonunun değerini, success isimli bool türden öznitelik modelin optimal 
    çözümünün olup olmadığını belirtmektedir. int türden status özniteliği çözümün başarısı hakkında ek birtakım bilgiler 
    vermektedir. nit özniteliği ise çözüme kaç iterasyonda sonuca varıldığını belirtmektedir. (Örneğin Simplex algoritması 
    her iterasyonda bir uç noktaya uğrar. Bu öznitelik Simplex kullanılıyorsa kaç iterasyonda çözüme ulaşıldığını belirtir.) 
    linprog fonksiyonun geri döndürdüğü nesneye ilişkin sınıfın __repr__ ve __str__ metotları çözüm ile ilgili bilgileri bize 
    birkaç satır ile yazı biçiminde vermektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi aşağıdaki gibi bir problemi linprog kütüphanesi ile çözelim:

    Bir çiftlikte üç farklı tür yem üretilmektedir: A, B ve C. Bu yemler, sığırlar için dengeli bir diyet oluşturmak amacıyla 
    kullanılmaktadır. Her yem türü farklı miktarda protein, lif ve enerji içermektedir. Çiftlik, günlük olarak en az 60 birim 
    protein, 40 birim lif ve 80 birim enerji içeren yem karışımı hazırlamak zorundadır. Yemlerin içerikleri ve maliyetleri 
    aşağıdaki gibidir:
    
    Yem Türü    Protein (birim/kg)    Lif (birim/kg)    Enerji (birim/kg)    Maliyet (TL/kg)
    A            10                    2                8                    5
    B            4                     5                4                    3
    C            2                    3                10                    4

    Problemin matematiksel modeli şöyle oluşturulabilir:

    Minimize Z = 5x₁ + 3x₂ + 4x₃

    10x₁ +  4x₂ +  2x₃ ≥  60    (Protein gereksinimi)
    2x₁ +  5x₂ +  3x₃ ≥  40     (Lif gereksinimi)
    8x₁ +  4x₂ + 10x₃ ≥  80     (Enerji gereksinimi)

    x₁, x₂, x₃ ≥ 0

    Bu problemi linprog ile çözerken önce kısıtları >= halinden <= haline döüştürmemiz gerekir:

    -10x₁ - 4x₂ - 2x₃ ≤ -60    (Protein)
    -2x₁ - 5x₂ - 3x₃ ≤ -40     (Lif)
    -8x₁ - 4x₂ -10x₃ ≤ -80     (Enerji)

    A_ub katsayı matrisi şöyle oluşturulabilir:

    aub = np.array([[-10, -4, -2], [-2, -5, -3], [-8, -4, -10 ]])

    b vektörü de şöyle olacaktır:

    bub = np.array([-60, -40, -80])

    Amaç fonksiyonunun katsayıları da şöyle oluşturulabilir:

    c = np.array([5, 3, 4])

    Artık bu NumPy dizilerini linprog fonksiyonuna verebiliriz:

    result = linprog(c, aub, bub)
    if result.success:
        print(result.x)
        print(result.fun)
    else:
        print('Optimal çözüm yok')
    
    Burada önce optimal çözümün olup olmadığına baktık. Optimal çözüm varsa çözüme ilişkin x değerlerini ve amaç fonksiyonun 
    değerini yazdırdık. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
from scipy.optimize import linprog

c = np.array([-3, -2])
aub = np.array([[1, 2], [2, 1], [-1, 1], [0, 1]])
bub = np.array([6, 8, 1, 2])

result = linprog(c, aub, bub)
if result.success:
    print(result.x)
    print(result.fun)
else:
    print('Optimal çözüm yok')
print('-' * 30)
print(result)  

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi aşağıdaki modeli linprog ile çözmeye çalışalım:

    Kısıtlar:

    x1 + 2x2 <= 6
    2x1 + x2 <= 8
    -x1 + x2 <= 1
    x2 <= 2

    Zmax = 3x1 + 2x2

    x1, x2 >= 0

    Burada katsayı matrisleri şöyle oluşturulur:

    c = np.array([-3, -2])
    aub = np.array([[1, 2], [2, 1], [-1, 1], [0, 1]])
    bub = np.array([6, 8, 1, 2])

    Problem bir maksimizasyon problemi olduğu için negatif ile çarpılarak minimizasyon biçimie dönüştürülmüştür. Tabii çözüm 
    sonucunda elde edilecek amaç fonksiyonunun değeri de negatif ile çarpılmalıdır. Aşağıdaki programla şözüm uygulandığında 
    şu sonuçlar elde edilmiştir:

     [3.33333333 1.33333333]
    12.666666666666666
    ------------------------------
            message: Optimization terminated successfully. (HiGHS Status 7: Optimal)
            success: True
            status: 0
                fun: -12.666666666666666
                x: [ 3.333e+00  1.333e+00]
                nit: 2
            lower:  residual: [ 3.333e+00  1.333e+00]
                    marginals: [ 0.000e+00  0.000e+00]
            upper:  residual: [       inf        inf]
                    marginals: [ 0.000e+00  0.000e+00]
            eqlin:  residual: []
                    marginals: []
            ineqlin:  residual: [ 0.000e+00  0.000e+00  3.000e+00  6.667e-01]
                    marginals: [-3.333e-01 -1.333e+00 -0.000e+00 -0.000e+00]
    mip_node_count: 0
    mip_dual_bound: 0.0
        mip_gap: 0.0 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
from scipy.optimize import linprog

c = np.array([-3, -2])
aub = np.array([[1, 2], [2, 1], [-1, 1], [0, 1]])
bub = np.array([6, 8, 1, 2])

result = linprog(c, aub, bub)
if result.success:
    print(result.x)
    print(-result.fun)
else:
    print('Optimal çözüm yok')
print('-' * 30)
print(result)  

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki modeli linprog ile çözmeye çalışalım:

    Kısıtlar

    6x1 + 4x2 <= 120    
    3x1 + 10x2 <= 180    
    x1, x2 >= 0

    Zmax = 45x1 + 55x2

    Burada katsayı matrisleri şöyle oluşturulabilir:

    c = np.array([-45, -55])
    aub = np.array([[6, 4], [3, 10]])
    bub = np.array([120, 180])

    Şu sonuçlar elde edilmiştir:

    [10. 15.]
    1275.0
    ------------------------------
            message: Optimization terminated successfully. (HiGHS Status 7: Optimal)
            success: True
            status: 0
                fun: -1275.0
                x: [ 1.000e+01  1.500e+01]
                nit: 2
            lower:  residual: [ 1.000e+01  1.500e+01]
                    marginals: [ 0.000e+00  0.000e+00]
            upper:  residual: [       inf        inf]
                    marginals: [ 0.000e+00  0.000e+00]
            eqlin:  residual: []
                    marginals: []
            ineqlin:  residual: [ 0.000e+00  0.000e+00]
                    marginals: [-5.938e+00 -3.125e+00]
    mip_node_count: 0
    mip_dual_bound: 0.0
            mip_gap: 0.0
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
from scipy.optimize import linprog

c = np.array([-45, -55])
aub = np.array([[6, 4], [3, 10]])
bub = np.array([120, 180])

result = linprog(c, aub, bub)
if result.success:
    print(result.x)
    print(-result.fun)
else:
    print('Optimal çözüm yok')
print('-' * 30)
print(result)  

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki modelde optimal çözüm yoktur. Modeli linprog ile çözmeye çalışalım:

    Kısıtlar

    x1 + x2 + 10x3 >= 15
    10x2 + 10x3 >= 30
    100x1 + 100x2 + 10x3 >= 10
    70x1 + 50x2 + 120x3 <= 80

    x1, x2, x3 >= 0

    Zmin = 2.25 x1 + 26 x2 + 0.21 x3

    Katsayı matrisleri şöyle oluşturulabilir:

    c = np.array([2.25, 26, 0.21])
    aub = np.array([[-1, -1, -10], [0, -10, -10], [-100, -100, -10], [70, 50, 120]])
    bub = np.array([-15, -30, -10, 80])
        
    Elde edilen çıktı şöyledir:

    Optimal çözüm yok
    ------------------------------
        message: The problem is infeasible. (HiGHS Status 8: model_status is Infeasible; primal_status is At lower/fixed bound)
        success: False
            status: 2
            fun: None
                x: None
            nit: 0
            lower:  residual: None
                    marginals: None
            upper:  residual: None
                    marginals: None
            eqlin:  residual: None
                    marginals: None
        ineqlin:  residual: None
                    marginals: None

#----------------------------------------------------------------------------------------------------------------------------

from scipy.optimize import linprog
import numpy as np

c = np.array([2.25, 26, 0.21])
aub = np.array([[-1, -1, -10], [0, -10, -10], [-100, -100, -10], [70, 50, 120]])
bub = np.array([-15, -30, -10, 80])

result = linprog(c, aub, bub)
print(result)
print('-----------')
print(f'Minimum value: {result.fun}')
print(f'Optimal values of variables: {result.x}')

#----------------------------------------------------------------------------------------------------------------------------
    Doğrusal programlamadaki çok karşılaşılan bir problem grubuna "ulaştırma problemleri (transportation problems)" denilmektedir. 
    Ulaştırma problemlerine şöyle bir örnek verilebilir:

    Bir lojistik firması, üç farklı depo (D1, D2, D3) üzerinden iki farklı mağazaya (M1 ve M2) ürün göndermektedir. Her deponun 
    gönderim kapasitesi ve her mağazanın talebi bellidir. Her bir depo-mağaza arasında birim taşıma maliyeti de farklıdır.

    Depo Kapasiteleri:

    D1: 100 birim
    D2: 150 birim
    D3: 200 birim

    Mağaza Talepleri:

    M1: 180 birim
    M2: 270 birim

    Taşıma Maliyetleri (TL/birim):

        M1    M2
    D1    4    6
    D2    5    2
    D3    3    4

    Amaç toplam taşıma maliyetini minimize ederek tüm talebi karşılamak ve depo kapasitelerini aşmadan ürün göndermektir.

    Problemin matematiksel modeli şöyle oluşturulabilir:

    x₁₁: D1’den M1’e gönderilen ürün miktarı
    x₁₂: D1’den M2’ye gönderilen ürün miktarı
    x₂₁: D2’den M1’e gönderilen ürün miktarı
    x₂₂: D2’den M2’ye gönderilen ürün miktarı
    x₃₁: D3’ten M1’e gönderilen ürün miktarı
    x₃₂: D3’ten M2’ye gönderilen ürün miktarı

    Amaç Fonksiyonu şöyle oluşturulabilir:

    Minimize Z = 4x₁₁ + 6x₁₂ + 5x₂₁ + 2x₂₂ + 3x₃₁ + 4x₃₂

    Kısıtlar şöyle oluşturulabilir:

    x₁₁ + x₁₂ ≤ 100      (D1 kapasitesi)
    x₂₁ + x₂₂ ≤ 150      (D2 kapasitesi)
    x₃₁ + x₃₂ ≤ 200      (D3 kapasitesi)

    x₁₁ + x₂₁ + x₃₁ = 180      (M1 talebi)
    x₁₂ + x₂₂ + x₃₂ = 270      (M2 talebi)

    xᵢⱼ ≥ 0  for all i = 1,2,3 and j = 1,2

    Burada linprog için katsayı matrisleri şöyle oluşturulabilir:

    c = np.array([4, 6, 5, 2, 3, 4])
    aub = np.array([
        [1, 1, 0, 0, 0, 0], 
        [0, 0, 1, 1, 0, 0], 
        [0, 0, 0, 0, 1, 1]])
    bub = np.array([100, 150, 200])
    aeq = np.array([[1, 0, 1, 0, 1, 0], 
                    [0, 1, 0, 1, 0, 1]])
    beq = np.array([180, 270])

    Aşağıda problemin çözümü verilmiştir. Programın çıktısı şöyledir:

    [100.   0.   0. 150.  80. 120.]
    1420.0
    ------------------------------
            message: Optimization terminated successfully. (HiGHS Status 7: Optimal)
            success: True
            status: 0
                fun: 1420.0
                x: [ 1.000e+02  0.000e+00  0.000e+00  1.500e+02  8.000e+01
                    1.200e+02]
                nit: 4
            lower:  residual: [ 1.000e+02  0.000e+00  0.000e+00  1.500e+02
                                8.000e+01  1.200e+02]
                    marginals: [ 0.000e+00  1.000e+00  4.000e+00  0.000e+00
                                0.000e+00  0.000e+00]
            upper:  residual: [       inf        inf        inf        inf
                                        inf        inf]
                    marginals: [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00
                                0.000e+00  0.000e+00]
            eqlin:  residual: [ 0.000e+00  0.000e+00]
                    marginals: [ 4.000e+00  5.000e+00]
            ineqlin:  residual: [ 0.000e+00  0.000e+00  0.000e+00]
                    marginals: [-0.000e+00 -3.000e+00 -1.000e+00]
    mip_node_count: 0
    mip_dual_bound: 0.0
            mip_gap: 0.0

#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
from scipy.optimize import linprog

c = np.array([4, 6, 5, 2, 3, 4])
aub = np.array([
    [1, 1, 0, 0, 0, 0], 
    [0, 0, 1, 1, 0, 0], 
    [0, 0, 0, 0, 1, 1]])
bub = np.array([100, 150, 200])
aeq = np.array([[1, 0, 1, 0, 1, 0], 
                [0, 1, 0, 1, 0, 1]])
beq = np.array([180, 270])

result = linprog(c, aub, bub, aeq, beq)

if result.success:
    print(result.x)
    print(result.fun)
else:
    print('Optimal çözüm yok')
print('-' * 30)
print(result)  

#----------------------------------------------------------------------------------------------------------------------------
    Tabii özellikle ulaştırma problemleri ve graf problemleri gibi problemlerde değişkenler ve kısıtlar çok fazla olabilir. 
    Aşağıdaki problemde 15 değişken vardır. Değişkenler xij biçiminde belirtilmiştir. 

    Aşağıdaki gibi bir model olsun:

    Kısıtlar

    x11 + x21 + x31 = 700     
    x12 + x22 + x32 = 300     
    x13 + x23 + x33 = 900     
    x14 + x24 + x34 = 600     
    x15 + x25 + x35 = 500     

    x11 + x12 + x13 + x14 + x15 <= 1200    
    x21 + x22 + x23 + x24 + x25 <= 1200    
    x31 + x32 + x33 + x34 + x35 <= 1200    

    x11, x12, x13, x14, x15, x21, x22, x23, x24, x25, x31, x32, x33, x34, x35 >= 0

    Zmin = 8x11 + 12x12 + 9x13 + 8x14 + 11x21 + 9x22 + 16x23 + 8x25 + 14x31 + x32 + 10x33 + 9x34 + 12x35

    Bu modelde 15 değişken vardır. Modelde "<=" ve "=" kısıtları birlikte bulunmaktadır. Katsayı matrisleri şöyle 
    oluşturulabilir:

    c = np.array([8, 12, 9, 8, 0, 11, 9, 16, 0, 8, 14, 0, 10, 9, 12], dtype='float')
    aub = np.array([
        [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 
        [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], 
        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], dtype='float')
    bub = np.array([1200, 1200, 1200])
    aeq = np.array([
        [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0], 
        [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], 
        [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], 
        [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1], 
        [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]], dtype='float')
    beq = np.array([700, 300, 900, 600, 500])

    Aşağıda problemin çözümü verilmiştir. Şöyle bir çıktı elde edilmiştir:

    [700.   0.  -0.   0. 500.   0.   0.   0. 600.   0.   0. 300. 900.   0.  0.]
    14600.0
    ------------------------------
            message: Optimization terminated successfully. (HiGHS Status 7: Optimal)
            success: True
            status: 0
                fun: 14600.0
                x: [ 7.000e+02  0.000e+00 ...  0.000e+00  0.000e+00]
                nit: 6
            lower:  residual: [ 7.000e+02  0.000e+00 ...  0.000e+00
                                0.000e+00]
                    marginals: [ 0.000e+00  1.300e+01 ...  9.000e+00
                                1.100e+01]
            upper:  residual: [       inf        inf ...        inf
                                        inf]
                    marginals: [ 0.000e+00  0.000e+00 ...  0.000e+00
                                0.000e+00]
            eqlin:  residual: [ 0.000e+00  0.000e+00  0.000e+00  0.000e+00
                                0.000e+00]
                    marginals: [ 9.000e+00 -0.000e+00  1.000e+01 -0.000e+00
                                1.000e+00]
            ineqlin:  residual: [ 0.000e+00  6.000e+02  0.000e+00]
                    marginals: [-1.000e+00 -0.000e+00 -0.000e+00]
    mip_node_count: 0
    mip_dual_bound: 0.0
            mip_gap: 0.0
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
from scipy.optimize import linprog

c = np.array([8, 12, 9, 8, 0, 11, 9, 16, 0, 8, 14, 0, 10, 9, 12], dtype='float')
aub = np.array([
    [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 
    [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0], 
    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], dtype='float')
bub = np.array([1200, 1200, 1200])
aeq = np.array([
    [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0], 
    [0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0], 
    [0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0], 
    [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1], 
    [0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]], dtype='float')
beq = np.array([700, 300, 900, 600, 500])

result = linprog(c, aub, bub, aeq, beq)

if result.success:
    print(result.x)
    print(result.fun)
else:
    print('Optimal çözüm yok')
print('-' * 30)
print(result)  

#----------------------------------------------------------------------------------------------------------------------------
    Doğrusal karak modellerinin çözümü için SciPy'ın linprog fonksiyonun dışında yaygın kullanılan bir kütüphane de PuLP isimli
    kütüphanedir. PuLP kütüphanesi daha kolay anlaşılabilir bir model sunmaktadır. PulP kütüphanesi doğrusal programlama için
    daha fazla olanaklara sahiptir. Örneğin bu kütüphaneyle "tamsayı programlama (integer programming)" problemleri de 
    çözülebilmektedir. 
    
    Kütüphane Anaconda içerisinde default olarak bulunmadığı için önce aşağıdaki gibi kurulmaldır:

    pip install pulp

    Kütüphanein dokümantasyonu aşağıdaki bağlantıda bulunmaktadır:

    https://coin-or.github.io/pulp/

    PuLP kütüphanesinin kullanımı adım adım şöyledir:

    1) Önce pulp.LpProblem sınıfı türünden bir nesne yaratılır. Bu yaratım sırasında modele bir isim verilir ve modelin 
    maksimizasyon mu minimizasyon mu olduğu belirtilir. Örneğin:

    lp = pulp.LpProblem('District_School_Problem', pulp.LpMaximize)

    2) Modeldeki değişkenler pulp.LpVariable türünden sınıf nesneleri ile temsil edilmektedir. Bu nesneler yaratılırken onlara 
    isimler alt ve üst limitler verilir. Alt ve üst limitlerin default değerleri eksi sonsuz ve artı sonsuz biçimindedir. Örneğin:

    x1 = pulp.LpVariable(name='x1', lowBound=0)
    x2 = pulp.LpVariable(name='x2', lowBound=0)

    3) Kısıtlar tamamen aritmetik operatörler kullanılarak oluşturulmaktadır. Yani LpProblem sınıfı bunun için çeşitli 
    operatör metotlarını zaten bulundurmuştur. Örneğin:

    lp += x1 + 2 * x2 <= 6
    lp += 2 * x1 + x2 <= 8
    lp += -x1 + x2 <= 2
    lp += x2 <= 2

    4) Amaç fonksiyonu da benzer biçimde oluşturulmaktadır. İfadenin sonunda karşılaştırma operatörü olmadığından sınıf bunun 
    amaç fonksiyonu olduğunu anlamaktadır. Örneğin:

    lp += 3 * x1 + 2 * x2

    5) Modeli çözmek için LpProblem sınıfının solve metodu kullanılmaktadır. Örneğin:

    lp.solve()

    solve metodu problemi çözerken bazı geri bildirimlerimleri mesaj olarak ekrana basmaktadır. Bunu istemiyorsanız metodu
    şöyle çağırabilirsiniz:

   lp.solve(pulp.PULP_CBC_CMD(msg=False))

   solve metodu işlemin başarısına yönelik 1 ya da 0 değerine geri dönmektedir. 

    6) LpProblem sınıfının __repr__ ve __str__ metotları modeli bize yazsısal biçimde vermektedir. 

    7) Çözüm elde edildikten sonra değişkenlerin değerleri pulp.value fonksiyonu ile ya da LpVariable sınıfının value metodu 
    ile elde edilebilir. Amaç fonksiyonun değeri de pulp.value(lp.objective) çağrısıyla elde edilebilmektedir. Örneğin:

    x1_result = x1.value()
    x2_result = x1.value()
    
    LpProblem sınıfının status örnek özniteliği problemin  çözüm başarısını bize verir. constraints özniteliği ise kısıtları 
    bize vermektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki modeli PuLP kürüphanesi ile çözleim:

    Kısıtlar:

    x1 + 2 x2 <= 6
    2 x1 + x2 <= 8
    -x1 + x2 <= 1
    x2 <= 2

    Zmax = 3x1 + 2x2

    x1, x2 >= 0

    Programdan şu sonuçlar elde edilmiştir:

    MyModel:
    MAXIMIZE
    3*x1 + 2*x2 + 0
    SUBJECT TO
    _C1: x1 + 2 x2 <= 6

    _C2: 2 x1 + x2 <= 8

    _C3: - x1 + x2 <= 2

    _C4: x2 <= 2

    VARIABLES
    x1 Continuous
    x2 Continuous

    --------------------------------------------------
    x1 = 3.3333333, x2 = 1.3333333
    Amaç fonksiyonun değer: 12.666666500000002
#----------------------------------------------------------------------------------------------------------------------------

import pulp

lp = pulp.LpProblem('MyModel', pulp.LpMaximize)

x1 = pulp.LpVariable(name='x1', lowBound=0)
x2 = pulp.LpVariable(name='x2', lowBound=0)

lp += x1 + 2 * x2 <= 6
lp += 2 * x1 + x2 <= 8
lp += -x1 + x2 <= 2
lp += x2 <= 2
lp += 3 * x1 + 2 * x2

lp.solve(pulp.PULP_CBC_CMD(msg=False))

print(lp)
print('-' * 50)

x1_result = x1.value()
x2_result = x2.value()

print(f'x1 = {x1_result}, x2 = {x2_result}')
objective_result = pulp.value(lp.objective)
print(f'Amaç fonksiyonun değer: {objective_result }')

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi aşağıdaki problemi PuLP kütüphanesi ile çözelim:

    Kısıtlar

    6x1 + 4x2 <= 120    
    3x1 + 10x2 <= 180    
    x1, x2 >= 0

    Zmax = 45x1 + 55x2

    Programdan şu sonuçlar elde edilmiştir:

    MyModel:
    MAXIMIZE
    45*x1 + 55*x2 + 0
    SUBJECT TO
    _C1: 6 x1 + 4 x2 <= 120

    _C2: 3 x1 + 10 x2 <= 180

    VARIABLES
    x1 Continuous
    x2 Continuous

    --------------------------------------------------
    x1 = 10.0, x2 = 15.0
    Amaç fonksiyonun değer: 1275.0
#----------------------------------------------------------------------------------------------------------------------------

import pulp

lp = pulp.LpProblem('MyModel', pulp.LpMaximize)

x1 = pulp.LpVariable(name='x1', lowBound=0)
x2 = pulp.LpVariable(name='x2', lowBound=0)

lp += 6 * x1 + 4 * x2 <= 120
lp += 3 * x1 + 10 * x2 <= 180
lp += 45 * x1 + 55 * x2

lp.solve(pulp.PULP_CBC_CMD(msg=False))

print(lp)
print('-' * 50)

x1_result = x1.value()
x2_result = x2.value()

print(f'x1 = {x1_result}, x2 = {x2_result}')
objective_result = pulp.value(lp.objective)
print(f'Amaç fonksiyonun değer: {objective_result }')

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de aşağıdaki modeli PuLP ile çözelim:

    Kısıtlar:

    x1 + x2 + 10 x3 >= 15
    10 x2 + 10 x3 >= 30
    100x1 + 100x2 + 10x3 >= 10
    70x1 + 50x2 + 120x3 <= 80

    x1, x2, x3 >= 0

    Zmin = 2.25x1 + 26x2 + 0.21x3

    Programın çalıştırılmasıyla şu sonuçlar elde edilmiştir:

    MyModel:
    MAXIMIZE
    2.25*x1 + 26*x2 + 0.21*x3 + 0.0
    SUBJECT TO
    _C1: x1 + x2 + 10 x3 >= 15

    _C2: 10 x2 + 10 x3 >= 30

    _C3: 100 x1 + 100 x2 + 10 x3 >= 10

    _C4: 70 x1 + 50 x2 + 120 x3 <= 80

    VARIABLES
    x1 Continuous
    x2 Continuous
    x3 Continuous

    --------------------------------------------------
    x1 = 0.0, x2 = 1.6666667, x3 = 1.6666667
    Amaç fonksiyonun değer: 43.61333419299999
#----------------------------------------------------------------------------------------------------------------------------

import pulp

lp = pulp.LpProblem('MyModel', pulp.LpMaximize)

x1 = pulp.LpVariable(name='x1', lowBound=0)
x2 = pulp.LpVariable(name='x2', lowBound=0)
x3 = pulp.LpVariable(name='x3', lowBound=0)

lp += x1 + x2 + 10 * x3 >= 15
lp += 10 * x2 + 10 * x3 >= 30
lp += 100 * x1 + 100 * x2 + 10 * x3 >= 10
lp += 70 * x1 + 50 * x2 + 120 * x3 <= 80
lp += 2.25 * x1 + 26 * x2 + 0.21 * x3

lp.solve(pulp.PULP_CBC_CMD(msg=False))

print(lp)
print('-' * 50)

x1_result = x1.value()
x2_result = x2.value()
x3_result = x3.value()


print(f'x1 = {x1_result}, x2 = {x2_result}, x3 = {x2_result}')
objective_result = pulp.value(lp.objective)
print(f'Amaç fonksiyonun değer: {objective_result }')

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de aşağıdaki modlei PuLP ile çözelim:

     Kısıtlar

    x11 + x21 + x31 = 700     
    x12 + x22 + x32 = 300     
    x13 + x23 + x33 = 900     
    x14 + x24 + x34 = 600     
    x15 + x25 + x35 = 500     

    x11 + x12 + x13 + x14 + x15 <= 1200    
    x21 + x22 + x23 + x24 + x25 <= 1200    
    x31 + x32 + x33 + x34 + x35 <= 1200    

    x11, x12, x13, x14, x15, x21, x22, x23, x24, x25, x31, x32, x33, x34, x35 >= 0

    Zmin = 8x11 + 12x12 + 9x13 + 8x14 + x15 + 11x21 + 9x22 + 16x23 + 0x24 + 8x25 + 14x31 + 10x33 + 9x34 + 12x35

    Burada 15 tane değişken vardır. 15 değişkenin satır satır yaratılması biraz zordur. Bu nedenle bu işlem aşağıdaki gibi 
    içlem kullanılarak ile yapılabilir:
  
    vairables = [pulp.LpVariable(f'x{i}{k}', lowBound=0) for i in range(1, 4) for k in range(1, 6)]

    Burada tüm değişkenleri bir liste içerisinde tuttuk. 

    Programın çalıştırıması ile şu çıktı elde edilmiştir:

    MyModel:
    MINIMIZE
    8*x11 + 12*x12 + 9*x13 + 8*x14 + 11*x21 + 9*x22 + 16*x23 + 8*x25 + 14*x31 + 10*x33 + 9*x34 + 12*x35 + 0.0
    SUBJECT TO
    _C1: x11 + x21 + x31 = 700

    _C2: x12 + x22 + x32 = 300

    _C3: x13 + x23 + x33 = 900

    _C4: x14 + x24 + x34 = 600

    _C5: x15 + x25 + x35 = 500

    _C6: x11 + x12 + x13 + x14 + x15 <= 1200

    _C7: x21 + x22 + x23 + x24 + x25 <= 1200

    _C8: x31 + x32 + x33 + x34 + x35 <= 1200

    VARIABLES
    x11 Continuous
    x12 Continuous
    x13 Continuous
    x14 Continuous
    x15 Continuous
    x21 Continuous
    x22 Continuous
    x23 Continuous
    x24 Continuous
    x25 Continuous
    x31 Continuous
    x32 Continuous
    x33 Continuous
    x34 Continuous
    x35 Continuous
    --------------------------------------------------
    x11:  700.0
    x12:  0.0
    x13:  0.0
    x14:  0.0
    x15:  500.0
    x21:  0.0
    x22:  0.0
    x23:  0.0
    x24:  600.0
    x25:  0.0
    x31:  0.0
    x32:  300.0
    x33:  900.0
    x34:  0.0
    x35:  0.0
    Amaç fonksiyonun değer: 14600.0
#----------------------------------------------------------------------------------------------------------------------------

import pulp

lp = pulp.LpProblem('MyModel', pulp.LpMinimize)

variables = [pulp.LpVariable(f'x{i}{k}', lowBound=0) for i in range(1, 4) for k in range(1, 6)]
x11, x12, x13, x14, x15, x21, x22, x23, x24, x25, x31, x32, x33, x34, x35 = variables

lp += x11 + x21 + x31 == 700     
lp += x12 + x22 + x32 == 300     
lp += x13 + x23 + x33 == 900     
lp += x14 + x24 + x34 == 600     
lp += x15 + x25 + x35 == 500 

lp += x11 + x12 + x13 + x14 + x15 <= 1200    
lp += x21 + x22 + x23 + x24 + x25 <= 1200    
lp += x31 + x32 + x33 + x34 + x35 <= 1200    

lp += 8 * x11 + 12 * x12 + 9 * x13 + 8 * x14 + 0 * x15 + 11 * x21 + 9 * x22 + 16 * x23 + 0 * x24 + 8 * x25 + \ 
        14 * x31 + 0 * x32 + 10 * x33 + 9 * x34 + 12 * x35

lp.solve(pulp.PULP_CBC_CMD(msg=False))

print(lp)
print('-' * 50)
for variable in variables:
    print(f'{variable}:  {variable.value()}')
objective_result = pulp.value(lp.objective)
print(f'Amaç fonksiyonun değer: {objective_result }')

#----------------------------------------------------------------------------------------------------------------------------
    Doğrusal karar modellerinde çok fazla değişken bulunabilmektedir. Bu durumda modelin bir dosyada oluşturulup yüklenmesi 
    işlemleri kolaylaştırmaktadır. PuLP kütüphanesinin bazı ayrıntıları vardır. Dokümantasyondan bu ayrıntıları öğrenebilirsiniz. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Bu bölümde graflar hakkında bazı temel bilgileri gözden geçireceğiz ve çok kullanılan bazı graf problemleri üzerinde 
    duracağız. Graf soyut bir veri ypısıdır. Gerçek dünyadaki çeşitli problemler bir graf veri yapısı ile temsil edilerek 
    geliştirilmiş olan algoritmalarla çözülebilmektedir. Graflar üzerinde işlemler "veri yapıları ve algoritmalar" dünyasında 
    önemli bir yer tutmaktadır. 

    Bir graf düğümlerden ve yollardan (düğümler arası bağlantılardan) oluşmaktadır. Düğümlere İngilizce "node" ya da "vertex"
    Yollar ise "edge" denilmektedir. Graflar "yönlü (directed)" ya da "yönsüz (undirected)" olabilmektedir. Eğer düğümler 
    arasındaki yollar için yön belirtiliyorsa bu tür graflara "yönlü graf" eğer yollar için bir yön belirtilmiyorsa bu tür 
    graflara da "yönsüz graf" denilmektedir. Yönsüz graf demek aslında iki yönlü graf demektir. Örneğin:

    A ---- B

    Burada A düğümünden B düğümüne de B düğümünden A düğümüne de bir yol olduğu varsayılabilir. Örneğin:

    A -->-- B

    Burada A düğümünden B düğümüne bir yol vardır fakat B düğümünden A düğümüne bir yol yoktur. 

    Graflarda düğümlere ve yollara bilgiler iliştirilebilmektedir. Örneğin düğümler şehirleri temsil ediyorsa onların isimleri, 
    nüfusları vs. söz konusu olabilir. Yollara bilgi iliştirilmesiyle de çok karşılaşılır. Örneğin iki düğüm arasındaki yola bir 
    uzaklık bilgisi ya da trafik yoğunluk bilgisi iliştirilebilir. 

    Bir grafta tüm düğümlere tek bir yerden gelinebiliyorsa bu tür graflara "ağaç (tree)" da denilmektedir. 

    Yukarıda da belirttiğimiz gibi gerçek hayattaki bazı problemler bir graf veri yapısı biçiminde temsil edilip o veri yapısı 
    üzerinde  çeşitli algoritmalar uygulanarak çözülmektedir. Örneğin biz kavşak noktalarını düğümlerle temsil edersek, yollar 
    da bu kavşak noktaları arasındaki uzaklıkları belirtirse böyle bir grafta pek çok algoritmik problemi çözebiliriz. Bir 
    noktadan başka bir noktaya en kısa yolun (shortest path) bulunması en popüler graf algoritmalarından biridir. 

    Graf algoritmaları uzmanlık isteyen bir alandır. Dolayısıyla genellikle programcılar bu konuda çalışan kişilerin oluşturdukları 
    kütüphanelerini kullanırlar. Çeşitli programlama dilleri için çeşitli graf kütüphaneleri oluşturulmuştur. C++'ta en yaygın 
    kullanılan ve en verimli olanlardan biri "Boost Graph Library (BGL)" denilen kütüphanedir. Python'da çeşitli seçenekler söz 
    konusudur. Ancak "Netwokx" ve "iGraph" denilen kütüphaneler diğerlerinden daha fazla tercih edilmektedir. Biz de kurusumuzun 
    bu bölümünde "NetworkX" kütüphanesini tanıtacağız.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                        118. Ders - 26/04/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    NetworkX kütüphanesi Anaconda dağıtımının default kurulumunda yüklenmemektedir. Kurulumu aşağıdaki gibi yapılabilir:

    pip install networkx

    Kütüphanenin dokümantasyonuna aşağıdaki bağlantıdan erişebilirsiniz:

    https://networkx.org/documentation/stable/index.html

    Genellikle programcılar tarafından kütüphane nx ismiyle import edilmektedir:

    import networkx as nx
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    MetworkX'te bir graph oluşturmak için önce bir graph nesnesini yaratmak gerekir. Dört çeşit graph nesneleri vardır:
    
    Graph
    DiGraph
    MultiGraph 
    MultiDiGraph
  
    Yönsüz graflar için Graph sınıfı yönlü graflar için DiGraph sınıfı kullanılmaktadır. Graph ve DiGraph sınıfları paralel 
    kenarlara (edges) izin vermemektedir. Paralel kenar demekle aynı düğümden başlayan ve aynı düğümde biten yollar kastedilmektedir. 
    Örneğin biz Grapg sınıfı ile A düğümünden B düğümüne bir yol oluşturduktan sonra yine A düğümünden B düğümüne başka bir yol 
    oluşturamayız. İşte MultiGraph ve MultiDiGraph sınıfları bu biçimdeki paralelliğe izin vermektedir. 

    Graf nesnesi yaratılırken birtakım kenarlar da verilebilir. Ayrıca istenildiği kadar isimli parametre yaratılan graf 
    nesnesine iliştirilmektedir. Örneğin:

    g = nx.Graph(title='Test Graph', date='26/02/2023')

    İliştirilen bu bilgiler Graph nesnesinin graph isimli sözlük özniteliğinden daha sonra elde edilebilir. Örneğin:

    print(g.graph['date'])

    Graph sınıfının __init__ metodunun parametrik yapısı şöyledir:

    class Graph(incoming_graph_data=None, **attr)
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.Graph(title='Test Graph', date='26/02/2023')

#----------------------------------------------------------------------------------------------------------------------------
    Grafa düğüm (vertex/node) eklemek için add_node metodu kullanılabilir. Bu metodun birinci parametresi zorunlu olan düğüm 
    anahtarını almaktadır. Düğüm anahtarı hashable herhangi bir nesne olabilir. Örneğin int bir değer bir string hashable 
    olduğu için düğüm anahtarı olarak kullanılabilmektedir. Bir düğüm eklenirken ona istenilen her türlü bilgi (networkx 
    kütüphanesinde iliştirilen bilgilere "attribute" denilmektedir) iliştirilebilir. Bunun için isimli parametreler kullanılır. 
    Örneğin:

    import networkx as nx

    g = nx.Graph(title='Test Graph'')
    g.add_node('A', count=10)
    g.add_node('B', count=20)

    Tabii düğümlere aynı türden ya da bilgilerin iliştirilmesi zorunlu değildir. Ancak genellikle tüm düğümler aynı türden 
    bilgiler içerir. add_node metodunun parametrik yapısı şöyledi:

    add_node(node_for_adding, **attr)

    İliştirilen bu bilgiler Graf'ın düğümlerinden elde edilebilmektedir. Bir grafın düğümleri graph nesnesinin nodes isimli
    özniteliğinden elde edilebilmektedir. Bu nodes özniteliği bir sözlük nesnesi gibi davranmaktadır. Biz de düğümün anahtarını 
    vererek onun bilgilerine erişebiliriz. Örneğin:

    a_info = g.nodes['A']

    Burada biz 'A' düğümünün bilgilerine eriştik. Bu bilgiler de bize bir sözlük nesnesi biçiminde verilmektedir. Örneğin:

    a_count = a_info['count']

    Tabii yukarıdaki işlem tek hamlede de şöyle yapılabilridi:

    a_count = g.nodes['A']['count']
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.Graph(title='Test Graph')

g.add_node('A', count=100)
g.add_node('B', count=200)
g.add_node('C', count=300)
g.add_node('D', count=400)
g.add_node('E', count=500)

#----------------------------------------------------------------------------------------------------------------------------
    Aslında tek hamlede birden fazla düğüm de grafa eklenebilmektedir. Bunun için graf sınıflarının add_nodes_from metotları
    kullanılır. Bu metotlara dolaşılabilir bir nesne verilirse metot o nesneyi dolaşır, dolaşım sırasında elde edilen değerleri 
    düğüm anahtarı kabul ederek onları tek tek grafa ekler. Örneğin:

    g = nx.Graph(title='Test Graph')
    g.add_nodes_from(['A', 'B', 'C', 'D', 'E'])

    Burada tek hamlede grafa 'A', 'B', 'C', 'D' ve 'E' anahtarlarına (isimlerine) sahip düğümler eklenmiştir. Tabii bu düğümlere 
    bilgiler iliştirilmemiştir. 

    Aşağıdaki örnekte 'FGH' stringi dolaşılabilir olduğu için 'F', 'G' ve 'H' için birer düğüm yaratılacaktır. Benzer biçimde 
    range nesnesi de dolaşılabilir olduğu için oradan elde edilen değerlerle de düğümler yaratılacaktır. 
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.DiGraph(title='My Graph')

g.add_node('A', count=10)
g.add_node('B', count=20)
g.add_node('C', count=30)
g.add_node('D', count=40)

g.add_nodes_from('FGH')
g.add_nodes_from(range(10))

print(g.nodes)

#----------------------------------------------------------------------------------------------------------------------------
    add_nodes_from metodunda isimli parametreler girilirse bunlar eklenen tüm düğümlere iliştirilir. Örneğin:

    g = nx.DiGraph(title='My Graph')

    g.add_node('A', count=10)
    g.add_node('B', count=20)
    g.add_node('C', count=30)
    g.add_node('D', count=40)

    g.add_nodes_from('FGH', count=50)
    
    Burada 'F', 'G've 'H' düğümlerinin count bilgilierinin herpsi 50 olacaktır.
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.DiGraph(title='My Graph')

g.add_node('A', count=10)
g.add_node('B', count=20)
g.add_node('C', count=30)
g.add_node('D', count=40)

g.add_nodes_from('FGH', count=50)

print(g.nodes)

#----------------------------------------------------------------------------------------------------------------------------
    add_nodes_from metodunda aslında iki elemanlı bir demet listesi de girilebilmektedir. Bu listeyi oluşturan demetlerin 
    birinci elemanları düğümün anahtarı, ikinci elemanları düğüme iliştirilecek bilgileri belirten sözlük nesnesi olmalıdır. 
    Böylece tek hamlede bilgileriyle birlikte pek çok düğümü grafa ekleyebiliriz. Örneğin:

    import networkx as nx

    g = nx.Graph(title='Test Graph')

    g.add_node('A', count=100)
    g.add_node('B', count=200)
    g.add_node('C', count=300)
    g.add_node('D', count=400)
    g.add_node('E', count=500)

    g.add_nodes_from([('I', {'count': 700}), ('J', {'count': 800})])
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.Graph(title='Test Graph')

g.add_node('A', count=100)
g.add_node('B', count=200)
g.add_node('C', count=300)
g.add_node('D', count=400)
g.add_node('E', count=500)

g.add_nodes_from([('I', {'count': 700}), ('J', {'count': 800})])

print(g.nodes)

#----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirttiğimiz gibi graph sınıflarının nodes isimli örnek öznitelikleri bir sözlük gibi davranmaktadır. Biz 
    grafa ilişkin bir düğümün bilgilerini elde etmek için nodes özniteliğine düğüme ilişkin anahtarı veriririz. nodes özniteliği 
    de bize o düğümün bilgilerini bir sözlük olarak verir. nodes örnek özniteliğinin bize verdiği nesne bir "view" belirtmektedir. 
    Yani bu nesne üzerinde değişiklik yapıldığında asıl graf üzerinde değişiklik yapılmış olur. nodes ile elde edilen view nesnesi 
    bir sözlük gibi davrandığı için aynı zamanda dolaşılabilir bir nesnedir. Bu nesne dolaşıldığında biz düğümlerin anahtarlarını 
    elde ederiz. Örneğin:

    g = nx.Graph(title='Test Graph')

    g.add_node('A', count=100)
    g.add_node('B', count=200)
    g.add_node('C', count=300)
    g.add_node('D', count=400)
    g.add_node('E', count=500)

    d = g.nodes['D']
    print(d)            # {'count': 400}
    d['count'] = 1000

    for node in g.nodes:
        print(node, g.nodes[node]['count'])
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.Graph(title='Test Graph')

g.add_node('A', count=100)
g.add_node('B', count=200)
g.add_node('C', count=300)
g.add_node('D', count=400)
g.add_node('E', count=500)

d = g.nodes['D']
print(d)            # {'count': 400}
d['count'] = 1000

for node in g.nodes:
    print(node, g.nodes[node]['count'])

#----------------------------------------------------------------------------------------------------------------------------
    nodes örnek özniteliği ile verilen nesne bir sözlük gibi davrandığı için o nesne üzerinde get metodu, items metodu  keys 
    ve values metotları uygulanabilir. get metodu yine anahtar yoksa ikinci parametresiyle belirtilen değere geri dönmektedir. 
    items metodu dolaşılabilir bir nesne verir. O nesne dolaşıldığında iki elemanlı demetler elde edilmektedir. Bu demetlerin 
    birinci elemanı düğümün anahtarını, ikinci elemanları düğüme iliştirilen bilgileri temsil eden sözlük nesnelerinden oluşmaktadır. 
    keys metodu bize anahtarlardan oluşan dolaşılabilir bir nesne, values metodu ise sözlüklerden oluşan dolaşılabilir bir nesne 
    vermektedir. nodes örnek özniteliğinin data isimli bir metodu da vardır. Bu data metodunun verdiği dolaşılabilir nesne 
    dolaşıldığında iki elemanlı demetler elde edilmektedir. Örneğin:
    
    g = nx.Graph(title='Test Graph')

    g.add_node('A', count=100)
    g.add_node('B', count=200)
    g.add_node('C', count=300)
    g.add_node('D', count=400)
    g.add_node('E', count=500)

    for key, attr in g.nodes.items():
        print(key, attr['count'])
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.Graph(title='Test Graph')

g.add_node('A', count=100)
g.add_node('B', count=200)
g.add_node('C', count=300)
g.add_node('D', count=400)
g.add_node('E', count=500)

g.add_nodes_from([('I', {'count': 700}), ('J', {'count': 800})])

d = g.nodes.get('Z', 'Not found')
print(d)        # Not found

for t in g.nodes.items():
    print(t)
    
for name, count in g.nodes.items():
    print(f'{name} ---> {count}')

for key in g.nodes.keys():
    print(key)
    
for value in g.nodes.values():
    print(value)

#----------------------------------------------------------------------------------------------------------------------------
    Grafa düğümler eklendikten sonra artık düğümler arasındaki yolların (edges) eklenmesi gerekir. Yol eklemek için Graf 
    sınıflarının add_edge metotları kullanılmaktadır. Graf sınıflarının add_edge metotları bizden başlangıç ve bitiş düğümüne 
    ilişkin anahtarları ve aynı zamanda o yola iliştirilecek diğer bilgileri isimli argümanlarla almaktadır. Örneğin:

    g.add_edge('A', 'B', length=100, density=0.3)

    Aslında önce düğümleri sonra yolları ekleme zorunluluğu yoktur. Zaten add_edge metotları eğer düğümler eklenmediyse onları 
    da grafa eklemektedir. 

    Yukarıda da belirttiğimiz gibi iki düğüm arasında birden fazla yolun olabilmesi için grafım multi graf türlerinden olması 
    gerekir. 

    Aşağıdaki örnekte önce bazı şehirler düğüm olarak grafa eklenmiş daha sonra da bu şehirler arasındaki bazı yollar 
    uzunluk belirtilerek grafa eklenmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

g = nx.Graph(title='Test Graph')

g.add_node('İstanbul', population=15_701_000)
g.add_node('Ankara', population=5_864_000)
g.add_node('Eskişehir', population=921_000)
g.add_node('Bilecik', population=228_000)
g.add_node('Yalova', population=307_000)
g.add_node('Bursa', population=3_238_000)
g.add_node('Kütahya', population=571_000)
g.add_node('İzmir', population=4_493_000)
g.add_node('Balıkesir', population=1_276_000)
g.add_node('Afyon', population=750_000)

g.add_edge('Ankara', 'Eskişehir', length=236)
g.add_edge('Ankara', 'Afyon', length=255)
g.add_edge('Eskişehir', 'Afyon', length=133)
g.add_edge('Eskişehir', 'Bursa', length=152)
g.add_edge('Bursa', 'Balıkesir', length=150)
g.add_edge('Yalova', 'Bursa', length=70)
g.add_edge('Eskişehir', 'Bursa', length=152)
g.add_edge('Yalova', 'İstanbul', length=92)
g.add_edge('Bursa', 'Kütahya', length=180)
g.add_edge('İzmir', 'Balıkesir', length=176)
g.add_edge('Bursa', 'Bilecik', length=95)
g.add_edge('Afyon', 'Kütahya', length=100)

#----------------------------------------------------------------------------------------------------------------------------
    Oluşturulan grafı çizdirmek için kütüphanedeki draw ya da draw_networkx fonksiyonları kullanılmaktadır. Graf çizmekte
    kullanılan pek çok algoritma vardır. Çünkü aynı graf çok değişik biçimlerde çizdirilebilmektedir. Yaygın kullanılan algoritmalardan 
    biri "Kamada-Kawai" algoritmasıdır. draw metodunun parametrik yapısı şöyledir:

    draw(G, pos=None, ax=None, **kwds)
   
    Metotların with_labels parametresi düğüm yuvarlaklarının içerisinde düğüm anahtarlarının bulundurulup bulundurulmayacağını 
    belirtir. Bu parametrenin default durumu False biçimdedir. node_size parametresi yuvarlakların büyüklüğünü belirlemekte 
    kullanılır. Bu göreli bir büyüklüktür. Default değeri 300'dür. Yönlü graflarda arrowsize okun büyüklüğünü belirtmektedir. 
    Bunun default değeri 10'dur. font_size parametresi düğüm içerisindeki ve yollardaki yazıların font büyüklüklerini, node_color 
    isimli parametre de düğümlerin renklerini belirtir. node_color için tek bir renk girilirse tm düğümler aynı renkte görüntülenir. 
    Ancak bir renk dizisi girilirse bu durumda her düğüm ayrı renkte görümtülenebilmektedir. Belli bir algoritmaya göre çizim 
    yapmak için önce graf o algoritma fonksiyonuna verilir. Bu fonksiyon bir sözlük nesnesi geri döndürür. O sözlük nesnesi 
    draw ya da draw_networkx metotlarının pos parametresine verilir. Örneğin:

    pos = nx.kamada_kawai_layout(g)
    nx.draw(g, pos=pos, with_labels=True, node_size=1500, font_size=24, 
            node_color=['yellow', 'green', 'red', 'magenta', 'yellow', 'pink', 'brown'], arrowsize=20)

    draw fonksiyonu matplotlib kullanılarak yazılmıştır. Dolayısıyla daha iyi bir kontrol sağlamak amacıyla çizim işleminde
    matplotlib fonksiyonlarını da kullabiliriz. Örneğin:

    import matplotlib.pyplot as plt

    plt.figure(figsize=(6, 6))
    plt.title('Şehirlerarası Uzaklıklar')
    pos = nx.kamada_kawai_layout(g)
    nx.draw(g, pos, node_size=2000, with_labels=True, font_size=8, node_color='pink')
    plt.show()

    Aşağıda yönlü graflara ilişkin bir çizim örneği verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.DiGraph(ntitle='Test Graph')

g.add_node('A')
g.add_node('B')
g.add_node('C')
g.add_node('D')

g.add_edge('A', 'B', length=150)
g.add_edge('A', 'C', length=125)
g.add_edge('C', 'D', length=15)
g.add_edge('A', 'F', length=175)

g.add_edge('E', 'D', length=65)
g.add_edge('E', 'F', length=90)
g.add_edge('A', 'E', length=85)
g.add_edge('F', 'B', length=185)
g.add_edge('B', 'E', length=60)
g.add_edge('G', 'D', length=72)
g.add_edge('D', 'G', length=200)

import matplotlib.pyplot as plt

plt.figure(figsize=(5, 5))
pos = nx.circular_layout(g)
nx.draw(g, pos=pos, with_labels=True, node_size=1500, font_size=24,
        node_color=['yellow', 'green', 'red', 'magenta', 'yellow', 'pink', 'brown'], arrowsize=20)
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıda şehirlerarası yollar için bir graf oluşturulmuş ve bu graf iki farklı algoritmayla çizdirilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.Graph(title='Test Graph')

g.add_node('İstanbul', population=15_701_000)
g.add_node('Ankara', population=5_864_000)
g.add_node('Eskişehir', population=921_000)
g.add_node('Bilecik', population=228_000)
g.add_node('Yalova', population=307_000)
g.add_node('Bursa', population=3_238_000)
g.add_node('Kütahya', population=571_000)
g.add_node('İzmir', population=4_493_000)
g.add_node('Balıkesir', population=1_276_000)
g.add_node('Afyon', population=750_000)

g.add_edge('Ankara', 'Eskişehir', length=236)
g.add_edge('Ankara', 'Afyon', length=255)
g.add_edge('Eskişehir', 'Afyon', length=133)
g.add_edge('Eskişehir', 'Bursa', length=152)
g.add_edge('Bursa', 'Balıkesir', length=150)
g.add_edge('Yalova', 'Bursa', length=70)
g.add_edge('Eskişehir', 'Bursa', length=152)
g.add_edge('Yalova', 'İstanbul', length=92)
g.add_edge('Bursa', 'Kütahya', length=180)
g.add_edge('İzmir', 'Balıkesir', length=176)
g.add_edge('Bursa', 'Bilecik', length=95)
g.add_edge('Afyon', 'Kütahya', length=100)

import matplotlib.pyplot as plt

plt.figure(figsize=(5, 5))
plt.title('Şehirlerarası Uzaklıklar')
pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1500, with_labels=True, font_size=8, node_color='pink')
plt.show()

plt.figure(figsize=(5, 5))
plt.title('Şehirlerarası Uzaklıklar')
pos = nx.circular_layout(g)
nx.draw(g, pos, node_size=1500, with_labels=True, font_size=8, node_color='pink')
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Grafın değişik öğeleri değişik fonksiyonlarla da oluşturulabilmektedir. Bu fonksiyonlar şunlardır:

    draw_networkx_nodes             (düğümleri çizer)
    draw_networkx_edges             (yolları çizer)
    draw_networkx_labels            (düğüm içerisindeki yazıları yazar)
    draw_networkx_edge_labels       (yollardaki yazıları yazar)

    Aslında draw metodu bu metotları kullanarak çizimi yapmaktadır. Örneğin biz çizimi aslında tek tek bu metotların bileşimi 
    ile yapabiliriz:

    pos = nx.kamada_kawai_layout(g)
    nx.draw_networkx_nodes(g, pos, node_size=1200, node_color=['yellow', 'brown', 'yellow', 'red', 'purple', 'gray', 
            'pink', 'green', 'magenta', 'red'], alpha=0.5)
    nx.draw_networkx_labels(g, pos, font_color='black', font_weight='bold')
    nx.draw_networkx_edges(g, pos, width=2, node_size=1200)
    nx.draw_networkx_edge_labels(g, pos, edge_labels=nx.get_edge_attributes(g, 'length'), font_weight='bold', 
            font_color='red', label_pos=0.4)

    Yollar üzerindeki yazıların yazdırılması için draw_networkx_edge_labels fonksiyonun ayrıca çağrılması gerekmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.DiGraph(ntitle='Test Graph')

g.add_node('A')
g.add_node('B')
g.add_node('C')
g.add_node('D')

g.add_edge('A', 'B', length=150)
g.add_edge('A', 'C', length=125)
g.add_edge('C', 'D', length=15)
g.add_edge('A', 'F', length=175)

g.add_edge('E', 'D', length=65)
g.add_edge('E', 'F', length=90)
g.add_edge('A', 'E', length=85)
g.add_edge('F', 'B', length=185)
g.add_edge('B', 'E', length=60)
g.add_edge('G', 'D', length=72)
g.add_edge('D', 'G', length=200)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
pos = nx.circular_layout(g)
nx.draw(g, pos=pos, with_labels=True, node_size=1500, font_size=24, node_color=['yellow', 'green', 'red', 'magenta', 
        'yellow', 'pink', 'brown'], arrowsize=20)
nx.draw_networkx_edge_labels(g, pos=pos, font_size=20, edge_labels=nx.get_edge_attributes(g, 'length'))
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Birden fazla yol tek hamlede add_edges_from metoduyla grafa eklenebilir. Bu metodun birinci parametresi iki elemanlı demetleri 
    içeren bir liste olmalıdır. Örneğin:
    
    g.add_edges_from([
    ('A', 'B'), 
    ('A', 'C'), 
    ('C', 'A'), 
    ('B', 'D'), 
    ('A', 'D'), 
    ('C', 'B'), 
    ('C', 'D')])  

    Tabii burada düğümler grafta yoksa aynı zamanda onlar da yaratılmaktadır.

    Aslında add_edges_from metoduna girilen liste üçlü demetlerden de oluşturulabilir. Bu durumda demetlerin üçüncü elemanları 
    ilgili yola ilişkin bilgileri içeren sözlük nesneleri olmak zorundadır. Örneğin:
    
    g.add_edges_from([
        ('A', 'B', {'length': 10}), 
        ('A', 'C', {'length': 20}), 
        ('C', 'A', {'length': 30}), 
        ('B', 'D',{'length': 40}), 
        ('A', 'D', {'length': 50}), 
        ('C', 'B', {'length': 60}), 
        ('C', 'D', {'length': 70})])  
#----------------------------------------------------------------------------------------------------------------------------

iimport networkx as nx

g = nx.Graph(ntitle='Test Graph')

g.add_edges_from([
    ('A', 'B'), 
    ('A', 'C'), 
    ('C', 'A'), 
    ('B', 'D'), 
    ('A', 'D'), 
    ('C', 'B'), 
    ('C', 'D')])  

g.add_edges_from([
    ('A', 'B', {'length': 10}), 
    ('A', 'C', {'length': 20}), 
    ('C', 'A', {'length': 30}), 
    ('B', 'D',{'length': 40}), 
    ('A', 'D', {'length': 50}), 
    ('C', 'B', {'length': 60}), 
    ('C', 'D', {'length': 70})])    

import matplotlib.pyplot as plt

plt.figure(figsize=(5, 5))
plt.title('Şehirlerarası Uzaklıklar')
pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1500, with_labels=True, font_size=8, node_color='pink')
nx.draw_networkx_edge_labels(g, pos=pos, font_size=10, edge_labels=nx.get_edge_attributes(g, 'length'))
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte şehirlerarası uzaklıklar da yollar üzerine yazdırılmıuştır.
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.Graph(title='Test Graph')

g.add_node('İstanbul', population=15_701_000)
g.add_node('Ankara', population=5_864_000)
g.add_node('Eskişehir', population=921_000)
g.add_node('Bilecik', population=228_000)
g.add_node('Yalova', population=307_000)
g.add_node('Bursa', population=3_238_000)
g.add_node('Kütahya', population=571_000)
g.add_node('İzmir', population=4_493_000)
g.add_node('Balıkesir', population=1_276_000)
g.add_node('Afyon', population=750_000)

g.add_edge('Ankara', 'Eskişehir', length=236)
g.add_edge('Ankara', 'Afyon', length=255)
g.add_edge('Eskişehir', 'Afyon', length=133)
g.add_edge('Eskişehir', 'Bursa', length=152)
g.add_edge('Eskişehir', 'Bilecik', length=80)
g.add_edge('Bursa', 'Balıkesir', length=150)
g.add_edge('Yalova', 'Bursa', length=70)
g.add_edge('Eskişehir', 'Bursa', length=152)
g.add_edge('Yalova', 'İstanbul', length=92)
g.add_edge('Bursa', 'Kütahya', length=180)
g.add_edge('İzmir', 'Balıkesir', length=176)
g.add_edge('Bursa', 'Bilecik', length=95)
g.add_edge('Afyon', 'Kütahya', length=100)
g.add_edge('Bursa', 'İstanbul', length=155)
g.add_edge('Yalova', 'Bilecik', length=120)
g.add_edge('Kütahya', 'İzmir', length=330)

import matplotlib.pyplot as plt

plt.figure(figsize=(5, 5))
plt.title('Şehirlerarası Uzaklıklar')
pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1500, with_labels=True, font_size=8, node_color='pink')
plt.show()

plt.figure(figsize=(5, 5))
plt.title('Şehirlerarası Uzaklıklar')
pos = nx.circular_layout(g)
nx.draw(g, pos, node_size=1000, with_labels=True, font_size=7, node_color='pink')
nx.draw_networkx_edge_labels(g, pos=pos, font_size=8, edge_labels=nx.get_edge_attributes(g, 'length'))
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Bir graftaki yolların hepsi graf sınıflarının edges isimli örnek öznitelikleri ile elde edilebilir. Bu edges özniteliği 
    bize yine sözlük gibi kullanılan bir nesne vermektedir. Biz graftaki belli bir yolun bilgilerini köşeli parantez ile ya 
    da get metodu ile iki düğümün anahtarını vererek elde edebiliriz. Örneğin:

    val = g.edges['A', 'B']

    Burada biz 'A' ile 'B' düğümleri arasındaki yolun bilgilerini bir sözlük nesnesi olarak elde etmiş olduk. Tabii bu işlem 
    aslında Python'da aşağıdaki ile eşdeğerdir:

    val = g.edges[('A', 'B')]   

    Yine edges örnek özniteliği ile biz get metodunu kullanabiliriz. Ancak metodun birinci parametresi iki elemanlı bir demet 
    olmalıdır.  Örneğin:

    val = g.edges.get(('A', 'B'), 'Not found')

    Burada 'A' ve 'B' düğümleri arasındaki yolun bilgileri elde edilmek istenmiştir. Eğer böyle bir yol yoksa metot exception 
    fırlatmak yerine 'Not Found' yazısını geri döndürecektir. 
    
    edges örnek özniteliğinin bir sözlük gibi davrandığına, sözlüğün anahtarlarının ise bir demet biçiminde olduğuna dikkat 
    ediniz. Bu durumda biz edges örnek özniteliğini for döngüsü ile dolaşırsak yollara ilişkin demetleri elde ederiz:

    for edge in edges:
        print(edge)         # yollara ilişkin demetler yazdırılacaktır
    
    Yine edges örnek özniteliği ile birlikte biz sınıfın keys ve values metotlarını da kullanabiliriz. keys bize yollara ilişkin 
    düğümleri ikişerli demet biçiminde dolaşılabilir bir nesne olarak verir. Örneğin:

    for t in g.edges.keys():
        print(t)

    Tabii yollara ilişkin düğümleri unpack yaparak da elde edebiliriz:

    for node1, node2 in g.edges.keys():
        print(node1, node2)
    
    values metodu da bize yollara ilişkin bilgileri temsil eden sözlük nesnelerini dolaşmakta kullanabileceğimiz dolaşılabilir 
    bir nesne vermektedir. Örneğin:

    for d in g.edges.values():
        print(d)

    Burada her dolaşımda bir yola iliştirilen değerlerin sözlük nesneleri elde edilecektir. 

    Tabii edges elemanı ile items metodu da çağrılabilir. Bu metot bize yola ilişkin anahtarları ve yola ilişkin bilgilerin 
    bulunduğu sözlük nesnesini dolaşılabilir bir nesne olarak verecektir. Örneğin:

    for t in g.edges.items():
        print(t)

    Burada biz her dolaşımda iki elemanlı bir demet elde ederiz. Demetin ilk elemanı yola ilişkin iki düğümün anahtarlarını, 
    ikinci elemanı ise o düğüme iliştirilen sözlük nesnesini belirtmektedir. Tabii biz unpack işlemi de yapabilirdik:

    for (node1, node2), d in g.edges.items():
        print(node1, node2, d)

    Graf sınıflarının edges örnek özniteliğinin ilişkin olduğu sınıfın __call__ metodu da yazıldığı için edges özniteliği 
    sanki bir metotmuş gibi de çağrılabilmektedir. Bu durumda belli bir düğüme ilişkin yıollar elde edilmektedir. Örneğin:
    
    for edge in g.edges('Ankara'):
        print(t)

    Burada Ankara düğümüyle ilgili olan tüm yollar elde edilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                        1   19. Ders - 27/04/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Yönlü graflar DiGraph sınıfıyla temsil edilmektedir. Bu sınıfın Graph sınıfından farkı yolların yönlere sahip olmasıdır. 
    DiGraph sınıfının genel kullanımı aynıdır. Graflar multi değilse iki düğüm arasına aynı yönde tek bir yol eklenebilir. Ancak 
    iki düğüm arasına aynı yönlü birden fazla yol klenmek istendiğinde bir exception oluşmaz. Yola ilişkin bilgiler yeni eklenen 
    bilgilerle güncellenir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Yönlü graflarda bir düğümden gidilebilecek düğümler graph sınıflarının successors metotlarıyla bir düğüme gelinecek düğümler 
    de predecessors metotlarıyla elde edilebilmektedir. Örneğin:

    for node in g.successors('A'):
        print(node)

    for node in g.predecessors('A'):
        print(node)

    Yönsüz graflarda bir düğüm ile bağlantılı olan düğümler adj örnek özniteliği ile elde edilmektedir. adj örnek özniteliği 
    bir sözlük gibi davranmaktadır. 
    
    Örneğin:

    for node in g.adj['B']:
        print(node)

    Burada A düğümünün doğrudan bağlı olduğu düğümler elde edilmiştir. Yönlü graflarda adj örnek özniteliği successors metodu 
    ile aynı düğümleri vermektedir. (Yani ilgili düğümden çıkan düümleri vermektedir.)

    Graph sınıflarının adjecency isimli metotları bize bir sözlük biçiminde tüm düğümlerin komşu düğümlerini vermektedir. 
    Bu metot parametre almaz. Eğer graf yönlüyse adjacency metodu bize düğümlerden çıkan düğümleri sözlük nesnesi olarak 
    vermektedir. 

    Bazen grafta belli bir yolun olup olmadığını anlamak da isteyebiliriz. Bunun için Grapgh sınıflarının has_edge metotları 
    kullanılmaktadır. Örneğin:

    if g.has_edge('Balıkesir', 'Afyon'):
        pass

    Bir grafta her düğüme giren ve her düğümden çıkan toplam yol sayısı graph sınıflarının degree metotlarıyla elde 
    edilebilmektedir. Bu metot parametreli bir biçimde de kullanılabilmektedir. Örneğin:

    result = g.degree('Eskişehir')
    print(result)

    Burada graf yönlüyse Eskişehir'e gelen ve giden yolların toplam sayııs elde edilmektedir. 
    
    Yönlü graflarda bir düğüme gelen yollar yönlü Graph sınıflarının in_edges metotlarıyla çıkan yollar out_edges metotlarıyla 
    elde edilebilmektedir. Bu metotlar yolları iki düğümden oluşan demetler biçiminde vermektedir. Yönsüz graflarda in_edges
    ve out_edges metotları yoktur. Bunun yerine edges metodu kullanılmaktadır. edges metodu yönlü graflarda da kullanılabilmektedir.
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.DiGraph(title='Test Graph')

g.add_node('İstanbul', population=15_701_000)
g.add_node('Ankara', population=5_864_000)
g.add_node('Eskişehir', population=921_000)
g.add_node('Bilecik', population=228_000)
g.add_node('Yalova', population=307_000)
g.add_node('Bursa', population=3_238_000)
g.add_node('Kütahya', population=571_000)
g.add_node('İzmir', population=4_493_000)
g.add_node('Balıkesir', population=1_276_000)
g.add_node('Afyon', population=750_000)

g.add_edge('Ankara', 'Eskişehir', length=236)
g.add_edge('Eskişehir', 'Ankara', length=236)
g.add_edge('Ankara', 'Afyon', length=255)
g.add_edge('Eskişehir', 'Afyon', length=133)
g.add_edge('Afyon', 'Eskişehir', length=133)
g.add_edge('Eskişehir', 'Bursa', length=152)
g.add_edge('Eskişehir', 'Bilecik', length=80)
g.add_edge('Bursa', 'Balıkesir', length=150)
g.add_edge('Yalova', 'Bursa', length=70)
g.add_edge('Eskişehir', 'Bursa', length=152)
g.add_edge('Yalova', 'İstanbul', length=92)
g.add_edge('Bursa', 'Kütahya', length=180)
g.add_edge('İzmir', 'Balıkesir', length=176)
g.add_edge('Bursa', 'Bilecik', length=95)
g.add_edge('Afyon', 'Kütahya', length=100)
g.add_edge('Bursa', 'İstanbul', length=155)
g.add_edge('Yalova', 'Bilecik', length=120)
g.add_edge('Kütahya', 'İzmir', length=330)
g.add_edge('İzmir', 'Kütahya', length=330)
g.add_edge('İzmir', 'Kütahya', length=330)

import matplotlib.pyplot as plt

plt.figure(figsize=(5, 5))
plt.title('Şehirlerarası Uzaklıklar')
pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1500, with_labels=True, font_size=8, node_color='pink')
plt.show()

plt.figure(figsize=(5, 5))
plt.title('Şehirlerarası Uzaklıklar')
pos = nx.circular_layout(g)
nx.draw(g, pos, node_size=1000, with_labels=True, font_size=7, node_color='pink')
nx.draw_networkx_edge_labels(g, pos=pos, font_size=8, edge_labels=nx.get_edge_attributes(g, 'length'))
plt.show()

for node in g.successors('Eskişehir'):
    print(node, g.edges['Eskişehir', node]['length'])
print('-' * 30)

for node in g.predecessors('Eskişehir'):
    print(node, g.edges['Eskişehir', node]['length'])
print('-' * 30)

for d in g.adjacency():
    print(d)
print('-' * 30)

if g.has_edge('Balıkesir', 'Afyon'):
    print('yol var')
else:
    print('yol yok')
print('-' * 30)   
result = g.degree('Eskişehir')
print(result)
print('-' * 30)   

for edge in g.in_edges('Eskişehir'):
    print(edge)
print('-' * 30)   

for edge in g.out_edges('Eskişehir'):
    print(edge)

#----------------------------------------------------------------------------------------------------------------------------
    Graflardan düğümler ve yollar silinebilir. Graph sınıflarının remove_node isimli metotları graftan belli bir düğümü silmek 
    için kullanılmaktadır. Graftan bir düğüm silinirse onunla ilişkli olan bütün yollar da silinmektedir. Benzer biçimde bir 
    yolu silmek için ise Graph sınıflarının remove_edge metotları kullanılır. Tabii bir yolun silinmesi ona ilişkin düğümlerin 
    silinmesine yol açmamaktadır. 

    Aşağıdaki örnekte graftaki 'Eskişehir' düğümü silinmiştir. Bunun sonucunda bu düğümle ilişkili tüm yolların da silindiğine 
    dikkat ediniz. 
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.DiGraph(title='Test Graph')

g.add_node('İstanbul', population=15_701_000)
g.add_node('Ankara', population=5_864_000)
g.add_node('Eskişehir', population=921_000)
g.add_node('Bilecik', population=228_000)
g.add_node('Yalova', population=307_000)
g.add_node('Bursa', population=3_238_000)
g.add_node('Kütahya', population=571_000)
g.add_node('İzmir', population=4_493_000)
g.add_node('Balıkesir', population=1_276_000)
g.add_node('Afyon', population=750_000)

g.add_edge('Ankara', 'Eskişehir', length=236)
g.add_edge('Eskişehir', 'Ankara', length=236)
g.add_edge('Ankara', 'Afyon', length=255)
g.add_edge('Eskişehir', 'Afyon', length=133)
g.add_edge('Afyon', 'Eskişehir', length=133)
g.add_edge('Eskişehir', 'Bursa', length=152)
g.add_edge('Eskişehir', 'Bilecik', length=80)
g.add_edge('Bursa', 'Balıkesir', length=150)
g.add_edge('Yalova', 'Bursa', length=70)
g.add_edge('Eskişehir', 'Bursa', length=152)
g.add_edge('Yalova', 'İstanbul', length=92)
g.add_edge('Bursa', 'Kütahya', length=180)
g.add_edge('İzmir', 'Balıkesir', length=176)
g.add_edge('Bursa', 'Bilecik', length=95)
g.add_edge('Afyon', 'Kütahya', length=100)
g.add_edge('Bursa', 'İstanbul', length=155)
g.add_edge('Yalova', 'Bilecik', length=120)
g.add_edge('Kütahya', 'İzmir', length=330)
g.add_edge('İzmir', 'Kütahya', length=330)
g.add_edge('İzmir', 'Kütahya', length=330)

import matplotlib.pyplot as plt

plt.figure(figsize=(5, 5))
plt.title('Şehirlerarası Uzaklıklar')
pos = nx.circular_layout(g)
nx.draw(g, pos, node_size=1000, with_labels=True, font_size=7, node_color='pink')
nx.draw_networkx_edge_labels(g, pos=pos, font_size=8, edge_labels=nx.get_edge_attributes(g, 'length'))
plt.show()

g.remove_node('Eskişehir')

plt.figure(figsize=(5, 5))
plt.title('Şehirlerarası Uzaklıklar')
pos = nx.circular_layout(g)
nx.draw(g, pos, node_size=1000, with_labels=True, font_size=7, node_color='pink')
nx.draw_networkx_edge_labels(g, pos=pos, font_size=8, edge_labels=nx.get_edge_attributes(g, 'length'))
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Graf dünyasında grafları matris ile temsil etmek için "komşuluk matris (adjacency matrix)" denilen yöntem de kullanılabilmektedir. 
    Komşuluk matrisi "iki boyutlu binary bir matris" görünümündedir. Bu matriste 0 "iki düğüm arasında yol yok", 1 ise "iki 
    düğüm arasında yol var" anlamına gelmektedir. İndeksler 0'dan başlatılır. Örneğin:

    01100
    00110
    01011
    01000
    10100

    komşuluk matrisinden bir graf oluşturmak için from_numpy_aray fonksiyonu kullanılabilir. Fonksiyonun birinci parametresi 
    Numpy dizisini, belirtir. create_using parametresi yaratılacak grafın türünü belirtmektedir. Örneğin:
    
    adj_matrix = np.array(
        [[0, 0, 1, 0, 1], 
        [0, 0, 1, 1, 0], 
        [0, 0, 0, 1, 0],
        [1, 0, 0, 0, 1],
        [1, 1, 1, 0, 0]])

    g = nx.from_numpy_array(adj_matrix, create_using=nx.DiGraph)

    Aşağıdaki örnekte komşuluk matrisinden hareketle graf oluşturulmuştur.
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx
import numpy as np

a = np.array([[0, 1, 1, 0, 0], [0, 0, 1, 1, 0], [0, 1, 0, 1, 1], [0, 1, 0, 0, 0], [1, 0, 1, 0, 0]])
              
g = nx.from_numpy_array(a, create_using=nx.DiGraph)
    
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 8))
pos = nx.circular_layout(g)
nx.draw(g, pos=pos, with_labels=True, node_size=1500, font_size=24, node_color='green', arrowsize=20)
nx.draw_networkx_edge_labels(g, pos=pos, font_size=20, edge_labels=nx.get_edge_attributes(g, 'length'),)
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte rastgele 0 ve 1'lerden oluşan bir NumPy dizisi oluştrulup bundan graf elde edilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx
import numpy as np

adj_matrix = np.array(
    [[0, 0, 1, 0, 1], 
    [0, 0, 1, 1, 0], 
    [0, 0, 0, 1, 0],
    [1, 0, 0, 0, 1],
    [1, 1, 1, 0, 0]])

g = nx.from_numpy_array(adj_matrix, create_using=nx.DiGraph)

import matplotlib.pyplot as plt

plt.figure(figsize=(5, 5))
pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1500, with_labels=True, font_size=8, node_color='pink')
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    from_edgelist isimli fonksiyon ikili demetlerden oluşan bir Python listesi alır. Her demet bir yolu belirtmektedir. Tabii 
    burada düğüm anahtarlarının sayı olması ve 0'dan başlaması gerekmez. Örneğin:

    edges = [('A', 'B'), ('B', 'C'), ('A', 'C'), ('C', 'A'), ('B', 'D'), ('D', 'C')]
    g = nx.from_edgelist(edges, create_using=nx.DiGraph)

    Aşağıdaki from_edgelist fonksiyonun kullanımına ilişkin örnek verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx
import numpy as np

edges = [('A', 'B'), ('B', 'C'), ('A', 'C'), ('C', 'A'), ('B', 'D'), ('D', 'C')]
g = nx.from_edgelist(edges, create_using=nx.DiGraph)

plt.figure(figsize=(4, 3))
pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=500, with_labels=True, font_size=8, node_color='pink')
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    from_pandas_adjecency ve from_pandas_edgelist fonksiyonları Pandas ile çalışmak üzere düşünülmüştür. Benzer şekilde from'lu 
    fonksiyonların  ters işi yapan to'lu biçimleri de vardır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Bir grafın dosyadan okunması için çeşitli fonksiyonlar bulundurulmuştur. read_adjlist fonksiyonu aşağıdaki formata uygun 
    biçimdeki dosyadan okuma yapar:

    a b c d
    b c d
    ...

    Burada satırın ilk elemanı düğümü belirtmektedir. Satırdaki diğer elemanlar ise o düğümden bağlantıları belirtir. Yani 
    yukarıdaki örnekte a->b, a->c, a->d, b->c, b->d bağlantıları vardır. Örneğin:

    g = nx.read_adjlist('graph.txt', create_using=nx.DiGraph)

    Fonksiyonun delimiter isimli bir parametresi de vardır. Bu parametre sayesinde CSV biçimindeki dosyalar da okunabilir. 
    Örneğin:

    g = nx.read_adjlist('graph.txt', create_using=nx.DiGraph, delimiter=',')

    Aşağıdaki örnekte kullanılan "graph.txt" dosyasının içeriği şöyledir:

    A B C
    C B A
    B C D
    D A C B
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.read_adjlist('graph.txt', create_using=nx.DiGraph)

import matplotlib.pyplot as plt

plt.figure(figsize=(3, 3))
pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=500, with_labels=True, font_size=8, node_color='pink')
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    read_multiline_adjlist fonksiyonu yukarıdakine benzerdir. Ancak her satırda aşağıdaki kaç satırın o satır ile bağlantılı 
    olduğu bilgisi belirtilir. Örneğin:

    a 2
    b
    c
    d 1
    e

    Burada "a" düğümü aşağıdaki iki satırla bağlantılıdır. Yani a->b ve a->c bağlantısı vardır. Benzer biçimde "d" ile yalnızca 
    "e" düğümü bağlantılıdır. 

    Aşağıdaki örnekte kullanılan "graph.txt" dosyasının içeriği şöyledir:

    A 5
    B
    C
    D
    E
    F
    B 2
    C
    D
    C 3
    A
    D
    F
    D 2
    A
    B
    E 3
    A
    C
    D
    F 1
    E
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.read_multiline_adjlist('graph.txt', create_using=nx.DiGraph)

import matplotlib.pyplot as plt

plt.figure(figsize=(3, 3))
pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=500, with_labels=True, font_size=8, node_color='pink')
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    read_edgelist isimli fonksiyon her satırında aşağıdaki gibi bir yol bilgisi olan dosyayı okumaktadır:

    A B {'length': 100}
    A C {'length': 200}
    B A {'length': 100}
    B C {'length': 150}
    B D {'length': 340}
    D A {'length': 130}
    C D {'length': 340}

    Burada iki düğüm anahtarının yanında istenirse bir sözlük formatıyla yolun özellikleri belirtilebilir. Örneğin:

    g = nx.read_edgelist('graph.txt', create_using=nx.DiGraph)

    Aşağıda fonksiyonun kullanımına ilişkin bir örnek veriyoruz.
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.read_edgelist('graph.txt', create_using=nx.DiGraph)

import matplotlib.pyplot as plt

plt.figure(figsize=(5, 5))
pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=500, with_labels=True, font_size=8, node_color='pink')
nx.draw_networkx_edge_labels(g, pos=pos, font_size=8, edge_labels=nx.get_edge_attributes(g, 'length'))
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    read_weigted_edelist fonksiyonu her satırda üçer öğe bulunan dosyaları okumak için kullanılmaktadır. Satırların üçüncü
    öğeleri yola iliştirilmiş değeri belirtmektedir. Burada yola iliştirilen değerler "weight" ismiyle iliştirilmektedir. 
    Örneğin:

    A B 10
    C B 20
    B C 20
    D A 30
    A C 40
    B D 30
    D C 25

    g = nx.read_weighted_edgelist('graph.txt', create_using=nx.DiGraph)

    Aşağıda buna ilişkin bir örnek verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.read_weighted_edgelist('graph.txt', create_using=nx.DiGraph)

import matplotlib.pyplot as plt

plt.figure(figsize=(5, 5))
pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1000, with_labels=True, font_size=8, node_color='pink')
nx.draw_networkx_edge_labels(g, pos=pos, font_size=8, edge_labels=nx.get_edge_attributes(g, 'weight'))
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Graflar üzerinde test işlemleri için başkaları tarafından oluşturulmuş pek çok veri kümesi vardır. Bunlardan biri "Knut-Miles" 
    isimli veri kümesidir. Bu veri kümesinin orijinal formatı biraz karmaşıktır. Bu kurs çerçevesinde orijinal format kurs dizininde 
    iki farklı biçime dönüştürülmüştür:

    "knut-miles.csv"
    "knut-miles-weighted.csv"

    Birinci dosya read_adjlist fonksiyonuyla, ikinci dosya ise read_weighted_edgelist fonksiyonuyla okunmalıdır. İkinci dosya 
    düğümler arasındaki uzaklığa ilişkin bir bilgi de içermektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Bizim graf veri yapısını oluşturmamızın nedeni bu veri yapısı üzerinde algoritmaları uygulamaktır. Örneğin şehirler düğümleri
    şehirler arasındaki yollar grafın yollarını temsil edebilir. Şehirlerarası uzaklıklar da yollara iliştilien bir bilgi durumunda 
    olabilir. Biz de bir şehirden diğerine en kısa yolu bulmak isteyebiliriz. Daha önceden de belirttiğimiz gibi aslında yüzlerce 
    graf algoritması vardır. Ancak bunların birkaç tanesi ile gerçek hayatta çok fazla karşılaşılmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    En kısa yol probleminin (shortest path problem) çözümü için NetworkX kütüphanesinde shortest_path isimli fonksiyon 
    kullanılmaktadır. Fonksiyonun parametrik yapısı şöyledir:

    shortest_path(G, source=None, target=None, weight=None, method='dijkstra')
    
    Bu fonksiyon bizden grafı, kaynak ve hedef düğüm isimlerini ve yol uzunluklarını belirten weight değerini almaktadır. weight 
    parametresi yollara iliştirilen hangi etiketli değerlerin yol uzunluğu olarak kullanılacağını belirlemektedir. Örneğin 
    weight='length' biçimindeki argüman girişi yol uzunluğunun yollara iliştirilen 'length' bilgisi olduğu anlamına gelmektedir. 
    Eğer bu parametre girilmezse bu durumda default olarak "weight" isimli etiketin yol uzunluğunu belirttiği varsayılmaktadır.
    Eğer  ilgili yola "weight" isimli bir etiket iliştirilmemişse yol uzunluğu 1 alınmakltadır. shortest_path fonksiyonu geri 
    dönüş değeri olarak bize iki düğüm arasındaki en kısa yolu düğüm anahtarlarından oluşan bir liste biçiminde vermektedir. 
    En kısa yolun uzunluğu ilgili yolun uzunluğu hesaplanarak bulunabilir. Ancak bunun için de shortest_path_length isimli bir 
    fonksiyon bulundurulmuştur. Bu fonksiyonun parametrik yapısı da şöyledir:

    shortest_path_length(G, source=None, target=None, weight=None, method='dijkstra')
    
    Bu fonksiyonlarda kaynak düğüm belirtilmezse her düğümden hedefe giden en kısa yollar biz sözlük nesnesi biçiminde verilmektedir. 
    Eğer hedef düğüm belirtilmezse bu durumda da her kaynaktan her düğüm gitmek için en kısa yollar bir sözlük nesnesi biçiminde 
    verilir.

    Tipik olarak uygulamacı önce shortest_path fonksiyonu ile en kısa yolu bulur. Sonra bir yolun uzunluğunu veren path_weight
    fonksiyonu ile uzunluğu hesaplar. Tabii yol uzunluğu aslında manuel bir biçimde de hesaplanabilir. Örneğin:

    path = nx.shortest_path(g, 'Eskişehir', 'İzmir', weight='length')

    total = 0
    for i in range(len(path) - 1):
        total += g.edges[path[i], path[i + 1]]['length']
    print(total)

    Fakat manuel hesaplama yerine yukarıda da belirttiğimiz gibi path_weight fonksiyonunu kullanabiliriz:

    result = nx.path_weight(g, path, weight='length')
    print(result)

    Aşağıdaki örnekte "Eskişehir" ile "İzmir" arasındaki en kısa yol bulunmuştur. Biz bu örnekte aynı zamanda en kısa yolu 
    draw_networkx_edges fonksiyonuyla da çizdirdik. Bu fonksiyon graftaki yolları bir demet listesi biçiminde alıp onları 
    istediğimiz renk ve kalınlıkta çizdirmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.DiGraph(title='Test Graph')

g.add_node('İstanbul', population=15_701_000)
g.add_node('Ankara', population=5_864_000)
g.add_node('Eskişehir', population=921_000)
g.add_node('Bilecik', population=228_000)
g.add_node('Yalova', population=307_000)
g.add_node('Bursa', population=3_238_000)
g.add_node('Kütahya', population=571_000)
g.add_node('İzmir', population=4_493_000)
g.add_node('Balıkesir', population=1_276_000)
g.add_node('Afyon', population=750_000)

g.add_edge('Ankara', 'Eskişehir', length=236)
g.add_edge('Eskişehir', 'Ankara', length=236)
g.add_edge('Ankara', 'Afyon', length=255)
g.add_edge('Eskişehir', 'Afyon', length=133)
g.add_edge('Afyon', 'Eskişehir', length=133)
g.add_edge('Eskişehir', 'Bursa', length=152)
g.add_edge('Eskişehir', 'Bilecik', length=80)
g.add_edge('Bursa', 'Balıkesir', length=150)
g.add_edge('Yalova', 'Bursa', length=70)
g.add_edge('Eskişehir', 'Bursa', length=152)
g.add_edge('Yalova', 'İstanbul', length=92)
g.add_edge('Bursa', 'Kütahya', length=180)
g.add_edge('İzmir', 'Balıkesir', length=176)
g.add_edge('Bursa', 'Bilecik', length=95)
g.add_edge('Afyon', 'Kütahya', length=100)
g.add_edge('Bursa', 'İstanbul', length=155)
g.add_edge('Yalova', 'Bilecik', length=120)
g.add_edge('Kütahya', 'İzmir', length=330)
g.add_edge('İzmir', 'Kütahya', length=330)
g.add_edge('İzmir', 'Kütahya', length=330)

path = nx.shortest_path(g, 'Eskişehir', 'İzmir', weight='length')
path_edges = list(zip(path, path[1:]))

import matplotlib.pyplot as plt

plt.figure(figsize=(5, 5))
plt.title('Şehirlerarası Uzaklıklar')
pos = nx.circular_layout(g)
nx.draw(g, pos, node_size=1000, with_labels=True, font_size=7, node_color='pink')
nx.draw_networkx_edge_labels(g, pos=pos, font_size=8, edge_labels=nx.get_edge_attributes(g, 'length'))
nx.draw_networkx_edges(g, pos, edgelist=path_edges, width=2, edge_color='red')
plt.show()

total = 0
for i in range(len(path) - 1):
    total += g.edges[path[i], path[i + 1]]['length']
print(total)

result = nx.path_weight(g, path, weight='length')
print(result)

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıda en kısa yol problemi için başka bir örnek daha verilmiştir
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.DiGraph(title='Test Graph')

g.add_node('İstanbul', population=15_701_000)
g.add_node('Ankara', population=5_864_000)
g.add_node('Eskişehir', population=921_000)
g.add_node('Bilecik', population=228_000)
g.add_node('Yalova', population=307_000)
g.add_node('Bursa', population=3_238_000)
g.add_node('Kütahya', population=571_000)
g.add_node('İzmir', population=4_493_000)
g.add_node('Balıkesir', population=1_276_000)
g.add_node('Afyon', population=750_000)

g.add_edge('Ankara', 'Eskişehir', length=236)
g.add_edge('Eskişehir', 'Ankara', length=236)
g.add_edge('Ankara', 'Afyon', length=255)
g.add_edge('Eskişehir', 'Afyon', length=133)
g.add_edge('Afyon', 'Eskişehir', length=133)
g.add_edge('Eskişehir', 'Bursa', length=152)
g.add_edge('Eskişehir', 'Bilecik', length=80)
g.add_edge('Bursa', 'Balıkesir', length=150)
g.add_edge('Yalova', 'Bursa', length=70)
g.add_edge('Eskişehir', 'Bursa', length=152)
g.add_edge('Yalova', 'İstanbul', length=92)
g.add_edge('Bursa', 'Kütahya', length=180)
g.add_edge('İzmir', 'Balıkesir', length=176)
g.add_edge('Bursa', 'Bilecik', length=95)
g.add_edge('Afyon', 'Kütahya', length=100)
g.add_edge('Bursa', 'İstanbul', length=155)
g.add_edge('Yalova', 'Bilecik', length=120)
g.add_edge('Kütahya', 'İzmir', length=330)
g.add_edge('İzmir', 'Kütahya', length=330)
g.add_edge('İzmir', 'Kütahya', length=330)

path = nx.shortest_path(g, 'Eskişehir', 'İzmir', weight='length')
path_edges = list(zip(path, path[1:]))

import matplotlib.pyplot as plt

plt.figure(figsize=(5, 5))
plt.title('Şehirlerarası Uzaklıklar')
pos = nx.circular_layout(g)
nx.draw(g, pos, node_size=1000, with_labels=True, font_size=7, node_color='pink')
nx.draw_networkx_edge_labels(g, pos=pos, font_size=8, edge_labels=nx.get_edge_attributes(g, 'length'))
nx.draw_networkx_edges(g, pos, edgelist=path_edges, width=2, edge_color='red')
plt.show()

total = 0
for i in range(len(path) - 1):
    total += g.edges[path[i], path[i + 1]]['length']
print(total)

result = nx.path_weight(g, path, weight='length')
print(result)

#----------------------------------------------------------------------------------------------------------------------------
                                        120. Ders - 03/05/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    En küçük örten ağaç (minimum spanning tree) gerçek hayatta da uygulamasına rastlanılan önemli bir graf problemidir. Burada 
    graftaki tüm düğümlere erişen minimum uzunlukta bir ağaç elde edilmeye çalışılır. Bu ağaç tüm düğümleri içermelidir. Gerçek 
    hayatta bu problem bütün noktaları birbirine bağlayan minimum malzeme harcanacak bağlantının tespit edilmesi amacıyla 
    kullanılmaktadır. Örneğin biz tüm evlere su borusu bağlamak isteyebiliriz. Boruyu bir eve döşediğimiz zaman oradan devam 
    edip başka bir eve de döşeyebiliriz. Bir biçimde su tüm evlere girmelidir. Fakat bir eve birden fazla borudan su gelmemelidir. 
    Ancak bu yapılırken de minimum boru döşenmelidir. Bir grafta tüm düğümleri içeren çok sayıda ağaç oluşturulabilir. En küçük 
    örten ağaç bu ağaçların toplam yol olarak en kısasını belirtmektedir. En küçük örten ağaç problemi yönsüz graflara uygulanan 
    bir problemdir.
    
    NetworkX kütüphanesinde en küçük örten ağaç için minimum_spannig_edges isimli bir fonksiyon bulundurulmuştur. Fonksiyonun 
    parametrik yapısı şöyledir:

    minimum_spanning_edges(G, algorithm='kruskal', weight='weight', keys=True, data=True, ignore_nan=False)

    Fonksiyon bize dolaşılabilir bir nesne verir. Bu nesne dolaşıldığında en küçük örten ağacın yollarına ilişkin üç elemanlı 
    demetler elde edilmektedir. 
    
    Aşağıdaki örnekte en küçük örten ağaç bulunmuş ve farklı bir renkte gösterilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.Graph(name='My Graph')

g.add_edge('A', 'B', length=150)
g.add_edge('C', 'A', length=125)
g.add_edge('D', 'C', length=15)
g.add_edge('A', 'F', length=175)

g.add_edge('E', 'D', length=65)
g.add_edge('E', 'F', length=90)
g.add_edge('A', 'E', length=140)
g.add_edge('F', 'B', length=185)
g.add_edge('B', 'E', length=60)
g.add_edge('D', 'G', length=200)

g.add_edges_from([('H', 'I'), ('I', 'J'), ('H', 'A')], length=128)
g.add_edges_from([('J', 'H', {'length': 143}), ('J', 'C', {'length': 450}), ('E', 'C', {'length': 148})])

import matplotlib.pyplot as plt

pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1200, with_labels=True)
nx.draw_networkx_edge_labels(g, pos, edge_labels=nx.get_edge_attributes(g, 'length'), 
        font_weight='bold', font_color='red', label_pos=0.4)
plt.show()

mst = nx.minimum_spanning_edges(g, weight='length')
mst_list = list(mst)
print(f'Minimum spanning tree: {mst_list}')

pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1200, with_labels=True)
nx.draw_networkx_edge_labels(g, pos, edge_labels=nx.get_edge_attributes(g, 'length'), 
        font_weight='bold', font_color='red', label_pos=0.4)
nx.draw_networkx_edges(g, pos, edgelist=mst_list, width=2, edge_color='red')
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Diğer çok karşılaşılan bir graf problemi de "maximum akış (maximum flow)" isimli problemdir. Bu problemde belli bir kaynak 
    düğümden hedef düğüme su taşınmaktadır. Bu sular borular kullanılarak düğümden düğüme iletilir. Ancak boruların kapasiteleri 
    farklıdır. Amaç kaynaktan hedefe en yüksek suyu taşımak için düğümlerden hangi düğümlere ne kadar kapasite kullanılarak suyun 
    taşınacağıdır. Buradaki kısıt iki düğüm arasındaki yolda belirtilen kapasitenin aşılmamasıdır. NetworkX kütüphanesinde bunun 
    için maximum_flow isimli bir fonksiyon bulundurulmuştur. Bu fonksiyon bize kaynaktan hedefe toplam taşınan su  miktarını ve 
    hangi düğümden hangi düğüme hangi miktarda su taşındığını bir demet olarak vermektedir. Tabii buradaki su bir kavramdır. Su 
    yerine elektirk tellerindeki kapasite ya da başka bir olgu da söz konusu olabilir. Problem gerçek hayattaki pek çok olguya 
    uygulanabilmektedir. Örneğin:

    - Veri iletiim ağları
    - Trafik akışı
    - İş planlaması
    - Su ve elektrik şebekeleri

    Maksimum akış problemiyönlü graflara da yönsüz graflara da uygulanabilmektedir. 

    maximum_flow fonksiyonun parametrik yapısı şöyledir:

    maximum_flow(flowG, _s, _t, capacity='capacity', flow_func=None, **kwargs)

    Aşağıda makismum akış probleminin çözümüne bir örnek görüyorsunuz.
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.Graph(name='My Graph')

g.add_edge('A', 'B', capacity=150)
g.add_edge('C', 'A', capacity=125)
g.add_edge('D', 'C', capacity=15)
g.add_edge('A', 'F', capacity=175)

g.add_edge('E', 'D', capacity=65)
g.add_edge('E', 'F', capacity=90)
g.add_edge('A', 'E', capacity=140)
g.add_edge('F', 'B', capacity=185)
g.add_edge('B', 'E', capacity=60)
g.add_edge('D', 'G', capacity=200)

g.add_edges_from([('H', 'I'), ('I', 'J'), ('H', 'A')], capacity=128)
g.add_edges_from([('J', 'H', {'capacity': 143}), ('J', 'C', {'capacity': 450}), ('E', 'C', {'capacity': 148})])
g.add_edge('G', 'I', capacity=200)

import matplotlib.pyplot as plt

plt.figure(figsize=(8, 8))

pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1200, with_labels=True, 
        node_color=['yellow', 'brown', 'yellow', 'red', 'purple', 'gray', 'pink', 'green', 'magenta', 'red'])
nx.draw_networkx_edge_labels(g, pos, edge_labels=nx.get_edge_attributes(g, 'capacity'), 
        font_weight='bold', font_color='red', label_pos=0.4)
plt.show()
maximum_flow = nx.maximum_flow(g, 'F', 'I', capacity='capacity')
print(maximum_flow)

#----------------------------------------------------------------------------------------------------------------------------
    Graf boyama denilen graf algoritmasının değişik biçimleri vardır. Tipik olarak bu problem bir haritadaki komşu şehirlerin 
    en az sayıda farklı renkte boyanmasına ilişkin bir problem olarak betimlenir. Örneğin Türkiye iller haritasında her şehir 
    bir renkle gösteriliyor olsun. Burada biz komşu iki şehri aynı renkle gösteremeyiz. Şüphesiz her şehir için ayrı bir renk 
    kullanılabilir. Ancak bu problemde boyama renklerinin bir maliyeti olduğu için minimum sayıda rengin kullanılması istenir. 
    NetworkX kütüphanesinde değişik algoritmik yöntemlerle graf boyaması yapan fonksiyonlar vardır. Örneğin equitable_color 
    isimli fonksiyon bizim belirlediğimiz sayıda renkle graf düğümlerini boyamaktadır. Bu fonksiyon bir sözlük nesnesine geri 
    döner. Sözlüğün anahtarları graf düğümlerinin isimlerinden değerleri de renk indekslerinden oluşmaktadır. Renk indeskleri 
    0'dan başlamaktadır. Graf boyama probleminde yollardaki bilgiler kullanılmamaktadır.

    equitable_color fonksiyonun parametrik yapısı şöyledir:

    equitable_color(G, num_colors)

    Fonksiyon grafi ve renk sayısını parametre olarak almaktadır. 

    Aşağıda örnek grafın 5 renge boyanması problemi çözülmüştür. 
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.Graph(name='My Graph')

d = [('A', 'B', {'length': 3}), 
    ('A', 'D', {'length': 6}), 
    ('A', 'E', {'length': 9}), 
    ('B', 'C', {'length': 2}), 
    ('B', 'D', {'length': 4}), 
    ('B', 'E', {'length': 9}), 
    ('C', 'D', {'length': 2}), 
    ('C', 'F', {'length': 8}), 
    ('C', 'G', {'length': 9})]

g.add_edges_from(d)

import matplotlib.pyplot as plt

figure = plt.gcf()
figure.set_size_inches((12, 12))

pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1200, with_labels=True)
nx.draw_networkx_edge_labels(g, pos, edge_labels=nx.get_edge_attributes(g, 'length'), 
        font_weight='bold', font_color='red', label_pos=0.4)

plt.show()

result = nx.equitable_color(g, 5)
print(result)

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte Türkiye haritasındaki şehirler 9 farklı renkle boyanmıştır. Buradaki "turkey-city-graph-adjlist.txt" 
    dosyasının içeriği şöyledir:

    Adana Hatay Kahramanmaraş Kayseri Mersin Niğde Osmaniye
    Adıyaman Diyarbakır Gaziantep Kahramanmaraş Malatya Şanlıurfa
    Afyonkarahisar Burdur Denizli Eskişehir Isparta Konya Kütahya Uşak
    Aksaray Ankara Konya Kırşehir Nevşehir Niğde
    Amasya Samsun Tokat Yozgat Çorum
    Ankara Aksaray Bolu Eskişehir Konya Kırıkkale Kırşehir Çankırı Çorum
    Antalya Burdur Isparta Karaman Konya Mersin Muğla
    Ardahan Artvin Erzurum Iğdır Kars
    Artvin Ardahan Erzurum Rize
    Aydın Denizli Manisa Muğla İzmir
    Ağrı Bitlis Erzurum Iğdır Kars Muş Van
    Balıkesir Bursa Kütahya Manisa Çanakkale
    Bartın Karabük Kastamonu Zonguldak
    Batman Bitlis Diyarbakır Mardin Siirt
    Bayburt Erzincan Erzurum Gümüşhane
    Bilecik Bolu Bursa Eskişehir Kütahya
    Bingöl Diyarbakır Elazığ Erzurum Muş Tunceli
    Bitlis Ağrı Batman Muş Siirt Van
    Bolu Ankara Bilecik Düzce Eskişehir Karabük Sakarya Zonguldak Çankırı
    Burdur Afyonkarahisar Antalya Denizli Isparta
    Bursa Balıkesir Bilecik Kocaeli Yalova
    Denizli Afyonkarahisar Aydın Burdur Isparta Manisa Muğla Uşak
    Diyarbakır Adıyaman Batman Bingöl Elazığ Malatya Mardin Şanlıurfa
    Düzce Bolu Sakarya Zonguldak
    Edirne Kırklareli Tekirdağ Çanakkale
    Elazığ Bingöl Diyarbakır Erzincan Malatya Tunceli
    Erzincan Bayburt Elazığ Erzurum Giresun Gümüşhane Sivas Tunceli
    Erzurum Ardahan Artvin Ağrı Bayburt Bingöl Erzincan Kars Muş
    Eskişehir Afyonkarahisar Ankara Bilecik Bolu Konya Kütahya
    Gaziantep Adıyaman Hatay Kahramanmaraş Kilis Osmaniye Şanlıurfa
    Giresun Erzincan Gümüşhane Ordu Sivas Trabzon
    Gümüşhane Bayburt Erzincan Giresun Trabzon
    Hakkari Van Şırnak
    Hatay Adana Gaziantep Kilis Osmaniye
    Isparta Afyonkarahisar Antalya Burdur Denizli Konya
    Iğdır Ardahan Ağrı Kars
    Kahramanmaraş Adana Adıyaman Gaziantep Kayseri Malatya Osmaniye Sivas
    Karabük Bartın Bolu Kastamonu Çankırı
    Karaman Antalya Konya Mersin
    Kars Ardahan Ağrı Erzurum Iğdır
    Kastamonu Bartın Karabük Sinop Çankırı
    Kayseri Adana Kahramanmaraş Nevşehir Niğde Sivas Yozgat
    Kilis Gaziantep Hatay
    Kocaeli Bursa Sakarya Yalova İstanbul
    Konya Afyonkarahisar Aksaray Ankara Antalya Eskişehir Isparta Karaman Niğde
    Kütahya Afyonkarahisar Balıkesir Bilecik Eskişehir
    Kırklareli Edirne Tekirdağ
    Kırıkkale Ankara Kırşehir Yozgat Çorum
    Kırşehir Aksaray Ankara Kırıkkale Nevşehir Yozgat
    Malatya Adıyaman Diyarbakır Elazığ Kahramanmaraş
    Manisa Aydın Balıkesir Denizli İzmir
    Mardin Batman Diyarbakır
    Mersin Adana Antalya Karaman
    Muğla Antalya Aydın Denizli
    Muş Ağrı Bingöl Bitlis Erzurum
    Nevşehir Aksaray Kayseri Kırşehir
    Niğde Adana Aksaray Kayseri Konya
    Ordu Giresun
    Osmaniye Adana Gaziantep Hatay Kahramanmaraş
    Rize Artvin
    Sakarya Bolu Düzce Kocaeli
    Samsun Amasya Çorum
    Siirt Batman Bitlis
    Sinop Kastamonu
    Sivas Erzincan Giresun Kahramanmaraş Kayseri
    Tekirdağ Edirne Kırklareli Çanakkale İstanbul
    Tokat Amasya
    Trabzon Giresun Gümüşhane
    Tunceli Bingöl Elazığ Erzincan
    Uşak Afyonkarahisar Denizli
    Van Ağrı Bitlis Hakkari
    Yalova Bursa Kocaeli
    Yozgat Amasya Kayseri Kırıkkale Kırşehir Çorum
    Zonguldak Bartın Bolu Düzce
    Çanakkale Balıkesir Edirne Tekirdağ
    Çankırı Ankara Bolu Karabük Kastamonu Çorum
    Çorum Amasya Ankara Kırıkkale Samsun Yozgat Çankırı
    İstanbul Kocaeli Tekirdağ
    İzmir Aydın Manisa
    Şanlıurfa Adıyaman Diyarbakır Gaziantep
    Şırnak Hakkari
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.read_adjlist('turkey-city-graph-adjlist.txt')

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 10))
pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1200, with_labels=True, font_size=6)
plt.show()

node_colors = nx.equitable_color(g, 9)
print(node_colors)
node_color_index = [node_colors[node] for node in g.nodes()]

plt.figure(figsize=(10, 10))
pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1200, with_labels=True, node_color=node_color_index, font_size=6,
        cmap=plt.cm.Set3)
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
                                        121. Ders - 04/05/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Gerçek hayatta sıkça karşılaşılan diğer bir graf problemi de "gezgin satıcı problemi (traveling salesperson (salesman) 
    problem (TSP))" denilen problemdir. Bu problemde bir satıcı merkezden çıkarak birtakım şehirlere uğrayıp yeniden merkeze 
    dönmektedir. Problemde her şehre yalnızca bir kez gidilmektedir. Gezgin satıcının bu şehirlerin hepsini dolaşıp geriye 
    dönmesini sağlayacak pek çok alternatif tur (cycle) vardır. Problemde bu turların en kısası bulunmaya çalışılmaktadır. 
    Gezgin satıcı problemi başka alanlarda da dolaylı bir biçimde karşımıza çıkabilmektedir. Örneğin biigisayar ekranında 
    görsel olarak oluşturulan deliklerin gerçek bir otomatik matkapla delinmesi durumunda delinecek noktalardın hepsine 
    matkabın uğraması gerekir. Ancak kat edilecek mesafenin en küçüklenmesi istenir. Bu tarz problemlere algoritmalar dünyasında 
    "NP (Non-polynomial) karmaşıklıkta problemler" denilmektedir. NP karmaşıklıkta problemler girdi parametresine göre üstel 
    ya da faktöryelsel biçimde işleme yol açan problemlerdir. Gezgin satıcı probleminde her şehir ile her şehir arasında 
    yol varsa tüm olası turların toplamı (n - 1)! / 2 kadardır. 100 tane şehir için bile bu sayı çok fazladır:

    933262154439441526816992388562667004907159682643816214685929638952175999932299156089414639761565182862536979208272237
    58251185210916864000000000000000000000000

    NetworkX kütüphanesinde gezgin satıcı problemi networkx.algorithms.approximation paketindeki traveling_salesman_problem 
    fonksiyonuyla gerçekleştirilmiştir. Fonksiyon grafı alır ve minimum turu bize verir. Turda aslında nereden başlandığının 
    bir önemi yoktur. Fonksiyonun parametrik yapısı şöyleidr:

    traveling_salesman_problem(G, weight='weight', nodes=None, cycle=True, method=None, **kwargs)

    Fonksiyonun birinci parametresi problemin çözüleceği grafı almaktadır. weight parametresi yollara atanmış olan etiketlerin
    hangisinin yol uzunluğunu belirttiğini belirlemek için kullanılmaktadır. Ancak bufonksiyonda wieght parametresine 'weight' 
    dışında başka argüman geçildiğinde çalışma kusuru ortaya çıkıyor. Siz yollara atanan uzaklıkları 'weight' etiketiyle belirtiniz
    ve bu parametreye değer girmeyiniz. 

    Aşağıdaki örnekte rastgele tüm düğümleri birbirine bağlı bir graf oluşturulmuş ve o grafın üzerinde gezgin satıcı problemi 
    uygulanmıştır. Fonksiyonda satıcının başlangıç şehri belirtilmemektedir. Çünkü elde edilen en kısa rotada başlangıç şehrinin 
    neresi olduğunun önemi yoktur.
#----------------------------------------------------------------------------------------------------------------------------

import random
import networkx as nx
from networkx.algorithms.approximation import traveling_salesman_problem

random.seed(12345)

g = nx.complete_graph(['A', 'B', 'C', 'D', 'E', 'F', 'G'])
for edge in g.edges:
    g.edges[edge]['weight'] = random.randint(1, 100)

import matplotlib.pyplot as plt

pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1200, with_labels=True)
nx.draw_networkx_edge_labels(g, pos, edge_labels=nx.get_edge_attributes(g, 'weight'), 
        font_weight='bold', font_color='red', label_pos=0.4)
plt.show()

cycle = traveling_salesman_problem(g, weight='length')
print(cycle)

tsp_list = list(zip(cycle, cycle[1:]))

pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1200, with_labels=True)
nx.draw_networkx_edge_labels(g, pos, edge_labels=nx.get_edge_attributes(g, 'weight'), 
        font_weight='bold', font_color='red', label_pos=0.4)
nx.draw_networkx_edges(g, pos, edgelist=tsp_list, width=2, edge_color='red')
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    NetworkX kütüphanesinde test amacıyla rastgele graf üreten çok sayıda hazır fonksiyon bulunmaktadır. Ancak bu fonksiyonlar 
    düğümlere ya da yollara bilgi iliştirmezler bilginin programcı tarafından iliştirilmesi gerekir. Örneğin complete_graph 
    fonksiyonu tüm düğümleri birbirine bağlı bir yönsüz graf oluşturmaktadır. (Tüm düğümler arasında yol olan özel graflara
    "tam graf (complete graph)" denilmektedir.) Fonksiyon parametre olarak düğüm anahtarlarını ya da bir sayı alır. Eğer 
    fonksiyona argüman olarak bir sayı geçilirse fonksiyon düğümlere sırasıyla 0, 1, 2, ... isimlerini vererek n düğümlü bir 
    tam graf oluşturur. Fonksiyonun parametrik yapısı şöyledir:

    complete_graph(n, create_using=None)

    Her ne kadar tam graflar genellikle yönsüz niçimde oluşturulsalar da fonksiyonun create_using parametresine nx.DiGraph 
    geçerek fonksiyon yönlü tam graf da oluşturabilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

import random
import networkx as nx

g = nx.complete_graph(['A', 'B', 'C', 'D', 'E'])

for edge in g.edges:
    g.edges[edge]['length'] = random.randint(1, 100)

import matplotlib.pyplot as plt
pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1200, with_labels=True)
nx.draw_networkx_edge_labels(g, pos, edge_labels=nx.get_edge_attributes(g, 'length'), 
        font_weight='bold', font_color='red', label_pos=0.4)
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    cycle_graph fonksiyonu n tane düğümden oluşan ve bir tur oluşturan bir fonksiyondur. Parametrik yapısı benzer biçimdedir.  
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.cycle_graph(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I'])

for edge in g.edges:
    g.edges[edge]['length'] = random.randint(1, 100)

import matplotlib.pyplot as plt
pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1200, with_labels=True)
nx.draw_networkx_edge_labels(g, pos, edge_labels=nx.get_edge_attributes(g, 'length'), 
        font_weight='bold', font_color='red', label_pos=0.4)
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    star_graph fonksiyonu bir merkezden diğer düğümlere tek bir yolun olduğu bir graf üretir. 
#----------------------------------------------------------------------------------------------------------------------------

import networkx as nx

g = nx.star_graph(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K'])

for edge in g.edges:
    g.edges[edge]['length'] = random.randint(1, 100)

import matplotlib.pyplot as plt

pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1200, with_labels=True)
nx.draw_networkx_edge_labels(g, pos, edge_labels=nx.get_edge_attributes(g, 'length'), 
        font_weight='bold', font_color='red', label_pos=0.4)
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    wheel_graph fonksiyonu çıtalı tekerlek görünümüne sahip bir graf üretir. Parametrik yapısı benzerdir.
#----------------------------------------------------------------------------------------------------------------------------

g = nx.wheel_graph(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K'])

for edge in g.edges:
    g.edges[edge]['length'] = random.randint(1, 100)

import matplotlib.pyplot as plt

pos = nx.kamada_kawai_layout(g)
nx.draw(g, pos, node_size=1200, with_labels=True)
nx.draw_networkx_edge_labels(g, pos, edge_labels=nx.get_edge_attributes(g, 'length'), 
        font_weight='bold', font_color='red', label_pos=0.4)
plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Çeşitli dokümanlarda birtakım graf resimleri oluşturmak için genel amaçlı graf çizim programları kullanılmaktadır. Bunlardan 
    en ünlüsü ve en yaygın kullanılanı "graphviz" denilen programdır. Graphviz açık kaynak kodlu bir yazılımdır. Çeşitli dokümanlarda 
    gördüğümüz grafa benzer çizimlerin çoğu bu utility programla yapılmaktadır. Bu bölümde kısaca graphviz programını tanıtacağız.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Graphviz "dot" denilen mini bir dil kullanmaktadır. Kullanıcı bu "dot" dilini kullanarak belirlenmiş kurallara göre bir 
    script oluşturur. Bunu bir dosya biçiminde save eder. Geleneksel olarak "dot" dilinde yazılmış olan script dosyalarına 
    "gv" ya da "dot" uzantıları verilmektedir. Graphviz "dot" isimli bir program yoluyla kullanılmaktadır. Tabii önce bu "dot" 
    programının makinemize kurulması gerekir. Programın kurulumu işlemi aşağıdaki bağlantıdan hareketle yapılabilir:

    https://graphviz.org/download/

    Debian tabanlı Linux sistemlerinde kurulum apg-get programıyla aşağıdaki gibi yapılabilir:

    sudo apt install graphviz
   
    Bu dosyayı oluşturduktan sonra resim dosyasının üretilmesi için dot programının aşağıdaki örnekteki gibi çalıştırılması 
    gerekir:

    dot -T png sample.gv -o sample.png

    Örnek bir script dosyası şöyle olabilir:

    digraph G {
        main -> parse -> execute;
        main -> init;
        main -> cleanup;
        execute -> make_string;
        execute -> printf
        init -> make_string;
        main -> printf;
        execute -> compare;
        compare -> cleanup;
    }

    graphviz utility'sinin dokümantasyonu aşağıdaki bağlantıda bulunmaktadır:

    https://graphviz.org/documentation/
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Python'da aslında arka planda graphviz kullanarak graf'ların programlama yoluyla oluşturulabilmesine olanak sağlayan 
    graphviz isimli bir kütüphane de bulunmaktadır. Tabii bu kütüphane Python'un standart bir kütüphanesi değildir. Dolayısıyla 
    aşağıdaki gibi manuel biçimde kurulmalıdır:

    pip install graphviz

    Python graphviz kütüphanesinin dokümantasyonuna aşağıdaki bağlantıdan erişebilirsiniz:

    https://graphviz.readthedocs.io/en/stable/manual.html
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Python graphviz kütüphanesi aslında "dot dili kullanılarak script yazma işleminin programlama yoluyla yapılmasını sağlayan" 
    bir kütüphanedir. Küphanenin ayrıntılı kullanımı için orijinal dokümanlara başvurabilirsiniz. Biz aşağıda örnek bir kod 
    vermekle yetineceğiz
#----------------------------------------------------------------------------------------------------------------------------

import graphviz

dot = graphviz.Digraph('Test Graph', format='png')

dot.node('A')
dot.node('B')
dot.node('C')

dot.edge_attr.update(arrowhead='vee', arrowsize='2')

dot.edge('A', 'B', label='100')

dot.edge('B', 'C', label='200')
dot.edge('A', 'D', label='300')

print(dot.source)

dot.render('test.dot')


#----------------------------------------------------------------------------------------------------------------------------
                                            122. Ders - 10/05/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Bu bölümde makine öğrenmesinde de kullanılan ismine "karar ağaçları (decision trees)" denilen istatistiksel yöntem 
    üzerinde duracağız. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Makine öğrenmesinde bazı durumlarda tercih edilebilecek yöntemlerden biri de "karar ağaçları (decision tress)" denilen 
    yöntemdir. Bu yöntemin özü oldukça basittir. Yöntemde sütuna dayalı olarak bir soru sorulur. Bu soru ya doğru olur ya da 
    yanlış olur. Sorunun doğru olduğu durumda ve yanlış olduğu durumda veri kümesi iki parçaya bölünür. Sonra bölünen iki parça 
    için yine bir sütuna dayalı olarak bir soru sorulur. Böylece veri kümesi yine iki parçaya ayrılır. Böyle böyle işlemler devam 
    ettirilip bir ağaç elde edilir. Ağaç ikili (binary) bir ağaçtır. Çünkü sorunun yanıtı iki seçenek içermektedir: Doğru ya da 
    yanlış. Bölme ve soru sorma konusundaki detaylar şöyledir:

    - Bir soru bir sütuna dayalı olarak sorulur. Sütun kategorikse soru da kategorik olacaktır. Sütun sayısal ise soru da >, < 
    biçiminde sayısal olacaktır. Örneğin X1 sütunu cinsiyet belirtiyor olsun. Buradaki soru "X1 = "Kadın mı" biçiminde sorulabilir. 
    Bu durumda X1 sütununun "Kadın" olup olmamasına göre veri kümesi iki kısma ayrılacaktır. Örneğin X2 sütunu uzunluk olabilir. 
    Uzunluk kategorik bir ölçek belirtmez. Örneğin soru şöyle olabilir: "X2 > 10 mu?". Burada da yine veri kümesi X2'nin 10'dan 
    büyük olup olmamasına göre iki parçaya ayrılacaktır. 

    - Ağaçta her soru sonucunda veri kümesi iki parçaya ayrılır. Her parça için yeniden başka bir soru sorulur. Ağacın iki alt 
    düğümünde (yani sol ve sağ düğümünde) aynı sütuna dayalı soru sormak zorunlu değildir. 

    - Bir sütuna dayalı sorunun bir kez sorulması da zorunlu değildir. Örneğin "X2 > 10 mu sorusu yukarıda sorulmuş olup daha 
    sonra "X2 > 30 mu" sorusu aşağıda bir yerde yeniden sorulabilir.

    - Aslında karar ağaçları ikili ağaç olmak zorunda değildir. Ancak en yaygın kullanılan ağaçlar ikili ağaç biçimindedir.
    Tabii ikili olmayan karar ağaçlarındaki sorunun nasıl olacağını merak edebilirsiniz. Düğümdeki soru örneğin sütun X olmak 
    üzere X <= 10,  10 < X <= 20 , X > 20 biçiminde sorulabilir. X <= 10 ayrı bir alt düğüme, 10 < X <= 20 ayrı bir alt düğüme 
    ve X > 20 de ayrı bir alt düğüme dallanabilir. Burada sorunun sorulduğu düğümün üç alt düğümü olacaktır. Çoklu (multiway) 
    karar ağaçlarını dışsal arama (external search) için kullanılan "B Tree" veri yapısına benzetebilirsinz.

    Pekiyi bu soruların sorulup ağacın derinleştirilmesindeki amaç nedir? İşte amaç gitgide düğümlerde homojen (pure) bir durumu 
    oluşturmaktır. Ağacın en aşağısındaki düğümlere "yaprak (leaf)" denilmektedir. Amaç yaprakların hedef değişken için (y 
    değerleri için) homojen (pure) olmasını sağlamaktır. Tabii bazen ağacın yapraklarının homojen olması için çok derinlere 
    inilmesi gerekir. Bu durum çeşitli nedenlerden dolayı istenmeyebilir. Bu durumda önceden belirlenmiş maksimum bir derinliğe 
    erişildiğinde işlemler kesilebilir. 

    Karar ağaçları denetimli (supervised) bir yöntemdir. Çünkü ağaç oluşturulurken yalnızca x değerleirnden değil aynı zamanda 
    y değerlerinden de faydalanılmaktadır. Ancak karar ağaçlarında birikimli eğitim yapılamaz. Yani eğitim veri kümesi genişletileceği 
    zaman tüm ağacın yeniden oluşturulması gerekir. 

    Pekiyi ağaç oluşturulduktan sonra kesitirim nasıl yapılacaktır? Kestirim için ağacın tepesinden (buna "ağacın kökü (root)" 
    de denilmektedir) sorular sorularak yapraklara kadar ilerlenir. İlgili yaprağa ulaşıldığında o yapraktaki sınıfların hangisi 
    fazlaysa karar ona göre verilmektedir. (Bu biçimdeki karar verme yaklaşımına "oylama (voting) denilmektedir.) Tabii yukarıda 
    da belirttiğimiz gibi ideal durum yaprakların homojen (pure) olmasıdır. Ancak yapraklar homojen değilse gelinen yapraktaki 
    duruma bakılarak karar verilir. 

    Her ne kadar buradaki anlatıma göre karar ağaçları sınıflandırma tarzı problemelere uygulanan bir yöntem gibi gözükse de  
    aslında regresyon problemlerine de benzer biçimde uygulanabilmektedir.

    Karar ağaçları yönteminin en önemli noktası en uygun sorunun nasıl belirleneceğidir. En uygun sorunun belirlenmesi 
    "entropy" ve "kazanç (gain)" kavramlarıyla ilgilidir. Bu konu izleyen paragraflarda açıklanacaktır.

    Karar ağaçları yöntemini kullanırken özel bazı uç durumalar dışında "özellik ölçeklemesi (feature scaling)" yapmaya 
    gerek yoktur. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    scikit-learn kütüphanesinde karar ağaçları için iki temel sınıf bulundurulmuştur: DecisionTreeClassifier ve DecisionTreeRegressor.
    DecisionTreeClassifier sınıfı sınıflandırma problemleri için, DecisionTreeRegressor sınıfı ise regresyon problemleri için 
    kullanılmaktadır.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    DecisionTreeClassifier sınıfının __init__ metodunun parametrik yapısı şöyledir:

    class sklearn.tree.DecisionTreeClassifier(*, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, 
            min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, 
            min_impurity_decrease=0.0, class_weight=None, ccp_alpha=0.0, monotonic_cst=None)
    
    criterion parametresi bölme konusunda kullanılacak entropy ölçüm yöntemini belirtmektedir. Bunun için genellikle "gini 
    ideksi (gini impurity de denilmektedir)" yöntemi ya da "Shannon entopisi" yöntemi kullanılmaktadır. Bu parametre "gini" 
    olarak girilirse (default durum) "gini indeksi" yöntemi, "entropy" olarak girilirse "Shannon entropisi" yöntemi seçilmiş 
    olur. max_depts parametresine ağacın maksimum yüksekliği girilebilir. Bu parametre girilmezse yapraklar homojen hale 
    getirilene kadar bölme devam ettirilir. Ancak uygulamacı bunu istemeyip belli bir maksimum derinlik belirleyebilir. 
    Metodun diğer parametreleri için scikit-learn dokümanlarına başvurabilirsiniz.

    Nesne yaratıldıktan sonra diğer scikit-learn sınıflarında olduğu gibi önce fit işlemi sonra da predict işlemi uygulanır. 
    Sınıfın score isimli metodu predict işlemini yapıp accuracy değerini hesaplamaktadır. 

    scikit-learn içerisindeki DecisionTreeClassifier sınıfı kategorik sütunları otomatik olarak anlayamamaktadır. Zaten bu 
    sınıf kategorik sütunları da sayısalmış gibi işleme sokmaktadır. Dolayısıyla eğer veri kümemizde kategorik sütunlar 
    varsa o sütunları LabelEncoder sınıfıyla sayısal hala getirebiliriz. Ancak LabelEncoder kategorik sınıfları 0, 1, 2, ... 
    biçiminde numaralandırmaktadır. Bu durumda sınıfların sanıfsal özellikleri algoritma tarafından göz ardı eidlmiş olur.  
    Kategorik sütunlar için yapılacak en iyi şey yine "one-hot-encoder" dönüştürmesidir. Bu sayede sütun soruları sınıflara 
    göre sorulur hale gelir. Bu konu izleyen paragraflarda açıklanmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------
    
#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "Breast Cancer Winconsin" veri kümesi üzerinde DecisionTreeClassifer sınıfı ile karar ağacı yöntemi 
    uygulanmıştır. Anımsanacağı gibi "Breast Cancer Winconsin" veri kümesinde kategorik sütunlar yoktur. Tüm sütunlar sayısal 
    biçimdedir. Örneğimizde DecisionTreeClassifer nesnesi yaratılırken max_depth parametresi girilmediği için tamamen homojen 
    bir yaprak durumu elde edilmiştir. Sonra oluşturulan bu karar ağacından da bir graphviz dosyası elde edilmiştir. Bunun için 
    sklearn.tree modülündeki Source sınıfının export_graphviz isimli sınıf metodu kullanılmıştır. Örneğin:

    export_graphviz(dtc, out_file='breast-cancer.dot')

    Sonra da örnekte oluşturulan bu ".dot" dosyası graphviz modülü ile görüntülenmiştir. Tabii anımsanacağı gibi görüntüleme 
    komut satırında "dot" programı ile de aşağıdaki gibi ".png" dosyası üretilerek manuel bir biçimde de yapılabilir:

    dot -T png -o breast-cancer.png breast-cancer.dot

    Source sınıfının export_graphviz isimli sınıf metodunun parametrik yapısı şöyledir:

    classmethod from_file(cls, filename, directory=None, format=None, engine=None, 
        encoding='utf-8', renderer=None, formatter=None)

    Burada format parametresi üretilecek görüntü dosyasının formatını belirtmektedir. Bu parametre girilmezse default durumda
    ".pdf" dosyası oluşturulmaktadır.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv("data.csv")

dataset_x = df.iloc[:, 2:-1].to_numpy()
dataset_y = np.zeros(len(df))
dataset_y[df['diagnosis'] == 'M'] = 1

"""
from sklearn.datasets import load_breast_cancer

bc = load_breast_cancer()
dataset_x = bc.data
dataset_y = bc.target
"""

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y \
        = train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=12345)

from sklearn.tree import DecisionTreeClassifier, export_graphviz

dtc = DecisionTreeClassifier()
dtc.fit(training_dataset_x, training_dataset_y)
predict_result = dtc.predict(test_dataset_x)
print(predict_result)

"""
from sklearn.metrics import accuracy_score

score = accuracy_score(test_dataset_y, predict_result)
print(score)
"""
score = dtc.score(test_dataset_x, test_dataset_y)
print(score)

export_graphviz(dtc, out_file='breast-cancer.dot')

import graphviz

dot = graphviz.Source.from_file(filename='breast-cancer.dot', format='png')
dot.view()

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "zambak (iris)" veri kümesi üzerinde karar ağacı yöntemi uygulanmıştır. Anımsanacağı gibi zambak veri 
    kümesi üç sınıflıdır. Bu veri kümesinde kategorik sütunlar yoktur. Zambak veri kümesi için oluşturulan karar ağıcının 
    yapraklarının üç sınıf temeleinde "pure" hale getirildiğine dikkat ediniz. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('Iris.csv')

dataset_x = df.iloc[:, 1:-1].to_numpy(dtype='float32')

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
dataset_y = le.fit_transform(df.iloc[:, -1])

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=12345)

from sklearn.tree import DecisionTreeClassifier, export_graphviz

dtc = DecisionTreeClassifier()
dtc.fit(training_dataset_x, training_dataset_y)
predict_result = dtc.predict(test_dataset_x)
print(predict_result)

"""
from sklearn.metrics import accuracy_score

score = accuracy_score(test_dataset_y, predict_result)
print(score)
"""
score = dtc.score(test_dataset_x, test_dataset_y)
print(score)

export_graphviz(dtc, out_file='breast-cancer.dot')

import graphviz

dot = graphviz.Source.from_file(filename='breast-cancer.dot', format='png')
dot.view()

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de kategorik değerler içeren sütunlara sahip bir veri kümesi üzerinde DecisionTreeClassifier sınıfını kullanalım. 
    Anımsanacağı biz daha önce gibi arabaların çeşitli kategorik özelliklerine dayalı olarak onların sınıflandırılmasına 
    yönelik "car" veri kümesi üzerinde çalışmıtık. Bu veri kümesinde sütunlar bir arabanın çeşitli özelliklerini kategorik 
    olarak betimliyordu. Veri kümesindeki y verileri toplam 4 sınıftan oluşuyordu:

    unacc
    acc
    good
    v-good

    Veri kümesinin 6 sütuna sahip olduğunu anımsayınız. Sütunların hepsi kategorik değerlerden oluşuyordu. Sütunları oluşturan 
    sınıflar da şöyleydi:

    buying       v-high, high, med, low
    maint        v-high, high, med, low
    doors        2, 3, 4, 5-more
    persons      2, 4, more
    lug_boot     small, med, big
    safety       low, med, high

    Veri kümesi "car.data" dosyasının içerisindeydi ancak CSV formatına ilişkindi. Dosyada bir başlık kısmı yoktu. Görünümü 
    aşağıdaki gibiydi:

    vhigh,vhigh,2,2,small,low,unacc
    vhigh,vhigh,2,2,small,med,unacc
    vhigh,vhigh,2,2,small,high,unacc
    vhigh,vhigh,2,2,med,low,unacc
    vhigh,vhigh,2,2,med,med,unacc
    .....

    Biz bu veri kümesi üzerinde DecisionTreeClassifier sınıfı ile fit işlemi yapmadan önce tüm kategorik sütunları "one-hot-encoder"
    dönüştürmesine sokmalıyız. Hedef sütun ise Labelencoder sınıfıyla sayısal hale getirilmelidir. Bu işlem şöyle yapılabilir:

    import pandas as pd

    df = pd.read_csv('car.data', header=None)
    df.columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']

    from sklearn.preprocessing import OneHotEncoder, LabelEncoder

    ohe = OneHotEncoder(sparse_output=False)
    ohe_dataset_x = ohe.fit_transform(df.iloc[:, :-1])

    le = LabelEncoder()
    dataset_y = le.fit_transform(df.iloc[:, -1].to_numpy(dtype='str'))

    Kodun tamamı aşağıda verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('car.data', header=None)
df.columns = ['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'class']

from sklearn.preprocessing import OneHotEncoder, LabelEncoder

ohe = OneHotEncoder(sparse_output=False)
ohe_dataset_x = ohe.fit_transform(df.iloc[:, :-1])

le = LabelEncoder()
dataset_y = le.fit_transform(df.iloc[:, -1].to_numpy(dtype='str'))

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(ohe_dataset_x, dataset_y, test_size=0.2)


from sklearn.tree import DecisionTreeClassifier, export_graphviz

dtc = DecisionTreeClassifier()
dtc.fit(training_dataset_x, training_dataset_y)

predict_result = dtc.predict(test_dataset_x)
print(predict_result)

score = dtc.score(test_dataset_x, test_dataset_y)
print(score)

export_graphviz(dtc, out_file='breast-cancer.dot')

import graphviz

dot = graphviz.Source.from_file(filename='breast-cancer.dot', format='png')
dot.view()

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de karar ağaçlarının algoritmik temeli üzerinde duralım. Karar ağaçlarının algoritmik temeli "entropy" kavramına 
    dayanmaktadır. Entropy düzensizliğin bir ölçüsüdür. Homojenite arttıkça entropi düşer, homojenite azaldıkça entropi artar. 
    Örneğin "+++++++-" kümesinin entropisi düşüktür. Ancak örneğin "++++----" ümesinin entropisi yüksektir. Entropi hesabı 
    için  çeşitli yöntemler kullanılabilmektedir. En sık kullanılan yöntemler "Shannon entropisi" ya da "Gini indeksi" yöntemlerdir. 
    Shannon entropisinin formülü şöyledir:

    H(S) = -∑[p(i) * log₂p(i)]

    Burada i sınıfların indekslerini belirtmektedir. p(i) i'inci sınıfın olasılığını (yani i'inci sınıfa ilişkin elemanların 
    sayısının satır sayısına oranını), log₂(pi) ise bu sayıların logaritmasını belirtmektedir. Örneğin + ve - iki sınıf belirtmek 
    üzere "++--+" kümesinin Shannon entropisini hesaplamak isteyelim. Burada 3 tane + , 2 tane - vardır. p(+) değeri 3/5 = 0.6, 
    p(-) değeri ise 2/5 = 0.4 biçimindedir. Bunarı bunları yerlerine yerleşirelim:

    H(S) = -[p(+) * log₂(p(+)) + p(-) * log₂(p(-))]
    H(S) = -[0.6 * log₂(0.6) + 0.4 * log₂(0.4)]
    H(S) ≈ 0.971

    Yukarıda da belirttiğimiz gibi diğer çok kullanılan bir entropi yönteminde de "Gini index'i ya da " "Gini impurity" denilmektedir. 
    Gini indeks şöyle hesaplanmaktadır:

    Gini(S) = 1 - ∑[p(i)²]

    Burada yine i sınıfların indekslerini belirtmektedir. Örneğin "++--+" kümesinin Gini indeksini şöyle elde edebiliriz: Burada 
    3 tane +, 2 tane - değeri vardır. Bunların olasılıkları şöyledir:

    p(+) = 3/5 = 0.6
    p(-) = 2/5 = 0.4

    O halde Gini indeksi şöyle hesaplanacaktır:

    Gini(S) = 1 - [p(+)² + p(-)²]
    Gini(S) = 1 - [(0.6)² + (0.4)²]
    Gini(S) = 1 - [0.36 + 0.16]
    Gini(S) = 1 - 0.52
    Gini(S) = 0.48

    Karar ağaçlarının algoritmik temelini şu soru oluşturmaktadır: "Bölme hangi sütuna göre ve o sütudaki hangi soruya göre 
    yapılacaktır?" İşte bu sorunun yanıtı iki aşamada oluşturulmaktadır:

    1) Alternatif bölme noktalarını oluşturulur.
    2) Alternatif bölme noktalarından sanki bölme yapılmış gibi işlemler gerçekleştirilir ve üst düğümün entropisinden alt 
    düğümlerin toplam entropisi çıkartılarak toplam kazanca bakılır. Toplam kazancın en yükek olduğu yerden bölme yapılır. 

    Pekiyi alternatif bölme noktaları nasıl oluşturulmaktadır? İşte bunun için değişik yöntemler kullanılabilmektedir. Kullanılan 
    yöntemler sütunların kategorik ya da sayısal olmasına göre değişebilmektedir. Biz bu bölme noktaları için kullanılabilecek 
    yöntemleri açıklarken aşağıdkai gibi basit bir veri kümesinden faydalanmak istiyoruz:

    X1  X2  X3         Y

    A   E   12      Pozitif
    B   E    6      Pozitif
    B   F    4      Negatif
    A   F   23      Pozitif
    C   G   18      Negatif
    C   E    9      Pozitif
    A   F   16      Negatif
    D   G    8      Negatif
    D   E   13      Pozitif
    ......

    Burada X1 sütunu A, B, C, D biçiminde dört sınıf, X2 sütunu da E, F, G biçiminde üç sınıf içermektedir. X3 de sayısal değerler 
    içeren bir sütundur. Bu örnek veri kümesinde y değerleri "Pozitif" ve "Negatif" biçiminde iki sınıflıdır. Yani burada iki 
    sınıflı bir sınıflandırma  problemi söz konusudur. 

    Kategorik sütunlar için alternatif bölme noktaları birkaç yöntemle oluşturulabilmektedir. En çok kullanılan iki yöntemi 
    açıklayalım:

    1) Alt küme oluşturma yoluyla alternatif bölme noktaları oluşturma yöntemi: Burada bölme sorusu "sütun değeri şu kümeye 
    dahil mi değil mi" biçiminde  yapılır. Örneğin X1 sütunu için alternatif bölme noktaları şöyle oluşturulabilir:

    "A mı" yoksa  "B ya da C ya da D mi?"
    "A ya da B" mi yoksa "C ya da D" mi?"
    "A ya da B ya da C mi" yoksa "D" mi?"
    ...

    Bunu küme gösterimi ile de ifade edebiliriz:

    "{A} mı yoksa {B, C, D} mi?"
    "{A, B} mi yoksa {C, D} mi?"
    "{A, B, C} mi yoksa {D} mi?"
    ....

    Pekiyi bu yöntemde n tane sınıfa sahip sütun için toplam kaç alternatif bölme noktası oluşturulur? n elemanlı bir kümenin 
    alt küme sayısı 2^n'dir. Ancak bu soruların yarısı zaten diğer yarısı ile simetrik olduğuna göre bu değeri ikiye bölmek 
    gerekir. Boş kümeyi de çıkartırsak buradan (2^n / 2) - 1 elde edilir. Tabii bu değer 2^(n- 1) - 1 biçiminde de ifade edilebilir. 
    Örneğin 4 sınıf için alternatif bölme noktalarının sayısı 7'dir. Yukarıdaki örnek veri kümesinde X1 kategorik sütunu için 7 
    alternatif bölme noktası X2 sütunu için 3 alternatif bölme noktası oluşacaktır. 

    2) Doğrudan sınıflara dayalı alternatif bölme noktası oluşturma yöntemi: Burada yukarıdaki alt küme yöntemi basitleştirilmiştir. 
    Sorular doğrudan sınıflara dayalı sorulmaktadır. Örneğin X1 sütunu için sorular şöyle oluşturulur:

    "A mı değil mi?"
    "B mi değil mi?"
    "C mi değil mi?"
    "D mi değil mi?"

    Burada sınıf sayısı kadar alternatif bölme noktası oluşturulmaktadır. 
    
    Pekiyi sütunlar sayısal ise bölme nasıl yapılabilir? İşte bunun için de birkaç yöntem kullanılmaktadır. Bu yöntemlerden 
    ikisini açıklayalım:

    1) Ardışıl değerlerin ortalaması yöntemi: Bu yöntemde sayısal sütun sıraya dizilir. Alt alta iki değerin ortalamaları 
    alınır. Tüm bu ortalamalar alternatif bölme noktaları olarak kullanılır. Örneğin X3 sütunu için alternatif bölme noktalarını
    oluşturmak isteyelim. Bu sütun sıraya dizlirse şöyle bir durum oluşacaktır:

    4
    6
    8
    9
    12
    13
    16
    18
    23

    Burada şu ortalamalar hesaplanır:

    mean(4, 6) = 5
    mean(6, 8) = 7
    mean(8, 9) = 8.5 
    mean(9, 12) = 10.5
    mean(12, 13) = 12.5
    mean(13, 16) = 14.5
    mean(16, 18) = 17
    mean(18, 23) = 20.5

    İşte alternatif sorular da bu oratalama değer kullanılarak şu biçimlerde sorulur:

    "X3 > 5 mi?"
    "X3 > 7 mi?"
   " X3 > 8.5 mi?"
    ...

    2) Değerleri kategorileştirme yöntemi: Bu yöntemde sütundaki değerler parçalara (örneğin eşit uzunluklu parçalara) 
    bölünerek adeta kategorik hale getirilir. Örneğin yukarıdaki veri kümesinde X3 sütunu 4 eşit parçaya bölünürse 
    dört kategori oluşturulmuş olur:

    Kategori 1: [4, 8.75)
    Kategori 2: [8.75 - 13.5)
    Kategori 3: [13.5 - 18.25)
    Kategori 4: [18.25 - 23]

    Sourlar da "X3 bu aralıkta mı" biçiminde sorulur. Burada aslında eşit aralıklı kategoriler yerine hedef değişkene dayalı 
    eşit frekanslı kategoriler de oluşturulabilir. Yani örneğin her kategoride dörder tane değer olacak biçimde kategoriler 
    oluşturulabilir. Sonra da bunların ortalamaları alınarak sorular bu ortalamalara dayalı biçimde sorulabilir. 

    Diğer alternatif bölme yöntemleri için başka kaynaklara başvurabilirsiniz. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                            123. Ders - 11/05/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Karar ağaçlarında alternatif bölme noktaları oluşturulduktan sonra en iyi bölmenin bu noktalardan hangisiyle yapılacağına 
    karar verilir. Sonra da o bölme (yani soru) tercih edilir. İşte hangi alternatif bölme noktasının daha iyi olduğuna entropy 
    ölçümüyle karar verilmektedir. Alternatif bir noktadan bölme yapıldığını (ancak bölmeyi henüz yapmıyoruz) varsayalım. Bu 
    durumda aşağıdaki gibi iki yaprak oluşacaktır:

            A
    B               C

    Burada A üst düğüm (yani bölme yapılmadan önceki küme) B ve C alt düğümlerdir (yani bölme yapıldıktan sonraki kümelerdir.)
    İşte üst düğümün entropisi ile alt düğümlerin toplam entropileri arasındaki fark ne kadar yüksekse kazanç (gain) o kadar 
    yüksek olur. Örneğin mevcut durumdaki (yani A dumundaki) entropinin 0.60 olduğunu varsayalım. Bölme yaptığımızda iki alt 
    düğümün entroplilerinin toplamının da 0.35 olduğunu düşünelim. Bu durumda biz böyle bir bölme yaparsak mevcut durumdan
    0.60 - 0.35 = 0.25 daha iyi duruma geçmiş oluruz. İşte tüm alternatif bölme noktaları için aşağıdaki kazanç hesaplanır:

    Kazanç = Üst_düğümün_entopisi - iki_alt_düğümün_toplam_entropisi

    Kazancı en yüksek olan alternatif bölme elde edilir. Bir düğümdeki alternatif tüm bölme noktaları için üst düğümün kümesi 
    aynı kalacağına göre ve kazancın en yüksek olması istendiğine göre alternatif bölme noktalarındaki alt düğümlerin toplam 
    entropisinin en küçük olduğu alternatif bölme noktası seçilecektir.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi scikit-learn içerisindeki DecisionTreeClassifier sınıfı hangi yöntemleri kullanmaktadır? İşte DecisionTreeClassifier
    sınıfı kategorik sütunlar üzerinde doğrudan işlem yapmamaktadır. Uygulamacaının önce kategorik sütunları sayısal hale 
    dönüştürmesi gerekir. DecisionTreeClassifier böylece sanki sütun sayısalmış gibi alternatif bölme noktalarını tespit 
    etmektedir. Ancak bunun şöyle bir sakıncası vardır: Örneğin 4 sınıflı bir sütun LabelEncoder ile sayısal biçime dönüştürülürse
    aşağıdaki gibi bir durum elde edilir:

    0
    1
    2
    1
    2
    3
    2
    1
    ...

    Burada peşi sıra gelen iki değerin ortalaması yöntemi kullanıldığında bölme sorusu sanıflarla ilişkili olmaktan çıkmaktadır. 
    Bu da daha kötü alternatif bölme noktalarının oluşturulmasına yol açabilmektedir. İşte burada önerilen önce one-hot-encoding 
    yapılmasıdır. Çünkü yukarıdaki gibi bir sütun one-hot-encoding yapılırsa aşağıdaki gibi 4 farklı sütun elde edilecektir:

    1 0 0 0 
    0 1 0 0
    0 0 1 0 
    0 1 0 0 
    0 0 1 0
    0 0 0 3
    0 1 0 0 
    ...

    İşte bu durumda bu sütunlara peşi sıra gelen iki değerin ortalaması sorucu sorulursa bu durum tamamen "doğrudan sınıflara 
    dayalı alernatif bölme noktası oluşturma yöntemi" ile aynı duruma gelmektedir. O halde örneğin yukarıdaki veri kümesi için 
    biz kategorik sütunları one-hot-encoding yaparsak bu durumda X1 sütunu için alternatif bölme noktaları şöyle oluşturulacaktır:

    "X1 A mı değil mi?"
    "X1 B mi değil mi?
    "X1 C mi değil mi?"
    "X1 D mi değil mi?"

    Ancak DecisionTreeClassifier sınıfının kaynak kodları incelendiğinde eğer veri kümesi Pandas DataFrame nesnesi olarak 
    verilmişse ve bu nesnesinin ilgili sütunun dtype özniteliği "kategorik" biçimde işaretlenmişse bu durumda DecisionTreeClassifier 
    doğrudan hiç sayısal hale dönüştürmeden sütunu kabul etmekte ve alternatif ayrıştırma noktalarını "alt küme oluşturma yöntemi 
    ile" elde etmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Karar ağaçları yalnızca sınıflandırma problemlerinde değil regresyon problemlerinde de kullanılabilmektedir. Ancak regresyon 
    problemlerinde karar ağaçları genellikle diğer alternatif yöntemlere göre daha kötü performans gösterme eğilimindedir. Karar 
    ağaçları regresyon problemlerinde kullanılırken yapraklar eğitim veri kümesindeki y değerlerinden oluşur. Yani adeta regresyon 
    problemindeki y değerleri sürekli değerler değil de birer sınıf belirtiyormuş gibi işlemlere sokulmaktadır. Yani işlem sonucunda 
    eğer "pure" bir durum oluşturulursa eğitim veri kümesinde olmayan bir değer elde edilmemektedir. 

    Karar ağaçlarıyla regresyon problemlerini çözmek içi scikit-learn kütüphanesindeki DecisionTreeRgressor sınıfı kullanılmaktadır. 
    Sınıfın genel kullanımı DecisionTreeClassifier sınıfına benzemektedir. Sınıfın __init__ metodunun parametrik yapısı şöyledir:

    class sklearn.tree.DecisionTreeRegressor(*, criterion='squared_error', splitter='best', max_depth=None, min_samples_split=2, 
            min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, 
            min_impurity_decrease=0.0, ccp_alpha=0.0, monotonic_cst=None)

    Buradaki önemli parametreler DecisionTreeClassifer sınıfı ile aynıdır. Bu sınıf türünden nesne yaratıldıktan sonra yine fit 
    işlemi ve predict işlemi yapılmaktadır. Sınıfın score metodu bize R^2 değerini bir ölçüt olarak vermektedir. 

    Pekiyi karar ağaçları ile regresyon işlemi problemleri çözülürken sütunlar üzerinde özellik ölçeklemesi (feature scaling)
    yapmaya gerek var mıdır? İşte genel olarak tıpkı sınıflandırma problemlerind olduğu gibi aynı gerekçelerle özellik ölçeklemssi
    yapmaya gerek duyulmaz. Ancak bazı özel durumlarda (örneğin kazancın hesaplanması yöntemleri bunu gerektiriyorsa) özellik
    ölçeklemesi yapılabilir. Tabii eğer veri kümesinde kategorik sütunlar varsa bunlar one-hot-encoding yöntemiyle yine 
    sayısal biçime dönüştürülmelidir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "Boston Hausing Prices" veri kümesi üzerinde karar ağaçları uygulanmıştır. Oluşturulan karar ağacı 
    incelendiğinde yapraklardaki değerlerin eğitim veri kümesindeki y değerlerinden oluştuğu görülecektir. Yani biz bu yöntemle 
    bir evin fiyatını tahmin ederken her zaman zaten mevcut bir evin fiyatı bize verilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

highway_class = df.iloc[:, 8].to_numpy()

from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)
ohe_highway = ohe.fit_transform(highway_class.reshape(-1, 1))

dataset_y = df.iloc[:, -1].to_numpy()
df.drop([8, 13], axis=1, inplace=True)
dataset_x = pd.concat([df, pd.DataFrame(ohe_highway)], axis=1).to_numpy()

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.1)

from sklearn.tree import DecisionTreeRegressor

dtr = DecisionTreeRegressor()
dtr.fit(training_dataset_x, training_dataset_y)
rsquare = dtr.score(test_dataset_x, test_dataset_y)
print(f'R^2:  {rsquare}')

predict_result = dtr.predict(test_dataset_x)
print(predict_result) 

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(test_dataset_y, predict_result)
print(f'Mean Absolute Error: {mae}')

from sklearn.tree import export_graphviz
import graphviz

export_graphviz(dtr, out_file='boston.dot')
dot = graphviz.Source.from_file(filename='boston.dot', format='png')
dot.view()

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi regresyon problemleri için oluşturulan karar ağaçlarının algoritmik temeli nasıldır? Regresyon için oluşturulan 
    karar ağaçlarında alternatif bölme noktaları tamamen sınıflandırma amacıyla oluşturulmuş olan karar ağaçlarıyla aynı biçimde 
    oluşturulmaktadır. Ancak regresyon için oluşturulan karar ağaçlarında entropi yöntemi kullanılmaz. Onun yerine "karesel 
    ortalama (mean squared error)" gibi "ortalama mutlak değer (mean absolute error)" gibi aşina olduğumuz yöntemler kullanılır. 
    Örneğin A üst düğümünün alternatif bir bölmesi B ve C olsun:

        A
    B       C

    İşte buradaki kazanç entropi hesabıyla değil karesel ortalama ile şöyle hesaplanmaktadır:

    Kazanç = üst_düğümün_karesel_ortalaması - iki alt_düğümün_karesel_ortalaması_toplamı

    Örneğimizde üst düğümün (yani A düğümünün) karesel ortalaması (mean squared error) demekle A düğümüne ilişkin kümenin y 
    değerlerinin karesel ortalaması kastedilmektedir. Karesel ortalamanın şöyle hesaplandığını anımsayınız:

    MSE = (1/n) * Σ(y_i - ŷ_i)²

    Burada y_i değerleri ilgili kümenin y değerlerini, ŷ_i ise bunların ortalamasını belirtmektedir. Anımsanacağı gibi aslında 
    bu istatistikteki varyans formülüyle aynıdır. 

    Pekiyi alternatif bölme noktalarından yukarıda ölçütlere göre en iyi bölmeler tespit edilip bu işlem devam ettirilidiğinde
    varılması istenen hedef ne olacaktır? Sınıflandırma problemindeki hedef kümelerin homojen hale getirilmesiydi. İşte buradaki 
    hedef de benzer biçimde kümlerin tek elemana ya da aynı değere ilişkin elemanlara indirgenmesidir. Yani başka bir deyişle 
    burada aslında y değerleri adeta bir sınıf gibi düşünülmektedir. Tabii maksimum derinlik belirtilerek yaprakların homojen 
    olması koşulu ortadan kaldırılabilir. Bu durumda yapraklar y değerlerinden yalnızca bir tanesi olmaktan çıkacaktır. Yapraklarda 
    bir grup satır bulunacağından dolayı ve bunların y değerleri de birbirinden farklı olacağından dolayı kestirim bu değerlerin 
    ortalaması biçiminde yapılacaktır. Yani derinlik kısıtlanırsa yaprakların değerleri aslında onlara ilişkin kümenin ortalama 
    değeri haline gelmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aslında karar ağaçlarında algoritmik yapı olarak ikili ağaçlar yerine ikiden daha fazla alt düğümü olan ağaçlar da 
    kullanılabilmektedir. Ancak en fazla kullanılan karar ağacı algoritması ikili ağaç temeline dayanmaktadır. Bu klasik yönteme
    "CART (Classification and Regression Trees" yöntemi de denilmektedir. scikit-learn CART yöntemini kullanmaktadır. Diğer 
    alternatif yöntemlerden biri de ID3 denilen yöntemdir. Bu yöntem yalnızca sınıflandırma için kullanılır. ID3 yönteminde Ağaç 
    ikili değil daha fazla alt düğüm içermektedir. ID3'ün gelişmiş biçimlerine CD4, CD5 gibi isimler verilmiştir. Bunların dışında 
    "CHAID (Chi-squared Automatic Interaction Detector)" ve "MARS (Multivariate Adaptive Regression Splines)" gibi yöntemler 
    de vardır. Bunlar için başka dökümanlara başvurabilirsiniz. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi karar ağaçları hangi durumlarda tercih edilmelidir? Aslında diğer alternatif yöntemlere göre karar ağaçlarının 
    tercih edilebileceği bazı durumlar söz konusu olmakla birlikte bu konuda kesin yargılarda bulunabilme olanağı yoktur. En 
    doğrusu çeşitli alternatif yöntemlerin denenip bir kararın verilmesidir. Ancak karar ağaçlarını diğer yöntemlerle birkaç 
    bakımdan kıyaslayıp masaya yatırabiliriz:
    
    - Karar ağaçları insan düşüncesine yakındır. Dolayısıyla verilen kararın izlediği yol sözcüklerle daha iyi açıklanabilmektedir. 
    Böyle bir gereksinim varsa karar ağaçları tercih edilebilir. 

    - Bilgilerin aşama aşama elde edildiği durumlarda (doktor muayenesi gibi) olayın akışı itibari ile karar ağaçları daha uygun 
    bir yöntem olabilmektedir. Kişiler karar ağaçlarına bakarak işlemleri manuel biçimde uygulayabilirler. (Örneğin doktor karar 
    ağacına bakarak "şu var mı? Varsa şu var mı?" gibi sorularla ilerleyerek hastanın durumunu anlayabilir.)

    - Karar ağaçları için özellik ölçeklemesi gibi ön işlemler gerekmemektedir. Bu da bu ön işlemler için vakit kaybının elimine 
    edilmesi anlamına gelmektedir. 

    - Karar ağaçları doğrusal olarak ayrıştırılamayan veri kümelerinde kullanılabilir. Çünkü burada ayrıştırma tek bir doğru 
    ile değil bir grup doğru ile yapılmaktadır.

    - İstatistiksel regresyon uç değerlerden karar ağaçlarına göre daha olumsuz etkilemektedir. Uç değerler söz konusu ise karar 
    ağaçları bir alternatif olarak düşünülebilir. 

    - Karar ağaçlarında satırların sütunlarında eksik veriler bulunduğunda herhangi bir doldurma (imputation) yapılmasa da 
    algoritma işletilebilir. Çünkü karar verme işlemleri sütunsal olarak yapıldığı için sütunlardaki eksik veriler görmezden 
    gelinebilir. Aynı satırın başka sütunları ile ilgili kararlarda eksik veri içeren satırların ilgili sütunları kullanılabilir. 

    - Karar ağaçları birikimli bir eğitime uygun değildir. Yani veri kümesine bir satır eklendiğinde tamamen bütün ağacın yeniden
    oluşturulması gerekir. 

    - Karar ağaçlarında veri kümesi çok küçük olduğunda ağaç bu durumdan diğer alternatif yöntemlere göre daha fazla etkilenebilmektedir. 
    Ancak diğer alternatif yöntemlere göre küçük veri kümelerinde duruma göre daha başarılı sonuçlar elde edilebilmektedir. 

    - Karar ağaçları "overfitting" olgusuna daha açıktır. Özellikle regresyon problemlerinde bu durum daha kötü bir hal alabilmektedir. 
    Yani karar ağaçları eğitim veri kümesine daha bağlı bir yöntemdir. Kötü bir küme ile eğitim yapılırsa overfitting ciddi 
    boyutlara varabilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Makine öğrenmesinde ve istatistikte "topluluk yöntemleri (ensemble methods)" ya da "topluluk öğrenmesi (ensemble learning)" 
    demekle "karar verme için birden fazla yöntemin kullanılması" anlaşılmaktadır. "Ensemble" sözcüğü "topluluk", "grup" gibi 
    anlamlara gelmektedir. Biz de bu bölümde topluluk yöntemleri üzerinde duracağız. Topluluk yöntemleri değişik kategorilere 
    ayrılarak ele alınabilmektedir. Biz burada en fazla kullanılan topluluk yöntemleri üzerinde duracağız.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Topluluk yöntemlerinden en sık kullanılanlardan biri "oylama (voting)" denilen yöntemdir. Oylama yöntemi sınıflandırma ve 
    regresyon problemlerinde kullanılabilmektedir. Oylama yönteminde problem değişik yöntemlerle (ya da değişik hyper parametrelerle) 
    çözülür. Sonra kestirim yapılırken tüm bu yöntemlere göre kestirimler yapılır. En yüksek oyu alan sınıf kestirimin nihai 
    değeri olarak belirlenir. Örneğin "positive" ve "negative" biçiminde ikili sınıflandırma problemi söz konusu olsun. Biz de 
    bu problemi alternatif olarak A, B, C, D ve E yöntemleriyle çözmüş olalım. Şimdi kesitirim yaparken kestirimde bu beş yöntemi 
    ayrı ayrı kullanalım. Şu sonuçşarın elde edildiğini varsayalım:

    A -> negative
    B -> negative
    C -> positive
    D -> negative
    E -> negative

    Burada oylama sonucunda "negative" değeri "negative" değerinden daha fazla oy almıştır. O zaman kestirimin nihai sonucu olarak 
    biz "negative" kararını verebiliriz.

    Oylama yönteminde tamamen farklı yöntemlerin kullanılması gerekmemektedir. Aynı yöntemler farklı hyper parametrelerle de 
    oylamaya sokulabilmektedir.

    Aşağıdaki örnekte "soğuk terapisi (cryotherapy)" denilen alternatif bir tedavi yönteminin başarısına ilişkin bir veri kümesi 
    kullanılmıştır. Bu veri kümesini Excel dosyası olarak aşağıdaki bağlantıdan indirebilirsiniz:

    https://archive.ics.uci.edu/dataset/429/cryotherapy+dataset

    Burada Excel dosyasını manuel biçimde "save as" özelliği ile CSV formatına dönüştürebilirsiniz. Ancak dönüştürülen verilerde 
    ondalık ayırcı "," biçiminde olabilir. (Bu durum aslında Excel'den de ayarlanabilmektedir. Excel de default olarak bunu 
    işletim sisteminin bölgesel ayarlarından almaktadır.) Eğer ondalık ayıracı "," biçimindeyse onu "." biçiminde değiştirmeniz 
    gerekir. Ayrıca Excel bazı ürettiği CSV dosyalarında sütun ayıraçlarını "," yerine ';' biçiminde de oluşturabilmektedir. 
    Bu duruma da dikkat ediniz. 

    "Cryotherapy" veri kümesi aşağıdaki görünümdedir:

    sex;age;Time;Number_of_Warts;Type;Area;Result_of_Treatment
    1;35;12;5;1;100;0
    1;29;7;5;1;96;1
    1;50;8;1;3;132;0
    1;32;11.75;7;3;750;0
    1;67;9.25;1;1;42;0
    1;41;8;2;2;20;1
    1;36;11;2;1;8;0
    1;59;3.5;3;3;20;0
    1;20;4.5;12;1;6;1
    2;34;11.25;3;3;150;0
    2;21;10.75;5;1;35;0
    2;15;6;2;1;30;1
    2;15;2;3;1;4;1
    2;15;3.75;2;3;70;1
    2;17;11;2;1;10;0
    2;17;5.25;3;1;63;1
    .....

    Burada "sex" ve "Type" kategorik sütunlardır. 

    Bu örneğimizde SVC, DecisionTreeClassifier, LogisticRegression yöntemleri ile problem çözülmüş sonra kestirilecek değerler 
    için oylama yapılmıştır. Buradaki bazı yöntemler özellik ölçeklemesine gereksinim duymaktadır. Biz burada özellik ölçeklemesini 
    işin başında yaptık. Özellik ölçeklemesi gerekmediği halde ölçekleme yapmak genellikle (her zaman olmayabilir) ilgili 
    yönetmelerde bir soruna yol açmamaktadır. Bir veri kümesini benzer biçimde işleme sokarken kategorik sütunların sayısal 
    hale dönüştürülmesi gerekebilir. Bunun için bazı yöntemlerde LabelEncoder bazı yöntemlerde one-hot-encoding uygulamak 
    uygun olmaktadır. 
    
    Eğer bazı yöntemlere özellik ölçeklemesi ve değişik sütun dönüştürmeleri uygulamak gerekiyorsa bunun için "pipeline" 
    mekanizmasından faydalanabilirsiniz. İzleyen paragraflarda bu mekanizmanın oylama yönteminde naısl kullanılacağını da 
    görceğiz. 

    Biz aşağıdaki örnekte oylama işlemini yapan VotingClassifier isimli bir sınıf oluştuduk. Bu sınıf bizden tahminleyici 
    (estimators) nesneleri alıp onlar üzerinde fit ve predict işlemlerini yapmaktadır. predict işlemi yapıldıktan sonra hangi 
    değer çoğunluktaysa o değer nihai sonuç olarak elde edilmiştir. Bunun için scipy kütüphanesindeki mode fonksiyonu 
    kullanılmıştır. Bu örneği eğitim ve test veri kümelerinde değişiklik yaraılması amacıyla çeşitli kereler çalıştırıp 
    sonuçlara bakıldığında veri kümesi için karar ağaçlarının mükemmel sonuç verdiği de görülmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('cryotherapy.csv', delimiter=';')

df_x = df.iloc[:, :-1]
df_y = df.iloc[:, -1]

from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)

oge_columns = ohe.fit_transform(df_x[['sex', 'Type']])
df_x.drop(['sex', 'Type'], inplace=True, axis=1)
df_x[['sex_male', 'sex_female', 'type_1', 'type_2', 'type_3']] = oge_columns

dataset_x = df_x.to_numpy()
dataset_y = df_y.to_numpy()

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

ss = StandardScaler()
ss.fit(training_dataset_x)
scaled_training_dataset_x = ss.transform(training_dataset_x)
scaled_test_dataset_x = ss.transform(test_dataset_x)

class VotingClassifier:
    def __init__(self, estimators):
        self.estimators = estimators
        self.fitted_flag = False
        self.predict_flag = False
        
    def fit(self, x, y):
        for estimator in self.estimators:
            estimator.fit(x, y)
        self.fitted_flag = True
    
    def predict(self, x):
        if not self.fitted_flag:
            raise ValueError('predict on not fitted dataset')
        self.predict_flag = True
        self.results = [estimator.predict(x) for estimator in self.estimators]
        return mode(self.results, axis=0, keepdims=True).mode.flatten()
    
    def score(self, y, y_hat):
        if not self.predict_flag:
            raise ValueError('score on not predictes dataset')
        acc_estimators = [accuracy_score(y, y_hat) for y_hat in self.results]
        acs = accuracy_score(y, y_hat)
        return acs,  acc_estimators
        
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from scipy.stats import mode

svc = SVC()
lr = LogisticRegression()
dtc = DecisionTreeClassifier()

vc = VotingClassifier([svc, lr, dtc])
vc.fit(scaled_training_dataset_x, training_dataset_y)
predict_result = vc.predict(scaled_test_dataset_x)
print(predict_result)

accuracy, accuracy_estimators = vc.score(test_dataset_y, predict_result)
print(accuracy, accuracy_estimators)

#----------------------------------------------------------------------------------------------------------------------------
    Sınıflandırma problemlerinde oylama yöntemi çoğunluk oyu yerine ortalama esasıyla da yapılabilmektedir. Örneğin iki sınıflı 
    bir modelde bazı yöntemler bize sonucu 0 ile 1 arasında bir sayı olarak da vermektedir. Biz bu yöntemlerde predict yaptığımızda
    sonuç hangi tarafa yakınsa o değeri elde eddriz. Ancak olasılıkların ortlaması alınırsa bazen daha iyi sonuçlar oluabilmektedir. 
    Örneğin 3 farklı sınıflandırıcıyı kullanarak oylama yapmış olalım. Bir sınıflandırıcı bize 0.99 gibi dir değer versin, diğer 
    iki snıflandırıcı da 0.48, 0.45 gibi değerler versin. Burada sınıfsal oylama yapıldığında nihai sonuç 0 olarak tespit edilecektir. 
    Halbuki bu olasılıkların ortalaması alınırsa nihai sonuç 1 olarak verilecektir.   
    
    Oylama yönteminde ortalama yöntemi özellikle regresyon problemlerinde default yöntem olarak kullanılmaktadır. Yani örneğin 
    regresyon problemlerinde problemi bir grup yöntemle çözeriz. Sonra kestirim aşamasında bu yöntemlerin hepsiyle kestirimde 
    bulunup birer değer elde ederiz. Nihayi değer olarak bunların ortalamasını alabiliriz. 

    Oylama yönteminde genellikle sınıfsal oylamalar için "hard voting", ortalamalar kullanılarak oylamalar için ise "soft
    voting" denilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                            124. Ders - 17/05/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Oylama yöntemi için scikit-learn içerisinde sklearn.ensemble modülünde VotingClassifier ve VotingRegressor isimli sınıflar 
    bulundurulmuştur. Bu sınıfların __init__ metotlarının parametrik yapısı şöyledir:

    class sklearn.ensemble.VotingClassifier(estimators, *, voting='hard', weights=None, 
            n_jobs=None, flatten_transform=True, verbose=False)

    class sklearn.ensemble.VotingRegressor(estimators, *, weights=None, n_jobs=None, verbose=False)

    Metotların birinci parametreleri yöntemlere ilişkin demet listelerinden oluşmaktadır. Bu listenin her elemanı olan demet 
    bir isim ve yönteme ilişkin sınıf nesnesi içermektedir. Metotlardaki weights parametresi yöntemlere ağırlık atamak için 
    kullanılmaktadır. Yani biz istersek her yönteme farklı bir ağırlık etkisi verebiliriz. Tabii default durumda her yöntemin 
    ağırlığı eşit olmaktadır. VotingClassifier sınıfının (VotingRegressor sınıfında bu parametre yoktur) voting parametresi 
    "hard" ya da "soft" olarak girilebilmektedir. "hard" (default değer) tamamen kestirilen sınıfların sayısına bakmaktadır. 
    "soft" ise sınıflarda olasılıksal bir değer üretiliyorsa bu olasılıkların ortalamasını alarak sonucu kestirmektedir. 
    Tabii 'soft' yöntemin uygulanması için her tahminleyicinin bir olasılık üretme özelliğinin olması gerekir. Örneğin SVC
    yçnteminde ayrıca olasılık üretilebilmesi için probability parametresnin True olarak geçilmesi gerekir. (Bu parametre 
    default durumda False biçimdedir.) Eğer tahminleyici bir olasılık üretimiyorsa predict işleminde exception oluşmaktadır. 

    Sınıfların kullanımı sklearn sınıflarında olduğu gibidir. Önce fit işlemi yapılır sonra da predict işlemi yapılır. score 
    metotları VotingClassifier için "accuracy" değerini, VotingRegressor sınıfı için ise R^2 değerini vermektedir. 

    Aşağıdaki örnekte "cryotherapy" veri kümesi üzerinde VotingClassifier sınıfı kullanılarak oylama yöntemi uygulanmıştır.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('cryotherapy.csv', delimiter=';')

df_x = df.iloc[:, :-1]
df_y = df.iloc[:, -1]

from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)

oge_columns = ohe.fit_transform(df_x[['sex', 'Type']])
df_x.drop(['sex', 'Type'], inplace=True, axis=1)
df_x[['sex_male', 'sex_female', 'type_1', 'type_2', 'type_3']] = oge_columns

dataset_x = df_x.to_numpy()
dataset_y = df_y.to_numpy()

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(training_dataset_x)
scaled_training_dataset_x = ss.transform(training_dataset_x)
scaled_test_dataset_x = ss.transform(test_dataset_x)

from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier

svc = SVC()
lr = LogisticRegression()
dtc = DecisionTreeClassifier()

from sklearn.ensemble import VotingClassifier

vc = VotingClassifier([('SVC', svc), ('LogisticRegression', lr), ('DecisionTreeClassifier', dtc)])

vc.fit(scaled_training_dataset_x, training_dataset_y)
predict_result = vc.predict(scaled_test_dataset_x)
print(f'Predict result: {predict_result}')

score = vc.score(scaled_test_dataset_x, test_dataset_y)
print(f'Accuracy: {score}')

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte arabaların mil başına yaktıkları yakıtın tahmin edilmesine yönelik "auto-mpg.data" veri kümesi kullanılmıştır.
    Örnekte kestirim için Lasso, SVR ve DecisionTreeRegressor sınıfları ortalama esasında oylamaya sokulmuştur. İşlemler 
    scikit-learn içerisindeki VotingRegressor sınıfıyla yapılmıştır.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd
import numpy as np

df = pd.read_csv('auto-mpg.data', delimiter=r'\s+', header=None)

df = df.iloc[:, :-1]
df.iloc[df.loc[:, 3] == '?', 3] = np.nan

df[3] = df[3].astype('float64')

from sklearn.impute import SimpleImputer

si = SimpleImputer(strategy='mean', missing_values=np.nan)
df[3] = si.fit_transform(df[[3]])

df_1 = df.iloc[:, :7]
df_2 = df.iloc[:, [7]]

dataset_1 = df_1.to_numpy()
dataset_2 = df_2.to_numpy()

import numpy as np
from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)
dataset_2 = ohe.fit_transform(dataset_2)

dataset = np.concatenate([dataset_1, dataset_2], axis=1)

dataset_x = dataset[:, 1:]
dataset_y = dataset[:, 0]

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(training_dataset_x)
scaled_training_dataset_x = ss.transform(training_dataset_x)
scaled_test_dataset_x = ss.transform(test_dataset_x)
        
from sklearn.linear_model import Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR

lr = Lasso()
dtr = DecisionTreeRegressor()
svr = SVR()

from sklearn.ensemble import VotingRegressor

vr = VotingRegressor([('LinearRgression', lr), ('DecisionTreeRegressor', dtr), ('SVR', svr)])
vr.fit(scaled_training_dataset_x, training_dataset_y)

predict_result = vr.predict(scaled_test_dataset_x)
print(f'Predict result: {predict_result}')

score = vr.score(scaled_test_dataset_x, test_dataset_y)
print(f'R^2 score: {score}')

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(test_dataset_y, predict_result)
print(f'Mean absolute error: {mae}')

#----------------------------------------------------------------------------------------------------------------------------
    Daha önceden de belirttiğimiz gibi bazı yöntemler birtakım önişlemlere gereksinim duyarken bazı yöntemler bunlara gereksinim 
    duymayabiliyordu. Biz yukarıdaki örneklerde tüm tahminleyiciler için aynı önişlemleri yaptık. VotingClassifier için "crypotherapy" 
    örneğini anımsayınız. Burada aslında DecisionTreeClassifier için özellik ölçeklemesi yapmaya gerek yoktur. (Gerçi karar 
    ağaçlarında özellik ölçeklemesi yapmak çoğu kez bir soruna yol açmamaktadır.) İşte bu tür durumlarda bazı tahminleyiciler için 
    değişik önişlemler yapılacaksa pipeline mekanizmasından faydalanılabilir. Örneğin:

    pl_svc = make_pipeline(StandardScaler(), SVC())
    pl_lr = make_pipeline(StandardScaler(), LogisticRegression())
    dtc = DecisionTreeClassifier()

    Burada SVC yöntemi için özellik ölçeklemesi yapılmıştır, LogisticRgression yöntermi için özellik ölçeklemesi yapılmıştır. 
    Ancak DecisionTreeClassifier yöntemi için özellik ölçeklemesi yapılmamıştır. Tabii artık VotingClassifer nesnnesini 
    oluştururken biz bu pipeline nesnelerini kullanmalıyız:

    vc = VotingClassifier([('SVC', pl_svc), ('LogisticRegression', pl_lr), ('DecisionTreeClassifier', dtc)])

    Bu biçimdeki çözümü bir bütün olarak aşağıda veriyoruz.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('cryotherapy.csv', delimiter=';')

df_x = df.iloc[:, :-1]
df_y = df.iloc[:, -1]

from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)

oge_columns = ohe.fit_transform(df_x[['sex', 'Type']])
df_x.drop(['sex', 'Type'], inplace=True, axis=1)
df_x[['sex_male', 'sex_female', 'type_1', 'type_2', 'type_3']] = oge_columns

dataset_x = df_x.to_numpy()
dataset_y = df_y.to_numpy()

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y =\
        train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import VotingClassifier

pl_svc = make_pipeline(StandardScaler(), SVC())
pl_lr = make_pipeline(StandardScaler(), LogisticRegression())
dtc = DecisionTreeClassifier()

vc = VotingClassifier([('SVC', pl_svc), ('LogisticRegression', pl_lr), ('DecisionTreeClassifier', dtc)])

vc.fit(training_dataset_x, training_dataset_y)
predict_result = vc.predict(test_dataset_x)
print(f'Predict result: {predict_result}')

score = vc.score(test_dataset_x, test_dataset_y)
print(f'Accuracy: {score}')

#----------------------------------------------------------------------------------------------------------------------------
    Benzer biçimde arabaların mil başına yaktıkları yakıtın tahmin edilmesine ilişkin "auto-mpg.data" veri kümesi üzerinde de 
    pipeline mekanizmasını kullanabiliriz. Anımsanacağı gibi DecisionTreeRegressor yöntemleri için özellik ölçeklemesi gerekmemekte
    ancak Lasso ve SVR yöntemleri için özellik ölçeklemesi gerekmektedir. Bu durumda pipeline nesnelerini şöyle oluşturabiliriz:

    pl_lasso = make_pipeline(StandardScaler(), Lasso())
    pl_svr = make_pipeline(StandardScaler(), SVR())
    dtr = DecisionTreeRegressor()

    VotingRegressor nesnesini de şöyle oluşturabiliriz:

    vr = VotingRegressor([('Lasso', pl_lasso), ('SupportVectorRegressor', pl_svr), ('DecisionTreeRegressor', dtr)])

    Örnek bir bütün olarak aşağıda verilmiştir.  
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd
import numpy as np

df = pd.read_csv('auto-mpg.data', delimiter=r'\s+', header=None)

df = df.iloc[:, :-1]
df.iloc[df.loc[:, 3] == '?', 3] = np.nan
df[3] = df[3].astype('float64')

from sklearn.impute import SimpleImputer

si = SimpleImputer(strategy='mean', missing_values=np.nan)
df[3] = si.fit_transform(df[[3]])

df_1 = df.iloc[:, :7]
df_2 = df.iloc[:, [7]]

dataset_1 = df_1.to_numpy()
dataset_2 = df_2.to_numpy()

import numpy as np
from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)
dataset_2 = ohe.fit_transform(dataset_2)

dataset = np.concatenate([dataset_1, dataset_2], axis=1)

dataset_x = dataset[:, 1:]
dataset_y = dataset[:, 0]

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Lasso
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import VotingRegressor

pl_lasso = make_pipeline(StandardScaler(), Lasso())
pl_svr = make_pipeline(StandardScaler(), SVR())
dtr = DecisionTreeRegressor()

vr = VotingRegressor([('Lasso', pl_lasso), ('SupportVectorRegressor', pl_svr), ('DecisionTreeRegressor', dtr)])
vr.fit(training_dataset_x, training_dataset_y)

predict_result = vr.predict(test_dataset_x)
print(f'Predict result: {predict_result}')

score = vr.score(test_dataset_x, test_dataset_y)
print(f'R^2 score: {score}')

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(test_dataset_y, predict_result)
print(f'Mean absolute error: {mae}')

#----------------------------------------------------------------------------------------------------------------------------
    scikit-learn içerisindeki ensemble yöntemleri uygulayan sınıflar sklearn dünyası için oluşturulmuştur. Pekiyi örneğin 
    biz oylama yöntemine bir de yapay sinir ağı modeli eklemek istesek ne yapmalıyız? Biz kursumuzda yapay sinir ağlarını Keras 
    kütüphanesi ile oluşturmuştuk. Keras kütüphanesinin de scikit-learn ile bir ilgisi yoktur. İşte Keras modellerinin bu tür 
    durumlarda scikit-learn içerisinden kullanılabilmesi için KerasClassifier ve KerasRegressor isimli uyumlandırma sınıflrı 
    oluşturulmuştur. Bu iki sınıf scikit-learn içerisinde değil scikeras denilen başka bir kütüphanesinin içerisinde bulunmaktadır. 
    (Eskiden bu iki sınıf Tensorflow içerisindeydi. Sonra bunlar scikeras içerisine alındı.) Bu kütüphane eğer sisteminde hazır 
    kurulu değilse onu şöyle kurabilirsiniz:

    pip install scikeras

    KerasClassifier nesnesi yaratılırken fonksiyonun birinci parametresine (model parametresine) Keras modelini oluşturan 
    fonksiyon verilir. Diğer parametreler Keras'ın fit metoduna geçirilecek parametrelerini belirtmektedir. Örneğin:

    kc = KerasClassifier(model=create_keras_model, epochs=10, batch_size=10, verbose=0)

    Keras modelini oluşturan fonksiyon katman nesnelerini eklemeli ve compile işlemini yapıp model nesnesiyle geri dönmelidir.
    Tabii fit işlemini bu fonksiyon yapmaz. fit işlemi adaptör sınıflar tarafından yapılmaktadır. Örneğin:
    
    def create_keras_model():  
        model = Sequential(name='Cryotherapy')
        model.add(Input((training_dataset_x.shape[1], ), name='Input'))
        model.add(Dense(64, activation='relu', name='Hidden-1'))
        model.add(Dense(64, activation='relu', name='Hidden-2'))
        model.add(Dense(1, activation='sigmoid', name='Output'))
        model.compile('rmsprop', loss='binary_crossentropy', metrics=['binary_accuracy'])
        return model

    Biz bu Keras modeli için de pipeline oluşturabiliriz:

    kc = KerasClassifier(model=create_keras_model, epochs=10, batch_size=10, verbose=0)
    pl_kc = make_pipeline(StandardScaler(), kc)

    VotingClassifier nesnesini de şöyle oluşturulabilir:

    pl_svc = make_pipeline(StandardScaler(), SVC())
    pl_lr = make_pipeline(StandardScaler(), LogisticRegression())
    dtc = DecisionTreeClassifier()

    vc = VotingClassifier([('SVC', pl_svc), ('LogisticRegression', pl_lr), 
            ('DecisionTreeClassifier', dtc), ('KerasClassifier', pl_kc)])

    Örnek bir bütün olarak aşağıda verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('cryotherapy.csv', delimiter=';')

df_x = df.iloc[:, :-1]
df_y = df.iloc[:, -1]

from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)

oge_columns = ohe.fit_transform(df_x[['sex', 'Type']])
df_x.drop(['sex', 'Type'], inplace=True, axis=1)
df_x[['sex_male', 'sex_female', 'type_1', 'type_2', 'type_3']] = oge_columns

dataset_x = df_x.to_numpy()
dataset_y = df_y.to_numpy()

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input
from scikeras.wrappers import KerasClassifier 
from sklearn.ensemble import VotingClassifier

pl_svc = make_pipeline(StandardScaler(), SVC())
pl_lr = make_pipeline(StandardScaler(), LogisticRegression())
dtc = DecisionTreeClassifier()

def create_keras_model():  
    model = Sequential(name='Cryotherapy')
    model.add(Input((training_dataset_x.shape[1], ), name='Input'))
    model.add(Dense(64, activation='relu', name='Hidden-1'))
    model.add(Dense(64, activation='relu', name='Hidden-2'))
    model.add(Dense(1, activation='sigmoid', name='Output'))
    model.compile('rmsprop', loss='binary_crossentropy', metrics=['binary_accuracy'])
    return model

kc = KerasClassifier(model=create_keras_model, epochs=10, batch_size=10, verbose=0)
pl_kc = make_pipeline(StandardScaler(), kc)

vc = VotingClassifier([('SVC', pl_svc), ('LogisticRegression', pl_lr), 
        ('DecisionTreeClassifier', dtc), ('KerasClassifier', pl_kc)])

vc.fit(training_dataset_x, training_dataset_y)
predict_result = vc.predict(test_dataset_x)
print(f'Predict result: {predict_result}')

score = vc.score(test_dataset_x, test_dataset_y)
print(f'Accuracy: {score}')

#----------------------------------------------------------------------------------------------------------------------------
                                            125. Ders - 18/05/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıda "auto-mpg.data" veri kümesi üzerinde Keras sinir ağı da dahil edilerek oylama yöntemi uygulanmıştır. Tabii artık 
    bir regresyon problemi söz konusu olduğu için uyumlandırma için KerasClassifier sınıfı yerine KerasRegressor sınıfı 
    kullanılmıştır. Örneğimizde Keras sinir ağı modeli aşağıdaki gibi oluşturulup kullanılmıştır:

    pl_lasso = make_pipeline(StandardScaler(), Lasso())
    pl_svr = make_pipeline(StandardScaler(), SVR())
    dtr = DecisionTreeRegressor()

    def create_keras_model():  
        model = Sequential(name='Autompg')
        model.add(Input((training_dataset_x.shape[1], ), name='Input'))
        model.add(Dense(64, activation='relu', name='Hidden-1'))
        model.add(Dense(64, activation='relu', name='Hidden-2'))
        model.add(Dense(1, activation='linear', name='Output'))
        model.compile('rmsprop', loss='mean_squared_error', metrics=['mean_absolute_error'])
        return model

    kr = KerasRegressor(model=create_keras_model, epochs=10, batch_size=10, verbose=0)
    pl_kr = make_pipeline(StandardScaler(), kr)

    vr = VotingRegressor([('Lasso', pl_lasso), ('SupportVectorRegressor', pl_svr), 
            ('DecisionTreeRegressor', dtr), ('KerasRegressor', pl_kr)])

    Kod bir bütün olarak aşağıda verilmiştir
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd
import numpy as np

df = pd.read_csv('auto-mpg.data', delimiter=r'\s+', header=None)

df = df.iloc[:, :-1]
df.iloc[df.loc[:, 3] == '?', 3] = np.nan

df[3] = df[3].astype('float64')

from sklearn.impute import SimpleImputer

si = SimpleImputer(strategy='mean', missing_values=np.nan)
df[3] = si.fit_transform(df[[3]])

df_1 = df.iloc[:, :7]
df_2 = df.iloc[:, [7]]

dataset_1 = df_1.to_numpy()
dataset_2 = df_2.to_numpy()

import numpy as np
from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)
dataset_2 = ohe.fit_transform(dataset_2)

dataset = np.concatenate([dataset_1, dataset_2], axis=1)

dataset_x = dataset[:, 1:]
dataset_y = dataset[:, 0]

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import Lasso
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.pipeline import make_pipeline
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input
from scikeras.wrappers import KerasRegressor
from sklearn.ensemble import VotingRegressor

pl_lasso = make_pipeline(StandardScaler(), Lasso())
pl_svr = make_pipeline(StandardScaler(), SVR())
dtr = DecisionTreeRegressor()

def create_keras_model():  
    model = Sequential(name='Autompg')
    model.add(Input((training_dataset_x.shape[1], ), name='Input'))
    model.add(Dense(64, activation='relu', name='Hidden-1'))
    model.add(Dense(64, activation='relu', name='Hidden-2'))
    model.add(Dense(1, activation='linear', name='Output'))
    model.compile('rmsprop', loss='mean_squared_error', metrics=['mean_absolute_error'])
    return model

kr = KerasRegressor(model=create_keras_model, epochs=10, batch_size=10, verbose=0)
pl_kr = make_pipeline(StandardScaler(), kr)

vr = VotingRegressor([('Lasso', pl_lasso), ('SupportVectorRegressor', pl_svr), 
        ('DecisionTreeRegressor', dtr), ('KerasRegressor', pl_kr)])
vr.fit(training_dataset_x, training_dataset_y)

predict_result = vr.predict(test_dataset_x)
print(f'Predict result: {predict_result}')

score = vr.score(test_dataset_x, test_dataset_y)
print(f'R^2 score: {score}')

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(test_dataset_y, predict_result)
print(f'Mean absolute error: {mae}')

#----------------------------------------------------------------------------------------------------------------------------
                                            125. Ders - 18/05/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Çok kullanılan bir ensemble yöntem de "bagging (bootstrap aggregation)" denilen yöntemdir. ("bootstrap" bir grup veriden 
    örnekleme yapılarak bir alt grubu seçme anlamına gelen bir terimdir. Aggregation ise "toplamak, bir araya getirmek" gibi 
    bir anlama gelmektedir.) Bu yöntem farklı tahminleyicileri değil farklı veri kümelerini bir araya getirerek modeli 
    güçlendirmektedir. Bu yöntemde veri kümesindeki satırlar iadeli biçimde belli büyüklerde örneklenerek n tane veri kümesi 
    elde edilir. Örneğin veri kümemizde 1000 tane satır olsun. Bu veri kümesinden her biri 30'arlı 100 tane rastgele iadeli 
    (with replacement) biçimde veri kümesi oluşturabiliriz. Bu işleme "boostrap" işlemi denilmektedir. Bagging yönteminde bir 
    tane sınıflandırma ya da regresyon yöntemi seçilir. Sonra oluşturulan bu alt kümelerle bu modeller eğitilerek çok sayıda 
    model oluşturulur. Örneğin sınıflandırma yöntemi olarak DecisionTreeClassifier kullanıyor olalım. Oluşturduğumuz 100 tane 
    küçük veri kümesi ile biz 100 ayrı eğitim yaparak 100 ayrı karar ağacı oluşturabiliriz. Sonra kestirim yapılırken kestirilecek 
    değeri bu 100 farklı karar ağacına da uygularız. Buradan bir oylama yaparak sonucu kestiririz. Benzer biçimde biz bu yöntemle 
    bir regresyon probleminde iadeli örnekleme ile 100 ayrı veri kümesi oluşturabiliriz. Tahminleyiciyi bu veri kümeleriyle 
    eğitebiliriz. Kestirim işleminde de bu veri kümelerinden elde edilen kesitirmlerin otyalamasını alabiliriz. 

    Bagging yöntemi özellikle karar ağaçlarında çokça kullanılmaktadır. Ancak yöntem geneldir. Bu nedenle bu yöntem karar 
    ağaçlarının dışında da başka tahminleyicilerle kullanılabilmektedir. Yöntemde örneklemenin iadeli yapılması önemli 
    olmaktadır. Pek çok çalışma iadeli örneklemenin daha iyi sonuç verdiğini göstermiştir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Bagging yöntemi için scikit-learn içerisinde sklearn.ensemble modülünde BaggingClassifier ve BaggingRegressor isimli 
    sınıflar bulundurulmuştur. Sınıfların __init__ metotlarının parametrik yapısı aşağıdaki gibidir:

    class sklearn.ensemble.BaggingClassifier(estimator=None, n_estimators=10, *, max_samples=1.0, max_features=1.0, 
        bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, 
        random_state=None, verbose=0, base_estimator='deprecated')

    class sklearn.ensemble.BaggingRegressor(estimator=None, n_estimators=10, *, max_samples=1.0, max_features=1.0,
         bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, 
         random_state=None, verbose=0, base_estimator='deprecated')

    Metotların birinci parametreleri rastgele alt kümelerin eğitiminde kullanılacak yöntemi yani tahminleyiciyi almaktadır. Bu 
    parametre girilmezse default olarak BaggingClassifier için DecisionTreeClassifier, BeggingRegressor için DecisionTreeRegressor
    sınıfları kullanılır. Programcı ilgili yöntem sınıfı türünden bir nesne yaratarak bu parametreye onu verebilir. Metotların 
    n_estimators parametreleri kaç tane örnek oluşturulacağını başka bir deyişle kaç tane ilgili sınıf türünden tahminleyici
    oluşturulacağını belirtir. Metotların max_samples parametresi çekilecek örneklerin eleman sayısını belirtmektedir. Bu bir 
    oran olarak verilebileceği gibi doğrudan bir sayı olarak da verilebilir. Bu sınıfta istenirse sütunların hepsi değil rastgele 
    belli sütunlar da kullanılabilir. Tüm sütunlar yerine rastgele sütunların kullanılması da özellikle overfitting konusunda 
    avantaj sağlamaktadır. (Yöntemleri bulanların ilk makalesinde "rastgele satırların iadesiz biçimde seçilmesine "pasting", 
    iadeli biçimde seçilmesine "bagging", sütunların rastgele seçilmesine "random subspacing", hem satırların hem de sütunların 
    rastgele seçilmesine ise "random patching" biçiminde isimler verilmiştir.) BaggingClassifier ve BaggingRegressor sınıfları 
    hem satırları hem de sütunları rastgele seçebilmektedir. Yani aslında farklı yöntemlerin bu sınıf bir arada kullanılmasına 
    izin vermektedir.) Metotların bootstrap parametreleri satırların seçilmesinin iadeli mi (with replacement) iadesiz mi (without 
    replacement) yapılacağını belirtmektedir. Default durumda iadeli seçim uygulanmaktadır. bootstrap_features parametresi 
    sütunların rastgele seçilmesi durumundaki seçimin iadeli mi iadesiz mi yapılacağını belirtmektedir. Bu parametrenin default 
    durumu iadesiz seçimdir. Metotların diğer parametreleri daha az önemdedir. Default değerlerle geçilebilir. Örneğin:

    bc = BaggingClassifier(DecisionTreeClassifier(), 100, max_samples=0.70)

    Burada tahminleyici olarak DecisionTreeClassifier nesnesi kullanılmıştır (zaten default durumdaDecisionTreeClassifier 
    nesnesi kullanılmaktadır), Veri kümesinde iadeli olarak her defasında %70 oranında satır çekilmiştir. Böylece 100 farklı 
    veri kümesi oluşurulmuştur. Tabii bu nesne yine pipeline içerisine yerleştirilebilir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "breast-cancer" veri kümesi üzerinde önce tek bir karar ağacı ile klasik çözüm uygulanmıştır. Sonra 
    "bagging" yöntemi ile satırların ve sütunların %70'i iadeli biçimde örneklenerek 100 ayrı karar ağacı ile oylama yapılmıştır. 
    Buradaki sonuçta bagging yönteminin daha başarılı olduğu görülmektedir.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv("data.csv")

dataset_x = df.iloc[:, 2:-1].to_numpy()
dataset_y = np.zeros(len(df))
dataset_y[df['diagnosis'] == 'M'] = 1

"""
from sklearn.datasets import load_breast_cancer

bc = load_breast_cancer()
dataset_x = bc.data
dataset_y = bc.target
"""

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import BaggingClassifier

dtc = DecisionTreeClassifier()
dtc.fit(training_dataset_x, training_dataset_y)
score = dtc.score(test_dataset_x, test_dataset_y)
print(f'Single DecisionTreeClassifier score: {score}')

dtc = DecisionTreeClassifier()
bc = BaggingClassifier(dtc, n_estimators=100, max_samples=0.70, max_features=0.70)
bc.fit(training_dataset_x, training_dataset_y)

predict_result = bc.predict(test_dataset_x)
print(f'Predict result: {predict_result}')

accuracy = bc.score(test_dataset_x, test_dataset_y)
print(f'Accuracy: {accuracy}')

#----------------------------------------------------------------------------------------------------------------------------
                                            126. Ders - 24/05/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "Boston Housing Prices" veri kümesine yalnızca DecisionTreeRegressor yöntemi ve BaggingRegressor ensemble
    yöntemi uygulanmıştır. İyileşme oldukça tatmin edici düzeydedir. Elde edilen örnek bir sonuç şöyledir: 

    Single DecisionTreeRegressor R^2:  0.6771352892223901
    Single DecisionTreeRegressor Mean Absolute Error: 3.468627450980392
    BaggingRegressor R^2:  0.875623925212663
    BaggingRegressor Mean Absolute Error: 2.220901960784315
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Diğer bir ensemble yöntem grubuna da "stacking" denilmektedir. Bu yöntemde problem n tane tahminleyici ile çözülür. Kestirim 
    yapılırken bu tahminleyicilerin kestirdiği değerler başka bir meta modele verilir. Kestirimin nihai sonucu bu meta modelin 
    verdiği sonuç olur. Tabii eğitim sırasında hem tahminleyiciler hem de meta tahminleyici eğitilmektedir. Şimdi stacking 
    yönteminin bazı ayrıntılarını gözden geçirelim. 

    Örneğin çeşitli sütunlardan oluşan "positive", "negative" biçiminde iki sınıflı bir sınıflandırma problemi söz konusu olsun. 
    Bu problemi çözen dört tahminleyici bulunsun. Her tahminleyici kestirim soucunda "positive", "negative" biçiminde bir sonuç 
    üretecektir. İşte bu stacking yönteminde bu dört tahminleyicinin ürettiği sonuçlar meta tahminleyici için bir eğitim veri
    kümesi olarak ele alınmaktadır. Örneğin.

    tahminleyici1_çıktısı   tahminleyici2_çıktısı   tahminleyici3_çıktısı  tahminleyici4_çıktısı    Gerçek Değer
    positive                negative                positive               positive                 positive
    negative                negative                positive               positive                 negative
    negative                negative                negative               positive                 negative
    .....                   .....                  .....                   .....                    .....

    Eğer bir regresyon problemi söz konusu olsaydı tahminleyicilerin çıktıları birer sayı olurdu. Bu durumda tahminleyicilerin 
    çıktılarından elde edilen veri kümelerinin örnek bir görünümü de şöyle olurdu:

    tahminleyici1_çıktısı       tahminleyici2_çıktısı tahminleyici3_çıktısı tahminleyici4_çıktısı   Gerçek Değer
    14.5                        15.2                  13.8                  10.2                    14.8
    20.7                        22.3                  21.9                  19.4                    21.3
    52.6                        51.4                  53.8                  50.9                    52.1
    .....                       .....                 .....                 .....                   .....  

    Bu yöntemde her bir sütunun aslında bir tahminleyicinin çıktısı olduğuna dikkat ediniz. Tahminleyicilerden elde edilen veri 
    kümesinin x matrisi satır sayısı kadar satırdan, tahminleyici sayısı kadar sütundan oluşmaktadır. Tabii nihai tahminleyici 
    için y değerleri yine gerçek y değerlerinden oluşmaktadır.

    Bu yöntemde ilginç bir sorun gözünüze çarpabilir. Bu tahminleyiciler nasıl eğitilmektedir? Eğer bu tahminleyiciler veri 
    kümesinin kendisiyle eğitilirse veri kümesinin kendisini tahmin ettiklerinde uygunsuz bir durum oluşacaktır. Anımsanacağı 
    gibi eğitim veri kümesiyle sınama ya da test veri kümeelerinin ayrıştırılması gerekmektedir. O halde "stacking "yönteminde 
    veri kümesini tahmin eden tahminleyiciler nasıl eğitilmektedir? İşte bu yöntemde tahminleyicilerin eğitilmesi için tipik 
    olarak K-Fold yöntemi kullanılmaktadır. Bu yöntemde veri kümesi K tane parçaya bölünür. Bir döngü içerisinde i'inci parçanın 
    dışındaki tüm parçalarla eğitim yapılır. i'inci parça kestirilmeye çalışılır. Böylece aslında hem aynı veri kümesiyle eğitim 
    uygulanmış olur hem de kestirimde eğitim veri kümesi kullanılmamış olur. Örneğin K = 4 olsun. Biz bu durumda veri kümesini 
    dört parçaya böleriz. Bu dört parça K1, K2, K3, K4 olsun. Şimdi biz tahminleyiciyi K2, K3 ve K4 parçalarıyla eğitip onun 
    K1'i kestirmesini sağlayabiliriz. Sonra da K1, K3, K4 ile eğitip onun K2'yi kestirmesini sağlayabiliriz. Böyle böyle tüm 
    veri kümesinin kestirimini yapabiliriz. Tabii bunu her tahminleyiciyle benzer biçimde yapmamız gerekir. Nihai tahminleyicide 
    de aynı sorun söz konusu olacaktır. Orada da yine aynı biçimde K-Fold yöntemiyle kestirimde bulunulmalıdır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Stacking yöntemi scikit-learn içerisindeki sklearn.ensemble modülünde bulunan StackingClassifier ve StackingRegressor 
    sınıfları yoluyla uygulanabilmektedir. Sınıfların __init__ metotlarının parametrik yapıları şöyledir:

    class sklearn.ensemble.StackingClassifier(estimators, final_estimator=None, *, 
        cv=None, stack_method='auto', n_jobs=None, passthrough=False, verbose=0)
    
    class sklearn.ensemble.StackingRegressor(estimators, final_estimator=None, *, cv=None, 
        n_jobs=None, passthrough=False, verbose=0)

    Metotların birinci parametreleri kullanılacak tahminleyicileri almaktadır. Bu tahminleyiciler demet listesi biçiminde metoda 
    verilir. Demetlerin birinci elemanları tahminleyiciye verilen isimlerden, ikinci elemanları ise tahminleyici nesnelerinden 
    oluşturulur. Metotların final_estimator parametreleri ise meta tahminleyiciyi almaktadır. Bu parametre belirtilmezse 
    StackingClassifier sınıfı için LogisticRegression, StackingRegressor sınıfı için RidgeCV nesneleri yaratılarak kullanılmaktadır. 
    Metotların cv parametreleri veri kümesinin K-Fold yöntemi için kaç parçaya ayrılacağını belirtmektedri. Bu paramre None 
    geçilirse (default durum) veri kümesi 5 parçaya ayrılmaktadır.

    StackingClassifier sınıfının score metodu binary accuracy değerini, StackingRegressor sınıfının score metodu ise 
    R^2 değerini vermektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "cryotherapy" veri kümesi üzerinde "stacking" ensemble yöntemi uygulanmıştır. Örnekte dört tahminleyici 
    kullanılmış ve bunların çıktıları meta tahminleyiciye verilmiştir. Meta tahminleyici için bir nesne belirtilmediğinden 
    dolayı default durumda LogisticRegression nesnesi kullanılmıştır. Örneğimizde kullanılan tahminleyici nesneleri şunlardır:

    SVC
    LogisticRegression
    GaussianNB
    DecisionTreeClassifier

    SVC ve LogisticRegression yöntemleri için özellik ölçeklemesi gerektiğini anımsayınız. Biz de örneğimizde bir boru 
    hattı ile bu yöntemler için özellik ölçeklemesi uyguladık:

    pl_svc = make_pipeline(StandardScaler(), SVC(kernel='rbf'))
    pl_lr = make_pipeline(StandardScaler(), Logistic
    
    StackingClassifier nesnesi de şöyle oluşturulup eğitilmiştir:

    sc = StackingClassifier([('SVC', pl_svc), ('LogisticRegression', pl_lr), ('GaussianNB', GaussianNB()), 
            ('DecisionTreeClassifier', DecisionTreeClassifier())])
    sc.fit(training_dataset_x, training_dataset_y)
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('cryotherapy.csv', delimiter=';')

df_x = df.iloc[:, :-1]
df_y = df.iloc[:, -1]

from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)

oge_columns = ohe.fit_transform(df_x[['sex', 'Type']])
df_x.drop(['sex', 'Type'], inplace=True, axis=1)
df_x[['sex_male', 'sex_female', 'type_1', 'type_2', 'type_3']] = oge_columns

dataset_x = df_x.to_numpy()
dataset_y = df_y.to_numpy()

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.ensemble import StackingClassifier

pl_svc = make_pipeline(StandardScaler(), SVC(kernel='rbf'))
pl_lr = make_pipeline(StandardScaler(), LogisticRegression())

sc = StackingClassifier([('SVC', pl_svc), ('LogisticRegression', pl_lr), ('GaussianNB', GaussianNB()), 
        ('DecisionTreeClassifier', DecisionTreeClassifier())])
sc.fit(training_dataset_x, training_dataset_y)

predict_result = sc.predict(test_dataset_x)
print(predict_result)

accuracy = sc.score(test_dataset_x, test_dataset_y)
print(f'Accuracy: {accuracy}')

#----------------------------------------------------------------------------------------------------------------------------
                                            127. Ders - 25/05/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "auto-mpg" veri kümesi üzerinde StackingRegressor ensemble yöntemi uygulanmıştır. Burada üç tahminleyici 
    kullanılmış ve ondan elde edilen değerler meta tahminleyiciye verilmiştir. Meta tahminleyici için bir sınıf nesnesi 
    oluşturulmadığından dolayı default olarak RidgeCV nesnesi kullanılmıştır.

    Bu örnekte kullandığımız tahminleyiciler şunlardır:

    Lasso
    SupportVectorRegressor
    DecisionTreeRegressor

    Yöntem aşağıdaki gibi uygulanmıştır:

    pl_lasso = make_pipeline(StandardScaler(), Lasso())
    pl_svr = make_pipeline(StandardScaler(), SVR())
    dtr = DecisionTreeRegressor()

    vr = StackingRegressor([('Lasso', pl_lasso), ('SupportVectorRegressor', pl_svr), ('DecisionTreeRegressor', dtr)])
    vr.fit(training_dataset_x, training_dataset_y)
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd
import numpy as np

df = pd.read_csv('auto-mpg.data', delimiter=r'\s+', header=None)

df = df.iloc[:, :-1]
df.iloc[df.loc[:, 3] == '?', 3] = np.nan

df[3] = df[3].astype('float64')

from sklearn.impute import SimpleImputer

si = SimpleImputer(strategy='mean', missing_values=np.nan)
df[3] = si.fit_transform(df[[3]])

df_1 = df.iloc[:, :7]
df_2 = df.iloc[:, [7]]

dataset_1 = df_1.to_numpy()
dataset_2 = df_2.to_numpy()

import numpy as np
from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)
dataset_2 = ohe.fit_transform(dataset_2)

dataset = np.concatenate([dataset_1, dataset_2], axis=1)

dataset_x = dataset[:, 1:]
dataset_y = dataset[:, 0]

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.preprocessing import StandardScaler

from sklearn.linear_model import Lasso
from sklearn.svm import SVR
from sklearn.tree import DecisionTreeRegressor
from sklearn.pipeline import make_pipeline
from sklearn.ensemble import StackingRegressor

pl_lasso = make_pipeline(StandardScaler(), Lasso())
pl_svr = make_pipeline(StandardScaler(), SVR())
dtr = DecisionTreeRegressor()

vr = StackingRegressor([('Lasso', pl_lasso), ('SupportVectorRegressor', pl_svr), ('DecisionTreeRegressor', dtr)])
vr.fit(training_dataset_x, training_dataset_y)

score = vr.score(test_dataset_x, test_dataset_y)
print(f'R^2 score: {score}')

from sklearn.metrics import mean_absolute_error

predict_result = vr.predict(test_dataset_x)
mae = mean_absolute_error(test_dataset_y, predict_result)
print(f'Mean absolute error: {mae}')

#----------------------------------------------------------------------------------------------------------------------------
    Diğer bir grup ensemble yöntemlere "boosting" denilmektedir. Boosting yönteminin de çeşitli varyasyonları vardır. En çok 
    kullanılan AdaBoosting ve GradientBoosting yöntemleridir. 

    AdaBoosting temelde sınıflandırma problemleri için geliştirilmiştir. AdaBoosting yönteminde problem zayıf (weak estimator) 
    bir tahminleyici ile çözülür. Sonra bu tahminleyicide yanlış tahmin edilen satırların (örneklerin) üzerinde özellikle 
    durularak problem yeniden çözülmektedir. Burada problem yeniden çözülürken zayıf tahminleyicide doğru tahmin edilememiş 
    satırların ağırlıkları kullanılan tahminleyici algoritmasında yükseltilip doğru tahmin edilen satırlarda düşürülmektedir. 
    Böylece ikinci aşamda ilk aşamada yanlış tahmin edilmiş olan bazı satırlar doğru tahmin edilecektir. Ancak bu sefer birinci 
    aşamada doğru tahmin edilen bazı satırlar da yanlış tahmin edilebilecektir. Üçüncü aşamada bu yöntem devam ettirilir. Yani 
    ikinci aşamda yanlış tahmin edilen satırların ağırlıkları yükseltilip doğru tahmin edilmiş satırların ağırlıkları düşürülmektedir.
    Böylece üçüncü bir model oluşturulmuş olur. Bu biçimde n defa algoritma devam ettirilir. Böylece bu işlemin sonucunda 
    elimizde n tane farklı ağırlıklık değerleriyle eğitilmiş model bulunacaktır. İşte kestirim aşamasında kestirilecek değer 
    bu n tane modele sokulur ve ağırlıklı oylama yöntemi uygulanır.

    Boosting yöntemlerinde genellikle zayıf tahminliyici çok basit bir tahminleyici olarak seçilir. Bunun en yaygın kullanılan
    zayıf tahminleyici tek bir düğümden oluşan karar ağaçlarıdır. Tek düğümden oluşan karar ağaçlarına "karar kütüğü (decision 
    stump") denilmektedir. Karar kütüklerinde tek bir soru sorulur, bu soruya göre iki küme oluşturulur. 

    Şimdi AdaBoosting ile bir sınıflandırma probleminin nasıl çözüldüğünü biraz daha ayrıntılara girerek ele inceleyelim:

    1) AdaBoosting yönteminde veri kümesindeki satırların birer ağırlık değeri vardır. Başlangıçta her satırın ağırlık değeri
    aynıdır. Veri kümesinde N tane satır olduğunu varsayarsak başlangıçta her satırın ağırlığı 1 / N olacaktır:

    w₁ⁱ = 1/N, i = 1, 2, ..., N

    2) Zayıf tahminleyici durumunda olan karar kütüğü için sorulacak alternatif sorular yine daha önce görmüş olduğumuz karar 
    ağaçlarındaki gibi oluşturulmaktadır. Yani yine alternatif bölme noktaları oluşturulur. Hangi bölme noktası en az hata 
    içeriyorsa o bölme noktası tercih edilir. Bölme noktası (yani en iyi soru) tespit edildikten sonra karar kütüğü veri 
    kümesini iki parçaya ayırır. 

    3) Zayıf tahminleyici ile veri kümesi iki parçaya bölündükten sonra buradan bir ağırlıklı hata değeri hesaplanır. Bu değer 
    sınıflandırma problemleri için "yanlış tahmin edilenlerin sayısı", regresyon problemleri için "ortalama karesel hata" 
    ile ilişkili biçimde oluşturulur. Tabii bu yanlış tahmin edilenlerin performans ölçütündeki değerleri ilgili satırın ağırlık 
    değerleriyle çarpılarak hesaplanmaktadır. Burada sınıflandırma problemleri için "ağırlıklı hata hesabı"şöyle yapılmaktadır:

    εₜ = Σᵢ₌₁ᴺ wₛⁱ · I(yᵢ ≠ hₜ(xᵢ)) / Σᵢ₌₁ᴺ wₜⁱ

    Burada εₜ ağırlıklı hatayı belirtmektedir. I değeri 1 anlamına gelmektedir. O halde bu hesabın sınıflandırma problemleri için
    anlamı şöyledir: "Yanlış tahmin edilen satırların ağırlıklarının toplamının toplam ağırlığa oranı". Tabii birinci aşamada 
    her satırın ağırlıkları aynı olduğu için bu toplam aslında yanlış tahmin edilenlerin sayısı anlamına gelir. Alternatif bölme 
    noktaları arasından en iyi bölme noktası zaten "ağırlıklı hatanın en küçük olduğu" nokta olacak biçimde seçilmektedir. 

    4) Ağırlıklı hata tespit edildikten sonra yeni ağırlıkların oluşturulması için bir alfa değeri hesaplanmaktadır. Bu 
    alfa değeri hatalı satırların ağırlıklarını artıran, doğru satırların ağırlıklarını azaltan bir fonksiyondur. Alfa 
    değeri şöyle hesaplanmaktadır:

    αₜ = ½ log((1 - εₜ)/εₜ)

    Buradaki log fonksiyonu e tabanına göre logaritmayı temsil etmektedir. 

    5) Bulunan bu alfa değeri ile tüm satırların yeni ağırlıkları hesaplanmaktadır. Yeni ağırlık hesaplama aşağıdaki formülle
    yapılmaktadır:

    wₜ₊₁ⁱ = wₜⁱ · exp(-αₜ · yᵢ · hₜ(xᵢ)) / Zₜ

    Burada wₜ₊₁ⁱ satırın yeni ağırlık değerini wₜⁱ ise önceki ağırlık değerini, yi o satırın gerçek değeri hₜ(xᵢ) ise tahmin edilen 
    değerini belirtmektedir. (Problemin bu formülasyonu iki sınıflı ve sınıfların +1 ve -1 ile temsil edildiği varsayımı ile yapılmıştır. 
    Burada kolay bir temsil için bu yöntem uygulanmıştır. Diğer temsiller için buranın biraz düzenlenmesi gerekir.) Buradaki Zₜ ise 
    toplam değerini belirtmektedir. Yani aslında burada bir normalizasyon da yapılmış olmaktadır:

    Zₜ = Σᵢ₌₁ᴺ wₜⁱ · exp(-αₜ · yᵢ · hₜ(xᵢ))

    Bu değeri eşdeğer olarak şöyle de ifade edebiliriz:

    Zₜ = (1 - εₜ) · exp(-αₜ) + εₜ · exp(αₜ)

    Bu biçimde tüm satırların yeni ağırlıkları hesaplandığında yeni ağırlıkların toplamının da 1 olacağına dikkat ediniz. 

    Pekiyi bu noktaya kadar neler olmuştur? Sözel bir anlatımla şunları söyleyebiliriz: "Burada aslında yanlış tahmin edilen 
    satırların ağırlıkları artırılmış, doğru tahmin edilen satırların ağırlıkları düşürülmüştür". Artık elimizde satırların 
    yeni ağırlıkları vardır. 

    6) Birinci aşama sonunda elimizde bir tane tahminleyici (decision stump) ve satırların yeni ağırlık değerleri vardır. 
    Bu durumda tüm işlemler başyan yinelenir. Yani bu yeni ağırlıklara göre yine alternatif bölme noktalarından een iyisi 
    tespit edilir. Yeni ağırlık değerleri yukarıda adımlardan geçilerek oluşturulur. Toplamda tüm işlemler bittiğinde 
    elimizde n tane farklı tahminleyici bulunacaktır. 

    7) Pekiyi nihai tahmin nasıl yapılmaktadır? İşte bu işlemler sonucunda elde edilen K tane tahminleyici ağırlıklı oylama 
    işlemine sokulur, böylece nihai tahmin değeri elde edilir. Burada çoğunluk oylaması yerine ağırlıklı oylama yapılmaktadır. 
    Yani oylama yapılırken her tahminleyicinin yukarıda hesaplanan alfa değeri ağırlık olarak kullanılmaktadır. Bu nihai tahmin
    matematiksel olarak şöyle ifade edilebilir:

    H(x) = sign(Σₜ₌₁ᵀ αₜ · hₜ(x))

    Burada H(x) nihai tahmini belirtmektedir. sign fonksiyonu (signum fonksiyonu) pozitif değerleri +1, negatif değerleri -1
    yapmaktadır. (Buradaki formül iki sınıflı bir sınıflandırma problemi biçiminde verilmiştir. Sınıflardan biri +1, diğeri 
    -1 biçimindedir.)

    AdaBoosting yöntemi ile sınıflandırma aslında iki sınıflı veri kümeleri için kullanılmaktadır. Ancak çok sınıflı veri 
    kümelerinde çok sınıflı lojistik regresyonda gördüğümüz yöntemlerin benzerleri uygulanmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirttiğimiz gibi AdaBoosting yöntemi aslında orijinal olarak iki sınıflı sınıflandırma problemleri için 
    tasarlanmıştır. Ancak yöntem regresyon problemlerine de biraz değiştirilerek uygulanabilmektedir. Regresyon problemleri 
    içim yukarıdaki adımlar aşağıdaki biçime dönüştürülmektedir:

    1) Yine satırların başlangıç ağırlık değerleri eşit olacak biçimde alınır:

    w₁ⁱ = 1/N, i = 1, 2, ..., N

    2) Tahminleyicinin başarısı artık "gerçek değerden sapmaların karelerinin toplamı" ile hesaplanır: 

    hₜ = argmin Σᵢ₌₁ᴺ wₜⁱ · (yᵢ - h(xᵢ))²       
    |eₜⁱ| = |yᵢ - hₜ(xᵢ)|                            Mutlak hata
    εₜⁱ = |eₜⁱ| / Dₜ                                 Göreli Hata
    ε̄ₜ = Σᵢ₌₁ᴺ wₜⁱ · εₜⁱ / Σᵢ₌₁ᴺ wₜⁱ                  Ortalama Göreli Hata

    Artık alfa yerine beta terimi kullanılmaktadır:

    βₜ = ε̄ₜ / (1 - ε̄ₜ)

    Ağırlık güncellemesi şöyle yapılır:

    wₜ₊₁ⁱ = wₜⁱ · βₜ^(1-εₜⁱ) / Zₜ

    Burada Zₜ yine normalizasyon için toplamı belirtmektedir:

    Zₜ = Σᵢ₌₁ᴺ wₜⁱ · βₜ^(1-εₜⁱ)

    Nihai tahmin ise şöyle yapılmaktadır:

    H(x) = median{hₜ(x) : t ∈ {t' : ln(1/βₜ') ≥ ½ · max ln(1/βⱼ)}}

    Yukarıdaki matematiksel formüller biraz karmaşıktır ve bu formüllerin üzerinde düşünülmesi gerekir. Ancak biz regresyon
    problemleri için yöntemin nasıl uygulandığını sözel olarak şöyle açıklayabiliriz: "Regresyon ptroblemlemlerinde bir sınıf
    değil gerçek bir değer tahmin edilmektedir. Dolayısıyla yapılan hata sınıfsal değil sayısal biçimde tahmin edilenle gerçek
    değer aradındaki farkın karesiyle hesaplanmaktadır. Ağırlık güncellemeleri de tamamen temel mantık aynı kalmak üzere bu 
    farklara dayalı olarak yapılmaktadır." Yöntemin ayrıntıları için başka kaynaklara başvurabilirsiniz. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    scikit-learn kütüphanesi içerisinde AdaBoosting yöntemini uygulamak için AdaBoostClassifier ve AdaBoosRegressor isimli 
    iki sınıf bulundurulmuştur. Bu sınıfların __init__ metotları şöyledir:

    class sklearn.ensemble.AdaBoostClassifier(estimator=None, *, n_estimators=50, learning_rate=1.0, algorithm='SAMME.R', 
            random_state=None, base_estimator='deprecated')

    class sklearn.ensemble.AdaBoostRegressor(estimator=None, *, n_estimators=50, learning_rate=1.0, loss='linear', 
            random_state=None, base_estimator='deprecated')
    
    Metotların birinci parametreleri kullanılacak tahminleyiciyi belirtmektedir. Bu parametre girilmezse AdaBoostClassifier 
    sınıfı için DecisionTreeClassifier, AdaBoostRegressor sınıfı için DecisionTreeRegressor nesneleri yaratılıp kullanılmaktadır. 
    Tabii bu nesneler max_depth = 1 parametresiyle yani "karar kütüğü (decision stump)" biçiminde oluşturulmaktadır. n_estimator 
    parametresi iterasyon sırasında oluşturuşacak tahminleyicilerin (yani karar kütüklerinin) sayısını belirtmektedir. Yani 
    ağırlıklar değiştirilerek toplam kaç yineleme yapılacaktır? Bu parametrenin default değerinin 50 olduğunu görüyorsunuz. 
    Diğer parametreler daha ayrıntılı ayarlamalar için kullanılmaktadır. Sınıfların yine fit, predict ve score metotları vardır. 
    score metotları AdaBoostClassifier için "accuracy" değerini, AdaBoostRegressor için "R^2" değerini hesaplamaktadır. 

    Aşağıdaki örnekte cryotherapy için AdaBoostClassfier ensemble yöntemi kullanılmıştır.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('cryotherapy.csv', delimiter=';')

df_x = df.iloc[:, :-1]
df_y = df.iloc[:, -1]

from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)

oge_columns = ohe.fit_transform(df_x[['sex', 'Type']])
df_x.drop(['sex', 'Type'], inplace=True, axis=1)
df_x[['sex_male', 'sex_female', 'type_1', 'type_2', 'type_3']] = oge_columns

dataset_x = df_x.to_numpy()
dataset_y = df_y.to_numpy()

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.ensemble import AdaBoostClassifier

adc = AdaBoostClassifier()
adc.fit(training_dataset_x, training_dataset_y)

predict_result = adc.predict(test_dataset_x)
print(predict_result)

accuracy = adc.score(test_dataset_x, test_dataset_y)
print('Accuracy: {accuracy}', accuracy)

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "auto-mpg.data" veri kümesi üzerinde (otomobillerin mil başına yaktıkları yakıtın tahmin edilmesine 
    ilişkin veri kümesi) AdaBoostRegressor ensemble yönteminin kullanımına ilişkin örnek verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd
import numpy as np

df = pd.read_csv('auto-mpg.data', delimiter=r'\s+', header=None)

df = df.iloc[:, :-1]
df.iloc[df.loc[:, 3] == '?', 3] = np.nan

df[3] = df[3].astype('float64')

from sklearn.impute import SimpleImputer

si = SimpleImputer(strategy='mean', missing_values=np.nan)
df[3] = si.fit_transform(df[[3]])

df_1 = df.iloc[:, :7]
df_2 = df.iloc[:, [7]]

dataset_1 = df_1.to_numpy()
dataset_2 = df_2.to_numpy()

import numpy as np
from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)
dataset_2 = ohe.fit_transform(dataset_2)

dataset = np.concatenate([dataset_1, dataset_2], axis=1)

dataset_x = dataset[:, 1:]
dataset_y = dataset[:, 0]

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.ensemble import AdaBoostRegressor

adr = AdaBoostRegressor()
adr.fit(training_dataset_x, training_dataset_y)

predict_result = adr.predict(test_dataset_x)
print(predict_result)

rsquare = adr.score(test_dataset_x, test_dataset_y)
print('R^2: {accuracy}', rsquare)

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(test_dataset_y, predict_result)
print(f'Mean absolute error: {mae}')
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi ensemble yöntem olarak AdaBoosting, Oylama (voting), Bagging ve Stacking yöntemlerinden hangisinin kullanılmasının 
    uygun olacağını nasıl belirleyebiliriz? Aslında deneme yöntemini uygulamadan buna karar vermenin sağlam bir yolu yoktur. 
    AdaBoosting zayıf bir tahminleyiciye dayandırıldığı için küçük veri kümelerinde daha başarılı olabilir. Ancak çok fazla 
    etken söz konusu olduğu için biz bu yöntemlerin hepsinin denenmesini ve en iyi sonuç verenin tercih edilmesini öneriyoruz. 
    Aşağıdaki ChatGPT'den alınma özet açıklamayı buraya aktarıyoruz:

    ************************************************************************
    
    1) Veri setinin yapısını iyi analiz et (gürültü, boyut, örnek sayısı).
    2) Problemin karmaşıklığını değerlendir.
    3) Zaman ve kaynak kısıtlarını göz önünde bulundur.
    
    Eğer hâlâ kararsızsan, şu öncelikli sıralama işine yarayabilir:

    Basit + hızlı sonuç → Voting
    Overfitting riski var → Bagging
    Hataları öğrenmek önemli → AdaBoost
    Her şeyi denemek istiyorum → Stacking
    
    ,************************************************************************

    Ancak ChatGPT de nihayinde bizim belirttiğimiz duruma dikkat çemiştir: "Yine de en sağlam sonuçlar, veriyle kısa deneyler 
    yaparak elde edilir."

    ClodeAI bu konuda aşağıdaki açıklamaları yapmıştır:

    ************************************************************************
    AdaBoost'u tercih edin:

    Zayıf öğrenicileriniz varsa (decision stumps gibi)
    Veri setinizde çok fazla noise yoksa
    Bias probleminiz varsa
    Sıralı eğitim süresini tolere edebiliyorsanız

    Voting'i tercih edin:

    Farklı türde güçlü algoritmalarınız varsa
    Hızlı sonuç istiyorsanız
    Basit bir ensemble yöntemi arıyorsanız
    Paralel işlem imkanınız varsa

    Stacking'i tercih edin:

    Maksimum performans hedefliyorsanız
    Yeterli veri setiniz varsa (overfitting'i önlemek için)
    Hesaplama kaynağınız boldaysa
    Kompleksliği tolere edebiliyorsanız

    Bagging'i tercih edin:

    High variance probleminiz varsa
    Decision tree gibi kararsız algoritmalar kullanıyorsanız
    Noise'lu veri setiniz varsa
    Random Forest benzeri yaklaşım istiyorsanız

    Pratik Öneriler

    Başlangıç için: Voting ile başlayın, basit ve etkilidir
    Veri boyutu küçükse: AdaBoost veya Bagging tercih edin
    Veri boyutu büyükse: Stacking deneyebilirsiniz
    Noise fazlaysa: Bagging en güvenli seçenektir
    Zaman kısıtınız varsa: Voting en hızlı çözümdür

    Genel olarak, probleminizin özelliklerine göre birkaç yöntemi deneyip cross-validation ile performanslarını 
    karşılaştırmanızı öneririm.

    ************************************************************************

    Tabii otomatik makine öğrenmesi araçları aslında bu denemeleri kendisi yapmaktadır. Bu araçları kullanarak üretilen 
    modeller incelenirse veri kümesi için hangi ensemble yöntemin daha iyi sonuç verdiğine yönelik bilgi edinilebilir. 
    İzleyen paragraflarda biz "auto-sklearn" ve "TPOT" otomatik makine öğrenmesi araçlarını ele alacağız. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Boosting yöntemlerinden bir diğerine de "GradientBoosting" denilmektedir. Bu yöntemde problem bir kez çözülür. Sonra gerçek 
    değerlerle tahmin edilen değerler arasındaki farklar (residuals) hesaplanır. Bu farkların küçültülmesi için yeniden model 
    oluşturulur. Her defasında bir önceki değerler sanki gerçek değerlermiş gibi işleme sokulmaktadır. Burada da yine her adımda 
    yeni bir tahminleyici oluşturulmaktadır. En sonunda yine oylama yapılarak kestirim gerçekleştirilmektedir. 

    GradientBoosting yönteminde aslında tahmin değer ile kestirilen değerin arasındaki farkın minimize edilmesi yönünde tahminleyicinin
    değiştirilmesidir. Bir regresyon probleminde (yi - yi_hat) ** 2 ifadesinin minime edilmesi için gradyen vektör elde edildiğinde 
    bu (yi - yi_hat) durumuna gelmektedir. Buna da "residüel (residual)" dendiğini anımsayınız. Yöntemin algortimik özeti aşağıdaki 
    gibi verilebilir:

    1. F₀(x) = arg min_γ Σᵢ L(yᵢ, γ)

    2. For m = 1 to M:
    a. rᵢₘ = -[∂L(yᵢ,F(xᵢ))/∂F(xᵢ)]_{F=Fₘ₋₁}  ∀i
    b. hₘ ← Fit(rᵢₘ, xᵢ)
    c. γₘ = arg min_γ Σᵢ L(yᵢ, Fₘ₋₁(xᵢ) + γhₘ(xᵢ))
    d. Fₘ(x) = Fₘ₋₁(x) + νγₘhₘ(x)
    
    3. Return F_M(x)

    Burada amaç yukarıda da belirttiğimiz gibi toplam rezidüellerin minimize edilmesidir. Bunun için de gradyen vektör kullanılmaktadır. 
    Tabii regresyon problemi için yukarıdaki algoritmada L ile belirtilen amaç fonksiyonu "farkların karesel ortalaması (mean 
    squared error)" olurken sınıflandırma problemlerinde "binary cross-entropy" olabilir. Bu yöntemde amaç fonksiyon değiştirebileceği 
    için yöntem hem sınıflama hem de regresyon problemlerine aynı biçimde uygulanabilmektedir. GradientBoosting yönteminde yine 
    tahminleyici olarak zayıf bir tahminleyici (örneğin "karar kütüğü") tercih edilmektedir. Burada da nihai karar her adımda 
    elde edilen karar kütüklerinden elde edilen değerlerin ağırlıklı oylamaya sokulmasıyla elde edilmektedir. Buradaki ağırlıklar 
    ilgili adımdaki gradyen vektör değerlerinden oluşmaktadır. 

    Karar ağaçları için özellik ölçeklemesinin gerekli olmadığından bahsetmiştik. Burada gradyen hesabı devreye girdiği için 
    ve genel olarak bu tür hesaplarda özellik ölçeklemesi gerektiği için çelişik bir durum varmış gibi görünmektedir. Ancak 
    buradaki gradyen hesap daha önceki yöntemlerde olduğu gibi uygulanmamaktadır. Dolayısıyla aslında bu yöntemde özellik ölçeklemesi 
    yapmaya genellikle gerek yoktur. Ancak bazı durumlarda özellik ölçeklemesinin uygulanması gerekebilir. Tabii daha önceden de 
    belirttiğimiz gibi gerekmediği halde özellik ölçeklemesi yapmanın da çoğu kez bir sakıncası olmamaktadır 

    Özet olarak GradientBoosting yöntemi aslında genel itibari ile AdaBoosting yöntemine benzemektedir. Bu yöntemde amaç gerçek
    değerlerle tahmin edilen değerlerin arasındaki farkların minimize edilmesi için satır ağırlıklarının değiştirilmesidir. 
    Yönteme "gradient" önekinin eklenmesinin amacı buradaki gradyen temelli minimizasyon işlemi nedeniyledir.

    scikit-learn içersinde Gradient Boosting işlemini yapan iki sınıf vardır: GradientBoostingClassifier ve GradientBoostingRegressor. 
    Bu sınıfların  __init__ metotlarının parametik yapıları şöyledir:

    class sklearn.ensemble.GradientBoostingClassifier(*, loss='log_loss', learning_rate=0.1, n_estimators=100, subsample=1.0, 
        criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, 
        min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, 
        warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)

    class sklearn.ensemble.GradientBoostingRegressor(*, loss='squared_error', learning_rate=0.1, n_estimators=100, 
        subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, 
        max_depth=3, min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, alpha=0.9, verbose=0, 
        max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0

    Bu sınıflar tahminleyici almamaktadır. Çünkü zaten gradient algoritma loss fonksiyonuna dayandırılmıştır. Defalt loss fonksiyonu 
    sınıflandırma problemleri için "log_loss", regresyon problemleri için "squared_error" biçimindedir. Sınıfların kullanımı 
    diğer sınıflarda olduğu gibidir. estimators parametresi yine kullanılacak modellerin (tahminleyicilerin) sayısını belirtmektedir. 
    Bu parametre default olarak 100 girilmiştir. 

    Aşağıdaki örnekte "cryotherapy" veri kümesi üzerinde GradientBoosting yöntemi uygulanmıştır.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('cryotherapy.csv', delimiter=';')

df_x = df.iloc[:, :-1]
df_y = df.iloc[:, -1]

from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)

oge_columns = ohe.fit_transform(df_x[['sex', 'Type']])
df_x.drop(['sex', 'Type'], inplace=True, axis=1)
df_x[['sex_male', 'sex_female', 'type_1', 'type_2', 'type_3']] = oge_columns

dataset_x = df_x.to_numpy()
dataset_y = df_y.to_numpy()

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.ensemble import GradientBoostingClassifier

adc = GradientBoostingClassifier()
adc.fit(training_dataset_x, training_dataset_y)

predict_result = adc.predict(test_dataset_x)
print(predict_result)

accuracy = adc.score(test_dataset_x, test_dataset_y)
print('Accuracy: {accuracy}', accuracy)

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte de "auto-mpg.data" veri kümesi üzerinde GradientBoostingRegressor sınıfı uygulanmıştır.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd
import numpy as np

df = pd.read_csv('auto-mpg.data', delimiter=r'\s+', header=None)

df = df.iloc[:, :-1]
df.iloc[df.loc[:, 3] == '?', 3] = np.nan

df[3] = df[3].astype('float64')

from sklearn.impute import SimpleImputer

si = SimpleImputer(strategy='mean', missing_values=np.nan)
df[3] = si.fit_transform(df[[3]])

df_1 = df.iloc[:, :7]
df_2 = df.iloc[:, [7]]

dataset_1 = df_1.to_numpy()
dataset_2 = df_2.to_numpy()

import numpy as np
from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output=False)
dataset_2 = ohe.fit_transform(dataset_2)

dataset = np.concatenate([dataset_1, dataset_2], axis=1)

dataset_x = dataset[:, 1:]
dataset_y = dataset[:, 0]

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.ensemble import GradientBoostingRegressor

adr = GradientBoostingRegressor()
adr.fit(training_dataset_x, training_dataset_y)

predict_result = adr.predict(test_dataset_x)
print(predict_result)

rsquare = adr.score(test_dataset_x, test_dataset_y)
print('R^2: {accuracy}', rsquare)

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(test_dataset_y, predict_result)
print(f'Mean absolute error: {mae}')

#----------------------------------------------------------------------------------------------------------------------------
    Karar ağaçları söz konusu olduğunda ismine "rassal orman (random forest)" denilen bir topluluk yöntemi de sıkça kullanılmaktadır. 
    Rassal orman yöntemi aslında daha önce görmüş olduğumuz "bagging (bootstarp aggregation)" yöntemine benzemektedir. Rassal 
    orman yönteminde tıpkı bagging yönteminde olduğu gibi örnekleme yapılmaktadır. Ancak bu iki yöntem arasında şu farklılıklar 
    vardır:

    - Bagging yönteminde tahminleyici olarak herhangi bir tahminleyici kullanılabilmektedir. Ancak rassal ormanlar yalnızca
    karar ağaçlarıyla kullanılmaktadır. 

    - Bagging yönteminde esas olan satırların örneklenmesidir (zaten "bootstrap" termi bu anlama gelmektedir) ancak rassal 
    ormanlarda esas olan sütunların örneklenmesidir. Ancak her iki yöntemde hem satırlarda hem de sütunlarda örnekleme 
    yapılabilmektedir. 

    - Her iki yöntemde de örnekleme iadeli çekim yoluyla yapılmaktadır. İadeli çekimde elemanlar teker teker çekilir. Ama her 
    çekilen iade edilir. Böylece çekilen değerlerin bazıları aynı olabilmektedir. (Örneğin n tane satırdan oluşan bir veri 
    kümesinde n'lik iadeli çekim yapıldığında bu durum n tane satırın hepsinin elde edileceği anlamına gelmemektedir.) Tabii 
    her iki yöntemde de yalnızca satırlar iadeli seçilmektedir. Sütunların iadeli seçilmesinin bir anlamı yoktur.

    - Bagging yönteminde sütunlar üzerinde örnekleme yapılırken örnekleme her tahminleyici için toplamda bir kez yapılmaktadır. 
    Ancak rassal ormanda sütunsal örnekleme ağacın her düğümü için yapılmaktadır. Bu iki yöntem arasındaki en önemli farklardan
    biridir. 

    Rassal orman yönteminin ana esasının her düğümde sütunlar üzerinde rastgele örnekleme yapılması olduğunu belirtmiştik. 
    Pekiyi bu oran ne olmalıdır? İşte pek çok araştırma sütun sayısının karekökü kadar sütunun örneklenmesinin iyi bir 
    performans sağladığını göstermektedir. 

    Karar ağaçları söz konusu olduğunda rassal orman yöntemi "bagging" yönteminden toplamda daha iyi performans gösterme 
    eğilimindedir. Rassal orman yönteminde overfitting'e maruz kalma miktarı daha düşüktür.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    scikit-learn kütüphanesinde rassal orman için iki sınıf bulundurulmuştur: RandomForestClassifier ve RandomForestRegressor. 
    Bu sınıflar kendi içlerinde DecisionTreeClassifier ve DecisionTreeRegressor sınıfıları kullanılarak gerçekleştirilmiştir. 
    Sınıfların __init__ metotlarının parametik yapısı şöyledir:

    class sklearn.ensemble.RandomForestClassifier(n_estimators=100, *, criterion='gini', max_depth=None, 
            min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features='sqrt', 
            max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, 
            random_state=None, verbose=0, warm_start=False, class_weight=None, ccp_alpha=0.0, max_samples=None, 
            monotonic_cst=None)

    class sklearn.ensemble.RandomForestRegressor(n_estimators=100, *, criterion='squared_error', max_depth=None, 
            min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=1.0, max_leaf_nodes=None, 
            min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, 
            warm_start=False, ccp_alpha=0.0, max_samples=None, monotonic_cst=None)

    Metotların birinci parametreleri kaç tane karar ağacının oluşturulacağını belirtmektedir. Yine metotların karar ağaçlarında
    olduğu gibi max_depth parametreleri vardır. Ancak metotların en önemli parametreleri max_features parametreleridir. Bu 
    parametre her düğümdeki sütunsal örneklemenin oranını belirtmektedir. Bu parametrenin default değerinin 'sqrt' biçiminde 
    olduğuna dikkat ediniz. Yani her düğümde toplam sütunların kaekökü kadar sütun elde seçilmektedir. Metotların bootstap 
    parametreleri satırsal örneklemenin yapılıp yapılmayacağını belirtir. Bu parametrelerin default değeri True biçimdedir. 
    Metotların max_samples parametreleri ise hangi oranda ya da miktarda satırsal örnekleme yapılacağını belirtmektedir. 
    Bu parametredeki default None değeri örneklemede tüm satırların kullanılacağı anlamına gelir. (boostrap = True, 
    max_samples = None bir çelişki oluşturmamaktadır. Çünkü seçim iadeli yapılmaktadır.)

    İlgili sınıf türünden nesne yaratıldıktan sonra yine bu nesne üzerinde fit metodu, predit metodu ve score metodu 
    benzer biçimde uygulnamktadır. 

    Aşağıdaki örnekte "breast cancer" veri kümesi üzerinde DecisionTreeClassifier, BaggingClassifier ve RandomForestClassifier
    sınıfları ile performans karşılaştırması yapılmıştır. Bu performans karşılaştırması yapılmıştır. Aslında bu tür karşılatırmalar
    için "K-Fold Çapraz Sınama" yöntemi tercih edilmektedir. Bu yöntem izleyen paragraflarda ele alınacaktır. Ancak biz 
    burada bu yöntemi de kullandık. Burada elde edilen sonuçlara göre BaggingClassifier ile RandomForestClassifier benzer 
    performnsı göstermektedir. Ancak RandomForestClassifier sınıfının parametreler daha iyi ayarlandığında performans 
    BaggingClassifer yöntemine göre biraz daha iyi olma eğilimindedir.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv("data.csv")

dataset_x = df.iloc[:, 2:-1].to_numpy()
dataset_y = np.zeros(len(df))
dataset_y[df['diagnosis'] == 'M'] = 1

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

import numpy as np
dtc = DecisionTreeClassifier()
dtc.fit(training_dataset_x, training_dataset_y)
score = dtc.score(test_dataset_x, test_dataset_y)
print(f'DecisionTreeClassifier score: {score}')

dtc = DecisionTreeClassifier()
bc = BaggingClassifier(dtc, n_estimators=100, max_samples=0.70, max_features=0.70)
bc.fit(training_dataset_x, training_dataset_y)

accuracy = bc.score(test_dataset_x, test_dataset_y)
print(f'BaggingClassifier Accuracy: {accuracy}')

rfc = RandomForestClassifier(n_estimators=100, max_samples=0.70)
rfc.fit(training_dataset_x, training_dataset_y)

accuracy = rfc.score(test_dataset_x, test_dataset_y)
print(f'RandomForestClassifier Accuracy: {accuracy}')

print('-' * 20)

accuracy_dtc = score = cross_val_score(dtc, training_dataset_x, training_dataset_y)
accuracy_bc = cross_val_score(bc, training_dataset_x, training_dataset_y)
accuracy_rfc = cross_val_score(rfc, training_dataset_x, training_dataset_y)

print(f'K-Fold DecisionTreeClassifier score: {np.mean(accuracy_dtc)}')
print(f'K-Fold BaggingClassifier score: {np.mean(accuracy_bc)}')
print(f'K-Fold RandomForestClassifier score: {np.mean(accuracy_rfc)}')

#----------------------------------------------------------------------------------------------------------------------------
                                            128. Ders - 31/05/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Sınama (validation) işlemleri için kullanılan ve ismine "K-Fold Çapraz Sınama (K-Fold Cross Validation)" denilen önemli 
    bir yöntem de vardır. Bu yöntem özellikle model araması ve karşılaştırması yapılırken kullanılmaktadır. Örneğin elimizde
    alternatif beş model olduğunu varsayalım. Bu modellerin hangisi daha iyi perfomans göstermektedir? Ya da elimizdeki modelin 
    bazı hyper parametrelerini değiştirelim. Hangi hyper parametreye ilişkin model daha iyi perfomans göstermektedir? Biz şimdiye 
    kadar bu tür karşılaştırmalar için veri kümesini eğitim ve test olarak ikiye ayırdık. Alternatif modelleri eğitim veri kümesi 
    ile eğitip test veri kümesiyle onların performanslarını karşılaştırdık. Ancak bu biçimdeki performans karşılaştırmalarında 
    veri kümesinin "eğitim" ve "test" biçiminde rastgele ayrıştırılması yanlılıklara yol açabilmektedir. Rastgele ayrıştırdığımız 
    eğitim veri kümesi ve test veri kümesi bazı modeller için daha iyi bir veri kümesi durumundayken bazı modeller için daha kötü 
    bir veri kümesi durumunda olabilir. Bu "eğitim" ve "test" veri kümeleri değiştirildiğinde modellerin performansları da 
    değişebilmektedir. Pekiyi bu yanlılıktan nasıl kurtulabiliriz? İlk akla gelen yöntem bu ayrıştırmayı bir kez değil çok kez
    yaparak bir ortalama değer bulmaktır. (Bagging yönteminde buna benzer bir işlem yapıldığını anımsayınız.) Ancak bu yöntemin de 
    bazı sakıncaları söz konusu olabilmektedir. İşte bu tür durumlarda genel olarak "K-Fold Çapraz Sınama" denilen yöntem tercih
    edilmektedir. 

    K-Fold Çapraz Sınama yönteminde veri kümesi K tane parçaya ayrılır. Her defasında bu K parçadan biri sınama için, geri kalanların 
    toplamı da eğitim için kullanılır. Her parçadan elde edilen performans ölçütlerinin ortalaması alınır. Örneğin K değerinin 5 olduğunu 
    varsayalım. Bu durumda veri kümesini 5 parçaya ayırırız:

    1. Parça
    2. Parça
    3. Parça
    4. Parça
    5. Parça

    Sonra aşağıdaki eğitim ve test veri kümeleriyle eğitim ve sınama işlemlerini yaparız:

    1. Eğtim/Sınama:

    Eğitim Veri Kümesi = 2. Parça + 3. Parça + 4. Parça + 5. Parça 
    Sınama Veri Kümesi = 1. Parça

    2. Eğtim/Sınama:

    Eğitim Veri Kümesi = 1. Parça + 3. Parça + 4. Parça + 5. Parça 
    Sınama Veri Kümesi = 2. Parça

    3. Eğtim/Sınama:

    Eğitim Veri Kümesi = 1. Parça + 2. Parça + 4. Parça + 5. Parça 
    Sınama Veri Kümesi = 3. Parça
    
    4. Eğtim/Sınama:

    Eğitim Veri Kümesi = 1. Parça + 2. Parça + 3. Parça + 5. Parça 
    Sınama Veri Kümesi = 4. Parça
    
    5. Eğtim/Sınama:

    Eğitim Veri Kümesi = 1. Parça + 2. Parça + 3. Parça + 4. Parça 
    TeSınamast Veri Kümesi = 5. Parça
    
    Buradan beş ayrı performans değeri edilerek bunların ortaalaması alınacaktır. 

    K-Fold Çapraz Sınama yöntemi "test amacıyla değil modelin alternatif modellere göre kıyaslanması amacıyla" kullanılmaktadır.
    Tabii bazen bu yöntem tek bir model söz konusu olsa da geliştirilen modelin genellenebilirliğini ve overfitting durumuna 
    direncini ölçmek için de kullanılmaktadır. Buradaki sınama veri kümeleri ile test veri kümesini karıştırmayınız. Test veri 
    kümesi nihai modelin nihai testi için kullanılmaktadır. Dolayısıyla biz örneğin alternatif beş yöntemi karşılaştırıp en 
    iyisini bulup onu kullanmak istiyorsak yine önce veri kümemizi "eğitim" ve "test" biçiminde iki kısma ayırıp "eğitim" veri 
    kümesi üzerinde K-Fold Çapraz Sınama işlemini yapmalıyız. Tabii en iyi modeli belirledikten sonra yine bu modeli tüm eğitim 
    veri kümesiyle eğitip test veri kümesiyle test etmemiz gerekir. Bu durumu biz şuna benzetebiliriz: Beş kişinin İngilizce 
    seviyesini kendi aralarında belli bir soru kümesi ile yarışma yaparak tespit edip buradan birinciyi seçtiğimizi düşünelim. 
    Şimdi bu birincinin başarısını bağımsız başka bir testle (örneğin TOEFL, IELTS gibi) nihai olarak belirlemek isteyebiliriz. 
        
    O halde K-Fold Çapraz Sınama yöntemi iki amaçla kullanılmaktadır:

    1) Tamamen farklı modelleri ya da aynı modelin farklı hyper parametreli biçimlerini daha iyi karşılaştırmak için.
    2) Belli bir modelin genellenebilirliğini yani overfitting davranışını daha iyi test etmek için.

    Pekiyi K-Fold Çapraz Sınama yerine biz veri kümesini her defasında rastgele "eğitim" ve "sınama" biçiminde ayırıp 
    bunu çok defa yapıp bir ortalama bulsak olmaz mı? Evet aslında bu yöntem de çoğu durumda çalışır. Ancak bu yöntemin 
    şu dezavantajları söz konusu olmaktadır:

    - K-Fold Çapraz Sınama yönteminde veri kümesindeki her satır eğitim ve test sürecine dahil olmaktadır. Ancak rastgele 
    seçilen satırlarda bu durum söz konusu olmayabilir. 

    - K-Fold Çapraz Sınama her uygulandığında aynı sonucu verir. Rastgele seçim farklı sonuçları verebilmektedir. 

    - K-Fold Çapraz Sınamada daha az çaba (dolayısıyla daha az bilgisayar zamanı) yeterli olmaktadır. Rastgele seçim yönteminde 
    çok fazla seçimin yapılması gerekebilir. 

    Pekiyi K-Fold Çapraz Sınama yöntemindeki bu K sayısı ne olmalıdır? Pek çok uygulamacı K için makul bir değerin 5 ile 10 
    arasında olduğunu belirtmektedir. 
    
    Eğer veri kümesi küçükse K-Fold Çapraz sınamanın "Leave-One-Out (LOO)" denilen bir varyasyonu da kullanılabilmektedir.  
    Bu varyasyonda sınama veri kümesi tek bir satırdan oluşur. Diğer tüm satırlar eğitimde kullanılır. Örneğin veri kümesi 
    100 satır ise her yinelemede 99 satır eğitim için 1 satır sınama için kullanılır. Tabii bu yöntem ancak satır sayısının 
    az olduğu (örneğin < 100 olduğu) durumlarda makul bir yöntem haline gelmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    scikit-learn kütüphanesinde K-Fold Çapraz Sınamayı manuel yapmak için KFold isimli yardımcı bir sınıf bulundurulmuştur. 
    KFold sınıfı şöyle kullanılmaktadır:

    1) Önce KFold sınıfı türünden bir nesne yaratılır. Sınıfın __init__ metodunun parametrik yapısı şöyledir:

    class sklearn.model_selection.KFold(n_splits=5, *, shuffle=False, random_state=None)

    Burada birinci parametre K sayısıdır. Bu parametrenin default değerinin 5 olduğunu görüyorsunuz. Pek çok uygulamada bu değer
    10 olarak girilmektedir. shuffle parametresi işlemlere başlamadan önce veri kümesinin karıştırılıp karıştırılmayacağını
    belirlemekte kullanılmaktadır. 

    2) KFold nesnesi ile sınıfın split metodu çağrılır. Metodun parametrik yapısı şöyledir:

    split(X, y=None, groups=None)

    split metodu parametre olarak bizden X veri kümesini almaktadır. Bu metot bize ürün olarak bir üretici nesne vermektedir. 
    Bu üretici nesne dolaşıldığında iki elemanlı demetler elde edilir. Bu demetlerin birinci elemanı eğitim için kullanılacak 
    satır indekslerini ikinci elemanı sınama için kullanılacak satır indekslerini belirtmektedir. Eğer KFold nesnesi yaratılırken 
    shuffle parametresi False geçilirse (default durum) buradaki indeksler ardışıl olur. Fakat bu parametre True geçilirse 
    ardışıllık ortadan kalkar. NumPy ve Pandas'ta indeksler bir dizi içerisidneyse tek hamlede bu indekslerdeki elemanların 
    elde edilebileceğini biliyoruz. 

    3) split metodu ile tipik olarak aşağıdaki gibi bir döngü oluşturulur:

    for train_ind, val_ind in kf.split(training_dataset_x):
        pass

    Bu döngüde ilgili tahminleyici nesnesi ile fit ve predict metotları çağrılıp (ya da varsa doğrudan tahminleyici sınıfının 
    score metodu da çağrılabilir) elde edilen değer biriktirilir:

    for train_ind, val_ind in kf.split(training_dataset_x):
        dtc.fit(training_dataset_x[train_ind], training_dataset_y[train_ind])
        
        predict_result = dtc.predict(training_dataset_x[val_ind])   
        score = accuracy_score(training_dataset_y[val_ind], predict_result)
        
        """
        score = dtc.score(training_dataset_x[val_ind], training_dataset_y[val_ind])
        """
        scores.append(score)

    Biriktirilen değerin de ortalamsı alınarak nihai sınama skoru elde edilir:

    cv_score = np.mean(scores)

    Aşağıda "zambak (iris)" veri kümesi üzerinde DecisionTreeClassfier tahminleyicisi ile bu biçimde bir sınama yapımıştır. 
    Tabii uygulamacının bu sınama değerlerini gözden geçirip değerler arasında önemli bir farklılığın olup olmadığına bakması 
    gerekir. Bu durum ilgili tahminleyicinin genelleştirilebilirliği konusunda fikir verecektir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('Iris.csv')

dataset_x = df.iloc[:, 1:-1].to_numpy(dtype='float32')

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
dataset_y = le.fit_transform(df.iloc[:, -1])

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.tree import DecisionTreeClassifier

dtc = DecisionTreeClassifier()

import numpy as np
from sklearn.metrics import accuracy_score
from sklearn.model_selection import KFold

scores = []
kf = KFold(10, shuffle=True)
for train_ind, val_ind in kf.split(training_dataset_x):
    dtc.fit(training_dataset_x[train_ind], training_dataset_y[train_ind])
    
    predict_result = dtc.predict(training_dataset_x[val_ind])   
    score = accuracy_score(training_dataset_y[val_ind], predict_result)
    
    """
    score = dtc.score(training_dataset_x[val_ind], training_dataset_y[val_ind])
    """
    scores.append(score)
    
print('K scores: {scores}')
cv_score = np.mean(scores)

print(f'K-Fold Cross Validation Score: {cv_score}')

dtc.fit(training_dataset_x, training_dataset_y)
predict_result = dtc.predict(test_dataset_x)
test_score = accuracy_score(test_dataset_y, predict_result)

"""
test_score = dtc.score(test_dataset_x, test_dataset_y)
"""

print(f'Test Score: {test_score}')

#----------------------------------------------------------------------------------------------------------------------------
    Aslında scikit-learn kütüphanesinde yukarıdaki işlemlerin hepsini yapan cross_val_score isimli bir fonksiyon da bulunmaktadır.
    Fonksiyonun parametrik yapısı şöyledir:

    sklearn.model_selection.cross_val_score(estimator, X, y=None, *, groups=None, scoring=None, cv=None, n_jobs=None, 
            verbose=0, params=None, pre_dispatch='2*n_jobs', error_score=nan)

    Fonksiyonun birinci parametresi tahminleyici nesnesini, ikinci parametresi x değerlerini, üçüncü parametresi ise y değerlerini 
    almaktadır. Fonksiyonun cv parmatresine parça sayısını belirten K değeri girilebilir. Default durumda bu değer 5 olarak 
    alınmaktadır. Fonksiyon bize her parçanın performans değerini (score değerini) bir NumPy dizisi olarak vermektedir. Fonksiyonun 
    scoring parametresi hesaplanacak skorun ne olduğunu belirtmektedir. Biz buraya scikit-learn metrik isimlerini girebiliriz. 
    Örneğin sınıflandırma problemleri için bu parametre "accuracy" biçiminde regresyon problemleri için ise "neg_mean_squared_error" 
    biçiminde girilebilir. Tabii bu parametre aslında genellikle girilmez. Bu durumda fonksiyonun birinci parametresinde belirtilen 
    tahminleyicinin score fonksiyonu kullanılmaktadır. 

    Aşağıda "zambak (iris)" veri kümesi üzerinde çapraz sınama işlemlerinin cross_val_score fonksiyonu ile yapılmasına bir 
    örnek verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('Iris.csv')

dataset_x = df.iloc[:, 1:-1].to_numpy(dtype='float32')

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
dataset_y = le.fit_transform(df.iloc[:, -1])

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.tree import DecisionTreeClassifier

dtc = DecisionTreeClassifier()

import numpy as np
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score

scores = cross_val_score(dtc, training_dataset_x, training_dataset_y, cv=10)
cv_score = np.mean(scores)

print(f'K-Fold Cross Validation Score: {cv_score}')

dtc.fit(training_dataset_x, training_dataset_y)
predict_result = dtc.predict(test_dataset_x)
test_score = accuracy_score(test_dataset_y, predict_result)

"""
test_score = dtc.score(test_dataset_x, test_dataset_y)
"""

print(f'Test Score: {test_score}')

#----------------------------------------------------------------------------------------------------------------------------
                                            129. Ders - 01/06/2025 - Pazar      
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi yapay sinir ağlarında model karşılaştırması için ya da hyper parametre ayarlaması için K-Fold Çapraz Sınama yöntemi
    nasıl kullanılabilir? Keras içerisinde K-Fold Çapraz Sınama işlemini yapan hazır bir sınıf ya da fonksiyon yoktur. Tabii 
    biz KFold sınıfını kullanarak Keras modeli üzerinde yine manuel bir biçimde fit işlemleri yapabiliriz. Eğer cross_val_score 
    fonksiyonunu kullanacaksanız bu durumda daha önce görmüş olduğumuz KerasClassfier ve KerasRegressor sınıflarıyla uyumlandırma 
    yapılması gerekir. Aşağıda "zambak (iris)" veri kümesi üzerinde uyumlandırma yapılarak bu fonksiyonun kullanılmasına örnek 
    verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('Iris.csv')

dataset_x = df.iloc[:, 1:-1].to_numpy(dtype='float32')

from sklearn.preprocessing import OneHotEncoder

ohe = OneHotEncoder(sparse_output= False)
dataset_y = ohe.fit_transform(df.iloc[:, -1].to_numpy().reshape(-1, 1))

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.1)

from sklearn.preprocessing import StandardScaler

ss = StandardScaler()
ss.fit(training_dataset_x)
scaled_training_dataset_x = ss.transform(training_dataset_x)

import numpy as np
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Input
from scikeras.wrappers import KerasClassifier 
from sklearn.model_selection import cross_val_score

ohe_training_dataset_y = to_categorical(training_dataset_y)

def create_keras_model():  
    model = Sequential(name='Iris')
    model.add(Input((scaled_training_dataset_x.shape[1], ), name='Input'))
    model.add(Dense(64, activation='relu', name='Hidden-1'))
    model.add(Dense(64, activation='relu', name='Hidden-2'))
    model.add(Dense(3, activation='softmax', name='Output'))
    model.compile('rmsprop', loss='categorical_crossentropy', metrics=['categorical_accuracy'])
    return model

kc = KerasClassifier(model=create_keras_model, epochs=10, batch_size=10, verbose=1)

scores = cross_val_score(kc, scaled_training_dataset_x, training_dataset_y, cv=10)
cv_score = np.mean(scores)

print(f'K-Fold Cross Validation Score: {cv_score}')

#----------------------------------------------------------------------------------------------------------------------------
    Sınıflandırma problemlerinde y değerlerine ilişkin sınıflar arasında orantısızlık varsa K-Fold yapılırken elde edilen 
    parçalardaki y değerleri sorunlara yol açabilmektedir. Örneğin iki sınıflı bir sınıflandırma problemi söz konusu olsun.
    Burada y değerlerinin A ve B sınıflarından oluştuğunu varsayalım. Ancak y değerlerine bakıldığında %90 A sınıfından,
    %10 B sınıfından oluştuğu görülmüş olsun. Şimdi biz bu veri kümesini KFold sınıfı ile parçalara ayırırsak parçalarda 
    bu oranlar bozulabilecektir. Hatta örneğin bazı parçalarda B sınıfı hiç bulunmayabilecektir. Bu da K-Fold işlemini 
    zayıflatacaktır. İşte bu durumlarda "tabakalı (stratified) K-Fold" uygulamak gerekir. Tabakalı K-Fold uygularken y 
    değerlerine ilişkin sınıflar parçalarda da aynı oranda korunmaya çalışılmaktadır. Yani yukarıdaki örneğimizde biz 
    tabakalı K-Fold uyguladığımızda her parçadaki A ve B oranları %90 ve %10 olacak biçimde ayarlanacaktır. 

    Tabakalı K-Fold (Stratified K-Fold) yöntemini manuel bir biçimde uygulamak için scikit-learn içerisinde StratifedKFold
    isimli bir sınıf bulundurulmuştur. Sınıfın __init__ metodunun parametrik yapısı şöyledir:

    class sklearn.model_selection.StratifiedKFold(n_splits=5, *, shuffle=False, random_state=None)

    Tabii artık split işlemi yapılırken hem x hem de y değerlerinin verilmesi gerekir. split metodunun parametrik yapısı da 
    şöyledir:

    split(X, y, groups=None)

    Sınıflandırma problemleri için her zaman K-Fold yerine tabakalı K-Fold kullanılması tavsiye edilmektedir. Tabii regresyon
    problemleri için tabakalı bir işlem söz konusu değildir. Ancak eğer böyle bir etki yaratılmak isteniyorsa y değerleri 
    manuel bir biçimde ayrık hale getirilip işleme sokulabilir. Ancak bu durum genel olarak tercih edilmemektedir. Biz fit
    metoduna bir regresyon modeline ilişkin x ve y değerlerini verirsek metot exception oluşturacaktır.

    Aşağıdaki örnekte daha önce yapmış olduğumuz manuel KFold işlemi bu kez StratifiedKFold sınıfıyla yapılmıştır.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('Iris.csv')

dataset_x = df.iloc[:, 1:-1].to_numpy(dtype='float32')

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
dataset_y = le.fit_transform(df.iloc[:, -1])

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from sklearn.tree import DecisionTreeClassifier

dtc = DecisionTreeClassifier()

import numpy as np
from sklearn.metrics import accuracy_score
from sklearn.model_selection import StratifiedKFold

scores = []
kf = StratifiedKFold(10, shuffle=True)
for train_ind, val_ind in kf.split(training_dataset_x, training_dataset_y):
    dtc.fit(training_dataset_x[train_ind], training_dataset_y[train_ind])
    
    predict_result = dtc.predict(training_dataset_x[val_ind])   
    score = accuracy_score(training_dataset_y[val_ind], predict_result)
    
    """
    score = dtc.score(training_dataset_x[val_ind], training_dataset_y[val_ind])
    """
    scores.append(score)
    
print('K scores: {scores}')
cv_score = np.mean(scores)

print(f'K-Fold Cross Validation Score: {cv_score}')

dtc.fit(training_dataset_x, training_dataset_y)
predict_result = dtc.predict(test_dataset_x)
test_score = accuracy_score(test_dataset_y, predict_result)

"""
test_score = dtc.score(test_dataset_x, test_dataset_y)
"""

print(f'Test Score: {test_score}')

#----------------------------------------------------------------------------------------------------------------------------
    Biz yukarıda scikit-learn kütüphanesinde K-Fold işlemlerini otomatik yapan cross_val_score fonksiyonunu da görmüştük.
    İşte bu fonksiyon sınıflandırma için oluşturulan veri kümelerinde default durumda tabakalı işlem yapmaktadır. Yani bu 
    fonksiyonu yazanlar default olarak tahminleyicie bakıp eğer tahminleyici regresyon amacıyla kullanılan tahminleyici ise 
    KFold sınıfını, sınıflandırma amacıyla kullanılan tahminleyici ise StratifiedKFold sınıfını kullanmıştır. Ancak fonksiyonun
    cv parametresi ile bu durum manuel olarak da ayarlanabilmektedir. Anımsanacağı gibi fonksiyonun cv parametresi K değerini 
    belirtiyordu. İşte bu parametreye bir K değeri girmek yerine sınıf ismi de girebiliriz. Örneğin bu cv parametresine 
    KFold ismini girersek bu durumda fonksiyon StratifiedKFold yerine bu sınıfı kullanacaktır.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Çok kullanılan otomatik makine öğrenmesi (Automated Machine Learning) kütüphanelerinden biri de "TPOT" denilen kütüphanedir. 
    Kursumuzun bu bölümünde TPOT kütüphanesinin temel kullanımı üzerinde duracağız.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    TPOT kütüphanesi ağırlıklı olarak istatistiksel yöntemleri kullanmaktadır ve sckit-learn kütüphanesinin üzerine oturtulmuştur. 
    Kütüphaneye daha sonraları yapay sinir ağları modülü de (nn modülü) eklenmiş durumdadır. Bu modül arka planda PyTorch 
    kütüphanesini kullanmaktadır. nn modülü kullanılmasa bile TPOT scikit-learn içerisindeki basit sinir ağı oluşturan MLPClassifier 
    ve MLPRegressor sınıflarını da modellerde denemektedir.

    TPOT çeşitli modelleri dener. Denemeler sırasında hyper parametreleri de ayarlamaya çalışır. Model denemesi ve hyper parametre 
    ayarlaması için arka planda "genetik algoritmalardan" faydalanılmaktadır. Genetik algoritmalarla iyi sonuç veren modeller 
    değiştirilerek model iyileştirilmeye çalışılmaktadır. 

    TPOT kütüphanesinin ana web sayfası aşağıdaki bağlantıda verilmiştir:

    http://epistasislab.github.io/tpot/

    TPOT pek çok işlemi kendisi yapabilmektedir. Örneğin özellik seçimi, ölçekleme işlemleri, model seçimi, hyper parametrelerin 
    ayarlanması gibi. Yukarıda da belirttiğimiz gibi TPOT genetik algoritmaları kullanarak ayarlamaları optimize etmeye çalışmaktadır. 
    Ancak TPOT kullanıcılar için nispeten basit bir arayüz sunmaktadır. Kütüphanede iki temel sınıf vardır: TPOTClassifier ve 
    TPOTRegerressor. TPOTClassifier sınıfı sınıflandırma problemleri için TPOTRegressor sınıfı ise regresyon problemleri için 
    kullanılmaktadır. 

    Otomatik makine öğrenmesi araçları iyi bir modelin bulunması için zamana gereksinim duymaktadır. Dolayısıyla iyi bir model 
    için çokça bilgisayar zamanı gerekebilmektedir. Bu nedenle bu tür araçların cloud sistemlerinde uzaktan idare edilmesi 
    yaygın bir uygulamadır. 

    TPOT ile iyi bir model bulunduktan sonra elde edilen modele ilişkin scikit-learn kullanılmış olan Python kodları da 
    üretilebilmektedir. Böylece oluşturulan model TPOT'tan bağımsız biçimde dış dünyadan da kullanılabilmektedir. 

    TPOT kütüphanesinin kurulumu şöyle yapılabilir:

    pip install tpot

    Aslında TPOT Python'dan bağımsız olarak komut satırından da çalıştırılabilmektedir. (Yani bu kurulumu yaptıktan sonra 
    aynı zamanda "tpot" isimli komut satırından çalışan bir program da yüklenmiş olmaktadır.) Bunun için çeşitli komut satırı 
    argümanlar kullanılmaktadır. Örneğin:

    tpot data/mnist.csv -is , -target class -o tpot_exported_pipeline.py -g 5 -p 20 -cv 5 -s 42 -v 2

    Eğer TPOT'u komut satırından kullanacaksanız dokümanlardan komut satırı argümanlarına ilişkin ayrıntıları incelemelisiniz.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
                                        130. Ders - 14/06/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    TPOT sınıfları üzerinde TPOT'un çeşitli versiyonlarında değişiklikler yapılmıştır. Biz burada kütüphanenin kursun yapıldığı
    sıradaki son verisyonunu dikkate alacağız. TPOT'un orijinal dokümanları maalesef geriden gelmektedir. (Yani bu dokümanlar
    kütüphanenin eski versiyonlarına ilişkin olabilir.) Kursun yapıldığı sıradaki son TPOT versiyonu 0.12.2'dir.
    
    TPOT'ta sınıflandırma işlemleri için TPOTClassifier sınıfı kullanılmaktadır. Sınıfın __init__ metodunun parametrik yapısı 
    şöyledir:

    TPOTClassifier(generations=100,
        population_size=100,
        offspring_size=None,         
        mutation_rate=0.9,
        crossover_rate=0.1,
        scoring='accuracy',
        cv=5,
        subsample=1.0,
        n_jobs=1,
        max_time_mins=None,
        max_eval_time_mins=5,
        random_state=None,
        config_dict=None,
        warm_start=False,
        memory=None,
        periodic_checkpoint_folder=None,
        early_stop=None,
        verbosity=0,
        disable_update_check=False,
        use_dask=False,      
    )        
        
    Buradaki generations, population_size, offspring_size, mutation_rate parametreleri model araması ile ilgili olan, genetik 
    algoritmalar tarafından kullanılan parametrelerdir. Genel olarak bu değerler yükseltildikçe modelin iyileşme olasılığı da 
    yükselmektedir. Ancak tabii bu değerlerin yükseltilmesi çözüm için daha çok zamanın harcanmasına da yol açacaktır. Eğer 
    uygulamacı genetik algoritmalar hakkında bilgi sahibi değilse bu parametreleri default değerlerde bırabilir. 
    
    Uygulamacı için modelin elde edilmesi için harcanacak zaman önemli olabilmektedir. Default parametreler çok fazla beklemeye 
    yol açabilmektedir. Bu nedenle bekleme zamanını kontrol altında tutabilmek için max_time_mins parametresi bulundurulmuştur. 
    Bu parametreye dakika cinsinden bir değer girilir. TPOT da bu kadar süre içerisinde en uygun modeli bulmaya çalışır. Biz 
    kursumuzaki denemelerde fazla beklememek için bu değeri düşük tutacağız. Ancak siz gerçek uygulamalarda bu değeri yükseltmelisiniz. 
    Tabii bazen burada belirtilen süreden daha önce de model araması bitirilebilmektedir.

    Metodun max_time_mins parametresi en iyi modelin bulunması için kullanılacak dakika cinsinden maksimum zamanı belirtmektedir. 
    Bu parametreye None değeri geçilirse (default durumda böyledir) bu durumda maksimun zaman için bir kısıtlama oluşturulmamaktadır.
    Metodun max_eval_time_mins parametresi ise oluşturulan her bir modelin sınanması için ayrılan maksimum zamanı belirtmektedir. 
    Genellikle bu parametre default değerle (5 dakika) geçilmektedir. Metodun verbosity parametresi TPOT çalışırken ekrana 
    çıkartılacak bildirimlerin yoğunluğunu belirtmektedir. Bu değer 0, 1, 2, 3 olabilir. Metodun scoring parametresi test işleminde 
    kullanılacak metrik fonksiyonunu belirtmektedir. Default durumda metrik olarak "accuracy" kullanılmaktadır.

    Örneğin:

    from tpot import TPOTClassifier

    tpc = TPOTClassifier(max_time_mins=5, verbosity=1)

    TPOTClassifier sınıf nesnesi yaratıldıktan sonra eğitim için yine sınıfın fit metodu, kestirim için de predict metodu çağrılır. 
    score metodu ise test işlemini yapmaktadır. Nesnenin fitted_pipeline_ isimli örnek özniteliğinden en iyi boru hattı nesnesi 
    elde edilebilmektedir. Örneğin:

    tpc.fit(training_dataset_x, training_dataset_y)
    predict_result = tpc.predict(predict_data)
    accuracy = tpc.score()
    
    Sınıfın export metodu oluşturulan en iyi modelin Python kaynak kodlarını vermektedir. Örneğin:

    tpc.export('tpot-automated-breastcancer.py')

    Pekiyi TPOT bizim için hangi önişlemleri yapmaktadır? TPOT'un eski versiyonlarında önişleme sokulacak sütunları uygulamacı 
    kendisi belirleyebiliyordu. Ancak daha sonra bu durum değiştirilmiştir. Mevcut sürümde artık yapılacak önişlemler bir 
    sözlük biçiminde TPOT sınıflarının config_dict parametresinde belirtilmektedir. Bu parametrede bir belirleme yapılmazsa 
    default durumda TPOT şu önişlemleri gerekli görürse kendisi yapmaktadır:

    - Eksik verilerin doldurulması (imputation)
    - Özellik ölçeklemesi 
    - Özellik seçimi 
    - Boyutsal özellik indirgemesi

    TPOT kategorik veri içeren yazısal sütunları eğer onların türleri dtype='object' ya da Pandas için dtype='category' biçimindeyse
    sayısallaştırıp gerekli görürse one-hot-encoding dönüştürmesi yapmaktadır. Ancak sayısal hale getirilmiş olan (örneğin LabelEncoder
    ile) sütunları eğer sütun içerisindeki farklı değerlerin sayısı 10'dan az ise kendisi one-hot-encoding işlemine sokmaktadır. Bu 
    otomatik one-hot-encoding işlemi TPOT'un eski versiyonlarında yapılmamaktadır. Eğer siz versiyonu dikkate almayacaksanız bu işlemi 
    manuel yapmalısınız. 

    TPOT hedef sütunun sayısallaştırılmasını da eğer sütunun türü dtype='object' ise ya da Pandas için dtype='category' ise otomatik
    olarak yapmaktadır. (Mevcut versiyonda TPOT hedef değişkeni eğitim amacıyla sayısallaştırırken test amacıyla sayısallaştırmamaktadır.) 
    Yukarıda da belirttiğimiz gibi eğer TPOT'un daha fazla önişlem yapmasını istiyorsanız yapılacak önişlemleri bir sözlük biçiminde 
    oluşturup sınıfların  __init__ metotlarının config_dict parametresine girmelisiniz. Tabii bu config_dict parametresine girilen 
    önişlemler TPOT tarafından "eğer gerekliyse" yapılmaktadır. 
    
    config_dict parametresi için oluşturulan sözlüğün anahtarları scikit-learn içerisindeki önişlem nesnelerinin isimlerinden, 
    değerleri ise bu önişlem nesnelerinin hyper parametrelerine ilişkin sözlüklerden oluşmaktadır. Aslında bu config_dict parametresi 
    yalnızca önişlemleri belirtmek için değil, dikkate alınması gereken modeleri belirtmek için de kullanılmaktadır. Aşağıda config_dict 
    kullanımına bir örnek veriyoruz:

    custom_config = {
        # Önişleyiciler
        'sklearn.preprocessing.StandardScaler': {},
        'sklearn.decomposition.PCA': {
            'iterated_power': [1, 2],
            'svd_solver': ['randomized']
        },
        'sklearn.preprocessing.PolynomialFeatures': {
            'degree': [2],
            'include_bias': [False],
            'interaction_only': [False]
        },

        # Model (estimator)
        'sklearn.ensemble.RandomForestClassifier': {
            'n_estimators': [100],
            'max_depth': [3, 5, None]
        }
    }

    tpot = TPOTClassifier(
        verbosity=2,
        config_dict=custom_config,

    )

    Aşağıda meme kanseri örneği TPOTClassifir sınıfı kullanılarak otomatize biçimde çözülmüştür. Yukarıda da belirttiğimiz gibi 
    burada maksimum süre olarak 5 dakika aldık. Ancak daha iyi bir sonuç elde etmek istiyorsanız bu zamanı artırmanız gerekebilir. 
    Bu örnekten elde edilen en iyi boru hattı nesnesi şöyledir:

    Pipeline(steps=[
        ('minmaxscaler', MinMaxScaler()),
        ('stackingestimator', StackingEstimator(estimator=BernoulliNB(alpha=0.1))),
        ('logisticregression', LogisticRegression(C=10.0))
    ])

    Buradaki StackingEstimator sınıfı TPOT'un kendi sınıfıdır. Ancak bu veri kümesi için "lojistik regresyonun" en iyi 
    model biçiminde seçildiği görülmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv("data.csv")

dataset_x = df.iloc[:, 2:-1].to_numpy()
dataset_y = np.zeros(len(df))
dataset_y[df['diagnosis'] == 'M'] = 1

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=12345)

from tpot import TPOTClassifier

tpc = TPOTClassifier(max_time_mins=5, verbosity=3)

tpc.fit(training_dataset_x, training_dataset_y)

import numpy as np

predict_data = np.array([
        [15.1, 22.02, 97.26, 712.8, 0.09056, 0.07081, 0.05253, 0.03334, 0.1616, 0.05684, 0.3105, 
        0.8339, 2.097,  29.91, 0.004675, 0.0103, 0.01603, 0.009222, 0.01095, 0.001629, 18.1, 31.69, 
        117.7, 1030, 0.1389, 0.2057, 0.2712, 0.153, 0.2675, 0.07873],  
        [11.52, 18.75, 73.34, 409, 0.09524, 0.05473, 0.03036, 0.02278, 0.192, 0.05907, 0.3249, 0.9591, 
        2.183, 23.47, 0.008328, 0.008722, 0.01349, 0.00867, 0.03218, 0.002386, 12.84, 22.47, 81.81, 506.2, 
        0.1249, 0.0872, 0.09076, 0.06316, 0.3306, 0.07036]])

predict_result = tpc.predict(predict_data)
print(predict_result)
accuracy = tpc.score(test_dataset_x, test_dataset_y)
print(accuracy)

best_pipeline = tpc.fitted_pipeline_
print(best_pipeline)

tpc.export('tpot-automated-breastcancer.py')

#----------------------------------------------------------------------------------------------------------------------------
    TPOTClassifier sınıfı ile export edilip bir Python programına dönüştürülen modelin kodları nasıldır? Maalesef üretilen 
    modele ilişkin kaynak kodlar hemen kullanılacak biçimde değildir. Programcının bunun üzerinde bazı değişikleri yapması 
    gerekmektedir. Yukarıdaki model için üretilen Python programı aşağıda verilmiştir:

    import numpy as np
    import pandas as pd
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split
    from sklearn.naive_bayes import BernoulliNB
    from sklearn.pipeline import make_pipeline, make_union
    from sklearn.preprocessing import MinMaxScaler
    from tpot.builtins import StackingEstimator

    # NOTE: Make sure that the outcome column is labeled 'target' in the data file
    tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)
    features = tpot_data.drop('target', axis=1)
    training_features, testing_features, training_target, testing_target = \
                train_test_split(features, tpot_data['target'], random_state=None)

    # Average CV score on the training set was: 0.9780219780219781
    exported_pipeline = make_pipeline(
        MinMaxScaler(),
        StackingEstimator(estimator=BernoulliNB(alpha=0.1, fit_prior=True)),
        LogisticRegression(C=10.0, dual=False, penalty="l2")
    )

    exported_pipeline.fit(training_features, training_target)
    results = exported_pipeline.predict(testing_features)
    
    Burada üretilen kodda çeşitli düzenlemelerin yapılması gerekmektedir. Bu düzenlemeler şunlardır:

    - Üretilen kod NumPy değil Pandas temelli oluşturulmuştur.
    - Üretilen kod içerisindeki 'PATH/TO/DATA/FILE' ve 'COLUMN_SEPARATOR' kısımları elle düzeltilmelidir. 
    - Üretilen kod içerisindeki hedef sütun "target" ismiyle bulunmaktadır. Bunun da elle düzeltimesi gerekir. 
    - Modelin ürettiği kodda hedef sütunun sayısal biçime dönüştürülmüş olması gerekmektedir. Aslında TPOTClassifier sınıfı bu 
    işlemi kendisi yapmaktadır. Ancak üretilen koddaki CSV dosyasında bu yapılmamaktadır. Bu nedenle bu alanın sayısallaştırılmış 
    olması gerekmektedir. 
    - Üretilen kodda hedef sütun CSV dosyasının içerisindedir ve sütun x datalarının oluşturulması sırasında drop edilmektedir. 
    Yani hedef sütunu siz drop etmemelisiniz.

    Tabii üretilen koddaki asıl önemli kısım pipline işlemleminde kullanılan sınıflar ve hyper parametrelerdir. 

    Aşağıda TPOT tarafından üretilen kodun düzeltilmiş biçimini veriyoruz:

    import numpy as np
    import pandas as pd
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split
    from sklearn.naive_bayes import BernoulliNB
    from sklearn.pipeline import make_pipeline, make_union
    from sklearn.preprocessing import MinMaxScaler
    from tpot.builtins import StackingEstimator

    # NOTE: Make sure that the outcome column is labeled 'target' in the data file
    tpot_data = pd.read_csv('data.csv')
    tpot_data = tpot_data.iloc[:, :-1]
    tpot_data['diagnosis'] = tpot_data['diagnosis'].apply(lambda s: 0 if s == 'M' else 1)

    features = tpot_data.drop('diagnosis', axis=1)
    training_features, testing_features, training_target, testing_target = \
                train_test_split(features, tpot_data['diagnosis'], random_state=None)

    # Average CV score on the training set was: 0.9780219780219781
    exported_pipeline = make_pipeline(
        MinMaxScaler(),
        StackingEstimator(estimator=BernoulliNB(alpha=0.1, fit_prior=True)),
        LogisticRegression(C=10.0, dual=False, penalty="l2")
    )

    exported_pipeline.fit(training_features, training_target)
    results = exported_pipeline.predict(testing_features)
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "titanic.csv" veri kümesi üzerinde TPOTClassifier sınıfı kullanılmıştır. "titanic.csv" veri kümesinde 
    bazı sütunlar gereksiz olduğundan atılmıştır. Kategorik sütunlar sayısal biçime dönüştürülmüştür. 5 dakikalık bir çalışma 
    sonrasında model elde edilmiş ve test edilmiştir. Export edilen model şöyledir:

    import numpy as np
    import pandas as pd
    from sklearn.ensemble import RandomForestClassifier
    from sklearn.model_selection import train_test_split
    from sklearn.pipeline import make_pipeline
    from sklearn.preprocessing import MinMaxScaler
    from sklearn.impute import SimpleImputer

    # NOTE: Make sure that the outcome column is labeled 'target' in the data file
    tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)
    features = tpot_data.drop('target', axis=1)
    training_features, testing_features, training_target, testing_target = \
                train_test_split(features, tpot_data['target'], random_state=None)

    imputer = SimpleImputer(strategy="median")
    imputer.fit(training_features)
    training_features = imputer.transform(training_features)
    testing_features = imputer.transform(testing_features)

    # Average CV score on the training set was: 0.8399093863882596
    exported_pipeline = make_pipeline(
        MinMaxScaler(),
        RandomForestClassifier(bootstrap=False, criterion="entropy", max_features=0.35000000000000003, 
                min_samples_leaf=8, min_samples_split=4, n_estimators=100)
    )

    exported_pipeline.fit(training_features, training_target)
    results = exported_pipeline.predict(testing_features)

    Buradan görüldüğü gibi TPOT bizim için karar ağaçları kullanarak "random forest" ensemble yöntemini seçmiştir. 

    Aşağıda modelin tüm kodları verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('titanic.csv')

dataset_y = df['Survived'].to_numpy()
df_dataset_x = df.drop(['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'], axis=1)
df_dataset_x['Sex'] = (df_dataset_x['Sex'] == 'male').astype('int')
dataset_x = pd.get_dummies(df_dataset_x, ['Embarked']).to_numpy()

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=12345)

from tpot import TPOTClassifier

tpc = TPOTClassifier(max_time_mins=5, verbosity=3)
tpc.fit(training_dataset_x, training_dataset_y)

score = tpc.score(test_dataset_x, test_dataset_y)
print(f'Accuracy scor: {score}')

tpc.export('automated-tpot-titanic.py')

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıda ise "cryotherapy.csv" veri kümesi üzerinde TPOTClassifier sınıfı ile model araması yapılmıştır. Bu veri kümesinda 
    sayısal biçimde kodlanmış kategorik veriler vardır. TPOT'un yeni versiyonları bu alanları otomatik one-hot-encoding yaptığı 
    için biz örneğimizde one-hot-encoding yapmadık. Ancak yukarıda da belirttiğimiz gibi geçmişe doğru uyumu korumak için siz 
    one-hot-encoding işlemini kendiniz yapabilrisiniz. TPOT'un özellik ölçeklemesini zaten kendisinin yaptığını anımsayınız.
    5 dakikalık çalışma sonucunda export edilen model aşağıdaki gibidir:

    import numpy as np
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.neural_network import MLPClassifier
    from sklearn.pipeline import make_pipeline
    from tpot.builtins import OneHotEncoder

    # NOTE: Make sure that the outcome column is labeled 'target' in the data file
    tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)
    features = tpot_data.drop('target', axis=1)
    training_features, testing_features, training_target, testing_target = \
                train_test_split(features, tpot_data['target'], random_state=None)

    # Average CV score on the training set was: 0.917142857142857
    exported_pipeline = make_pipeline(
        OneHotEncoder(minimum_fraction=0.2, sparse=False, threshold=10),
        MLPClassifier(alpha=0.01, learning_rate_init=0.01)
    )

    exported_pipeline.fit(training_features, training_target)
    results = exported_pipeline.predict(testing_features)

    exported_pipeline.fit(training_features, training_target)
    results = exported_pipeline.predict(testing_features)

    Buradan da görüldüğü gibi TPOT önce sütunları min-max ölçeklemesine sonra max-abs ölçeklemesine sokmuş sonra da
    tek saklı katmanlı bir sinir ağı kullanmıştır. Buradan %100'e yakın bir accuracy değeri elde edilmiştir.

    Yukarıdaki örnekte de gördüğünüz gibi her ne kadar scikit-learn kütüphanesinin yapay sinir ağlarıyla bir ilgisi yoksa 
    da kütüphane içerisinde basit çok katmanlı sinir ağı oluşturan MlpClassifier ve MlpRegressor isimli iki sınıf da 
    barındırmaktadır. Bu sınıflarda eğer saklı katmanların sayısı belirtilmezse yalnızca bir tane saklı katman oluşturulmaktadır. 
    Yukarıdaki TPotClassifier sınıfında da tek bir saklı katman oluşturulmuştur. Tabii scikit-learn kütüphanesi Keras gibi 
    derin öğrenme uygulamaları için kullanılabilecek özelliklere sahip bir kütüphane değildir. 
    
    Programın Python kodu aşağıda verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('cryotherapy.csv', delimiter=';')

dataset_x = df.iloc[:, :-1].to_numpy()
dataset_y = df.iloc[:, -1].to_numpy()

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from tpot import TPOTClassifier

tpc = TPOTClassifier(max_time_mins=5, verbosity=3)
tpc.fit(training_dataset_x, training_dataset_y)

score = tpc.score(test_dataset_x, test_dataset_y)
print(f'Accuracy scor: {score}')

tpc.export('automated-tpot-cryotherapy.py')

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de "fish.csv" veri kümesi üzerinde TPOTClassifier sınıfı ile model araştıralım. "fish.csv" veri kümesinde balıkların 
    sütunlar  halinde çeşitli özellikleri bulunmaktadır. Veri kümesi aşağıdaki bağlantıdan indirilebilir:

    https://www.kaggle.com/datasets/gurmolsingh/fish-datasetrket

    Veri kümesinin görünümü aşağıdaki gibidir:

    Species,Weight,Length1,Length2,Length3,Height,Width
    Bream,242,23.2,25.4,30,11.52,4.02
    Bream,290,24,26.3,31.2,12.48,4.3056
    Bream,340,23.9,26.5,31.1,12.3778,4.6961
    ...

    Bu veri kümesi aslında balık ağırlıklarını tahmin etmek için oluşturulmuştur. Ancak biz burada balıkların ağırlıklarını 
    değil cinslerini tahmin etmeye çalışacağız. Export edilen model şöyledir:

    import numpy as np
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from sklearn.svm import LinearSVC

    # NOTE: Make sure that the outcome column is labeled 'target' in the data file
    tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)
    features = tpot_data.drop('target', axis=1)
    training_features, testing_features, training_target, testing_target = \
                train_test_split(features, tpot_data['target'], random_state=None)

    # Average CV score on the training set was: 0.9766153846153847
    exported_pipeline = LinearSVC(C=15.0, dual=False, loss="squared_hinge", penalty="l2", tol=1e-05)

    exported_pipeline.fit(training_features, training_target)
    results = exported_pipeline.predict(testing_features)
    
    Programın Python kodu aşağıda verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('fish.csv')

dataset_x = df.iloc[:, 1:].to_numpy()
dataset_y = df.iloc[:, 0].to_numpy()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
dataset_y = le.fit_transform(dataset_y)

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from tpot import TPOTClassifier

tpc = TPOTClassifier(max_time_mins=5, verbosity=3)
tpc.fit(training_dataset_x, training_dataset_y)

score = tpc.score(test_dataset_x, test_dataset_y)
print(f'Accuracy scor: {score}')

tpc.export('tpot-automated-fish.py')

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de MNIST sınıflandırma problemini TPOTClassifier ile çözmeye çalışalım. Anımsanacağı gibi MNIST veri kümesi her biri 
    28x28'lik "gri tonlamalı (gray scale)" resimlerden oluşuyordu. Biz bu veri kümesini iki boyutlu bir dizi biçiminde oluşturup 
    TPOTClassifier sınıfına verdik. 5 dakikalık bir süre içerisinde TPOT tarafından elde ettiğimiz model şöyledir:

    import numpy as np
    import pandas as pd
    from sklearn.decomposition import PCA
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split
    from sklearn.pipeline import make_pipeline

    # NOTE: Make sure that the outcome column is labeled 'target' in the data file
    tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)
    features = tpot_data.drop('target', axis=1)
    training_features, testing_features, training_target, testing_target = \
                train_test_split(features, tpot_data['target'], random_state=None)

    # Average CV score on the training set was: 0.9114486179403839
    exported_pipeline = make_pipeline(
        PCA(iterated_power=1, svd_solver="randomized"),
        LogisticRegression(C=25.0, dual=False, penalty="l2")
    )

    exported_pipeline.fit(training_features, training_target)
    results = exported_pipeline.predict(testing_features)

    MNIST büyük bir veri kümesidir. Dolayısıyla model araştırması diğerlerine göre daha fazla zaman almaktadır. Bu nedenle 
    model araması için belirleyeceğiniz zamanı biraz büyütmelisiniz. (Biz 30 dakikalık bir zaman kullandık) Tabii aslında 
    bu tür resim tanıma işlemleri için derin öğrenme ağları çok daha başarılı sonuçlar vermektedir. 

    Programın Python kodu aşağıda verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df_training = pd.read_csv('mnist_train.csv')
df_test = pd.read_csv('mnist_test.csv')

training_dataset_x = df_training.iloc[:, 1:].to_numpy()
training_dataset_y = df_training.iloc[:, 0].to_numpy()

test_dataset_x = df_test.iloc[:, 1:].to_numpy()
test_dataset_y = df_test.iloc[:, 0].to_numpy()

from tpot import TPOTClassifier

tpc = TPOTClassifier(max_time_mins=30, verbosity=3)

tpc.fit(training_dataset_x, training_dataset_y)

score = tpc.score(test_dataset_x, test_dataset_y)
print(f'Accuracy scor: {score}')

tpc.export('automated-tpot-mnist.py')

#----------------------------------------------------------------------------------------------------------------------------
    TPOT ile regresyon işlemleri TPOTRegressor sınıfı ile gerçekleştirilmektedir. Sınıfın __init__ metodunun parametrik yapısı 
    şöyledir:

     def __init__(
        self,
        generations=100,
        population_size=20,
        offspring_size=None,
        mutation_rate=0.9,
        crossover_rate=0.1,
        max_time_mins=None,
        max_eval_time_mins=5,
        random_state=None,
        cv=5,
        subsample=1.0,
        n_jobs=1,
        max_iter=None,
        warm_start=False,
        memory=None,
        config_dict='TPOT sparse',
        template=None,
        crossover_type='uniform',
        scoring=None,
        verbose=0,
        disable_update_check=False,
        use_dask=False,
        periodic_checkpoint_folder=None,
        max_no_migrations=None,
        early_stop=None,
        use_compiled_pipeline=False,
        **kwargs
    )

    Metodun parametrik yapısı TPOTClassifier sınıfına oldukça benzemektedir. Yine burada max_time_mins modelin toplamda kaç 
    dakika zaman içerisinde bulunacağını belirtmektedir. Diğer parametrelerin çoğu zaten TPOTClassifier sınıfındakilerle 
    aynıdır. Yine bu sınıfta da kategorik verilerin sayısal hale getirilmesi otomatik yapılmamaktadır. Ancak aşağıdaki 
    önişlemler default konfigürasyonda "eğer gerekli görülürse" yapılmaktadır:

    - Eksik verilerin doldurulması (imputation)
    - Özellik ölçeklemesi 
    - Özellik seçimi 
    - Boyutsal özellik indirgemesi

    Sınıfın kullanımı tamamen TPOTClassifier sınıfında olduğu gibidir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte "Boston Housing Prices" veri kümesi üzerinde TPOTRegressor sınıfı ile model araştırması yapılmıştır. TPOT 
    yalnızca scikit-learn kütüphanesini değil bazı üçüncü parti kütüphaneleri de kullanmaktadır. Örneğin XGB Boosting işlemini 
    yapan xgboost kütüphanesi de TPOT tarafından kullanılmaktadır. "Boston Housing Prices" veri kümesinden TPOT'un 5 dakika 
    çalıştırmayla elde ettiği model şöyledir:

    import numpy as np
    import pandas as pd
    from sklearn.linear_model import ElasticNetCV
    from sklearn.model_selection import train_test_split
    from sklearn.pipeline import make_pipeline, make_union
    from tpot.builtins import StackingEstimator
    from xgboost import XGBRegressor

    # NOTE: Make sure that the outcome column is labeled 'target' in the data file
    tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)
    features = tpot_data.drop('target', axis=1)
    training_features, testing_features, training_target, testing_target = \
                train_test_split(features, tpot_data['target'], random_state=None)

    # Average CV score on the training set was: -12.795525074005127
    exported_pipeline = make_pipeline(
        StackingEstimator(estimator=ElasticNetCV(l1_ratio=0.1, tol=0.1)),
        XGBRegressor(learning_rate=0.1, max_depth=8, min_child_weight=6, 
                n_estimators=100, n_jobs=1, objective="reg:squarederror", subsample=0.5, verbosity=0)
    )

    exported_pipeline.fit(training_features, training_target)
    results = exported_pipeline.predict(testing_features)

    Görüldüğü gibi burada xgboost kütüphanesinden faydalanılmıştır. 
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \*
        train_test_split(dataset_x, dataset_y, test_size=0.2)

from tpot import TPOTRegressor

tpr = TPOTRegressor(max_time_mins=5, verbosity=3)
tpr.fit(training_dataset_x, training_dataset_y)

predict_result = tpr.predict(test_dataset_x)

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(test_dataset_y, predict_result)
print(f'Mean Absolute Error: {mae}')

tpr.export('tpot-automated-boston.py')

#----------------------------------------------------------------------------------------------------------------------------
                                            131. Ders - 15/06/2025 - Pazar
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de sağlık sigortası için poliçe bedelinin tahmin edildiği "insurance.csv" veri kümesi üzerinde TPOTRegressor sınıfını 
    kullanalım. Veri kümesini aşağıdaki bağlantıdan indirebilirsiniz:

    https://www.kaggle.com/code/bbhatt001/predictors-of-medical-expenses/input
 
    Veri kümesinin görünümü şöyledir:

    age,sex,bmi,children,smoker,region,charges
    19,female,27.9,0,yes,southwest,16884.924
    18,male,33.77,1,no,southeast,1725.5523
    28,male,33,3,no,southeast,4449.462
    33,male,22.705,0,no,northwest,21984.47061
    32,male,28.88,0,no,northwest,3866.8552
    31,female,25.74,0,no,southeast,3756.6216
    46,female,33.44,1,no,southeast,8240.5896
    .......

    "insurance.csv" veri kümesinde "sex", "smoker" ve "region" sütunları kategorik sütunlardır. Bu nedenle bu örnekte biz önce 
    bu sütunları sayısal hale dönüştürdük. Sonra TPOTRegressor sınıfına soktuk. 

    TPOT tarafından elde edilen model şöyledir:

    import numpy as np
    import pandas as pd
    from sklearn.model_selection import train_test_split
    from xgboost import XGBRegressor

    # NOTE: Make sure that the outcome column is labeled 'target' in the data file
    tpot_data = pd.read_csv('PATH/TO/DATA/FILE', sep='COLUMN_SEPARATOR', dtype=np.float64)
    features = tpot_data.drop('target', axis=1)
    training_features, testing_features, training_target, testing_target = \
                train_test_split(features, tpot_data['target'], random_state=None)

    # Average CV score on the training set was: -21051246.4
    exported_pipeline = XGBRegressor(learning_rate=0.1, max_depth=2, min_child_weight=8, 
            n_estimators=100, n_jobs=1, objective="reg:squarederror", subsample=0.55, verbosity=0)

    exported_pipeline.fit(training_features, training_target)
    results = exported_pipeline.predict(testing_features)

    Programın Python kodu aşağıda verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('insurance.csv')

dataset_y = df['charges'].to_numpy(dtype='float32')

df_dataset_x = df.drop(['charges'], axis=1)

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df_dataset_x['sex'] = le.fit_transform(df_dataset_x['sex'])
df_dataset_x['smoker'] = le.fit_transform(df_dataset_x['smoker'])
df_dataset_x = pd.get_dummies(df_dataset_x, ['region'])
dataset_x = df_dataset_x.to_numpy()

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=12345)

from tpot import TPOTRegressor

tpr = TPOTRegressor(max_time_mins=5, verbosity=3)
tpr.fit(training_dataset_x, training_dataset_y)

predict_result = tpr.predict(test_dataset_x)

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(test_dataset_y, predict_result)
print(f'Mean Absolute Error: {mae}')

tpr.export('automated-tpot-insurance.py')

#----------------------------------------------------------------------------------------------------------------------------
    İstatistiksel makine öğrenmesi yöntemleriyle model araması yapan diğer bir otomatik makine öğrenmesi kütüphamesi de 
    "auto-sklearn" isimli kütüphanedir. auto-sklearn pek çok bakımdan TPOT kütüphanesine benzemektedir. Bazı araştırmalarda 
    iki kütüphane karşılaştırıldığında auto-sklearn kütüphanesinin sınıflandırma tarzı problemlerde TPOT kütüphanesinin 
    ise regresyon problemlerinde daha başarılı olduğunu bulunmuştur. Bazı veri kümeleri üzerinde çeşitli koşullarda yapılan 
    testlerden şu sonuçlar elde edilmiştir (buradaki tablo ChatGPT tarafından verilmiştir):

    +-----------------------+------------+-------------------+---------------+
    |      Veri Seti        | TPOT (F1)  | auto-sklearn (F1) |    Kazanan    |
    +-----------------------+------------+-------------------+---------------+
    | Breast Cancer         |   0.97     |       0.98        | auto-sklearn  |
    | Adult Income          |   0.84     |       0.86        | auto-sklearn  |
    | Titanic               |   0.80     |       0.82        | auto-sklearn  |
    | Higgs Boson (büyük)   |   0.65     |       0.72        | auto-sklearn  |
    | Synthetic (karmaşık)  |   0.91     |       0.90        | TPOT          |
    +-----------------------+------------+-------------------+---------------+

#----------------------------------------------------------------------------------------------------------------------------
                                        132. Ders - 21/06/2025 - Cumartesi
#----------------------------------------------------------------------------------------------------------------------------
    auto-sklearn kütüphanesi de scikit-learn kütüphanesi üzerine oturtulmuştur. Yani bu kütüphane de oluşturduğu modellerde 
    sckit-learn sınıflarını ve fonksiyonlarını kullanmaktadır.

    Maalesef auto-sklearn kütüphanesi aşırı derece UNIX/Linux sistemlerine bağımlı biçimde yazılmıştır. Bu nedenle en azından 
    şimdilik kütüphane Windows altında altında ve macOS sistemleri altında çalıştırılamamaktadır. Siz de bu kütüphaneyi Linux'ta 
    çalıştırmalısınız. Bunun için bilgisayarınıza sanal makinede çalışacak biçimde Linux kurabilirsiniz. Linux'un Mint dağıtımı 
    Windows'a benzer bir masaüstü görüntüsüne sahip olduğu için Windows'a alışmış olan kişilere bu dağıtım daha aşina gelmektedir. 
    Linux'un Mint dağıtımını aşağıdaki bağlantıdan ".iso" dosyası biçiminde indirebilirsiniz:

    https://linuxmint.com/edition.php?id=319
    
    Ancak bu bağlamda dağıtımın bir önemi yoktur. auto-sklearn aracının kendi sitesinde ayrıca hazır Docker imajı bulundurulmaktadır.

    auto-sklearn kütüphanesinin resmi sitesine aşağıdaki bağlantıdan erişebilirsiniz:

    https://automl.github.io/auto-sklearn/master/#

    auto-sklearn kütüphanesi Debian tabanlı Linux sistemlerinde şöyle kurulmaktadır:

    pip install auto-sklearn
     
    Kütüphanenin modül import ismi autosklearn biçimindedir. Ancak burada bir sorun üzerinde durmak istiyoruz. Maalesef 
    auto-sklearn Python'un yeni versiyonlarının bulunduğu sistemlerde install edilememektedir. Bu sorun muhtemelen zaman 
    içerisinde giderilecektir. Ancak kütüphanenin kullanılabilmesi için Python'un eski bir versiyonun (örneğin 3.8.20) yüklü 
    olması gerekmektedir. Bunun için Anaconda Navigator'da yeni bir sanal ortam yaratabilirsiniz. Bu yeni sanal ortamda 
    Python versiyonunu 3.8.20 gibi bir versiyona düşürebilirsiniz. 

    auto-sklearn kategorik sütunlarda yazısal içerik varsa (yani onların dtype türleri dtype='object' ya da Pandas için 
    dtype='category' ise) o sütunları otomatik olarak sayısallaştırıp gerekirse one-hot-encoding işlemini kendisi yapmaktadır. 
    Ancak zaten sayısal biçimde bulunan kategorik sütunlar üzerinde one-hot-encoding işlemi yapmamaktadır. auto-sklearn de 
    tıpkı TPOT'ta olduğu gibi diğer pek çok önişlemi kendisi otomatik yapmaktadır. auto-sklearn tarafından default olarak 
    yapılan önişlemlerin önemli olanları şunlardır:

    - Eksik verilerin doldurulması(imputation)
    - Özellik ölçeklemesi
    - Özellik seçimi
    - Özellik indirgemesi
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    auto-sklearn kütüphanesinin genel kullanım biçimi TPOT kütüphanesine oldukça benzemektedir. Kütüphane içerisinde iki temel 
    sınıf vardır: AutoSklearnClassifier ve AutoSklearnRegressor. Sınıflandırma problemleri için AutoSklearnClassifier regresyon 
    problemleri için AutoSklearnRegressor sınıfı kullanılmaktadır. Kütüphanede ayrıca birkaç önemli global fonksiyon da bulunmaktadır. 

    AutoSklearnClassifier sınıfının __init__ metodunun parametrik yapısı şöyledir:

    class autosklearn.classification.AutoSklearnClassifier(time_left_for_this_task=3600, per_run_time_limit=None, 
            initial_configurations_via_metalearning=25, ensemble_size: int | None = None, 
            ensemble_class: Type[AbstractEnsemble] | Literal['default'] | None = 'default', ensemble_kwargs: 
            Dict[str, Any] | None = None, ensemble_nbest=50, max_models_on_disc=50, seed=1, memory_limit=3072, 
            include: Optional[Dict[str, List[str]]] = None, exclude: Optional[Dict[str, List[str]]] = None, 
            resampling_strategy='holdout', resampling_strategy_arguments=None, tmp_folder=None, 
            delete_tmp_folder_after_terminate=True, n_jobs: Optional[int] = None, 
            dask_client: Optional[dask.distributed.Client] = None, disable_evaluator_output=False, get_smac_object_callback=None, 
            smac_scenario_args=None, logging_config=None, metadata_directory=None, metric: Scorer | Sequence[Scorer] | None = None, 
            scoring_functions: Optional[List[Scorer]] = None, load_models: bool = True, 
            get_trials_callback: SMACCallback | None = None,  dataset_compression: Union[bool, Mapping[str, Any]] = True, 
            allow_string_features: bool = True)

    Tabii bu parametrelerin çok azı sıklıkla kullanılmaktadır. Burada time_left_for_this_task parametresi model araması için 
    kullanılacak toplam zaman miktarını saniye cinsinden belirlemek amacıyla bulundurulmuştur. Bu parametre TPOT kütüphanesindeki 
    max_time_mins parametresine benzemektedir. Ancak bu parametredeki değer dakika cinsinden değil saniye cinsindendir. Metodun 
    per_run_time_limit parametresi denenen modelleriden her biri için maksimum harcanacak zamanı belirtmektedir. Metodun diğer 
    parametreleri için auto-skleran dokümanlarına başvurulabilirsiniz.

    AutoSklearnClassifier nesnesi yaratıldıktan sonra yine model aramasını sağlamak için fit metodu kullanılır. Model oluşturulduktan 
    sonra predict metodu ile tahminleme yapılabilir. Örneğin:
    
    aslc = AutoSklearnClassifier(time_left_for_this_task=5*60)
    aslc.fit(training_dataset_x, training_dataset_y)

    Araştırılan modeller hakkında bilgi edinmek için birkaç metot bulundurulmuştur. leaderboard metodu en iyi k tane modeli 
    Pandas DataFrame nesnesi olarak, show_models metodu araştırılan modelleri bir Python sözlük nesnesi olarak vermektedir. 
    score metodu ise elde edilen en iyi modelin başarısını sınamak için kullanılmaktadır.

    Aşağıda "breast-cancer" veri kümesi üzerinde auto-sklearn ile sınıflandırma işlemi yapılmıştır. Burada AutoSklearnClassifier 
    sınıf nesnesi yaratılmış ve toplam 5 dakikalık bir model araması yapılmıştır. Bu işlemden %96.4 lük bir başarı elde 
    edilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv('data.csv')

dataset_x = df.iloc[:, 2:-1].to_numpy()
dataset_y = np.zeros(len(df))

dataset_y[df['diagnosis'] == 'M'] = 1

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.2)

from autosklearn.classification import AutoSklearnClassifier

aslc = AutoSklearnClassifier(time_left_for_this_task=5*60)
aslc.fit(training_dataset_x, training_dataset_y)

df_lb = aslc.leaderboard(top_k=3)
print(df_lb)

models_dict = aslc.show_models()
print(models_dict)

predict_result = aslc.predict(test_dataset_x)
print(predict_result)

score = aslc.score(test_dataset_x, test_dataset_y)
print(f'Accuracy Score: {score}')               # 0.9649

#----------------------------------------------------------------------------------------------------------------------------
    Yukarıda belirttiğimiz gibi TPOT ile auto-sklearn arasında performans kıyaslaması yapan makaleler genel olarak auto-sklearn 
    kütüphanesinin sınıflandırma problemlerinde TPOT kütüphanesinin ise regresyon problemlerinde daha iyi sonuç verdiğini 
    belirtmektedir. 

    Aşağıda "Breast Cancer Winconsin" veri kümesi her iki kütüphane üzerinde uygulanarak bir kartşılaştırma yapılmıştır. Bu 
    karşılaştırmada iki aracın da toplam 5 dakika zaman kullanması sağlanmıştır. Burada elde edilen doğruluk skoru şöyledir:

    TPOT Accuracy scor: 0.956140350877193
    AutoSklearn Accuracy Score: 0.9649122807017544

    Görüldüğü gibi auto-sklearn az da olsa TPOT'tan daha iyi sonuç vermiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import pandas as pd

df = pd.read_csv('data.csv')

dataset_x = df.iloc[:, 2:-1].to_numpy()
dataset_y = np.zeros(len(df))

dataset_y[df['diagnosis'] == 'M'] = 1

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=12345)

# TPOT

from tpot import TPOTClassifier

tpc = TPOTClassifier(max_time_mins=5, verbosity=3)
tpc.fit(training_dataset_x, training_dataset_y)
score = tpc.score(test_dataset_x, test_dataset_y)
print(f'TPOT Accuracy score: {score}')                      # 0.9561

# AutoSklearn

from autosklearn.classification import AutoSklearnClassifier

aslc = AutoSklearnClassifier(time_left_for_this_task=5*60)
aslc.fit(training_dataset_x, training_dataset_y)
score = aslc.score(test_dataset_x, test_dataset_y)
print(f'AutoSklearn Accuracy Score: {score}')               # 0.9649

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıda "zambak (iris)" veri kümesinde TPOT ve auto-sklearn kütüphaneleri ile sınıflandırma yapılmıştır. Yine her iki 
    çözümde de toplam 5 dakikalık bir süre kullanılmıştır. Elde edilen doğruluk skoru şöyledir:

    TPOT Accuracy scor: 0.9666666666666667
    AutoSklearn Accuracy Score: 0.9666666666666667

    Görüldüğü gibi buradaki başarı aynıdır. Tabii bu aynılık durumu veri kümesinin kendisine özgü durumundan kaynaklanmaktadır.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('iris.csv')

dataset_x = df.iloc[:, 1:-1].to_numpy()

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
dataset_y = le.fit_transform(df.iloc[:, -1])

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=12345)

from tpot import TPOTClassifier

tpc = TPOTClassifier(max_time_mins=5, verbosity=3)

tpc.fit(training_dataset_x, training_dataset_y)

score = tpc.score(test_dataset_x, test_dataset_y)
print(f'TPOT Accuracy scor: {score}')

# AutoSklearn

from autosklearn.classification import AutoSklearnClassifier

aslc = AutoSklearnClassifier(time_left_for_this_task=5*60)
aslc.fit(training_dataset_x, training_dataset_y)

score = aslc.score(test_dataset_x, test_dataset_y)
print(f'AutoSklearn Accuracy Score: {score}')    

#----------------------------------------------------------------------------------------------------------------------------
    Auto-sklearn ile regresyon problemleri için AutoSklearnRegressor sınıfı kullanılmaktadır. Sınıfın __init__ metodunun 
    parametrik yapısı şöyledir:

    class autosklearn.regression.AutoSklearnRegressor(time_left_for_this_task=3600, per_run_time_limit=None, 
        initial_configurations_via_metalearning=25, ensemble_size: int | None = None, 
        ensemble_class: Type[AbstractEnsemble] | Literal['default'] | None = 'default', ensemble_kwargs: Dict[str, Any] | None = None, 
        ensemble_nbest=50, max_models_on_disc=50, seed=1, memory_limit=3072, include: Optional[Dict[str, List[str]]] = None, 
        exclude: Optional[Dict[str, List[str]]] = None, resampling_strategy='holdout', resampling_strategy_arguments=None, 
        tmp_folder=None, delete_tmp_folder_after_terminate=True, n_jobs: Optional[int] = None, 
        dask_client: Optional[dask.distributed.Client] = None, disable_evaluator_output=False, get_smac_object_callback=None, 
        smac_scenario_args=None, logging_config=None, metadata_directory=None, metric: Scorer | Sequence[Scorer] | None = None, 
        scoring_functions: Optional[List[Scorer]] = None, load_models: bool = True, get_trials_callback: SMACCallback | None = None, 
        dataset_compression: Union[bool, Mapping[str, Any]] = True, allow_string_features: bool = True)

    Görüldüğü gibi metodun çok fazla parametresi vardır. Bu parametrelerin hepsi default değer almaktadır. Yine buradaki en önemli 
    parametre time_left_for_this_task parametresidir. Bu parametre sınıfın model araştırmak için kullanacağı saniye cinsinden 
    maksimum zamanı belirtmektedir. Sınıfın kullanımı AutoSklearnClassifier sınıfında olduğu gibidir. Yine fit metodu ile eğitim,  
    predict metodu ile kestirim yapılır. score metodu ile de regresyonun başarı skoru elde edilebilmektedir. score metodu bize 
    R^2 değerini vermektedir. Yine sınıfın leaderboard ve show_models isimli metotları bulunmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıda "Boston Housing Prices" veri kümesi üzerinde hem TPOT hem de auto-sklearn kullanılarak regresyon problemi çözülmüştür. 
    Çözümden sonra "mean absolute error" değeri elde edilip yazdırılmıştır. Yine her iki deneme için de 5'er dakikalık model 
    arama zamanı kullanılmıştır. Elde edilen değerler şöyledir:

    TPOT Mean Absolute Error: 2.407825001548432
    AutoSklearn Mean Absolute Error: 2.3694112300872803
    
    Burada auto-sklearn ile biraz daha iyi bir sonuç elde edilmiştir. Ancak 5 dakikalık bir denemeyle bu iki kütüphanenin 
    performanslarının kıyaslanması uygun değildir. TPOT arka planda model üretirken genetik algoritmaları kullanmaktadır. 
    Genetik algoritmalarda iyi bir soncun elde edilmesi için nispeten daha fazla zamana gereksinim duyulmaktadır.
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('housing.csv', delimiter=r'\s+', header=None)

dataset_x = df.iloc[:, :-1].to_numpy(dtype='float32')
dataset_y = df.iloc[:, -1].to_numpy(dtype='float32')

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=12345)

from tpot import TPOTRegressor

tpr = TPOTRegressor(max_time_mins=5, verbosity=3)
tpr.fit(training_dataset_x, training_dataset_y)

predict_result = tpr.predict(test_dataset_x)

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(test_dataset_y, predict_result)
print(f'TPOT Mean Absolute Error: {mae}')

from autosklearn.regression import AutoSklearnRegressor

aslr = AutoSklearnRegressor(time_left_for_this_task=5*60)
aslr.fit(training_dataset_x, training_dataset_y)
predict_result = aslr.predict(test_dataset_x)

mae = mean_absolute_error(test_dataset_y, predict_result)
print(f'AutoSklearn Mean Absolute Error: {mae}')

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıda sağlık sigortası poliçesinin bedelini tahmin etmeye yönelik hazırlanmış olan "insurance.csv" veri kümesi üzerinde 
    TPOT ve auto-sklearn ile resgresyon uygulnmıştır. Yine model araması için 5 dakikalık bir süre belirlenmiştir. Elde edilen 
    sonuçlar şöyledir:

    TPOT Mean Absolute Error: 2281.1085680343954
    AutoSklearn Mean Absolute Error: 1955.048485072691
#----------------------------------------------------------------------------------------------------------------------------

import pandas as pd

df = pd.read_csv('insurance.csv')

dataset_y = df['charges'].to_numpy(dtype='float32')

df_dataset_x = df.drop(['charges'], axis=1)

from sklearn.preprocessing import LabelEncoder

le = LabelEncoder()
df_dataset_x['sex'] = le.fit_transform(df_dataset_x['sex'])
df_dataset_x['smoker'] = le.fit_transform(df_dataset_x['smoker'])
df_dataset_x = pd.get_dummies(df_dataset_x, ['region'])
dataset_x = df_dataset_x.to_numpy()

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = \
        train_test_split(dataset_x, dataset_y, test_size=0.2, random_state=12345)

from tpot import TPOTRegressor

tpr = TPOTRegressor(max_time_mins=5, verbosity=3)
tpr.fit(training_dataset_x, training_dataset_y)

predict_result = tpr.predict(test_dataset_x)

from sklearn.metrics import mean_absolute_error

mae = mean_absolute_error(test_dataset_y, predict_result)
print(f' TPOT Mean Absolute Error: {mae}')

from autosklearn.regression import AutoSklearnRegressor

aslr = AutoSklearnRegressor(time_left_for_this_task=5*60)
aslr.fit(training_dataset_x, training_dataset_y)
predict_result = aslr.predict(test_dataset_x)

mae = mean_absolute_error(test_dataset_y, predict_result)
print(f'AutoSklearn Mean Absolute Error: {mae}')

#----------------------------------------------------------------------------------------------------------------------------
    Diğer bir otomatik makine öğrenmesi aracı da AutoGluon isimli araçtır. AutoGluan Amazon tarafından 2019 yılında geliştirilmeye
    başlanmıştır. Amazon'un SageMaker isimli aotomaik makine öğrenmesine ilişkin bulut aracı da bu projenin kod tabanından 
    faydalanmaktadır. Kütüphanenin kurulumu şöyle yapılabilir:

    pip install autogluon

    Kütüphanenin dokümantasyonuna aşağıdaki bağlantıdan erişebilirisniz:

    https://auto.gluon.ai/stable/index.html

    AutoGluan kütüphanesi arka planda yoğun biçimde Pandas kullanmaktadır. Bu nedenle veri kümelerinizi Pandas DataFrame nesnesi 
    biçiminde oluşturmalısınız. 

    Kütüphanenin en önemli sınıfı TabularPredictor isimli sınıftır. Sınıfın __init__ metodunun parametrik yapısı şöyledir:

    class autogluon.tabular.TabularPredictor(label: str, problem_type: str = None, eval_metric: str | Scorer = None, 
            path: str = None, verbosity: int = 2, log_to_file: bool = False, log_file_path: str = 'auto', 
            sample_weight: str = None, weight_evaluation: bool = False, groups: str = None, 
            positive_class: int | str | None = None, **kwargs

    Metodun label parametresi kesitirimin yapılacağı hedef sütunu belirtmektedir. Bu sütun veri kümesindem çıkartılmaz. Hedef 
    sütunun veri kümesinden ayrıştırılması AutoGluon tarafından yapılmaktadır. Metodun problem_type parametresi problemin türünü 
    belirtmektedir. Bu parametre ikili sınıflandırmalar için "binary", çok sınıflı sınıflandırmalar için "multiclass" ve regresyon
    problemleri için "regression" biçiminde girilmelidir. Eğer bu parametreye bir argüman girilmezse AutoGluan hedef sütuna 
    bakarak problem türünü kendisi tespit etmeye çalışır. eval_metric parametresi model performansı için kullanılacak metik 
    değeri belirtmektedir. Bu parametreye argüman girilmezse problem türüne göre önceden belirlenmiş metrikler kullanılmaktadır. 
    Default metrik sınıflandırma problemleri için "accuracy", regresyon problemleri için "root_mean_squared_error" biçimindedir. 
    Örneğin:

    tp = TabularPredictor(label='diagnosis')

    AutoGluon tarafından otomatik yapılan önişlemler şunlardır:

    - Eksik verilerin doldurulması (imputation)
    - Özellik ölçeklemesi
    - Özellik seçimi

    AutoGluan da diğer otomaik makine öğrenmesi araçlarında olduğu gibi Dataframe sütununun türü "object" ise ya da "category"
    ise sütunu one-hot-encoding yöntemi ile sayısallaştırmaktadır. Ancak zaten sayısal biçimde olan (örneğin LabelEncoder uygulanmış
    olan) sütunlar üzerinde "one-hot-encoding" uygulamamaktadır. Bu tür sütunları sizin "one-hot-encoding" yaparak AutoGluon'a  
    vermeniz gerekir.

    Tabii fit işlemi sırasında artık fit metoduna x ve y veri kümeleri ayrı ayrı verilmez. Veri kümesinin bütün sütunları 
    bir bütün olarak verilir. Örneğin:

    tp.fit(training_df)

    Model araması için kullanılacak maksimum zaman saniye cinsinden fit metodunun time_limit parametresi ile belirtilebilmektedir. 
    Örneğin:

    tp.fit(training_df, time_limit=300)

    En iyi modeller yine sınıfın leaderboard metoduyla bir DataFrame nesnesi olarak elde edilebilir. Bu DataFrame nesnesinin
    satırları iyiden kötüye doğru modelleri belirtmektedir. Örneğin:
    
    leader_boards = tp.leaderboard()
    
    Örnek bir leaderboard çıktısı şöyledir:

                      model  score_val  ... can_infer  fit_order
    0         LightGBMLarge   0.982456  ...      True         12
    1   WeightedEnsemble_L2   0.982456  ...      True         13
    2               XGBoost   0.973684  ...      True         11
    3            LightGBMXT   0.973684  ...      True          3
    4              LightGBM   0.973684  ...      True          4
    5              CatBoost   0.964912  ...      True          7
    6       NeuralNetFastAI   0.964912  ...      True         10
    7      RandomForestGini   0.947368  ...      True          5
    8        ExtraTreesGini   0.947368  ...      True          8
    9      RandomForestEntr   0.947368  ...      True          6
    10       ExtraTreesEntr   0.947368  ...      True          9
    11       KNeighborsDist   0.807018  ...      True          2
    12       KNeighborsUnif   0.745614  ...      True          1

    En iyi modelin ismi nensenin model_best özniteliğinden elde edilebilir. Modelin parametrik bilgileri ise mdoel ismi 
    verilererek model_info metoduyla elde edilebilmektedir. Diğer metotlar için sınıfın dokümantasyonunu inceleyebilirsiniz. 
    Kestirim için yine predict metodu kullanılmaktadır. Örneğin:

    predict_result = tp.predict(test_df)
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Anımsanacağı gibi kursun başlarında makine öğrenmesini üç kısmı ayırmıştık:

    1) Denetimli Öğrenme (Supervied Learning)
    2) Denetimsiz Öğrenme (Unsupervised Learning)
    3) Pekiştirmeli Öğrenme (Reinforcement Learning)

    Biz denetimli öğrenme ve denetimsiz öğrenmenin temel yöntemlerini uygulamalı biçimde inceledik. Şimdi de pekiştirme öğrenme denilen 
    yöntemler grubunu inceleyeceğiz. Pekiştirme öğrenme makine öğrenmesinde ilginç bir konudur. Pekiştirmeli öğrenme yapay zeka kavramının 
    halk arasındaki karşılığına en yakın kısmını oluşturmaktadır. Pekiştirmeli öğrenme "kendine öğrenen sistemler" oluşturma gayretindedir. 

    Pekiştirmeli öğrenme psikolojideki "edimsel koşullanma (operant conditioning)" denilen kavramdan hareketle geliştirilmiştir. Edimsel 
    koşullanma canlılar için en önemli öğrenme yöntemlerinden biridir. Pek çok olgu edimsel koşullanma yoluyla öğrenilmektedir. 
    Bu öğrenme biçiminde organizma bir eylemde bulunur. Bu eylem sonucunda hoşa giden bir durum oluşursa bu hoşa giden durumu yeniden oluşturabilmek için
    organizma eylemi yineler. Böylece yinelenen eylem davranışın bir parçası haline gelir ve öğrenilmiş olur. Bu süreçte organizmanın
    hoşuna gidecek uyaranlara "pekiştireç (reinforecer)" denilmektedir. Eylem ne kadar pekiştirilirse o kadar iyi öğrenilir. 
    Pekiştireçler bir ödelül (reward) niteliğindedir. Örneğin çocuk arzu edeilen bir davranış yaptığında ona şeker verilirse çocuk 
    o davranışı yeniden yapar. Çocuk terbiyesinde edimsel koşullanma çok etkilidir. Bu konudaki ilk çalışmalar Edward Thorndike isimli
    psikolog tarafından yapılmıştır. Thorndike bu süreci fark etmiş ve bunu "etki yasası (rule of effect)" biçiminde isimlendirmiştir. 
    Ancak kuramı asıl teori haline getiren kişi B. Frederick Skinner'dır. Pekiştireç terimi de Skinner tarafından uydurulmuştur. 
    Skinner konunun epey ayrıntısına girmiş ve çeşitli yönlerden edimsel koşullanmayı incelemiştir. Edimsel koşullanmanın davranışı 
    şekillendirmede önemini göstermiştir. Skinner'a göre iki tür pekiştireç vardır: Pozifit ve negatif. Pozitif pekiştireçler doğurdan 
    organizamaya haz veren uyaranlardır. Negatif pekiştireçler ise organizmanın içinde bulunduğu hoş olmayan durumu ortadan kaldıran pekiştireçlerdir. 
    Hem pozitif hem de negatif pekiştirilecek sonuçta organizma için daha iyi bir durum sağlarlar. Örneğin arabalarda emniyet kemeri takılmadığında 
    bir ses çıkmaktadır. Kişiler de bu sesi duymamak için emniyet kemerini takarlar. Sonra zamanla bu sese aldırış etmeden emniyet kemerini takmak normal 
    bir uygulama haline gelir. Burada emniyet kemeri takıldığında kesilen ses negatif pekiştireçtir. Skinner pekiştireçlerin hangi sıklıkta 
    uygulanması gerektiği konusunda da çalışmalar yapmıştır. Pekiştireçler arzu edilen her davranış tekrarlandığında verilebilir. Buna sabit oranlı 
    pekiştirme tarifesi denilmektedir.  Eğer pekiştireç belli miktar arzu edilen davranış tekrarlandığında veriliyorsa buna da değişken oranlı pekiştirme
    tarififesi denir. Eğer pekiştireç sabit zamanlarda veriliyorsa buna sabit zamanlı tarife, değişken zamanlı veriliyorsa buna da değişken zamanlı 
    tarife denilmektedir. Örneğin çalışan kişilere verilen maaş "sabit zamanlı (fixed time)" bir pekiştireeçtir. Kumar makinelerinde 
    kişi tesadüfi belli zamanlarda ödül almaktadır. Bu da "değişkenli zamanlı (variable time)" pekiştirme tarifesine örnektir. 
    Bir çocuk her soruyu doğru bildiğinde ödül veriliyorsa ya da her n tane soruyu doğru bildiğinde ödül veriliyorsa bu türlü bir pekiştirmeye 
    "sabit oranlı (fixed ratio)" pekiştirme denir. Eğer çocuk bazen 3, bazen 5 bazen 8 gibi miktarlarda soruyu doğru bildiğinde ödül veriliyorsa 
    buna da "değişken oranlı (variable ratio)" pekiştirme denilmektedir. 

    Ceza da bir çeşit edimsel koşullanma süreci oluşturmaktadır. Ceza da bir pekiştireçtir. Ancak bir eylemin tekrarlanmaması için uygulanır. 
    Eylem karşısında ceza gören organizma o eylimi yinelemez. Böylece istenemeyn davranışlar engellenmiş olur. Ancak ceza pek çok durumda 
    iyi bir işlev görmemektedir. Çünkü ceza ortadan kalktığında eski davranış geri gelmektedir. Ayrıca cezanın saldırgan davranışları artırma 
    gibi bir etkisi de vardır. Organizmaya doğurdan acı veren cezalara "birincil cezalar" denilmektedir. Organizmaya dolaylı acı veren cezalara ise
    "ikincil cezalar" denir. Yaramazlık yapan çocuğun dövülmesi birincil cezadır. Ancak onun televizyon seyretmesine izin verilmemesi ikincil 
    cezaya örnektir. Yani ikincil cezada aslında organizmaya acı vermek yerine haz veren bir öğe ortamdan çekilmektedir. O nedenle birincil 
    cezalar yerine ikincil cezalar tercih edilmelidir. 

    Pekiyi edimsel koşullanma sonucunda öğrenilmiş bir davranış söz konusu olsun. Artık edim (action) terkrarlandığında pekiştireç 
    verilmezse ne olur? Örneğin bir çocuk ağladığında ebeyn onun isteğini karşılıyorsa bu uyaran pozitif bir pekiştireçtir. Çocuğun 
    ağlama davranışını artıracaktır. Ancak zamanla ebeveyn çocuk ağlsa da artık onun istediği şeyi almazsa zamanla "sönümlenme (extinction)"
    oluşur. Yani öğrenilen davranış kaybolur. 

    Bazı canlılar ve özellikle insanlar başkalarını izleyerek onlara verilen pekiştireçleri görerek dolaylı bir biçimde de pekiştirmeye
    maruz kalabilmektedir. Örneğin etrafını izleyen bir çocuk başka bir arkadaşının yaptığı davranış üzerine kendisinin değil ama 
    onun ödül aldığını görürse kendi davranışını da değiştirebilmektedir. Bu öğrenme biçiminde psikolojide "sosyal bilişsel öğrenme (social cognitive learning)"
    denilmektedir. 

    Psikolojide organizmanın bütün bilgi işlem faaliyetlerine "biliş (cognition)" denilmektedir. Yani düşünme, akıl yürütme, 
    hafıza, algılama, bilinç, zeka gibi konular "bilişsil psikoloji (cognitive pschology)" denilen alana ilişkin konulardır. 
    Eskidne bilişsel faaliyetler "bilişsel psikoloji" içerisinde ele alınıyordu. Ancak bilişsel faaliyetleri beyin bölgeleriyle ilişkilendirerek inceleyen 
    ismine "bilişsel nörobilim (cognitive neuroscience)" denilen yeni bir bilim dalı ortaya çıkmıştır. Tıptaki nöroloji hastalık temelli olarak 
    konuya yaklaşmaktadır. Dolayısıyla sosyal bilişsel öğrenme yani başkalarını taklit ederek ve onların aldığı ödüllere ve cezaları göz önünde 
    bulundurarak öğrenme bilişsel unsurlar da içermektedir. Halbuki edimsel koşullanmada bilişsel faaliyetler en az düzeydedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Makine öğrenmesinde pekiştirmeli öğrenme tamamen psikolojideki edimsel koşullanma süreci taklit edilerek modellenmektedir. 
    Makine (yazılımı kstediyoruz) rastgele bir şeyler yapar. Ondan ödül elde ederse onu tekrarlamaya çalışır. En sonunda ödül kazamnak için 
    hedefi gerçekleştirmeyi öğrenir. Pekiştirmeli öğrenmede bazı terimler sıkça kullanılmaktadır. Öncelikle bu terimleri açıklayalım:

    Yazılımsal Etmen (Software Agent): Pekiştirmeli öğrenmede öğrenme işlemini yapan yani edimlerde bulunan yazılıma "yazılımsal etmen"
    denilmektedir. Sıklıkla "yazılımsal etmen" yerine yalnızca "etmen" sözcüğü kullanılmaktadır. Etmen öğrenmedeki aktördür. 

    Çevre (Environment): Etmenin içinde bulunduğu ortama denilmektedir. Örneğin bir labirentte yol bulmaya çalışan etmen söz konusu olsun. Burada 
    labirent çevreyi oluşturmaktadır. Etmenler bir çevre içerisinde bulunmaktadır. 

    Eylem (Action): Etmenin çevre içerisinde yaptığı faaliyetlere eylem (action) denilmektedir. Örneğin bir labirentte etmen sola, sağa, 
    yukarı ya da aşağıya gidebilir. Bu hareketler eylemleri belirtir. Etmen de çevrenin bir parçasıdır. Bir etmenin yapablieceği eylemlerin topluluğuna
    "eylem alanı (action space)" denilmektedir. 

    Durum (Status): Çevrenin içinde bulunduğu hale "durum" denilmektedir. Örneğin etmen bir hareket yaptığında bir kapı açılıyor olabilir. 
    Yani bu eylemde çevrede bir değişilik olmaktadır. İşte çevrenin her farklı haline durum denilmektedir. Bir labirennte etmen sola gidince 
    artık bir durum oluşmaktadır. Çünkü artık etmen başka bir yerdedir. Etmen de çevrenin bir parçasıdır. 

    Ödül/Ceza (Reward/Penalty): Ödül ve ceza pekiştirmeli öğrenmenin önemli bir unsudurur. Eemen bir eylem yaptığında çevrede bir durum 
    değişikliği olur. Bu durumda etmen bir ödül ya da ceza alabilir. Etmenin amacı ödülü maksimize etmek ve cezadan kaçınmaktır. 
    Yani pekiştirmeli öğrenmede bir eyleme ödül ya da ceza verilmezse öğrenme gerçekleşmez. Ödül ile ceza aynı etkiye yol açmaktadır. 
    Bir eylem ödülle de tekrarlanabilir. Ceza almayarak da tekrarlanabilir. 

    Bir çevre (environment) deterministik olabilir ya da olmayabilir. Deterministik çevre demek çevrenin belli bir durumunda belli bir eylem yapıldığında 
    ne olacağının bilinmesi yani yeni durumun biliniyor olması demektir. Başka bir deyişle deterministik bir çevrede belli bir 
    durumda belli bir eylem yapıldığı zaman her zaman aynı yeni durum oluşur. 

    Bir çevre ayrık (discrete) ya da sürekli (contigous) olabilir. Ayrık çevre demek çevredeki eylem sonucunda oluşan durumların sayısının
    sınırlı olması demektir. Örneğin bir oyun programında etmen bir hareket yaptığında oluşacak yeni durum sınırlı sayıda ise bu çevre ayrıktır. 
    Ancak etmen bir eylem yaptığında oluşacak durumların sayısı sonsuz ise bu çevre sürekli bir çevredir. Pekiştirmeli öğrenmede genellikle
    sürekli çevre ayrık hale getirilmektedir. Sonsuz sayıda durum ile başa çıkmak pek çok durumda zordur. 

    Bir çevredeki öğelerin durumlarının tespit edilebildiği çevrelere "gözlemlenebilir (observable)" çevre denilmektedir. 
    Gözlemlenebilir bir çevrede sonsuz sayıda durum olabilir. Ancak biz bu durumların her birini gerektiğinde öğrenebiliriz. 
    Eğer biz çevredeki öğelerin durumlarını öğrenemiyorsak böyle çeverelere "gözlemlenemeyen (unobservable)" çevre denilmektedir. 
    Bazen çevrenin bazı öğeleri gözlemlenebilir iken bazıları gözlemlenemeyebilir. Böyle çevrelere de "kısmi gözlemlenebilir (partially obvervable)"
    çevreler denilmektedir. Çevredeki gözlemlenebilen bütün öğelere "gözlem alanı (abservation space)" de denilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Pekiştirmeli öğrenme pek alanda kullanılabilmektedir. Örneğin otomatik kontrol sistemleri pekiştirmeli öğrenme ile gerçekleştirilebilir. 
    Etmen pekiştirmeli öğrenme ile yeni bir durum karşısında ne yapması gerektiğini öğrenebilmektedir. Yani içinde bulunduğu duruma 
    uyum sağlayabilmektedir. Pekiştirmeli öğrenme finansal sistemlerde de kullanılabilmektedir. Pek çok veriyi elde edip kar maksimizasyonu 
    sağlamak için etmenin ne yapması gerektiği pekiştirmeli öğrenmeyle etmene öğretilebilmektedir. Pekiştirmeli öğrenme üretim problemlerine de 
    uygulanabilmektedir. Benzer biçimde ne zaman ne kadar stok tutulacağı içinde bulunulan duruma bağlıdır. Stok yönetim problemlerinde de pekiştirmeli 
    öğrenme kullanılabilmektedir. Dağıtım problemlerinde de problemin dinamik yapısından dolayı pekiştirmeli öğrenmeden faydalanılabilmektedir.
    Oyun programları pekiştirmeli öğrenme için tipik örnekleri oluşturur. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Pekiştirme öğrenme çalışmaları için çevrenin oluşturulması gerekmektedir. Çevranin oluşturulması da biraz zahmetlidir. Bu 
    nedenle bu konuda çalışma yapan kurumlar çeşitli çevreler için simülatörler oluşturmaktadır. Böylece bu alanda çalışacak kişiler de 
    çevreleri kendileir oluşturmak yerine bu hazır simülatörleri kullanabilmektedir. 
    
    Pekiştirmeli öğrenme için çevre oluşturan çeşitli simülatör yazılımları gerçekleştirilmiştir. Bunların en ünlülerinden biri OpenAI 
    denilen kurumun geliştirmiş olduğu "gym" kütüphanesidir. OpenAI son zamanlarda ChatGPT'nin son versiyonlarıyla geniş kesimler 
    tarafından tanınır hale gelmiştir. OpenAI kar amacı gütmeyen bir kurum olarak kurulmuştu. Bu kurum pek çok büyük yatırımcıdan ve şirketten
    yapay zeka çalışmalarını geliştirmek amacıyla maddi destek alıyordu. Ancak son zamanlarda OpenAI ticari dünyaya da açılmış, Microsoft ile 
    işbirliğine de girişmiştir. Yine son zamanlarda gym simülatörleri OpenAI bünyesinden çıkartılarak Farama denilen kuruma devredilmiştir. 
    gym ortamını egliştirneler de o kurum bünyesinde çalışmaya başlamıştır. Gym ortamının resmi sitesi şöyledir:

    https://www.gymlibrary.dev/

    OpenAI kurumunun gym kütüphanesi dışında benzer simülatörler sunan başka kurumlar ve kütüphaneler de bulunmaktadır. Örneğin 
    Google'ın DeepMind platformu da bu tarz simülatörler sunmaktadır. 

    gym ortamı aşaıdaki gibi krulabilir:

    pip install gym
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    gym kütüphanesi içerisindeki simülatörlere "çevre (envirionment)" denilmektedir. Bu simülatörler çeşitli ana başlıklar altında 
    gruplandırılmıştır. Biz de kursumuzda bunlardan bir bölümünü kullanacağız. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Cart Pole isimli simülatörde hareketli bir parçaya (araba) bağlı direk vardır. Amaç bu direğin belli bir açıda düşürülmeden 
    dik tutulmasıdır. Simülatörde arabaya belli bir kuvvet soldan ya da sağdan uygulanır. Kuvvetin büyüklüğü değiştirilememektedir. 
    Yalnızca uygulama yönü değiştirilmektedir. (Tabii bir kuvvet belli bir noktaya uygulanırsa bir ivme oluşur). Dolayısıyla
    simülatörde etmen için iki eylem tanımlıdır: Sola kuvvet uygulamak ya da sağa kuvvet uygulamak. 
    
    Bu simülatörde çevreden (environment) elde edilecek bilgiler dört tanedir: Arabanın x eksenindeki konumu, arabanın o andaki hızı, 
    direğin o andaki açısı ve direğin o andaki açısal hızı. Direğin açısı dik durumdan 12 dereceden fazla kayarsa denemenin başarısız olduğuna
    karar verilmektedir. Başka bir deyişle amaç direğin 12 dereceden daha az bir açıyla dik tutulmasıdır. Simülatörde her bir eylem sonrasında 
    eğer direk 12 derece açının dışına çıkmamaışsa ödül olarak simülatör 1 puan vermektedir. Simülatör orta nokta 0 olmak üzere -0.05 ile
    0.05 arasında rastgele bir x konumundan başlatılmaktadır. Simülasyon şu durumlarda sonlanmaktadır: 

    1) Arabaya bağlı direğin 12 direceden fazla sola ya da sağa yatması durumunda (başarısızlık).
    2) Arabanın x ekseninde +2.4 ya da -2.4'lük bölgeden çıkmasıyla. Burası görünen bölgedir (başarısızlık).
    3) 500 defadan fazla eylem yapıldığında (bu durumda işlem başarılmış kabul edilmektedir).
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    gym kütüphanesinin Mountain Car isimli simülatöründe yine bir araç vardır. Bu araç iki tarafı tepe olan bir çukur bölgede 
    bulunur. Bu araca soldan ya da sağdan sabit bir kuvvet uygulanabilmeketedir. Amaç bu aracın tepeyi aşarak bayrak olan noktaya 
    erişmesini sağlamaktır. Bu similatörde çevreden elde edilecek iki bilgi vardır. Arabanın x eksenindeki konumu ve arabanın hızı. 
    Arabaya uygulanacak üç eylem vardır: Soldan kuvvet uygulamak, sağdan kuvvet uygulmaak ve kuvvet uygulamayı kesmek. Bu eylemlerden biri 
    uygulandığında biz çevrenin o andaki durumunu elde edip sonraki eyleme karar verebiliriz. Tabii insan zekasıyla bu problem kolay bir 
    biçimde çözülebilmektedir. Arabaya önce soldan sürekli kuvvet uygularız. Araba tepeyi aşamayacaktır. Arabanın hızı 0'a kadar düşecektir. 
    Bu durumda arabaya ters yönde kuvvet uygularız bu biçimde işlemlerini devam ettiririz. Tabii bu simülatörden amaç arabanın tepeyi aşmasının 
    kendi kendine öğrenilmesidir. Simülatörde araba her eylem sonucunda eğer hedefe (bayrağa) ulaşamamışsa -1 ceza puanı verilmektedir. 
    Ödül ile cezanın benzer etkiler yaptığını anımsayınız. Simülatör araban konumunu -0.6 ile -0.4 arasında rastgele bir yerden başlatır. 
    Başlangıç hızı da 0 olmaktadır. Simülatör şu iki durumda sonlamkatadır:

    1) Araba bayrak noktasına gelmiştir. Bayrak noktası +0.5 pozisyonundadır (başarı durumu).
    2) 200 eylemden dfaha fazla eylem uygulanmıştır (başarısızlık).

#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Taxi isimli simülatörde 5x5'lik bir matris içerisinde 4 tane durak vardır. Durakların yerleri sabittir. Yani simülatör her 
    çalıştırıldığında duraklar aynı yerlerde bulunur. Taksi matris içerisinde dört yöne hareket edilebilmektedir. Ancak matris içerisinde
    duvarlar da vardır. Duvara çarpılırsa bu durum oyunun sonlanmasına yol açmaz ancak bir konum değişikliği oluşturmamaktadır. 
    Dört taksi durağı RGYB harfleriyle temsil edilmiştir. Mavi renkteki durak yolcunun alınacağı durağı, kırmızı renkteki durak yolcunun 
    bırakılacağı durağı belirtmektedir. Araba eğer içerisinde yolcu yoksa kırmızı renkte varsa mavi renkte gözükmektedir. 

    Bu similatörde etmenin (taksinin) 6 tane eylemi vardır. Yani simülatörün eyşem alanı (action space) 6 seçenekten oluşmaktadır. Simülatörderki 
    belli bir andaki durum sayısı 500 tanedir. Çünkü araba 5x5'lik matristeki herhangi bir yerde bulunuyor olabilir (25 seçenek). 
    Yolcu o sırada herhangi bir durakta ya da arabanın içerisinde bulunuyor olabilir (5 seçenek). Yolcu herahngi bir durağa bırakılacak 
    olabilir (4 seçenek). Dolayısıyla simülatörün "gözlem uzayı (observation sapce)" 500 durumdan birine ilişkin olabilir. 

    Simülatörün verdiği ödül/ceza puanları şöyledir: 
    
    - Eğer yolcu doğru yerde bırakılırsa +20 puan ödül
    - Eğer yolcu yanlış yerden alınıp ya da yanlış yere bırakılırsa -10 puan ceza
    - Her adımda -1 puan ceza

    Pekiştirmeli öğrenmede ödülün en büyüklenmesi ve cezanın en küçüklenmesi istendiğine göre eğitim soncunda taksi en kısa yoldan 
    hedefine varmaya çalışacaktır. 

    Bu oyunda bitme koşulu yoktur.
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Frozen Lake (donmuş göl) isimli simülatörde 4x4'lük ya da 8x8'lik bir göl vardır. Bu göl donmuş olmakla birlikte çatlak 
    kısımlardan oluşmaktadır. Amaç bir kişinin S noktasından G noktasına çatlak yerlere (bunlara delik de diyebiliriz) basmadan gidebilmesidir. 
    Simülatör kaygan (slippery) ya da kaygan olmayan modda çalıştırılabilemktedir. Kaygan olmayan modda etmen hangi yöne gidilecekse gerçekten o yöne 
    gitmektedir. Ancak kaygan modda etmen bir yöne gitmek isterken o yöne dik olan bir yöne de kayma neticesinde gidebilir. Örneğin 
    kaygan modda etmen sağa gitmek istesin. Sağ yöne dik olan yön yukarı aşağısıdır. O zaman etmen kayarak sağa gitmek isterken yukarı ya da
    aşağıya da gidebilir. Kaygan modda etmen bir yöne giderken 1/3 olasılıkla istediği yöne gider. 1/3 olasılıkla dik yönlerden birine, 
    1/3 olasılıkla da dik yönlerden diğerine gitmektedir. 

    Bu simülatörde etmenin yapacağı eylem sayısı dört tanedir. Yani simülatörün eylem uzayı 4 elemandan oluşmaktadır. Simülatörden 
    elde edilen durum bilgisi yani gözlem uzayı 4x4'lük versiyon için 16 elemandan 8x8'lik versiyon için 64 elemandan oluşmaktadır. 
    Simülatör deliğe düşmede ve hedefe varamayan her adımda 0 puan, hedefe varıldığında ise +20 puan ödül vermektedir. Deliğe düşüldüğünde
    oyun bitmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Lunar Lander (Aya inme) isimli simülatörde bir ay aracı vardır. Bu ay aracı iki bayrağın arasındaki bölgeye inmeye çalışmaktadır. 
    Etmen için (ay aracı) dört eylem söz konusudur: Motoru sola çalıştırmak, motoru sağa çalıştırmak, ana motoru çalıştırmak ve 
    motorları susturmak. Çevreden elde edilecek bilgiler ise 8 tanedir: Ay aracının x ve y eksenindeki koordinatları (2 tane), 
    x ve y eksenindeki doğrusal hızları (2 tane), açısı (1 tane), ay aracının açısal hızı (1 tane), ay aracının iki ayağının ayrı ayrı
    
    yere deyip deymediği bilgisi (2 tane). Oyunun sonlanma koşulları şunlardır:

    - Ay aracı hızlı bir biçimde yerle temas ederek parçalandığında
    - Ay aracı görünen bölgenin sınırları dışına çıktığında 

    Simülatör eğer ay aracı bayrakla belirtilen bölgeye indirilmişse indirilmenin yumuşaklığına göre 100 puan ilke 140 puan arasında
    ödül verilmektedir. Eğer ay aracı bayraklı bölgenin dışına indirildiğinde herhangi bir ödül ya da ceza verilmemektedir. 
    Eğer ay aracı yere sert inerek parçalanırsa -100 ceza puanı verilmektedir. Ana motor çalıştırıldığında -0.3 ceza puanı verilmektedir. 
    Sol ve sağ motorlar çalıştırılında ise -0.03 ceza puanı verilmektedir. Eğer ay aracı yere inip kararlı bir duruma gelirse +100 
    puan ödül verilmektedir.

    Amaç en etkin biçimde ve en az ceza alacak biçimde (yani en yumuk ve hızlı biçimde) aracı indirmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    gym kütüphanesinde bol miktarda atari oyunları da vardır. Örneğin Pac-Man oyunu dünyanın en popüler atari oyunlarındandır. 
    Bu oyunda hareket eden oyuncuyu 4 hayalet öldürmeye çalışmaktadır. Oyuncu noktalarla belirtilen besinleri yiyerek onları bitirmeye çalışır. 
    Büyük yopaklar oyuncuya kuvvet kazandırmaktadır. Eğer büyük bir topak yenirse hayaletler maviye döner ve artık oyuncu da hayaletleri 
    yiyebilir hale gelir. Oyuncu hayalete yakalnırsa can kaybetmektedir. Oyuncunun toplamda dört canı vardır. Oyunda zaman geçtikçe 
    hayaletlerin hızları artar. Artan puan değerleri için her turda exkstra bir meyve verilir. Meyve yenirse ekstra puan kazanılır. 
    Oyunun başka ayrıntıları da vardır. 

    Pac-Man simülasyonunda simülatörün konfigürasyonuna göre eylemler değişebilmektedir. Temel eylem oyuncunun dört yönden birine gitmesi ya da 
    hiçbir yere gitmemesidir. Oyunda gözlem uzayı olarak bize PAc-Man'nin resimsel görüntüsü verilmektedir. Yani oyunun oynandığı alanın 
    resmi bize her adımda verilmektedir. Verilen bu resim 210x160x3 boyutlarındadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Tuğla kırmaca (breakout) en eski oyunlardan biridir. Yukarıda tuğlalar, aşağıda bir raket vardır. Top rakete çarpınca yansımaktadır. 
    Amaç topla tüm tuğlaları kırmaktır. Oyunda etmenin (raket) dört eylemi vardır: Raketi sola bir birim götürmek, sağa bir birim götürmek,
    oyunu başlatan "fire" düğmesine basmak, hiçbir şey yapmamak. Oyun bize gözlemolarak yine o andaki durumu bir gri tonlamalı bir resim biçiminde vermektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    gym simülatörlerinde son zamanlarda bazı değişiklikler yapılmıştır. 0.21 versiyonu ile kursun yapıldığı sıradaki en yüksek versiyon 
    olan 0.26 arasındaki değişiklikler kodun gözden geçirilmesini gerekli hale getirebilmektedir. Aşağıdaki örnekler daha çok 0.21 versiyonu 
    dikkate alınarak verilmiştir. 
   
    gym simülatörleri şu adımlardan geçilerek kullanılmaktadır:

    1) Her simülatörün bir ismi vardır. Bu isimlerin neler olduğu orijinal dokümanlardan öğrenilebilir. gym modülündeki 
    make isimli fonksiyon simülatörün ismini ve bazı diğer parametrik bilgileri alır ve bize ismine "çevre nesnesi (environment object)"
    denilen bir nesne verir. Çevre nesneleri farklı sınıflardan oluşsa da aslında hep aynı biçimde kullanılmaktadır. Örneğin:

    import gym

    env = gym.make('CartPole-v1)

    Eskiden make işlemi sırasında render_mode belirtilmek zorunda değildi. Ancak kütüphanenin yeni versiyonlarında render işlemi için 
    artık render_mode gerekmektedir. Tipik render_mode "human" biçiminde kullanılabilir. Örneğin:

    env = gym.make('CartPole-v1, render_mode='human')

    2) Çevre nesnesi elde edildikten sonra reset metodu çağrılarak simülatörün reset edilmesi gerekir. reset metodu bize oyunun 
    başladığı ilk durumun gözlem değerini bir NumPy dizisi olarak vermektedir. Örneğin CartPole simülasyonunda bu gözlem değeri 
    aranbanın x eksenindeki knumu, arabanın hızı, diğerin açısı ve direğin açısal hızından oluşmaktadır. Örneğin:

    obs = env.reset()

    3) Etmene eylem yaptırmak için çevre sınıfının step metotları kullanılmaktadır. step metotları yapılacak eylemi anlatan bir 
    parametreye sahiptir. Tabii step metotların parametreleri simülatöre göre değişebilmektedir. Örneğin CartPole simülasyonunda
    eylem 0 ya da 1'den oluşmaktadır. 0 motorun sola çalıştırılacağını 1 ise sağa çalıştıralacağını belirtmektedir. step metodu kütüphanenin 
    0.21 versiyonunda dörtlü bir demete geri dönerken 0.26'lı son versiyonda beşli bir demete geri dönmektedir. 
    
    0.21 versiyonundaki dörtlü demetin birinci elemanı eylem sonrasındaki çevrenin durumunu yani gözlem sonucunu vermektedir. 
    İkinci eleman eylem sonucunda elde edilecek ödülü belirtmektedir. (Tabii eğer bu değer pozitifse bir ödül, negatifse biz ceza söz konusudur.)
    Demetin üçüncü elemanı oyunun bitip bitmediğini belirten bool bir değerdir. Eğer bu değer True ise oyun bitmiş, False ise bitmemiştir. 
    Demtin son elemanı ise simülatörün bazı bilgilerini vermektedir. Genellikle bu eleman kullanılmamaktadır. Örneğin:

    obs, reward, done, info = env.step(action)
    
    Ancak kütüphanein 0.26'lı versiyonlarında step metodu beşli bir demete geri dönmektedir. Demetin done ve info elemanları arasında 
    trunacted diye isimlendirilen simülatörün erken sonlanıp sonlanmadığını belirtien bir eleman daha vardrı:

    obs, reward, done, truncated, info = env.step(action)

    Eğer bu info değerleri ile ilgilenilmiyorsa okunabilirliği artırmak için demetin son elemanı _ ile isimlendirilebilir:

    obs, reward, done, _ = env.step(action)

    step metodunun geri dönüş değerine ilişkin demete "truncation" elemanı yeni eklenmiştir. Eskşden step metodu 4 elemanlı bir 
    demete geri dönmekteydi. 

    step metodu bir kez değil bir döngü içerisinde çağrılarak işlemler peşi sıra yaptırılır. Tipi bir döngü şöyle olabilir:

    while True:
        obs, reward, done, _ = env.step(action)
        if done:
            break
        env.render()   
 
    4) reset ve step işlemlerinden sonra simülatörün durumunu görüntülemek için çevre sınıfının render metodu kullanılmaktadır. 
    Bu metot make fonksiyonunda belirtilen render_mode parametresine göre görüntüleme yapmaktadır. En normal render_mode 'human'
    biçimindedir. gym kütüphanesi simülatörü görüntülemek için "pygame" isimli bir programı kullanmaktadır. Dolayısıyla sistemimizde
    bu programın da kurulu olması gerekir. 

    5) En sonunda simülatörü çevre sınıfının close metodu ile kapatmak gerekir. 

    Simülatör çalıştırılırken step metodundan elde edilen bilgilerden hareketle done koşulu sağlandığında işlem sonlandırılmalıdır. 
    Aslında bu sonlandırma zorunlu değildir. Ancak oyunun bitme koşullarına uyulacaksa bu sonlandırma yapılmalıdır. 

    çevre nesnelerinin action_space isimli bir örnek özniteliği vardır. Bu öznitelik bize bir space nesnesi vermektedir. Bu space nesnesinin
    n örnek özniteliği toplam eylemlerin sayısını vermektedir. Bu sınıfın sample isimli metodu bize rasgele bir eylem vermektedir. 
    Örneğin biz simülatöre rastegele eylemleri şöyle yaptırabiliriz:

    while True:
        action = env.action_space.sample()
        obs, reward, done, _  = env.step(action)
        if done:
            break
        env.render()   

    Simülatörün 0.26'lı versiyonlarında çıkış koşulu için truncated elemanına da bakılmalıdır:

    while True:
        action = env.action_space.sample()
        obs, reward, done, truncated, _  = env.step(action)
        if done or truncated:
            break
        env.render()   

    Çevre nesnelerinin observation_space isimli örnek öznitelikleri yine bir space nesnesi vermektedir. Buradan elde edilen space
    nesnesinin en önemli iki örnek özniteliği low ve high öznitelikleridir. low özniteliği bize gözlem alanının en düşük değerlerini 
    vermektedir. high ise en tüksek değerlerini verir. Yine bu space nesnesinin sample metodu rastgele bir gözlem değerini bize verir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte CartPole simülatörüne rastgele hareketler yaptırılmıştır. 
#----------------------------------------------------------------------------------------------------------------------------

import gym

env = gym.make('CartPole-v1')

obs = env.reset()
env.render()

while True:
    action = env.action_space.sample()
    obs, reward, done, _  = env.step(action)
    if done:
        break
    env.render()   
        
env.close()

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte MountainCar simülatörünün insan zekasıyla görevi başarması sağlanmıştır. Burada biza önce motoru sağa 
    çalıştırıp hızın tepeden dolayı dçok düştüğü noktada sola çalıştırıyoruz. Böylece hem potansiyel enerjiden hem de motor enerjisinden
    faydalanıyoruz. Hız sıfır olmayabilir ancak sıfıra yaklaşabilir. Bu nedenle if içerisinde bir epsilon değeri kullanılmıştır.
#----------------------------------------------------------------------------------------------------------------------------

import gym

env = gym.make('MountainCar-v0', render_mode='human')

obs = env.reset()
env.render()

action = 2
counter = 0
while True:
    obs, reward, done, _  = env.step(action)
    if done:
        break
    env.render()   
    if abs(obs[1]) < 0.001:
        action = 0 if action == 2 else 2
env.close()

#----------------------------------------------------------------------------------------------------------------------------
    Taxi simülatörü yine make fonksiyonu ile aşağıdaki gibi yaratılır:

    env = gym.make('Taxi-v3')

    Daha sonra simülatör reset edilir ve oradan gözlem değerleri elde edilir. Taxi simülatöründe bir tane gözlem değeri vardır. O da
    bir sayıdır. Bu sayı taksinin nerede olduğunu, yolcunun durumuna göre belirlemektedir. Örneğin:

    obs = env.reset()

    Burada simülatörün durumu tek bir değerler bize verşlmektedir. Bu değerin anlamı şöyledir:

    arabanın satır numarası * 100 +  arabanın sütun numarası * 20 + yolcunun konumu * 4 + yolcunun bırakılacağı yer

    Burada arabanın satır ve sütun numarası sol-üst köşeden itibaren 0 orijinli bir biçimde belirtilmektedir. Yolcunun konumu ise
    0, 1, 2, 3, 4 ile temsil edilmeketedir. Bu değerler sırasıyla R, G, Y, B ve taksinin içiyle eşleşmektedir. Yolcunun bırakılacağı durak da 
    yine 0, 1, 2, 3 ile temsil edilir ve bunlar da R, G, Y, B ile eşleştirilmiştir. 

    Simülatörde durakların yerleri hiç değişmemektedir. Duraklar şu pozisyonlarda bulunmaktadır:

    R -> (0, 0)
    G -> (0, 4)
    Y -> (4, 0)
    B -> (4, 3)

    Bu değeri set eden ve reset eden çevre sınıfının encode ve decode isimli metotları bulunmaktadır. encode metodu bizden 
    sırasıyla taksinin bulunduğu yerin satır numarasını, sütun numarasaını, yolcunun bulunduğu yeri ve yolcunun bırakılcağı 
    durağı parametre olarak almaktadır. Bize bunun sayısal bir biçimde kodlanmış halini vermektedir. Örneğin:

    env.encode(2, 2, 2, 1)
    Out[55]: 249

    Bu sayı şöyle elde edilmiştir:

    2 * 100 + 2 * 20 + 2 * 4 + 1 = 249

    Dokümante edilmemiş olsa da kaynak kodlara bakıldığında simülatgörün belli bir duruma getirilmesi için env.env.s 
    örnek özniteliğinin kullanıldığı anlaşılmaktadır. Bu sayede biz reset metoduyla rastgele bir durumdan başlamak yerine 
    belirli bir durumdan başlayabiliriz. Örneğin taksinin 2'nci satır, 2'inci sütunda olmasını yolcunun sağ üst köşedeki G'de 
    olmasını ve yolcunun bırakılacağı yerin de sol üst köşedeki R olmasını isteyelim. Bunu şöyle sağlarız:

    import gym

    env = gym.make('Taxi-v3')

    obs = env.reset()

    val = env.encode(2, 2, 1, 0)
    env.env.s = val

    env.render()

    Çevre sınıfının decode metodu ters işlemi yapmaktadır. Yani bizden bir sayı alır. Bu sayıyı dörlü bir demete dönüştürür. 
    Demetin ilk elemanı taksinin bulunduğu satır numarası, ikinci elemanı sütun numarası, üçüncü elemanı yolcunun konumunu ve 
    dördüncü elemanı da yolcunun bırakılacağı yeri belirtmektedir. Örneğin biz önce encode sonra decode işlemi yaparsak aynı değeri 
    elde ederiz:

    import gym

    env = gym.make('Taxi-v3')

    obs = env.reset()

    val = env.encode(2, 2, 1, 0)
    row, col, passenger, drop = env.decode(val)
    print(row, col, passenger, drop)

    Burada aktardığımız bilgiler dokümanlarda bulunmamaktadır. Tamamen kaynak kodların incelenmesiyle elde edilmiştir. Bu nedenle
    buradaki bilgiler simülatörür sonraki versiyonlarında değişebilmektedir. Öte yandan simülatörün tasarımında da eksikler vardır. 
    Programcının simülatörü rastgele bir konumdan değil belli bir konumdan başlatılmasi gerekebilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Taksi simülatöründe taksiyi hareketli bir biçimde göstermek için şöyle bir yöntem kullanılmaktadır: render metodunda mode parametresi 
    'ansi' girilirse render metodu ekrana bir şey basmaz ancak "ansi teminal karakterleri" denilen karakterlerden oluşan bir yazı 
    verir. Bu yazı print fonksiyonuyla bastırılırsa aynı görüntü karşımıza çıkmaktadır. Örneğin:

    s = env.render(mode='ansi')
    print(s)

    Burada aslında yapılmak istenen şey aşağıdakiyle aynıdır:

    env.render()

    render metodu zaten default durumda ekrana batırmaktadır. Fakat ANSI terminal karakterleri print ile basılırken "bulunuln satırın      
    başına geçmek için uygun ANSI terminal karakteri kullanılırsa basım hep aynı yere yapılır. Böylece hareketli bir görüntü elde edilir. 
    Aşağıda bu biçimdeki harekete bir örnek verilmektedir:
#----------------------------------------------------------------------------------------------------------------------------

import time
import gym

env = gym.make('Taxi-v3')

obs = env.reset()
env.render()

for i in range(100):
    action = env.action_space.sample()
    obs, reward, done, _ = env.step(action)
    s = env.render(mode='ansi')
    print('\x1b[1J' + s, end='')
    time.sleep(0.5)

#----------------------------------------------------------------------------------------------------------------------------
    Frozenlake sümülatörü de benzer biçimde kullanılmaktadır. Burada gözlem değeri (durum bilgisi) tek değerden oluşmaktadır. 
    Bu değer kişinin bulunduğu yerin "satır numarası * 8 + sütun numarası" biçimindedir. Bu simülatörde etmenin yapacağı hareketler 
    4 tanedir:

    0 --> Sola
    1 --> Aşağıya
    2 --> Sağa
    3 --> Yukarı
    
    Simülatörden amaç etmene S noktasından G noktasına deliğe düşmeden etkin biçimde gitmeyi öğretmektir. Simülatör burada etmene 
    hedefe vardığında 1 puan, varamadığında her eylem için 0 puan vermektedir. Simülatörün 4x4'lük bir versiyonu da vardır. 

    Aşağıdaki örnekte simülatörde etmene rastgele hareketler yaptırılmıştır. Etmen deliğe düştüğünde işlem sonlandırılmıştır. 
#----------------------------------------------------------------------------------------------------------------------------

import time
import gym

env = gym.make('FrozenLake-v1', map_name="8x8")
obs = env.reset()

env.render()

for i in range(100):
    action = env.action_space.sample()
    obs, reward, done, _ = env.step(action)
    s = env.render(mode='ansi')
    print('\x1b[1J' + s, end='')
    if done:
        break
    time.sleep(0.5)
    
#----------------------------------------------------------------------------------------------------------------------------
    MsPacman oyununa ilişkin simülatörün kullanılabilmesi için bazı gym sürümlerinde aşağıdaki kurulumların yapılması gerekmektedir:

    pip install gym[atari]
    pip install gym[accept-rom-license]

    MsPacman oyununda her bir eylem sonrasında çevreye ilişkin gözlem (durum) bilgisi o andaki oyunun resimsel görüntüsüdür. 
    Bu görüntü bize (210, 160, 3) biçiminde RGB bir resim olarak verilmektedir. Örneğin biz simülatörü reset edip elde ettiğimiz 
    gözlem değerine ilişkin resmi aşağıdaki gibi çizdirebiliriz:

    import gym

    env = gym.make("MsPacman-v4")

    obs = env.reset()

    import matplotlib.pyplot as plt

    plt.figure(figsize=(10, 10))

    plt.imshow(obs)

    Simülatörde etmenin yapacağı eylemler şunlardır:

    0 --> NOOP
    1 --> UP
    2 --> RIGHT
    3 --> LEFT
    4 --> DOWN
    5 --> UPRIGHT
    6 --> UPLEFT
    7 --> DOWNRIGHT
    8 --> DOWNLEFT

    Ancak oyun belli bir süre başlamamaktadır. Belli bir süreden sonra başlamaktadır. 

    Aşağıdaki örnekte simülatöre rastgele 1000 tane hareket yaptırılmıştır. Önce Pacman hareket etmemekte yaklaış 90 adımdan 
    sonra hareketler başlamaktadır. Oyunda toplam 3 can vardır. 3 can bitince done koşulu gerçeklemektedir. 
#----------------------------------------------------------------------------------------------------------------------------

import gym

env = gym.make("MsPacman-v4", full_action_space=False)

obs = env.reset()

import matplotlib.pyplot as plt

for i in range(1000): 
    action = env.action_space.sample()
    obs, reward, done, _ = env.step(action)
    if done:
        break
    plt.figure(figsize=(10, 10))


    plt.imshow(obs)
    plt.show()

#----------------------------------------------------------------------------------------------------------------------------
    Tuğla kırmaca oyununda toplamda 4 eylem vardır:

    0 --> NOOP
    1 --> FIRE
    2 --> RIGHT
    3 --> LEFT

    Oyunda başlangıçta FIRE düğmesine basılmazsa raket hareket eder ancak top düşmez böylece oyun da başlamaz. 
    Yine her eylemden sonra simülatör bize o andaki oyunun resimini (210, 160, 3) boyutlarında bir resim olarak vermektedir. 
    Oyunda toplam 5 hak vardır. Bu 5 hak kaybedildiğinde done koşulu sağlanır. 

    Oyunda tuğlalar kırıldıkça ödül verilmektedir. Ancak verilen ödül kırılan tuğlanın rengine de bağlıdır. Ödül mekznizması 
    için Atari'nin orijinal dokümanlarına başvurrulabilir:

    https://atariage.com/manual_html_page.php?SoftwareID=889

    Aşağıdaki örnekte raket rastgele hareket ettirilmiştir. 

#----------------------------------------------------------------------------------------------------------------------------

import gym

env = gym.make("Breakout-v4")

obs = env.reset()

obs, reward, done, _ = env.step(1)

import matplotlib.pyplot as plt

for i in range(1000):
    
    action = env.action_space.sample()
    obs, reward, done, _ = env.step(action)
    if done:
        break

    plt.figure(figsize=(10, 10))

    plt.imshow(obs)
    plt.show()
    print('\x1b[1J')

#----------------------------------------------------------------------------------------------------------------------------
    Pekiştirmeli öğrenmede kullanılan birkaç önemli yöntem vardır. Bunların en yalını ve yaygın kullanılanı Q-Learning denilen 
    yöntemdir. Buradaki "Q" harfi "Quality (kalite)" sözcüğünden hareketle uydurulmuştur.  
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Q-Learning yönteminde ismine Q-Tablosu denilen bir tablo kullanılır. Q-Tablosu temelde iki boyutlu bir matris gibi düşünülebilir. 
    Bu tablonun satırlarında olası bütün durumlar (yani gözlem değerleri) sütunlarında da olası tüm eylemler bulunmaktadır. Örneğin
    etmenin içinde bulunduğu durum 5 farklı durumdan birisi olabilsin. Belli bir durumda da üç eylem söz konusu olsun.  Bu durumda
    Q-Tablosu şöyle olacaktır:

       A1 A2 A3
    S1 
    S2
    S3
    S4

    Burada matris 5x3 = 15 tane eleman içerecektir. Başlangıçta Q-Tablosu 0'larla doludur:

        A1 A2 A3
    S1   0  0  0
    S2   0  0  0
    S3   0  0  0
    S4   0  0  0

    Ancak zamanla öğrenme gerçekleştiğinde tablo yavaş yavaş dolmaya başlar. Nihayetinde dolu bir tablo haline gelir. Örneğin:

          A1      A2     A3
    S1   0.2    0.5    0.3
    S2   0.8    0.6    0.1
    S3   0.2    0.7    0.2
    S4   0.3    0.2    0.6

    Q-Tablosunun dolmuş olduğunu varsayalım. Artık etmen belli bir durumdayken en iyi eylemi gerçekleştirebilir durumda olur. 
    Örneğin reset durumunda etmen S3 durumunda olsun. S3 satırı hangi eylemlerin hangi kalitede olduğunu bize vermektedir. Oradaki 
    en kaliteli yani puanı en yüksek olan eylem seçilir. Örneğimizde S3 durumundaki en iyi eylem A2 eylemidir. Etmen A2 eylemini yaptığında 
    başka bir durum oluşacaktır. Bu durumun S1 olduğunu düşünelim. Artık etmen S1 durumundadır. S1 durumundaki en iyi eylem yine A2 eylemidir. 
    Bu kezmen yine A2 eylemini yapar. Şimdi artık yeni bir durum içerisine girilmiştir. Bu yeni durumun S2 olduğunu varsayalım. 
    Bu durumda etmen en iyi eylem olan A1 eylemini gerçekleştirecektir. Özetle Q-Tablosu hangi durumdaki eylemin en iyi eylem olduğunu vermektedir. 

    Q-Learning yöntemini uygulayabilmek için bizim şu bilgilere gereksinimimiz vardır:

    - Ortamdaki tüm durumların neler olduğu bilgisine
    - Belli bir durumdaki eylemlerin neler olduğu bilgisine
    - Q-Tablosunun nasıl güncelleneceğine ilişkin bilgi

    Q-Tablosu tipik olarak bir matris biçimindedir. Baştan seyrek (sparse) görünümdedir. Bazı olgularda her durumda her eylem yapılamaz. 
    Bu durumda Q-Tablosunun bir matris biçiminde değil bir sözlük biçiminde oluşturulması daha etkin bir yöntem olabilir. 

    Belli bir ortamdaki tüm durumların ve eylemlerin tespit edilmesi ve bunun Q-Tablosunun satırları haline getirilmesi önemli bir aşamadır. 
    
    Belli bir durumsal özelliğin sürekli olması sonsuz sayıda satırın bulunmasına yol açar. Bunun Q-Tablosu yönteminde sonlu sayıda durum 
    haline getirilmesi gerekmektedir. Yani bizim sürekli durum özelliklerini ayrık hale getirmemiz gerekir. Örneğin CartPole simülatöründe 
    aracın X eksenindeki konumu, aracın hızı, direğin açısı ve direğin açısal hızı sürekli bilgilerdir. Bu sürekli bilgilerin ayrık hale 
    getirilip sonlu sayıda durumun oluşturulması gerekir. Bunu sağlamanın basit bir yolu şöyledir: Sürekli değerin iki uç sınırı arasındaki
    uzaklık hespalanır. Sonra bu uzaklık belli bir sayıya bölünür. Böylece aslında sürekli bir durum ayrıkmış gibi ele alınır. Örneğin CartPole
    similatöründe arabanın X eksenindeki konumu [-4.8, +4.8] aralığındadır. Buradaki toplam uzaklık 9.6'dır. Biz bu aralığı 100 eşit parçaya 
    bölersek her 0.096'lık konum ayrı bir durum gibi ele alınır. Tabii bu ayrık hale getirme işlemi bilgi kaybına da yol açmaktadır. Zira örneğin
    CartPole simülatöründeki konum bilgisini 100 eşit parçaya böldüğümüzde biz her 0.096'lık aralığı aynı durum kabul ederiz. Yani adeta bize
    göre araba sıçrayarak gitmektedir. Şüphesiz sürekli olguları bu biçimde ayrık hale getirdiğimizde bölme faktörünü yükseltirsek daha az bilgi 
    kaybederiz. Ancak bu sefer de Q-Tablosunu büyütmüş oluruz. 
    
    Şimdi daha önce görmüş olduğumuz gym simülatörlerinde bu durum bilgisinin ve eylemlerin neler olacağına bakalım. 

    - CartPole simülatöründe her eylem sonrasında simülatör bize çevreye (duruma) ilişkin 4 bilgi veriyordu: Aracın X erksenindeki konumu, 
    aracın hızı, direğin açısı ve direğin açısal hızı. Maalesef bu dört bilgi de ayrık değil süreklidir. Bu dört bilgi aslında Q-Tablosunun 
    satırlarını oluşturmaktadır. Ancak bu dört bilginin ayrık hale getirilmesi gerekir. Bu biçimde birden fazla sürekli durum bilgisinin 
    ayrık hale getirilmesinde hep aynı bölme faktörü kullanılmak zorunda değildir. Örneğin biz X eksenindeki konumu 100 parçaya bölerken 
    direğin açısal hızını 50 parçaya bölebiliriz. Ancak şimdi biz burada bu dört durum bilgisini de 100 parçaya böldüğümüzü düşünelim. 
    Bu durumda Q-Tablosunun satır sayısı ne olacaktır? Tabii toplam satır sayısı 100 * 100 * 100 * 100 olur. Bu değer de 10 ^ 8 = 100000000'dur.
    Yani burada Q-Tablosunun 100 milyon satırı olacaktır. Pekiyi belli bir durumdaki eylem sayısı CartPole simülatöründe kaç tanedir? 
    Yanıt 2 tanedir. Motor ya sola çalıştırılır ya da sağa çalıştırılır. Bu durumda Q-Tablosu 100 milyon satırdan ve 2 sütundan oluşacaktır. 
    Böyle bir NumPy dizisinin float32 dtype özelliği ile yaratılacağını düşünürsek Q-Tablosu için toplam bellek miktarı 800 milyon byte'tır. 
    Yani 1GB civarındadır. Pekiyi CartPole simülatöründe elimizde 100 milyon elemanlı bir durum bilgisi varsa biz buradaki durumu Q-Tablosundaki satıra nasıl 
    dönüştürebiliriz? Burada en makul çözüm iki boyutlu matris kullanmak yerine beş boyutlu bir matris kullanmaktır. Öyle ki:

    qtable[arabanın_x_konumu, arabanın_hızı, diğerin_açısı, direğin_açısal_hızı, 2]

    Burada ilk dört bilgiyi verdiğimizde biz iki elemanlı bir NumPy dizisi elde ederiz:

    qresult = qtable[arabanın_x_konumu, arabanın_hızı, diğerin_açısı, direğin_açısal_hızı]

    Burada qresult iki elemanlı satır bilgisini belirtmektedir. 

    - MountainCar simülatöründe gözlem değerleri iki tanedir: Arabanın x eksenindeki konumu ve arabanın o andaki hızı. Bu iki değer de sürekli 
    değerlerdir. O halde Q-Tablosunu oluşturmak için bu iki değerin ayrık hale getirilmesi gerekir. Arabanın konumu [-1.2, 0.6] aralığında, 
    hızı ise [-0.07, 0.07] aralığındadır. Yine bu iki özelliği 100 eşit parçaya bölebiliriz. Bu durumda Q-Tablosunun satırları 100 * 100 = 10000
    elemandan oluşacaktır. Pekiyi yapılacak eylemlerin sayısı da 3 tane idi: Motoru sola çalıştırmak, sağa çalıştırmak ve motoru durdurmak. 
    O halde Q-Tablosu örnekte (100, 100, 3)'lük bir NumPy dizisi olabilir:

    qtable[arabanın_x_konumu, arabanın_hızı, 3]

    Yine biz iki bilgiyi verdiğimizde üç elemanlı bir NumPy dizisi elde ederiz:

    qresult = qtable[arabanın_x_konumu, arabanın_hızı]

    - Taxi simülatöründe o andaki durum bilgisi "taksinin satır numarası, sütun numarası, yolcunun o anda nerede olduğu ve 
    yolcunun nerede bırakılacağı yer". Anımsanacağı gibi zaten bu dört bilgi Taxi simülatöründe tek bir değer biçiminde ifade
    edilmekteydi. Buradaki durum bilgisi ayrıktır ve toplam 500 farklı seçenekten biridir. Etmenin yapacağı eylem sayısı da toplam 6 taneydi:
    "Arabayı sola, sağa, yukarı, aşağıya götür; yolcu al ve yolcu bırak". O halde burada Q-Tablosu (500, 6)'lık bir NumPy dizisidir. 

    - 80x8'lik Frozen Lake simülatöründe kişi 8x8'lik matrisel alanda herhangi bir hücrede bulunabiliyordu. Bu matrisel hücre "kişinin 
    bulunduğu satır numarası * 8 + kişinin bulunduğu sütun numarası" biçiminde sayısal bir değere dönüştürülüyordu. Yani toplamda bu simülatörde 
    durum bilgisi 64 taneydi. Bu simülatörde etmenin yapacağı eylemler "sağa gitmek, sola gitmek, yukarı gitmek ya da aşağı gitmek" biçiminde
    toplam 4 taneydi. O halde bu simülatördeki Q-Tablosu (64, 4)'lük bir NumPy dizisi olmalıdır. 

    - MsPacman oyununda ekrandaki resim 210X160 pixel çözünürlüğündedir. Her pixel RGB olarak 256x256x250'lık bir kombinasyondan olutuğuna 
    göre toplam olası pixel kombinasyonlarının sayısı 210 * 16* * 256 * 256 * 256 biçimindedir. Bu değer 563714457600 (beş yüz milyar civarı)
    farklı kombinasyon anlamına gelir. Yani Q-Tablosu çok büyüktür. Etmenin olası eylemlerinin sayısı da 9 tanedir. Tabii bu kadar büyük Q-Tablosunun 
    oluşturulması ve doldurulması çok zordur. Onun yerine "Deep Q-Learning" algoritması tercih edilir. 

    - Breakout (tuğla kırmaca) oyunu da MsPacman oyununda olduğu gibi bize 210x160'lık bir resim vermektedir. Olası durumların sayısı 
    MsPacman'de olduğu gibidir. Burada toplam hareketlerin sayısı 4 tanedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi Q-Tablosunun doldurulmasında kullanılan formül üzerinde duralım. Formül şyledir:

    Q(St, At) = Q(St, At) + alpha * (Rt + gamma * max(St+1, a) - Q(St, At))

    Buradaki terimlerin anlamlaı da şöyledir:

    Q(St, At): Belli bir t durumunda (yani Q tablosunun belli bir satırında) A eylemi yapılması durumu. Bu Q-Tablosunda St satırı ve 
    A sütununun kesiştiği hücreyi belirtir. Tablonun bu değeri güncellenecektir. Yani etmen belli bir durumdayken belli bir eylemi 
    yaptığında Q tablosunun o duruma ilişkin satırın o eyleme ilişkin sütunu güncellenmektedir. 

    alpha: [0, 1] aralığında "öğrenme hızını (learning rate)" temsil eden bir değerdir. Bu değer bir hyper parametredir. Uygulamacı tarafından 
    belirlenmektedir. 

    gamma: [0, 1] aralığında "indirim faktörü denen bir değerdir. Bu değer bir hyper parametredir. Uygulamacı tarafından 
    belirlenmektedir. 

    Rt: Etmen St durumundayken At eylemini yaptığında elde edeceği ödüldür. 

    max(St+1, a): Etmen St durumundayken At eylemini yaptığında St+1 durumuna geçecektir. Bu Q-Tablosunda St+1'e durumuna ilişkin bir 
    satırı temsil etmektedir. İşte bu satırdaki en büyük değer max(St+1, a) ile temsil edilmektedir. Burada etmen "bu eylem yapılırsa bir sonraki
    adımdaki en iyi eylem hangisi" diye bakmaktadır. Şüphesiz ilgili eylem yapıdlığındaki en iyi eylem de aslında benzer mantıkla oluşturulmuştur. 

    Formüldeki alpha ve gamma sabitlerini görmezden gelelim. Pekiyi bu formal bize ne anlatmaktadır? Formüldeki max(St+1, a) - Q(St, At) 
    çıkartma işlemi mevcut durum ile sonraki durum arasındaki iyileşme miktarını belirtmektedir. Etmen bir durumda bir eylem yaptığında 
    mevcut durumunu iyileştirmek ister. Yani örneğin iyi bir durumdan yüksek değerli ancak daha kötü bir duruma geçmek bir iyileştirme 
    anlamına gelmez. Aradaki fark iyileştirmeyi belirtmektedir. 

    Q-Tablosu baştan sıfırlarla doludur. Pekiyi tablo nasıl doldurulacaktır? Baştan her şey 0 olduğuna göre durumu sıfırlardan kurtaracak 
    şey ödül ya da cezadır. 

    Şimdi tablonun güncellenmesi üzerinde çalışma yapmak için aşağıdaki gibi bir oyun düşünelim:

    Gxx
    xxx
    xxx

    Burada amaç etmenin (0, 0) noktasındaki hedefe varmayı öğrenmesi olsun. Hedefe varan eyleme 1 puan ödül verelim. Varmayan eyleme de 
    0 puan verelim. Q Tablosu aşağıdaki gibi olacaktır (Left, Right, Up, Down):

            L   R   U   D
      S0    0   0   0   0
      S1    0   0   0   0
      S2    0   0   0   0
      S3    0   0   0   0
      S4    0   0   0   0
      S5    0   0   0   0
      S6    0   0   0   0
      S7    0   0   0   0
      S8    0   0   0   0

    Şimdi etmenin (0, 1) pozsiyonunda olduğunu düşünelim ve Sola hareket etmek istediğini varsayalım:

    GAx
    xxx
    xxx

    Etmenin durumu şu anda S1'dir. O halde tabloda güncellenecek hücre (S1, L ) hücresidir. Formülde alpha = 0.90, gamma = 1 alalım. 
    Formülde ilgili değerleri yerine koyalım:
    
    Q(S1, L) = Q(S1, L) + 0.90 * (1 + 1 * 0 - 0)

    Q(s1, L) = 0.90

    Şimdi Q tablosunda bir hücreyi güncellemiş olduk:

            L   R   U   D
      S0    0   0   0   0
      S1    0.9 0   0   0
      S2    0   0   0   0
      S3    0   0   0   0
      S4    0   0   0   0
      S5    0   0   0   0
      S6    0   0   0   0
      S7    0   0   0   0
      S8    0   0   0   0

    Şimdi etmenin (1, 1) durumunda olduğunu ve yukarı gitmek istediğini düşünelim. Etmen S4 durumundadır ve Yukarıya (Up) gitmek 
    istemektedir. 

    Gxx
    xAx
    xxx

    O halde Q tablosu şöyle güncellenecektir:

    Q(S4, U) = Q(S4, U) + 0.90 * (0 + 1 * 0.90 - 0)
    S(S4, U) = 0.81

    Şimdi Q-Tablosu şu duruma gelecektir:

            L    R    U    D
      S0    0    0    0    0
      S1    0.9  0    0    0
      S2    0    0    0    0
      S3    0    0    0    0
      S4    0    0    0.81 0
      S5    0    0    0    0
      S6    0    0    0    0
      S7    0    0    0    0
      S8    0    0    0    0

    Şimdi etmenin (2, 1) hücresinde olduğunu ve yukarı gitmek istediğini düşünelim:
    
    Gxx
    xxx
    xAx
     
    Konum olarak (2, 1) S7'dir. O halde güncellenecek hücre Q(S7, U) hücresidir. Q formülünde değerleri yerine koyalım:

    Q(S7, U) = Q(S7, U) + 0.90 * (0 + 1 * 0.81 - 0)
    Q(S7, U) = 0.729

    Q Tablosu şu hele gelecektir:

             L    R   U      D
      S0    0    0    0      0
      S1    0.9  0    0      0
      S2    0    0    0      0
      S3    0    0    0      0
      S4    0    0    0.81   0
      S5    0    0    0      0
      S6    0    0    0      0
      S7    0    0    0.729  0
      S8    0    0     0     0

    Burada görüldüğü gibi tablo yavaş eğitim sırasında doldurulmaktadır. Yani eğitim aslında Q-Tablosunun doldurulması anlamına gelmektedir. 
    Pekiyi şimdi etmenin S7'de olduğunu düşünelim ve etmenin hedefe varmak istediğini varsayalım. Bu durumda S7 satırındaki en yüksek değere
    bakılır. Bu değer 0.729'dur. Burada etmen yukarı hareket eder. etmen yukarı hareket edince S4 durumu oluşur. S4 durumundaki en
    iyi eylem yine yukarı gitmektir. Bu duurmda S1 durumuna geçilir. S1 durumundaki en iyi eylem sola gitmektir. Hedefe varılır. 

    Yani tablo dolduğunda etmen nerede olursa olsun hedefe varmak için en iyi eylemi artık öğrenmiştir. Pekiyi tablo nasıl doldurulacaktır?
    İşte işin başında tablo sıfırlarla dolu olduğuna göre aşağıdaki Q formül ü ancak bir ödül ya da ceza durumunda 0 dışı bir değer verebilir:

    Q(St, At) = Q(St, At) + alpha * (Rt + gamma * max(St+1, a) - Q(St, At))

    O halde ödül ya da ceza olmazsa bu öğrenme gerçekleşemez. 

#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Q_learning algoritmasında en önemli noktakardan biri ilk baştan itibaren eğitimin nasıl yapılacağının belirlenmesidir. 
    Biz bilmediğimiz bir bölgeyi nasıl öğreniriz? Önce rastgele sokaklara dalarız. Biraz oraları öğreniriz. Ondan sonra öğrenilmiş 
    yerleri de kullanarak biraz bildiğimiz yerlerden hareket ederek bilmediğimiz rastgele sokaklara gireriz. Gitgide bildiğimiz alanı 
    genişletiriz. Sürekli bildiğimiz yerlerde dolaşırsak etrafı iyi öğrenemeyiz. Sürekli rastgele yerlerde dolaşırsak sentezleme zorlaşır. 
    O halde biraz rastegele biraz da öğrenilmiş yerleri kullanma stratejisini uygularız. İşte aynı durum pekiştirmeli öğrenmede de 
    benzer biçimde uygulanmaktadır. Buna pekiştirmeli öğrenmede "keşif/işletme stratejisi (exploration/explotation strategy)" 
    denilmektedir. 
    
    Eğer bir bölgede hiçbir yeri bilmiyorsak önce rastgele yerlerde daha fazla dolaşırız. Sonra yavaş yavaş biraz bildiğimiz yerlerde
    biraz da rastgele yerlerde dolaşmaya çalışırız. Burada bazı keşif/işletme stratejileri üzerinde duracağız.

    Epsilon greedy denilen keşif/işletme stratejisinde bir epsilon değeri alınır. Sonra o epsilon değeri olasılığında keşif yapılır, 
    1 - epsilon olasılığında ise işletme yapılır. Bunu Python'da şöyle ifade edebiliriz:

    if np.random.uniform(0, 1) < EPSILON:
        # keşif
    else:
        # işletme

    Burada EPSILON değerinin 0.20 olduğunu varsayalım. np.random.uniform fonksiyonu [0, 1] aralığında rastgele bir sayı üretmektedir. 
    Bu sayı 0.2'den küçükse rastgele bir hareket yapılacak, büyükse zaten öğrenilmiş en iyi hareket yapılacaktır. Başka bir deyişle 
    etmen hangi konumdaysa %20 olasılıkla rastegele bir eylem yapacaktır. Örneğin birt satranç programını eğitecek olalım. Belli bir 
    pozisyonda %20 olasılıkla etmen rastgele bir hamle oynacaktır. Ancak %80 olasılıkla daha önce öğrendiği en iyi hamleyi 
    oynayacaktır. Tabii eğitim sırasında çok defalar bu işlemlerin yapılması gerekir. Örneğin:

    import numpy as np

    EPOCHS = 100
    EPSILON = 0.20

    for i in range(EPOCHS):
        if np.random.uniform() < EPSILON:
            print('Exploration')
        else:
            print('Explotation')
        
    Başlangıçta etmen bir şey bilmedieğine göre "işletme (explotation)" uygulamanın bir anlamı yoktur. O halde başlangıçta daha fazla
    keşif yapıp daha az işletme yapabiliriz. Sonra zamanla keşif olasılığını düşürüp işletme olasılığını yükseltebiliriz. Yani işin 
    başında etmen bir şey bilmediğine göre daha fazla keşif yapmalıdır. İşte yüksek bir keşif oranının giderek düşürülmesine 
    İngilizce "epsilon decay" denilmektedir. 

    Epsilon decay işlemi için en basit yöntemlerden biri keşfetme olasılığını her yinelemede oransal olarak düşürmektir. Ancak 
    eğitim sırasında keşfin de çok azalması iyi değildir. Keşif için minimum bir oran tutulabilir. Örneğin:

    import numpy as np

    EPOCHS = 200
    EPSILON = 0.20
    EPSILON_MIN = 0.20

    for i in range(EPOCHS):
        epsilon = max(1 - i / EPOCHS, EPSILON_MIN)
        if np.random.uniform() < epsilon:
            print('keşif')
        else:
            print('işletme')

    Burada keşif oranı başlangıçta çok yüksek tutulup yavaş yavaş düşürülmüştür. Ancak %20'den daha fazla düşürülmemiştir. 

    Epsilon düşürme işlemi döngü değişkeninin belli bir değerle çarparak da sağlanabilir. Örneğin:

    import numpy as np

    EPOCHS = 200
    DECAY_RATE = 0.99
    EPSILON_MIN = 0.20

    epsilon = 1
    for i in range(0, EPOCHS):
        epsilon = epsilon * DECAY_RATE
        epsilon = max(epsilon, EPSILON_MIN)

        if np.random.uniform() < epsilon:
            print('keşif')
        else:
            print('işletme')

    Burada 1 değeri her defasında DECAY_RATE (0.99) ile çarpılarak düşürülmüştür. Ancak yine %20 gibi bir orana gelindiğinde artık
    keşfin daha da düşürülmesi engellenmiştir. 

    Epsilon değerini düşürmek için üstel fonksiyonlar da yaygın kullanılmaktadır. Örneğin e ** (-M * i) gibi bir ifade 
    yüksek bir değerden gittikçe düşüm yapabilmektedir. Buradaki M sabit bir deeğerdir. Örneğin M değeri 0.01 gibi alınabilir:

    import numpy as np

    EPOCHS = 200
    M = 0.01
    EPSILON_MIN = 0.20

    for i in range(0, EPOCHS):
        epsilon = np.exp(-M * i)
        epsilon = max(epsilon, EPSILON_MIN)
        if np.random.uniform() < epsilon:
            print('keşif')
        else:
            print('işletme')

    Yine epsilon değerini azaltmak için ters karekök (inverse square root) yöntemi de kullanılabilmektedir. Bu yöntemde 

    1 / sqrt(1 + i * DECAY_RATE)

    biçiminde azaltım uygulanır. Örneğin:

    import numpy as np

    EPOCHS = 300
    DECAY_RATE = 0.08
    EPSILON_MIN = 0.20

    epsilon = 1
    for i in range(EPOCHS):
        epsilon = 1 / np.sqrt(1 + i * DECAY_RATE)
        epsilon = max(epsilon, EPSILON_MIN)
        print(epsilon)
-
#----------------------------------------------------------------------------------------------------------------------------
    Şimdi artık Q-Learning algoritmasını uygulayabilmek için pek çok şeyi öğrendik. Gerçekleştirimi Python'da nasıl yapabiliriz?
    Eğitimin bir fonksiyon tarafından yapılması, o fonksiyonun Q-Tablosunu oluşturup bize vermesi uygun olur. Böyle bir train 
    fonksiyonunun parametrik yapısı nasıl olmalıdır? Tabii Q-Learning algoritmasındaki hyper parametrelerin fonksiyona yansıtılması 
    gerekir. Fonksiyonun Gym çevre nesnesini (environment) alması da uygundur. Bunların dışında eğitimin kaç epoch süreceği, 
    bir epoch'ta eğer done koşulu sağlanmazsa maksimum kaç yineleme yapılacağı fonksiyona parametre olarak verilebilir. Örneğin:

    def train(env, alpha = 0.90, gamma = 1, epochs = 20000, max_iter = 1000):
        pass
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import gym

EPOCHS_DEF = 20000
MAX_ITER_DEF = 1000
ALPHA_DEF = 0.1
GAMMA_DEF = 0.6
EPSILON = 0.20

def train(env, alpha = ALPHA_DEF, gamma = GAMMA_DEF, epochs = EPOCHS_DEF, max_iter = MAX_ITER_DEF):
    qtable = np.zeros((env.observation_space.n, env.action_space.n))
    
    for _ in range(epochs):
        obs = env.reset()
        for i in range(max_iter):
            if np.random.uniform() < EPSILON:
                action = env.action_space.sample()
            else:
                action = np.argmax(qtable[obs])
                
            next_obs, reward, done, _ = env.step(action)
            
            qtable[obs, action] = qtable[obs, action] + alpha * (reward + gamma * np.max(qtable[next_obs]) - qtable[obs, action])
            obs = next_obs
            
            if done:
                break
    
    return qtable

import time

def execute(env, qtable):
    obs = env.reset()
    
    count = 0
    while True:
        print('\x1b[1J' + env.render(mode='ansi'), end='')
        
        action = np.argmax(qtable[obs])
        obs, reward, done, _ = env.step(action)
        if done:
            break
        count += 1
        time.sleep(0.5)
        
    return count

env = gym.make('Taxi-v3')
qtable = train(env)

count = execute(env, qtable)
print(count)

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıda epsilonunun çarpansal biçimde decay işlemiyle azaltılmasına ilişkin örnek verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import gym

EPOCHS_DEF = 20000
MAX_ITER_DEF = 1000
ALPHA_DEF = 0.1
GAMMA_DEF = 0.6
DECAY_RATE = 0.99
EPSILON_MIN = 0.20

def train(env, alpha = ALPHA_DEF, gamma = GAMMA_DEF, epochs = EPOCHS_DEF, max_iter = MAX_ITER_DEF):
    qtable = np.zeros((env.observation_space.n, env.action_space.n))
    
    epsilon = 1
    for _ in range(epochs):
        obs = env.reset()
        for i in range(max_iter):
            epsilon = epsilon * DECAY_RATE
            epsilon = max(epsilon, EPSILON_MIN)
            if np.random.uniform() < epsilon:
                action = env.action_space.sample()
            else:
                action = np.argmax(qtable[obs])
                
            next_obs, reward, done, _ = env.step(action)
            
            qtable[obs, action] = qtable[obs, action] + alpha * (reward + gamma * np.max(qtable[next_obs]) - qtable[obs, action])
            obs = next_obs
            
            if done:
                break
    
    return qtable

import time

def execute(env, qtable):
    obs = env.reset()
    
    count = 0
    while True:
        print('\x1b[1J' + env.render(mode='ansi'), end='')
        
        action = np.argmax(qtable[obs])
        obs, reward, done, _ = env.step(action)
        if done:
            break
        count += 1
        time.sleep(0.5)
        
    return count

env = gym.make('Taxi-v3')
qtable = train(env, epochs=10000)

count = execute(env, qtable)
print(count)

#----------------------------------------------------------------------------------------------------------------------------
    Frozen-Lake simülatöründe ödül mekanizmasında bir problem vardır. Anımsanacağı gibi bu simülatörde ödül olarak deliğe düşüldüğünde de 
    hedefe varılamadığında da 0 puan verilmekte hedefe varıldığında ise 1 puan verilmekteydi. Ödül mekanizmasının bu biçimde alınması 
    eğitimi zorlaştırmaktadır. Çünkü etmen deliğe düşmemeyi bu ödül mekanizmasıyla zor çok zor öğrenmektedir. Ödül mekanizmasının 
    kötü eylemlerde negatif biçimde azaltılması iyi eylemlerde pozitif biçimde yükseltilmesi önemlidir. Bu nedenle biz aşağıda 
    Frozen-Lake simülatöründe deliğe düşülmesi durumunda etmene yüksek bir ceza vereceğiz. Pekiyi deliğe düşmeyi nasl anlayacağız?
    İşte eğer done olmuşsa ve ödül de sıfırsa deliğie düşülmüş demektir. O halde biz aşağıdaki gibi bir kod parçasıyla ödül-ceza 
    puanlamasını daha iyi bir boyuta getirebiliriz:

    next_obs, reward, done, _ = env.step(action)
    
    if reward == 0:
        reward = -20 if done else -1

    Artık biizm ödül mekanizmamız şöyşedir: 
    
    - Deliğe düşülmesi durumunda -20 puan ceza
    - Deliğe düşülmeden hedefe varılmaması durumunda -1 puan ceza
    - Hedefe varılması durumunda +1 puan ödül

    Aşağıdaki programda Frozen-Lake simülatörü kayganlık özelliği kaldırılarak eğitilmiştir. Keşif/İşletme yöntemi 
    olarak en basit epsilon greedy yöntemi kullanılmıştır.            
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import gym

EPOCHS_DEF = 20000
MAX_ITER_DEF = 1000
ALPHA_DEF = 0.6
GAMMA_DEF = 0.9
EPSILON = 0.2

def train(env, alpha = ALPHA_DEF, gamma = GAMMA_DEF, epochs = EPOCHS_DEF, max_iter = MAX_ITER_DEF):
    qtable = np.zeros((env.observation_space.n, env.action_space.n))
    
    for _ in range(epochs):
        obs = env.reset()
        for i in range(max_iter):
           
            if np.random.uniform() < EPSILON:
                action = env.action_space.sample()
            else:
                action = np.argmax(qtable[obs])
                
            next_obs, reward, done, _ = env.step(action)
           
            if reward == 0:
                reward = -20 if done else -1
            
            qtable[obs, action] = qtable[obs, action] + alpha * (reward + gamma * np.max(qtable[next_obs]) - qtable[obs, action])
            obs = next_obs
            
            if done:
                break
    
    return qtable

import time

def execute(env, qtable):
    obs = env.reset()
    print('\x1b[1J' + env.render(mode='ansi'), end='')
    
    count = 0
    while True:       
        action = np.argmax(qtable[obs])
        obs, reward, done, _ = env.step(action)
        print('\x1b[1J' + env.render(mode='ansi'), end='')
        if done:
            break
        count += 1
        time.sleep(0.5)
        
    return count

env = gym.make('FrozenLake-v1', map_name='8x8', is_slippery=False)
qtable = train(env, epochs=10000)

count = execute(env, qtable)
print(count)

#----------------------------------------------------------------------------------------------------------------------------
    Anımsanacağı gibi Frozen-Lake simülatöründe etmen eğer zemin kaygansa (is_slippery=True ise) gitmek istediği yönüm dik yönlerine 
    1/3 olasılıkla yanlışlıkla gidebiliyordu. O halde etmenin bu modda çok daha akıllı davranması gerekmektedir. Örneğin:

    FFF
    HXF
    FFF

    Etmen X durumunda olsun. Artık etmenin sola girmeti, yukarı ve aşağı gitmesi tehlikelidir. Çünkü deliğe düşme olsaılığı vardır.
    O halde buarada en güvenli eylem sağa gitmektir. 

    Aşağıda simülatörün kayganlık özelliği aktive edilerek aynı örnek verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import gym

EPOCHS_DEF = 50000
MAX_ITER_DEF = 1000
ALPHA_DEF = 0.6
GAMMA_DEF = 0.9
EPSILON = 0.2

def train(env, alpha = ALPHA_DEF, gamma = GAMMA_DEF, epochs = EPOCHS_DEF, max_iter = MAX_ITER_DEF):
    qtable = np.zeros((env.observation_space.n, env.action_space.n))
    
    for _ in range(epochs):
        obs = env.reset()
        for i in range(max_iter):
            
            if np.random.uniform() < EPSILON:
                action = env.action_space.sample()
            else:
                action = np.argmax(qtable[obs])
                
            next_obs, reward, done, _ = env.step(action)
           
            if reward == 0:
                reward = -50 if done else -5
            
            qtable[obs, action] = qtable[obs, action] + alpha * (reward + gamma * np.max(qtable[next_obs]) - qtable[obs, action])
            obs = next_obs
            
            if done:
                break
    
    return qtable

import time

def execute(env, qtable):
    obs = env.reset()
    print('\x1b[1J' + env.render(mode='ansi'), end='')
    
    count = 0
    while True:       
        action = np.argmax(qtable[obs])
        obs, reward, done, _ = env.step(action)
        print('\x1b[1J' + env.render(mode='ansi'), end='')
        if done:
            break
        count += 1
        time.sleep(0.5)
        
    return count

env = gym.make('FrozenLake-v1', map_name='8x8', is_slippery=True)
qtable = train(env)

count = execute(env, qtable)
print(count)

#----------------------------------------------------------------------------------------------------------------------------
    CartPole simülatöründe anımsanacağı gibi bir araba ve arabanın üzerinde bir direk vardı. Amaç bu diğeri dik tutabilmekti.
    Simülatörde toplam iki eylem vardı: Rabanın motorunu sola çalıştırmak (0), ya da sağa çalıştırmak (1). Çevreye ilişkin 
    toplam dört gözlem değeri vardı: Arabanın konumu, arabanın hızı, diğreğin açısı ve direğin açısal hızı. Ancak bu simülatörde gözlem değerleri 
    sürekli değişkenlerdne oluşuyordu. Biz CartPole örneğini Q-Learning algoritmasıyla çözerken bu sürekli 4 gözlem bilgisini ayrık hale 
    getireceğiz. Tabii sürekli verileri ayrık hale getirirken ayrık durum sayısının iyi bir biçimde belirlenmesi gerekmektedir. 
    CartPole örneğinde şöyle bir problem de vardır: Gözlem değerlerinden arabanın minimum ve maksimum hızları, direğin minimum ve 
    maksimum açısal hızları [-sonsuz, +sonsuz] arasında değer almaktadır. Bu sonsuz değerleri ayrık hale getiremiyiz. Bizim bir biçimde 
    bu değerleri öncelikle -sonsuz, +sonsuz aralığından çıkartıp daha düşük bir aralığa hapsetmemiz gerekmektedir. ÖZet olarak bizim 
    CartPole örneğinde şu noktalara dikkat etmemiz gerekmektedir:

    - Sürekli verilen kaç parçaya ayrılarak ayrık hale getirileceği
    - Eğitimde uygulanacak tekrar (epoch) sayısı
    - Uygun bir epsilon decay işlemi 
    - Modelin alpha ve gamma hyper parametreleri

    Sürekli değerlerin ayrık hale hale getişrilmesinde oluşturulacak parça sayısı Q-Tablosunu büyütmektedir. Q-Tablosunun büyümesi ise
    daha uzun bir eğitimin gerekeceği anlamına gelmektedir. Bu durumda uygulanacak epsilon decay işlemi de daha önem kazanmaktadır. 

    Bu noktaların sezgisel olarak belirlenmesi kolay değildir. Bu tür pekiştirmeli öğrenme modellerinde deneme yanılma yöntemlerinin 
    uygulanması kaçınılmazdır. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import gym

EPOCHS_DEF = 150000
ALPHA_DEF = 0.5
GAMMA_DEF = 0.95
EPSILON = 0.2

DISCRETE_STATES = 40

def obs2states(env, obs):
    state_intervals = (env.observation_space.high - env.observation_space.low) / DISCRETE_STATES
    states = np.round((obs - env.observation_space.low) / state_intervals).astype(int)
    return np.clip(states, 0, DISCRETE_STATES - 1)
    
    return states
   
def train(env, alpha = ALPHA_DEF, gamma = GAMMA_DEF, epochs = EPOCHS_DEF, verbose=1):
    env.observation_space.low[1] = -10
    env.observation_space.low[3] = -10
    env.observation_space.high[1] = 10
    env.observation_space.high[3] = 10

    nactions = env.observation_space.shape[0]
    nobservations = env.action_space.n
                     
    qtable = np.zeros((DISCRETE_STATES, ) *  nactions + (nobservations, ))
    
    for i in range(epochs):
        if verbose == 1 and i % 1000 == 0:
            print(f'{i} ', end='')
        obs = env.reset()
        while True: 
            x, v, angle, vangle = obs2states(env, obs)
            if np.random.uniform() < EPSILON:
                action = env.action_space.sample()
            else:
                states = obs2states(env, obs)
                x, v, angle, vangle = states
                action = np.argmax(qtable[x, v, angle, vangle])
     
            next_obs, reward, done, _ = env.step(action)
            next_x, next_v, next_angle, next_vangle = obs2states(env, next_obs)
            
            qtable[x, v, angle, vangle, action] = qtable[next_x, next_v, next_angle, next_vangle, action] + alpha * (reward + gamma * np.max(qtable[next_x, next_v, next_angle, next_vangle]) - qtable[next_x, next_v, next_angle, next_vangle, action])
            obs = next_obs
            
            if done:
                break
    
    return qtable

import time

def execute(env, qtable):
    obs = env.reset()
    env.render()
    
    count = 0
    while True:       
        x, v, angle, vangle = obs2states(env, obs)
        
        action = np.argmax(qtable[x, v, angle, vangle])
        obs, reward, done, _ = env.step(action)
        env.render()
        if done:
            break
        count += 1
        time.sleep(0.1)        
        
    return count


env = gym.make('CartPole-v1')


qtable = train(env)

count = execute(env, qtable)
print(count)
env.close()

#----------------------------------------------------------------------------------------------------------------------------
    Anımsanacağı gibi MountainCar simülatöründe bir araba bir tepeyi aşmaya çalışıyordu. Burada üç eylem söz konusuydu: Motorun çağa
    çalıştırılması, motorun sola çalıştırılması ve motorun durdurulması. Bu similatörde iki gözlem değeri vardı: Arabanın konumu ve
    arabanın hızı. Ödül mekanizması ceza puanı üzerine oturtulmuştu. Yani hedefe varamayan her eyleme -1 puan veriliyordu.

    Bu örnekte de sürekli verilerin ayrık hale getirilmesi gerekmektedir. Aşağıda MountainCar örneği için bir çözüm verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np
import gym

EPOCHS_DEF = 20000
ALPHA_DEF = 0.60
GAMMA_DEF = 0.90
EPSILON = 0.2

DISCRETE_STATES = 80

def obs2states(env, obs):
    state_intervals = (env.observation_space.high - env.observation_space.low) / DISCRETE_STATES
    states = np.round((obs - env.observation_space.low) / state_intervals).astype(int)
    return np.clip(states, 0, DISCRETE_STATES - 1)
    
    return states
   
def train(env, alpha = ALPHA_DEF, gamma = GAMMA_DEF, epochs = EPOCHS_DEF, verbose=1):
    nactions = env.observation_space.shape[0]
    nobservations = env.action_space.n
                     
    qtable = np.zeros((DISCRETE_STATES, ) *  nactions + (nobservations, ))
    
    for i in range(epochs):
        if verbose == 1 and i % 1000 == 0:
            print(f'{i} ', end='')
        obs = env.reset()
        while True: 
            x, v = obs2states(env, obs)
            if np.random.uniform() < EPSILON:
                action = env.action_space.sample()
            else:
                states = obs2states(env, obs)
                x, v = states
                action = np.argmax(qtable[x, v])
     
            next_obs, reward, done, _ = env.step(action)
            next_x, next_v = obs2states(env, next_obs)
            
            qtable[x, v, action] = qtable[next_x, next_v, action] + alpha * (reward + gamma * np.max(qtable[next_x, next_v]) - qtable[next_x, next_v, action])
            obs = next_obs
            
            if done:
                break
    
    return qtable

import time

def execute(env, qtable):
    obs = env.reset()
    env.render()
    
    count = 0
    while True:       
        x, v = obs2states(env, obs)
        
        action = np.argmax(qtable[x, v])
        obs, reward, done, _ = env.step(action)
        env.render()
        if done:
            break
        count += 1
        time.sleep(0.1)        
        
    return count


env = gym.make('MountainCar-v0')


qtable = train(env)

count = execute(env, qtable)
print(count)
env.close()

#----------------------------------------------------------------------------------------------------------------------------
    Q-Learning algoritmasının en önemli handikapları şunlardır:

    - Q-Tablosunun çok büyük olduğu durumda tablonun doldurulması için gereken eğitim uzun bir zaman almaktadır.
    - Sürekli gözlem değerlerinin bulunduğu durumda bunların ayrık hale getirilmesi zahmetlidir ve bu işlem çok büyük 
    bir Q-Tablosunun oluşmasına yol açmaktadır.
    - Yönetmin bellek gereksinimi Q-Tablolarından dolayı fazladır. 
    - Gözlem değerlerinin çok fazla olması durumunda yöntemin performansı düşmektedir. 

    İşte Q-Learning algoritmasının bu dezavantajlarını ortadan kaldırmak için "deep Q-Learning" denilen yöntem kullanılmaktadır. 
    Deep Q-Learning yöntemi nispeten yeni bir yöntemdir. Yöntem hakkında temel çalışmalar yaklaşık 10 sene önce başlamıştır. Kısa 
    zaman içerisinde hızlı bir ilerleme sağlanmıştır. Deep Q-Learning yönteminin ana noktaları şunlardır:

    - Q-Tablosu sütunlarında eylemlerin satırlarında durumların bulundupu bir tabloydu. Biz de belli bir durumdaki satırın en yüksek 
    Q değerine sahip sütunundaki eylemi tercih ediyorduk. İşte bir satırın en iyi Q değerinin bulunması için geniş bir Q-Tablosu oluşturmak yerine
    bunu bir kestirim problemi haline getirip bu kestirim sinir ağına yaptırılmaktadır. Bu durumda oluşturulacak sinir ağının girdileri 
    gözlem bilgilerinden oluşacak çıktıları ise Q-Tablosundaki eylemlerin Q değerlerinden oluşacaktır. Başka bir deyişle bir sinir ağına 
    satır bilgisini verdiğimizde ağ bize sütun bilgisini verecektir. 

    - Durumlardan Q değerlerinin elde edilmesinin sinir ağına devredilmediyse biz sürekli olguları ayrık hale getirme zorunluluğundan 
    kurtulmuş oluruz. Çünkü biz sinir ağı ile lojistik olmayan bir regresyon problemini çözmüş olmaktayız.

    - Durumlardan Q değerlerinin sinir ağı ile kesitirilmesi sayesinde yöntem daha ölçeklenebilir (scalable) hale gelmektedir. 

    - Yöntemin sinir ağının oluşturulması dışındaki diğer kısımları daha önce yaptığımız gibi yürütülmektedir. 

    - Yöntemde sinir ağı üzerinde çalışılan probleme göre çeşitli biçimlerde oluşturulabilmektedir. Örneğin CartPole örneği için 
    sinir ağı şöyle oluşturulabilir:

    model = Sequential(name='Cartpole-DeepLearning')
    model.add(Dense(64, activation='relu', input_dim=env.observation_space.shape[0], name='Dense-1'))
    model.add(Dense(64, activation='relu', name='Dense-2'))
    model.add(Dense(env.action_space.n, activation='linear', name='Output'))
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])

    Burada ağda bir girdi katmanı iki saklı katman ve bir de çıktı katmanı bulunmaktadır. Girdi katmanındaki möron sayısının 
    env.observation_space.shape[0] kadar olduğuna dikkat ediniz. Yani girdi katmanındaki nöron sayısı durum bilgisini belirten
    gözlem uzayı kadardır. (Yani örneğim CatrPole similatörü için 4, MountainCar simülatörü için 2). Modelin çıktı katanında 
    toplam env.action_space.n tane nöronun bulunduğuna dikkat ediniz. Yani model bize her eylem için Q değerlerini verecektir. 
    Tabii buradaki sinir ağı mimarisi problemin biçimine göre değişecektir. Örneğin bir Atari oyunununda görüntü işleme söz konusu olduğuna 
    göre ona göre evrişimli ve çok katmanlı bir ağ kullanılmalıdır. 

    - Yönetmin en önemli noktalarından biri sinir ağının nasıl eğitileceğidir. Biz bir durum bilgisinden hareketle Q formülünü 
    uygulayarak bir değer elde ediyorduk. Bu değeri de Q tablosunun ilgili satır ve sütununa kaydediyorduk. İşte eğitim yapılırken 
    ismine "replay buffer" denilen bir veri yapısı kullanılır. Etmene eylem yaptırılıp bunun sonuçları ve ödülleri bu replay buffer 
    içerisine kaydedilir. Bu replay buffer veri yapısının elemanları aşağıdaki gibi demetlerden oluşmaktadır:

    (state, action, reward, next_state)

    Burada o anda etmenin için bulunduğu durum demetin "state" elemanı ile temsil edilmiştir. Etmenin o durumda yaptığı eylem "action" 
    ile temsil edilmiştir. Demetin "reward" ile temsil edilen üçüncü elemanı etmenin bu eylemi yaptığındaki elde ettiği ödülü 
    belirtmektedir. Nihayet demetin son "next_state" elemanı eylemden sonra oluşacak yeni durumu belirtir. Bizim Q formülünü uygulayabilmemiz için 
    bu bilgilere gereksinimiz vardır. Buradaki relay buffer son n tane değeri tutabilecek bir veri yapısı biçiminde tasarlanmalıdır. 
    Bunun için Python standart kütüphanesindeki collections modülünde bulunan deque (double-ended-queue) sınıfından faydalanılabilir. Yönetmde 
    replay buffer oluşturulduktan sonra bunun içerisinden rastgele k tane eleman seçilir. Sonra bu elemanlar ağın eğitiminde kullanılır. 

    Deep Q-Learning yönteminin tipik gerçekleştirimi maddeler haline şöyledir:

    1) Probleme uygun bir sinir ağı modeli oluşturulur.

    2) Bir replay buffer oluşturulur. Bu buffer son n tane "durum, eylem, ödül ve sonraki durumdan" oluşan bir veri yapısıdır. Yani bu veri yapısı 
    n tane aşağıdaki gibi demetlerden oluşmaktadır:

    (state, action, reward, next_state)

    Bu replay buffer "son n tane elemanı tutacak biçimde" organize edilir. Bunun için yukarıda da belirttiğimiz gibi deque sınıfı 
    kullanılabilir.
    
    3) Bir epoch döngüsü oluşturulur. Bu epoch döngüsü içerisinde etmene eylemler yaptırılır. Bu eylemlerden elde edilen bilgiler 
    yukarıda belirtildiği gibi replay buffer içerisinde saklanır. 

    4) Bu replay buffer'dan "BATCH_SIZE < n" kadar rastgele eleman seçilir. Bu elemanlar sinir ağını eğitmekte kullanılır. 
    Burada eğitim sırasında gereksinim duyulacak y değerleri (yani Q değerleri) Q formülünden elde edilir. Ancak Q formülü uygulanırken
    sonraki durumun en yüksek Q değerine gereksinim duyulmaktadır. İşte bu değer de sinir ağından kestirim yoluyla elde edilebilmektedir. 
    
    Aşağıda Carpole simülatrörü için bir Deep Q Learning (DQN) örneği verilmiştir. Bu tür DQN uygulamalarında eğitim oldukça 
    uzun zaman almaktadır.     
#----------------------------------------------------------------------------------------------------------------------------

import random
import time
import collections
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

DEF_EPOCHS = 1000
DEF_BATCH_SIZE = 32
DEF_BUFFER_SIZE = 200
EPSILON = 0.20

EPSILON_INIT = 0.95
EPSILON_MIN = 0.20
DECAY_RATE = 0.95

ALPHA = 0.01
GAMMA = 0.95

def train(env, epochs = DEF_EPOCHS, batch_size=DEF_BATCH_SIZE, buffer_size = DEF_BUFFER_SIZE, verbose=1):
    model = Sequential(name='Cartpole-DeepLearning')
    model.add(Dense(64, activation='relu', input_dim=env.observation_space.shape[0], name='Dense-1'))
    model.add(Dense(64, activation='relu', name='Dense-2'))
    model.add(Dense(env.action_space.n, activation='linear', name='Output'))
    model.summary()
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    
    deq = collections.deque(maxlen=buffer_size)
    
    epsilon = EPSILON_INIT
    for i in range(epochs):
        if verbose == 1:
            print(f'{i} ')
        
        obs = env.reset()

        while True:
            if np.random.uniform() < epsilon:
                action = env.action_space.sample()
            else:
                qvalues = model.predict(obs.reshape(1, -1))[0]
                action = np.argmax(qvalues)
                
            obs_next, reward, done, _ = env.step(action)
            deq.append((obs, action, reward, obs_next))
        
            if len(deq) > batch_size:
                sample = random.sample(deq, batch_size)
                batch_x = np.zeros((batch_size, env.observation_space.shape[0]))
                batch_y = np.zeros((batch_size, env.action_space.n)) 
                for index, (obs_s, action_s, reward_s, obs_next_s) in enumerate(sample):
                    qvals = model.predict(obs_next_s.reshape(1, -1))
                    next_max_qval =  np.max(qvals[0])
                    print(next_max_qval )
                    target_qvals = ALPHA * (reward_s + GAMMA * next_max_qval)
                    qvals[0, action_s] = target_qvals
                    
                    batch_x[index] = obs_s
                    batch_y[index] = qvals
                
                model.fit(batch_x, batch_y, batch_size=batch_size, epochs=1, verbose=0)
                
            obs = obs_next
                
            if done:
                break
        
        epsilon *= DECAY_RATE
        epsilon = np.max([epsilon, EPSILON_MIN])    
    
    return model

def execute(env, model):
    obs = env.reset()    

    while True:
        env.render()
        action = np.argmax(model.predict(obs.reshape(1, -1))[0])
        obs, reward, done, _ = env.step(action)
        if done:
            break   
        time.sleep(0.5)    
        
    env.close()    

import gym

env = gym.make('CartPole-v1')
model = train(env)
execute(env, model)

#----------------------------------------------------------------------------------------------------------------------------

import random
import time
import collections
import numpy as np
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

DEF_EPOCHS = 1000
DEF_BATCH_SIZE = 32
DEF_BUFFER_SIZE = 200
EPSILON = 0.20

EPSILON_INIT = 0.95
EPSILON_MIN = 0.20
DECAY_RATE = 0.95

ALPHA = 0.01
GAMMA = 0.95

def train(env, epochs = DEF_EPOCHS, batch_size=DEF_BATCH_SIZE, buffer_size = DEF_BUFFER_SIZE, verbose=1):
    model = Sequential(name='Cartpole-DeepLearning')
    model.add(Dense(64, activation='relu', input_dim=env.observation_space.shape[0], name='Dense-1'))
    model.add(Dense(64, activation='relu', name='Dense-2'))
    model.add(Dense(env.action_space.n, activation='linear', name='Output'))
    model.summary()
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    
    deq = collections.deque(maxlen=buffer_size)
    
    epsilon = EPSILON_INIT
    for i in range(epochs):
        if verbose == 1:
            print(f'{i} ')
        
        obs = env.reset()

        while True:
            if np.random.uniform() < epsilon:
                action = env.action_space.sample()
            else:
                qvalues = model.predict(obs.reshape(1, -1))[0]
                action = np.argmax(qvalues)
                
            obs_next, reward, done, _ = env.step(action)
            deq.append((obs, action, reward, obs_next))
        
            if len(deq) > batch_size:
                sample = random.sample(deq, batch_size)
                batch_x = np.zeros((batch_size, env.observation_space.shape[0]))
                batch_y = np.zeros((batch_size, env.action_space.n)) 
                for index, (obs_s, action_s, reward_s, obs_next_s) in enumerate(sample):
                    qvals = model.predict(obs_next_s.reshape(1, -1))
                    next_max_qval =  np.max(qvals[0])
                    print(next_max_qval )
                    target_qvals = ALPHA * (reward_s + GAMMA * next_max_qval)
                    qvals[0, action_s] = target_qvals
                    
                    batch_x[index] = obs_s
                    batch_y[index] = qvals
                
                model.fit(batch_x, batch_y, batch_size=batch_size, epochs=1, verbose=0)
                
            obs = obs_next
                
            if done:
                break
        
        epsilon *= DECAY_RATE
        epsilon = np.max([epsilon, EPSILON_MIN])    
    
    return model

def execute(env, model):
    obs = env.reset()    

    while True:
        env.render()
        action = np.argmax(model.predict(obs.reshape(1, -1))[0])
        obs, reward, done, _ = env.step(action)
        if done:
            break   
        time.sleep(0.5)    
        
    env.close()    

import gym

env = gym.make('CartPole-v1')
model = train(env)
execute(env, model)

#----------------------------------------------------------------------------------------------------------------------------
    Bizim yukarıda uyguladığımız "deep reinforcement learning" yöntemine "değer tabanlı (value based)"  yöntemler denilmektedir. 
    Genellikle bu yöntemler DQN (Deep Q Learning) olarak bilinmektedir. Biz bu yöntemlerde en iyi q değerlerini tahmin edecek 
    bir sinir ağı oluşturmaya çalıştık. Halbuki son 10 yıldır bu yöntemin çeşitli problemlerini ortadan kaldırmak için "policy gradient" 
    denilen yeni yöntemler gelişirilmiştir. Bu policy gradient yöntemler çeşitli alt gruplara ayrılmaktadır. Biz kursumuzda bu 
    yöntemlerin algoritmik yapıları üzerinde durmayacağız. Ancak bazı automated pekiştirmeli öğrenme kütüphaneleri üzerinde 
    bu yöntemleri uygulayacağız. 

    DQN yöntemleriyle son 10 senedir geliştirilmiş olan policy gradient yöntemler arasındaki temel farlılıklar şınlardır:

    - DQN yöntemi en iyi Q değerlerinin bulunmaısnı hedeflemektedir. Ancal Policy Gradient yöntemler doğrudan en iyi eylemin belirlenmesini 
    hedeflemektedir Yani DQN yönteminde Q değerlerinden hareketle en iyi eylem tespit edilmeye çalışılırken Policy Gradient 
    yöntemlerde doğrudan en iyi eylkemklerin tepsit edilmeye çalışmaktadır. 

    - DQN yöntemi ayrık eylemlerin söz konusu olduğu durumlarda kullanılırken Policy Gradient yöntemler süreki eylemlerin 
    söz konusu olduğu durumlarda tercih edilmektedir. 

    Son 10 yıldır geliştirilmiş olan Policy Gradient yöntemlerden önemli olanları şunlardır:

    - Vanilla Policy Gradient (VPG)
    - Trust Region Policy Optimization (TRPO)
    - Proximal Policy Optimization (PPO)
    - Actor-Critic Methods
    - Asynchronous Actor-Critic (A2C)
    - Asynchronous Advantage Actor-Critic (A3C)
    - Natural Policy Gradient (NPG)
    - Trust-PCL

    Tabii bu yöntemlerin hepsi yapay sinir ağı içermektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Yüksek seviyeli pekiştirmeli öğrenme kütüphanelerinin en önemlilerinden biri OpenAI kurumunun (ChatGPT'yi geliştiren kurum)
    oluşturduğu "Stable Baselines" isimli kütüpahnedir. OpenAI bu kütüphaneyi geliştirmiş olmakla birlikte artık yeni sürümlerini
    geliştirmeyi bırakmıştır. Stable Baselines kütüphanesinin en yeni versiyonu 3 versiyonudur. Kütüphane 3'lü versiyonlara kadar
    Tensorflow kütüphanesi kullanılarak geliştirilmiştir. 3 versiyonuyla birlikte taban kütüphane olarak PyTorch kütüphanesi kullanılmaya başlanmıştır. 

    Kütüphanenin 3 versiyonu aşağıdaki gibi kurulabilir:

    pip install stable-baselines3

    Kütüphaneyi kullanırken bazı parametreler bazı başka kütüphanelerin kurulumunu gerektirebilmektedir. Bu yardımcı kütüphanelerin 
    kurulması aşağıdakigibi yapılabilir:

    pip install stable-baselines3[extra]

    Kütüphanenin 3 versiyonun dokümantasyonuna aşağıdaki bağlantıdan erişebilirsiniz:

    https://stable-baselines3.readthedocs.io/en/master/
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Stable Baselines kütüphanesi tüm problemlerin gym simülatörleri gibi ifade edildiği varsayımıyla gerçekleştirilmiştir. 
    Yani bizim Stable baselines kütüphanesini "gym" ile birlikte kullanmamız gerekmektedir. Tabii kendimize özgü pekiştirmeli öğrenme 
    problemlerini çözmek için bizim problememizi "gym" ortamı gibi oluşturmamız gerekmektedir. Başka bir deyişle uygulamacı kendi 
    problemi için "custom environment" oluşturması gerekmektedir. 

    Programcı bir gym ortamı oluşturduktan sonra kullancağı pekiştirmeli öğrenme algoritmasını belirlemesi gerekir. Bu algoritmaların 
    çoğu "Policy Gradient" denilen son 10 senedir geliştirilen algoritmalardır. Kullanılacak algoritma isimsel olarak da belitirlebilir, 
    sınıf nesnesi olarak da belirtilebilir. Örneğin aşağıdaki algoritmalara ilişkin sınıflar hazır biçimde bulunmaktadır:

    A2C
    DDPG
    DQN
    HER
    PPO
    SAC
    TD3

    Bu algoritmaların hepsi gene olmakla birlikte bazı algoritmalar bazı problemler için daha uygun olmaktadır. Programcı bir algoritma seçip 
    o algoritmaya ilişkin bir sınıf nesnesi yaratır. Buna model nesnesi diyebiliriz. Eğitim işlemi bu model nesnelerinin learn isimli metotlarıyla 
    yapılmaktadır. Eğitim bittikten sonra model sınıfının predict metodu ile durum bilgisi metoda verilerek o durumda uygulanacak eylem 
    metottan elde edilir. Model sınıflarının save metotları eğitimden oluşan bilgiyi diske save etmek için load isimli metotları da bunları 
    yüklemek için kullanılmaktadır. Özetle kütüphanenin kullanılması için sırasıyla şu işlemler yapılmalıdır:

    1) Öncelikle gym similatör nesnesi (gym environmet) oluşturulur.

    2) Algoritma belirlenir ve algoritması nesnesi yaratılır. Algoritma nesnelerine model nesmneleri de diyebiliriz. 

    3) Eğitim model nesnelerinin learn metoduyle yapılmaktadır. 

    4) Artık belli bir durumda hangi eylemin yapılacağını belirlemek için model sınıflarının predict metotları kullanılır. 

    5) Eğitim bilgilerinin save edilmesi için model sınıflarının save metodu geri yüklemek için ise load metotları kullanılmaktadır.

#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi CartPole similatörünü Stable Baselines kütüphanesi ile çözmeye çalışalım. İlk aşamada bizim gym similatör nesnesini 
    yaratmamız gerekir. Örneğin:

    import gym

    env = gym.make('CartPole-v0')

    Bundan sonra kullanılacak algoritma seçilir. Burada DQN algoirmasını seçecek olalım. DQN yukarıda analltığımız "value based"
    Deep Q Learning algoritmasını uygulamaktadır. DQN sınıfının __init__ metodunun pek çok parametresi vardır:

    class stable_baselines3.dqn.DQN(policy, env, learning_rate=0.0001, buffer_size=1000000, learning_starts=50000, 
            batch_size=32, tau=1.0, gamma=0.99, train_freq=4, gradient_steps=1, replay_buffer_class=None, 
            replay_buffer_kwargs=None, optimize_memory_usage=False, target_update_interval=10000, 
            exploration_fraction=0.1, exploration_initial_eps=1.0, exploration_final_eps=0.05, 
            max_grad_norm=10, stats_window_size=100, tensorboard_log=None, 
            policy_kwargs=None, verbose=0, seed=None, device='auto', _init_setup_model=True)

    Burada metodun policy parametresi kullanılacak sinir ağı mimarisini belirtmektedir. Bu mimari basit regresyon modelleri için "MlpPolicy"
    olarak resimsel işlemler için (örneğin Atari oyunlarında olduğu gibi) "CnnPolicy", Çok girişli işlemleri için MultiInputPolicy biçiminde 
    olabilmektedir. Metodun ikinci parametresi gym simülatörünü almaktadır. Diğer parametreler "Deep Reinforcemt Q Learning" algoritmasında kullanılan
    parametrelerdir. Tabii bu parametreler default değerlerle geçilebilir. Örneğin:

    from stable_baselines3.dqn import DQN

    model = DQN('MlpPolicy', env)

    Artık eğitime aşamasına geçebiliriz. Yuklarıda da belirtidliği gibi eğitim model sınıflarının learn metotlarıyla yapılmaktadır. DQN sınıfının 
    learn metodunun parametrik yapısı şöyledir:

    learn(total_timesteps, callback=None, log_interval=4, tb_log_name='DQN', reset_num_timesteps=True, progress_bar=False

    Metodun birinci parametresi similatörün eğitim sırasında kaç kere step yapılacağını belirtmektedir. Bu parametre ne kadar 
    büyük geçilirse o kadar iyi bir sonuç elde edilir ancak eğitim zamanı da uzamaktadır. Örneğin:

    model.learn(1000000)

    Artık eğitim tamamlanmıştır. Biz kestirimlerde bulunup similatöre işlemler yaptırabiliriz. predict metodunun parametrik yapısı şöyledir:

    predict(observation, state=None, episode_start=None, deterministic=False

    Metot bize uygulanacak eylemi ve oluşacak yeni durumu vermektedir. Biz genellikle yalnızca eylem ile ilgileniriz. 

    Aşağıda CrtPole simülatörünün DQN ile çözümüne ilişkin bir örnek verilmiştir. Genel olarak DQN yöntemi bu tür oproblemlerde 
    Policy Gradient yöntemlerine göre daha düşük başarı sağlamaktadır. DQN yönteminde eğitim adımlarının yüksek tutulması ile 
    iyileşme sağlanmaktadır. Aşağıdaki örnekte CartPole için 500000 adım düşük bir eğitim sağlamaktadır. 
 #----------------------------------------------------------------------------------------------------------------------------

 import gym

    env = gym.make('CartPole-v1')

    from stable_baselines3.dqn import DQN

    model = DQN('MlpPolicy', env)

    model.learn(500000)

    obs = env.reset()

    import time

    count = 0
    while True:
        action, _ = model.predict(obs)
        obs, reward, done, _ = env.step(action)
        env.render()
        time.sleep(0.5)
        count += 1
        if done:
            break
        
    env.close()

    print(f'Total count: {count}')

#----------------------------------------------------------------------------------------------------------------------------
    Stable Baselines kütüphanesindeki A2C (Asycnchronous Actor Critic) algoritması pek çok durumda DQN'den daha iyi sonuç verme eğiliminbdedir. 
    Örneğin CartPole simülatöründe A2C açık bir biçimde DQN algoritmasında iyi bir sonuç vermektedir. A2C sınıfının __init__ metodunun 
    parametrik yapısı şöyledir:

    classstable_baselines3.a2c.A2C(policy, env, learning_rate=0.0007, n_steps=5, gamma=0.99, gae_lambda=1.0, ent_coef=0.0, 
            vf_coef=0.5, max_grad_norm=0.5, rms_prop_eps=1e-05, use_rms_prop=True, use_sde=False, sde_sample_freq=-1, 
            normalize_advantage=False, stats_window_size=100, tensorboard_log=None, policy_kwargs=None, verbose=0, 
            seed=None, device='auto', _init_setup_model=True)

    Yine metodun ilk parametresi sırasıyla uygulanacak yapay sinir ağının mimarisini ve gym simülatör nesnesini almaktadır. Yine bu parametre 
    normal uygulamakar için "MlpPolicy"  olarak resimsel işlemler için (örneğin Atari oyunlarında olduğu gibi) "CnnPolicy", çok girişli işlemleri 
    için MultiInputPolicy biçiminde olabilmektedir. Diğer parametreler A2C algoritmasında hyper parametrelerdir. 

    Aşağıdaki örnekte CartPole simülatörü 250000 adım için A2C algoritmasıyla eğitilmiştir. A2C algoritması 250000 adım için
    tam başarıyı elde etmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import gym

env = gym.make('CartPole-v1')

from stable_baselines3.a2c import A2C

model = A2C('MlpPolicy', env)

model.learn(250000)

obs = env.reset()

count = 0
while True:
    action, _ = model.predict(obs)
    obs, reward, done, _ = env.step(action)
    env.render()
    count += 1
    if done:
        break

    
env.close()

print(f'Total count: {count}')

#----------------------------------------------------------------------------------------------------------------------------
    PPO (Proximal Policy Optimization) isimli algoritma en yeni algoritmalardan biridir. Bu algoritma da Policy Gradient
    denilen sınıftandır. Sınıfının __init__ metodunun parametrik yapısı şöyledir:
    
    classstable_baselines3.ppo.PPO(policy, env, learning_rate=0.0003, n_steps=2048, batch_size=64, n_epochs=10, gamma=0.99, 
        gae_lambda=0.95, clip_range=0.2, clip_range_vf=None, normalize_advantage=True, ent_coef=0.0, vf_coef=0.5, 
        max_grad_norm=0.5, use_sde=False, sde_sample_freq=-1, target_kl=None, stats_window_size=100, tensorboard_log=None, 
        policy_kwargs=None, verbose=0, seed=None, device='auto', _init_setup_model=True)

    Yine sınıfın ilk paranetresi aynı anlamdadır. Diğer parametreler algoritmanın hyper parametreleridir.     

    PPO yöntemi pek çok uygulamada A2C ve ve DQN yöntemlerinden daha iyi sonuç vermektedir. Bu durum CartPole simülatöründe de 
    açıkça göerülmektedir. 

    Aşağıda CarPole simülatörüne PPO algoritması uygulanmıştır. 50000 adım bile problemi çözmeye yetmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import gym

env = gym.make('CartPole-v1')

from stable_baselines3.ppo import PPO

model = PPO('MlpPolicy', env)

model.learn(50000)

obs = env.reset()

count = 0
while True:
    action, _ = model.predict(obs)
    obs, reward, done, _ = env.step(action)
    env.render()
    count += 1
    if done:
        break
    
env.close()

print(f'Total count: {count}')

#----------------------------------------------------------------------------------------------------------------------------
    Aşağıda MounCar simülatörü PPO algoritmasıyla çözlümeye çalışılmıştır. Ancak PPO algoritmasındaki default epoch 10'dur. 
    Bu epoch miktarı MountainCar için yetersiz kalmaktadır. Aynı zamanda bu simülatörde learning_rate de büyütülürse hedefe 
    daha hızlı varılabilmektedir. 

    Bu tür problemlerde default parametrelerle arzu edilen sonuç elde edilemiyorsa hyper parametrelerle oynak gerekir. 
    En önemli hyper parametreler şüphesiz n_epochs, learning_rate ve learn metodundaki adım sayısıdır. 
#----------------------------------------------------------------------------------------------------------------------------

import gym

env = gym.make('MountainCar-v0')

from stable_baselines3.ppo import PPO

model = PPO('MlpPolicy', env, learning_rate=0.01, n_epochs=50)

model.learn(50000)

obs = env.reset()

count = 0
while True:
    action, _ = model.predict(obs)
    obs, reward, done, _ = env.step(action)
    env.render()
    count += 1
    if done:
        break
    
env.close()

print(f'Total count: {count}')

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de ayrık durumlardan ve eylemlerden oluşan Taxi simülatörünü Stable Baselines ile çözöeye çalışalım. Ayrık olaylar için 
    en iyi algoritmalardan biri DQN'dir. Ancak burada da hyper parametrelerin probleme özgü biçimde iyi ayarlnamaıs gerekebilir. 
    Aşağıda Taxi simülatörü DQN ile çözülmüştür.
#----------------------------------------------------------------------------------------------------------------------------

import gym
from stable_baselines3 import DQN

env = gym.make('Taxi-v3')

model = DQN('MlpPolicy', env, exploration_fraction=0.01, learning_rate=0.001, buffer_size=50000)
model.learn(total_timesteps=1000000)

import time

obs = env.reset()
while True:
    action, _ = model.predict(obs)
    obs, reward, done, _ = env.step(int(action))
    if done:
        break
    print( '\x1b[1J' + env.render(mode='ansi'))
    time.sleep(0.2)
    
env.close()
    
model.save('taxi.model')
del model
model = DQN.load('taxi.model')

obs = env.reset()
while True:
    action, _ = model.predict(obs)
    obs, reward, done, _ = env.step(int(action))
    if done:
        break
    print( '\x1b[1J' + env.render(mode='ansi'))
    time.sleep(0.2)
    
env.close()

#----------------------------------------------------------------------------------------------------------------------------
    Aslında Stable Baselines'ın algoritmaları aynı anda bireden fazla simülatör ile paralel bir biçimde eğitim yapabilmektedir. 
    Yani ilgili Algoritma sınıflarının env parametreleri aslında bir grup simülatör nesnesinden de oluşabilmektedir. Bu amaçla bir grup similatör nesnesi
    oluşturmak için make_vec_env isimli bir fonksiyon kullanılmaktadır. Fonksiyonun parametrik yapısı şöyledir:

    stable_baselines3.common.env_util.make_vec_env(env_id, n_envs=1, seed=None, start_index=0, monitor_dir=None,
        wrapper_class=None, env_kwargs=None, vec_env_cls=None, 
        vec_env_kwargs=None, monitor_kwargs=None, wrapper_kwargs=None)

    Fonksiyonun birinci parametresi simülatör nesnesini ikinci parametresi ise oluşturulacak simülatör nesne sayılarınıo belirtmektedir. 
    Bu fonksiyonun geri döndürdüğü nesne doğrudan algorima sınıflarında kullanılabilmektedir. 

#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirttiğimiz gibi Stable Baselines kütüphanesi "gym" simülatör (environment) sistemi üzerine oturtulmuştur. 
    Uygulamacının kendilerine ilişkin uygulamalarını yapabilmeleri için karşılaştıkları problemleri gym simülatörü gibi 
    ifade edebilmeleri gerekmektedir. Buna "gym için custom  simülatör (environment)" yazımı denilmektedir.. Custom simülatör (environment) 
    yazımı şu adımlardan geçilerek yapılmaktadır:

    1) gym.Env sınıfından bir sınıf türetilir. Örneğin:

    from gym import Env

    class MyEnv(Env):
        pass

    2) Programcının bu türemiş sınıf için bazı elemanları yazması gerekmektedir. Programcının minimal olarak oluşturması gereken 
    elemanlar şunlardır:

        - observation_space isimli örnek özniteliği
        - action_space isimli örnek özniteliği
        - reset metodu
        - step metodu
        - render metodu (zorunlu değil)
        - close metodu (zorunlu değildir)

    observation_space örnek özniteliği simülatörümüzün içinde bulunduğu durumun maksimum ve minimum değerlerini vermektedir. 
    Eğer simülatörün durum bilgileri sürekli ise (MounCar, CartPole simülatörlerinde olduğu gibi) bu observation_space 
    örnek özniteliği Box denilen bir sınıf türünden olmalıdır. Eğer simülatörümüzün durum bilgileri ayrık ise (Taxi, FrozenLake simülatörlerinde olduğu 
    gibi= bu durumda bu örnek özniteliği Discrete isimli bir sınıf türünden olmak zorundadır. 

    Box nesnesi oluşturulurken low ve high parametrelerine durum bilgisinin en düşük ve en yüksek değerleri girilir. Eğer durum bilgisi 
    birden fazla bilgiden oluşuyorsa ve bu bilgilerinin hepsinin en düşük ve en yüksek değerleri aynı ise bu durumda Box nesnesi 
    shape belirtilerek kolay bir biçimde oluşturulabilmektedir. Örneğin:

    Box(low=-1.0, high=2.0, shape=(3, 4), dtype=np.float32)

    Burada toplam 3x4'lük 12 tane durumsal bilginin olduğunu bunların hespnin en düşük değerlerinin -1.0, en yüksek değerlerinin 2.0 
    olduğunu anlamaktayız. Bu örnekte tüm durumsal bilgilerin low ve high değerleri aynıdır. Ancak bunlar farklı ise bizim 
    bu low ve high değerlerini bir liste biçiminde tel tek belirtmemiz gerekir. Tabii bu durumda artık shape parametresinin bir anlamı 
    kalmamaktadır. Örneğin:

    Box(low=np.array([-1.0, -2.0]), high=np.array([2.0, 4.0]), dtype=np.float32)

    Burada iki tane durum bilgisinin olduğunu bunların en küçük değerlerinin [-1.0, -20.0] ve en yüksek değerlerinin [2.0, 4.0]
    olduğunu anlamaktayız. 

    Eğer durum bilgileri ayrık bilgilerse bu ayrık bilgilere Discrete isimli bir sınıf ile temsil edilmelidir. Discrete sınıfı 
    yalnızca ayrık durum bilgisini içermektedir. Ayrık durumlar için en düşük ve en yüksek değer kavramının bir anlamı yoktur. 
    Örneğin:

    Discrete(500)

    Burada simülatörde ayrık toplam 500 tane durumun olduğu belirtilmektedir. Bu durumlar [0, 499] arası sayısal değerlere sahiptir. 

    Programcı action_space örnek özniteliğine simülatörün yapabileceği eylemlerin sayısını ve sınırlarını kodlamalıdır. Biz şimdiye kadar 
    hep ayrın eylemler üzerinde çalışmış olsak da aslında eylemler sürekli de olabilmektedir. Örneğin CartPole simülaötüründe iki eylem 
    vardır: Motorun sola çalıştırılması, motorun sağa çalıştırılması. Burada eylem uzayı ayrıktır. İşte yine bizim eylemler sürekli ise 
    onların limitlerini Box nesnesi olarak, ayrık ise Discrete nesnesi olarak yukarıda açıklandığı gibi oluşturmamız gerekir. 

    Programcı oluşturduğu sınıfte reset metodunu yazmalıdır. Bu reset metodu gözlem nesnesine geri dönmelidir. Programcı belli bir eylemi alıp
    bundan dörtlü demet veren step metodunu yazmalıdır. Anımsanacağı gibi step metodunun geri döndürdüğü dörtlü demetin elemanları şunlardır:

    obs, reward, done, info = env.step(action)

    Programcı eğer görsel bir sunum yapma istiyorsa oluşturduğu sınıfta render isimli metodu da yazmalıdır. 

    Nihayet close metodunda programcı oluşturduğu sınıf için son birtakım işlemleri yapabilir. Programcı bu metodu yazmazsa taban Env sınıfının 
    close metodu çağrılacaktır.

    Aşağıdaki örnekte basit bir "custom environment" yazılmıştır. Burada 3x3'lük matrisel bir alanda bir etmen hedef (G) noktasına
    varmaya çalışmaktadır. Ancak bu matrisel alan içerisinde delikler (X) vardır. Bu custom environment sınıfındaki ödül mekanizması 
    şöyle ayarlanmıştır:

    - Deliğe düşme -10 puan
    - Deliğe düşmeden hedefe vararamayan eylem -1 puan
    - Hedefe varan eylem 10 puan

    Sınıf içerisinde yukarıda belirtilen elemanlar yazılmıştır. render metodu aşağıdaki gibi bir görüntü oluşturmaktadır:

    X X G
    A . .
    . . X

#----------------------------------------------------------------------------------------------------------------------------

"""
Actions:

LEFT = 0
UP = 1
RIGHT = 2
DOWN = 3

"""

import numpy as np
from gym import Env
from gym.spaces import Discrete

GOAL_POS = 2

class GoalPositionError(Exception):
    def __str__(self):
        return "Agent already at goal position"
    
class HolePositionError(Exception):
    def __str__(self):
        return "Agent already at hole position"

class MyEnv(Env):
    def __init__(self):
        super().__init__()
        self.observation_space = Discrete(9)
        self.action_space = Discrete(4)        
        self._holes = [0, 1, 8]
        self._pos_dict = {3: (5, 0, 4, 6), 4: (3, 1, 5, 7), 5: (4, 2, 3, 8), 6: (8, 3, 7, 0), 7: (6, 4, 8, 1) }
        
    def reset(self):
        none_holes = list(set(range(self.observation_space.n)).difference(self._holes + [GOAL_POS]))
        self._agent_pos = np.random.choice(none_holes)
        return self._agent_pos
    
    def step(self, action):
        if self._agent_pos == GOAL_POS:
            raise GoalPositionError()
    
        if self._agent_pos in self._holes:
                raise HolePositionError() 
            
        newpos = self._pos_dict.get(self._agent_pos)[action]
         
        self._agent_pos = newpos
        
        if newpos in self._holes:
            reward = -10
            done = True
        elif newpos == GOAL_POS:
            reward = 10
            done = True
        else:
            reward = -1
            done = False
            
        return newpos, reward, done, {}
    
    def render(self, text=False):
        s = ''
        for row in range(3):
            for col in range(3):
                pos = row * 3 + col
                if pos in self._holes:
                    if self._agent_pos == pos:
                        s += 'Q '
                    else:
                        s += 'X '
                elif pos == GOAL_POS:
                    if self._agent_pos == pos:
                        s += 'Q '
                    else:
                        s += 'G '
                elif pos == self._agent_pos:
                    s += 'A '
                else:
                    s += '. '
            s += '\n'
        if text:
            return s
        else:
            print(s)
        
from stable_baselines3.ppo import PPO

env = MyEnv()

model = PPO('MlpPolicy', env, learning_rate=0.1, n_epochs=100)

model.learn(30000)
            
import time
  
obs = env.reset()
print('\x1b[1J' +  env.render(text=True), end='')
time.sleep(1)

while True:
    action, _ = model.predict(obs)
    obs, reward, done, _ = env.step(action)
    
    print('\x1b[1J' +  env.render(text=True), end='')
    time.sleep(1)
    if done:
        break
    
#----------------------------------------------------------------------------------------------------------------------------
    Yukarıdaki "custom envirionment" daha genel bir biçimde de oluşturulabilir. Örneğin matrisin genişliğini deliklerin yerlerini 
    ve başka birtakım değişebilecek öğeleri parametrik hale getirebiliriz. Aşağıdaki örnekte MyEnv isimli simülatör bu biçimde 
    parametrik hale getirilmiştir. MyEnv sınıfının __init__ metodunun parametrik yapısı şöyledir:

    def __init__(self, rowsize = 3, colsize = 3, goal_pos = 2, holes = [0, 1, 8], hole_reward=-10, step_reward=-1, goal_reward=10
    
    Sınıf default durumda 3x3'lük bir matris kullanmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Diğer bir pekiştirmeli öğrenme kütüphanesi "keras-rl" isimli kütüphanedir. Kütüphane aşağıdaki gibi install edilebilir:

    pip install keras-rl

    Kütüphanesinin dokümantasyonu biraz zayıftır. Kütüphanenin belli bir düzeye gelmesi için de biraz zaman gerekmektedir. 
    Projenin web sayfasına aşağıdaki bağlantıdan erişilebilir:

    https://github.com/keras-rl/keras-rl

    Dokümantasyon için aşağıdaki bağlantıdan da faydalanılabilir:

    https://keras-rl.readthedocs.io/en/latest/

    Keras-rl kütüphanesinde de hazır birtakım etmen sınıfları bulunmaktadır. Tipik çalışma döngüsü şöyle gerçekleştirilir:

    1) Programcı bir sinir ağını kendisi Keras kullarak oluşturur. Örneğin:

    import gym

    env = gym.make('CartPole-v1')

    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense, Flatten
    from tensorflow.keras.optimizer import Adam

    model = Sequential(name='Cartpole-DeepLearning')
    model.add(Flatten(input_shape=(1,) + env.observation_space.shape), name='Flatten')
    model.add(Dense(64, activation='relu', input_dim=env.observation_space.shape[0], name='Dense-1'))
    model.add(Dense(64, activation='relu', name='Dense-2'))
    model.add(Dense(env.action_space.n, activation='linear', name='Output'))
    model.summary()

    2) Bir policy nesnesi yaratılır. Örneğin:

    from rl.policy import EpsGreedyQPolicy

    policy = EpsGreedyQPolicy(eps=0.2)

    Çeşitli policy sınıfları hazır bir biçimde bulunmaktadır. Bu Policy nesneleri isimsel olarak da girilebilmektedir. 

    3) Daha sonra bir memory nesnesi yaratılır. Çeşitli memory sınıfları oluşturulmuştur. Örneğin:

    from rl.memory import SequentialMemory
    
    memory = SequentialMemory(limit=50000, window_length=1)

    4) Bundan sonra bir Agent nesnesi oluşturulur. Çeşitli algoritmalar için çeşitli agent sınıfları bulunmaktadır. Örneğin:

    from rl.agents.dqn import DQNAgent

    agent = DQNAgent(model, nb_actions=env.action_space.n, memory=memory, policy=policy, nb_steps_warmup=10, target_model_update=1e-2)  

    Görüldüğü gibi agent sınıfı türünden nesne yaratılırken daha önce oluşturmuş olduğumuz "model nesnesi, "memory" nesnesi ve 
    "policy" nesnesi sınıfın __init__ metodunda parametre olarak verilmektedir. 

    5) Daha sonra agent nesnesi ile compile ve fit işlemleri yapılır. Örneğin:

    agent.compile(Adam(lr=1e-3, metrics=['mae']))
    agent.fit(env, nb_steps=10000)

    Burada fit işleminde environment nesnesinin de metoda verildiğine dikkat ediniz. Tıpkı Stable Baselines kütüphanesinde 
    olduğu gibi bu kütüphane için de "custom environment" oluşturulabilmektedir. 

    6) Artık model eğitilmiştir. Etmen hareket ettirilebilir. Örneğin:

    obs = env.reset()
    while True:
        action, _ = model.predict(obs)
        obs, reward, done, _ = env.step(action)
        if done:
            break
        env.render()
        
    env.close()

    Keras-rl kürüphanesi Stable Baselines kütüphanesine göre daha zayıf bir dokümantasyona sahiptir. Zaten kütüphane Stable Baselines'tan 
    sonra geliştirilmeye başlanmıştır. Henüz olgun bir aşamaya gelmemiştir. 

    Keras-rl kütüphanesi için örnek kodlar aşağıdaki bağlantıdan elde edilebilir:

    https://github.com/keras-rl/keras-rl/tree/master/examples

    Aşağda Cartplo simülatörünün keras-rl ile çözümü örnek olarak verilmiştir. 

#----------------------------------------------------------------------------------------------------------------------------

import gym

env = gym.make('CartPole-v1')

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.optimizer import Adam

model = Sequential(name='Cartpole-DeepLearning')
model.add(Flatten(input_shape=(1,) + env.observation_space.shape), name='Flatten')
model.add(Dense(64, activation='relu', input_dim=env.observation_space.shape[0], name='Dense-1'))
model.add(Dense(64, activation='relu', name='Dense-2'))
model.add(Dense(env.action_space.n, activation='linear', name='Output'))
model.summary()

from rl.policy import EpsGreedyQPolicy
policy = EpsGreedyQPolicy(eps=0.2)

from rl.memory import SequentialMemory
memory = SequentialMemory(limit=50000, window_length=1)

from rl.agents.dqn import DQNAgent

agent = DQNAgent(model, nb_actions=env.action_space.n, memory=memory, policy=policy, nb_steps_warmup=10, target_model_update=1e-2)
agent.compile(Adam(lr=1e-3, metrics=['mae']))
agent.fit(env, nb_steps=10000)

obs = env.reset()
while True:
    action, _ = model.predict(obs)
    obs, reward, done, _ = env.step(action)
    if done:
        break
    env.render()
    
env.close()

#----------------------------------------------------------------------------------------------------------------------------
    Sinir ağları için nispeeten aşağı seviyeli olan üç kütüphane (framework de denilebilir) yaygın olarak kullanılmaktadır:

    - Tensorflow
    - PyTorch
    - Theano
    
    Tensorflow Google firması tarafından bu firmanın öncülüğünde açık kaynak kodlu biçimde oluşturulmuştur. PyTorch ise 
    Facebook firması tarafından bu firmanın öncülüğünde yine açık kaynak kodlu biçimde oluşturulmuştur. Theano kütüphanesi
    daha genel amaçlıdır ve birkaç üniversite tarafından geliştirilmiştir. Tensorflow ve PyTorch kütüphaneleri için oldukça fazla
    kitap ve kaynak bulunmaktadır. 

    Tensorflow ve PyTorch kütüphaneleri üzerine oturtulmuş daha yüksek seviyeli kütüphaneler bulunmaktadır. Bunlara "ecosystem" de
    denilmektedir. Örneğin Keras kütüphanesi aslında Tensorflow kullnılarak oluşturulmuş yüksek seviyeli bir kütüphanedir. 
    Her iki kütüphane de ilk çıktığından bu yana gittikçe iyileştirilmiştir. Tensorflow kütüphanesinde 2'li versiyonlarla birlikte 
    geçmişe doğru uyumu bozan önemli farklılıklar bulunmaktadır. Bu bağlamda PyTorch kütüphanesinin geriye doğru uyumu daha yüksektir. 

    Biz kurusumuzda önce PyTorh kütüphanesinin genel kullanımı üzerinde duracağız sonra Tensorflow kütüphanesini inceleyeceğiz. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    PyTorch kütüphanesinin dokümantasyonuna aşağıdaki bağlantıdan erişilebilir:

    https://pytorch.org/docs/stable/index.html

    Pytorch kütüphanesi aşağıdaki gibi install edilebilir:

    pip install torch

#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    PyTorch kütüphanesinde ana öğe "tensör" denilen veri yapısıdır. PyTorch tensörleri aslında NumPy dizilerine benzemektedir. 
    Yani NumPy dizileri ile Numpy'da yapılanların benzerleri PyTorch tensörleri ile Pytorch'ta yapılabilmektedir. Ancak tensör ,
    makine öğrenmesi ve özellikle de sinir ağları için oluşturulmuş olan bir veri yapısıdır. Bu baımdan her ne kadar NumPy'ın ndarray 
    dizisine benze de farklı yetenekler sunmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    PyTorch kütüphanesinin import ismi "torch" biçimindedir. Tipik olarak kütüphane aşağıdaki gibi import edilmektedir:

    import torch
#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    PyTorch'da ilk öğrenilecek şey tensör yaratmaktır. Tensörler torch.Tensor isimli bir sınıfla temsil edilmiştir. 
    Bir tensör yaratmanın pek çok yolu vardır. En basit yolu torch.tensor fonksiyonunu kullanmaktır. Bu fonksiyonun birinci 
    parametresinde tensörü oluşturan değerler Python listesi biçiminde ya da NumPy dizisi biçiminde verilebilmektedir.
#----------------------------------------------------------------------------------------------------------------------------
   
import torch

t1 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]])

print(type(t1))

import numpy as np

a = np.random.random((10, 10))

t2 = torch.tensor(a)

print(t2)

#----------------------------------------------------------------------------------------------------------------------------
    PyTorch'da da tıpkı Tensorflow ve numpy'da olduğu gibi tensörlerin C Programlama Dilindeki temsilleri dtype parametresiyle belirtilebilmektedir. 
    PyTorch kütüphanesindeki dtype diğerlerinde olduğuı gibidir. Ancak bazı farklılıklar vardır. dtype belirtilmezse 
    default olarak tensor değerlerine de bakılarak torch.in32 ya da torch.float64 alınmaktadır. 

    PyTorch'ta dtype türü yazısal olarak belirtilemez. NumPy'daki dtype sınıfları da bunun kullanılamamaktadır. dtype türleri 
    torch modülünün içerisindeki sınıflarla temsil edilmiş durumdadır. Örneğin torch.float32, torch.in32 gibi. 

    Eğer bir tensör NumPy dizisiniden oluşturuluyorsa ve tensor fonksiyonunda dtype belirtilmemişse tensör nesnesinin dtype türü
    NumPy nesnesinden alınmaktadır. Tabii biz dtype türünü kendimiz vererek bu türün NumPy dizisinden alınmasını englleyebiliriz. 
#----------------------------------------------------------------------------------------------------------------------------
   
import torch

t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float32)

print(t)

a = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype='float32')
t = torch.tensor(a)

print(t)

#----------------------------------------------------------------------------------------------------------------------------
    torch.empty fonksiyonu ilkdeğer verilmemiş belli bir boyutta tensör oluşturmakta kullanılır. Yani oluşturulan tensörün 
    elemanlarında rastgele değerler vardır. 
#----------------------------------------------------------------------------------------------------------------------------
   
import torch

t = torch.empty((10, 10), dtype=torch.int32)

print(t)

#----------------------------------------------------------------------------------------------------------------------------
    Tıpkı NumPy kütüphanesinde olduğu gibi torch.zeros içi sıfırlarla dolu, torch.ones içi 1'lerle dolu tensörler oluşturmaktadır.
#----------------------------------------------------------------------------------------------------------------------------
   
import torch

t1 = torch.zeros((10, 10), dtype=torch.int32)

print(t1)

t2 = torch.ones((10, 10), dtype=torch.int32)

print(t2)

#----------------------------------------------------------------------------------------------------------------------------
    torch.full fonksiyonu tıpkı numpy.full fonksiyonu gibi tensör nesnesini belli bir değerle yaratmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------
   
t = torch.full((5, 5), 10, dtype=torch.float32)
print(t)

#----------------------------------------------------------------------------------------------------------------------------
    torch.rand fonksiyonu 0 ile 1 arasında rastgele değerlerden, torch.randn fonksiyonu standart normal dağılma göre rastgele değerlerden ve
    torch.randint fonksiyonu belli aralıkta rastgele tamsayı değerlerden tensörler oluşturmaktadır.
#----------------------------------------------------------------------------------------------------------------------------
   
import torch

t1 = torch.rand((10, 10), dtype=torch.float32)

print(t1)

t2 = torch.randn((10, 10), dtype=torch.float32)

print(t2)

t3 = torch.randint(10, 20, (10, 10), dtype=torch.int32)

print(t3)

#----------------------------------------------------------------------------------------------------------------------------
    torch.eye fonksiyonu birim matric biçiminde tensör oluşturmaktadır.
#----------------------------------------------------------------------------------------------------------------------------

import torch

t = torch.eye(10, dtype=torch.float32)
print(t)

#----------------------------------------------------------------------------------------------------------------------------
    Pytorch tensörleri torch.Tensor isimli bir sınıf türündendir. Bu sınıfın pek çok faydalı metodu ve özniteliği vardır. shape isimli örnek özniteliği
    bize tensörün boyutlarını torch.Size isimli bir sınıf türünden vermektedir. torch.Size sınıfı köşeli parantez operatörünü destekler. Dolayısıyla biz
    tensörün boyutlarını böyle elde edebiliriz. 
#----------------------------------------------------------------------------------------------------------------------------

import torch

t = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)

print(type(t.shape))
print(t.shape)
print(t.shape[0], t.shape[1])
print(len(t.shape))

#----------------------------------------------------------------------------------------------------------------------------
    Tensor sınıfının dtype örnek özniteliği yine bize nesnenin dtype bilgisini verir. Bir tensör yaratılırken onun nerede işleneceği 
    de belirtilebilmektedir. Buna tensörün "device" bilgisi denilmektedir. Device bilgisi default olarak "cpu" biçimindedir.
    Tensör yaratan fonksiyonların hepsinde bu device parametresi bulunmaktadır. Bu device parametresi "gpu" yapılırsa tensör grafik işlemci üzerinde
    işleme sokulmaktadır. Ancak tensörün grafik işlemci üzerinde işleme sokulabilmesi için gpu kütüphanelerinin (örneğin Windows için cuda)
    yüklenmiş olması gerekmektedir. Tensor sınıfının "device" örnek özniteliği ile biz bu bilgiyi geri alabiliriz. 
#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    Bir tensörün içerisindekileri torch.Tensor sınıfının numpy metodu ile NumPy dizisine dönüştürebiliriz. 
#----------------------------------------------------------------------------------------------------------------------------
   
import torch

t = torch.tensor([[1, 2, 3], [4, 5, 6]], dtype=torch.float32)

a = t.numpy()

print(type(a))
print(a)

#----------------------------------------------------------------------------------------------------------------------------
    torch.tensor fonksiyonu ile biz zaten bir NumPy dizisinden de Tensor nesnesi elde edebiliyorduk. Ancak istenirse torch.from_numpy fonksiyonuyla da
    benzer işlem yapılabilir. Bu fonksiyonun tek bir parametresi vardır o da numpy dizisidir. 
#----------------------------------------------------------------------------------------------------------------------------
   
import torch
import numpy as np

a = np.random.random((5, 5))
t = torch.from_numpy(a)

print(t)

#----------------------------------------------------------------------------------------------------------------------------
    Bir tensör nesnesinin elemanlarına [] operatörü ile erişebiliriz. Ancak elemanlar bize yine Tensor nesnesi olarak verilmektedir. 
    Tensör nesnelerinin elemanları da atama yoluyla değiştirilebilmektedir. Benzer biçimde tensör nesneleri de dilimlenebilmektedir.
#----------------------------------------------------------------------------------------------------------------------------
   
import torch

t = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float32)

print(t)
x = t[1, 1]
print(x)
t[1, 1] = 100
print(t)
y = t[1:2, 0:3]
print(y)
t[1:2, 0:3] = 0
print(t)

#----------------------------------------------------------------------------------------------------------------------------
    Tıpkı NumPy dizilerinde olduğu gibi Tensör nesneleri üzerinde aritmetik işlemler yapılabilmektedir. Örneğin iki tensör 
    nesnesi toplanabilir, çıkartılabilir. Bir tensör nesnesi bir skalerle işleme sokulabilir. Bu kullanım NumPy 
    kütüphanesindekine oldukça benzemektedir. 
#----------------------------------------------------------------------------------------------------------------------------

import torch

t1 = torch.tensor([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=torch.float32)
t2 = torch.tensor([[9, 8, 7], [6, 5, 4], [3, 2, 1]], dtype=torch.float32)

result = t1 + t2
print(result)

result = t1 * 2 + t2
print(result)

#----------------------------------------------------------------------------------------------------------------------------
    Bir tensör içerisinde tek bir eleman varsa (bu eleman çok boyutlu bir tensörün içerisinde de olabilir) o eleman Tensor 
    sınıfının item metoduyla elde edilebilir. item metodu birden fazla elemana sahip tensörlere uygulanamaz. Bu durumda 
    eleman önce köşeli parantez operatöryle alınıp sonra item metodu uygulanmalıdır. [] operatörünün her zaman tensör nesnesi 
    verdiğini anımsayınız.
#----------------------------------------------------------------------------------------------------------------------------

import torch

t = torch.tensor([[[1]]], dtype=torch.float32)

val = t.item()
print(val)

t = torch.rand((5, 5))
val = t[3, 2].item()
print(val)

#----------------------------------------------------------------------------------------------------------------------------
    torch.Tensor sınıfının pek çok matematiksel işlem yapan metodu vardır. Bu metotlar tensörün her elemanı üzerinde işlem yapıp yine bir 
    tensör nesnesi vermektedir. Aslında bu metotların pek çoğunun birer global karşılıkları da vardır. Başka bir deyişle t bir 
    tensör nesnesi olmak üzere foo da bir matematiksel metot olmak üzere:

    result = t.foo(...)

    işlemlerinin çoğu:

    result = torch.foo(t, ...)

    biçiminde de yapılabilmektedir. 

    NumPy kütüphanesindeki axis kavramı PyTorch kütüphanesinde benzer biçimde dim kavramıyla oluşturulmuştur. Bu iki kavramın kullanım mantığı aynıdır. 
    Bazı matemetiksel işlem yapan metotlar (ya da fonksiyonlar) şöyledir: 
    - max
    - min
    - argmax
    - argmin
    - sin,  cos, tan, asin, acons, atan
    - log, log10, exp
    - sqrt
    - pow
    ...

    Bunların çoğu dim parametresi almaktadır. Bu parametre ihmal edildiğinde tıpkı NumPy'da olduğu gibi tüm değerler üzerinde işlem yapılır. 
    dim=0 sütun temelinde işlemler için, dim=1 satıt temelinde işlemler için kullanılmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    Pytorch temel olarak bir yapay sinir ağı kütüphanesidir. Kütüphane içerisinde aşağı seviyeli bir biçimde yapay sinir ağı modelleri 
    oluşturulabilmektedir. Aynı zamanda yüksek seviyeli birtakım öğeler de bulunmaktadır. Hatta çeşitli konulara ilişkin hazır pek çok sınıf PyTorch projesine
    eklenti oluşturan yan projelerde bulunmaktadır. Örneğin bir resim sınıflandırma işlemi için model tamamen sıfırdan oluşturulabileceği gibi zaten 
    hazır larak bulunan çeşitli modellerden biri seçilip az bir çabayla da işlemler yürütülebilmektedir. 

    PyTorch bir kütüphane olarak Tensorflow'a göre daha "nesne yönelimli" tasarlanmıştır. Programcı çeştili modeller için var olan sınıflardan türetmeler
    yaparak işlemlerini yürütebilmektedir. Bu bağlamda bazı işlemler sınıfsal düzeyde gerçekleştirilmektedir.  
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da PyTorch'ta yüksek seviyeli özel konulara ilişkin çeitli kütüphanelerin bulunduğunu bunlara "PyTorch ecosystem" 
    dendiğni söylemiştik. Ecosystem içerisindeki yüksek seviyeli önemli kütüphaneler şunlardır:

    TorchVision: Tamamen görüntü işleme ile ilgili işlemler oluşturulmuş kütüphanedir. Örneğn resimlerin sınıflandırılması için
    bu torchvision paketinden faydalanılabilir. 

    TorchText: Metinsel işlemler için kullanılan yüksek seviyeli kütüohanedir. Örneğin metinlerin sınıflandırılması için bu paketteki 
    öğelerden faydalanılablir. 

    TorchAudio: Voice processing işlemleri için bulundurulmuş yüksek seviyeli kütüpahenedi.r 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    PyTorch kütüphanesinde de hazır pek çok veri kümesi bulunmaktadır. Resimsel sınıflandırmaya ilişkin yüksek seviyeli birtakım sınıflar ve hazır veriler 
    torchvision paketindedir. Yazısal sınıflandırmaya ilişkin hazır birtakım sınıflar ve veriler ise torchtext paketinde bulunmaktadır. Benzer biçimde işitsel
    öğeler için torchaudio, hareketli görüntüsel öğeler için torchvideo gibi yüksek düzeyli paketler ana kütüphaneye entegre edilmiştir.
#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    PyTorch modelinde önemli kavramladan biri "dataset" kavramıdır. Dataset veri kümesini temsil eden bazı metotları bulunan bir arayüz sınıftır. 
    PyTorch içerisindeki hazır birtakım veri kümeleri yüklendiğinde aslında bu veri kümeleri Dataset arayüzünü destekleyen sınıflar biçiminde bize verilmektedir.
    Tabii programcı kendi verileri için arayüz Dataset sınıfını kendisi oluşturmak durumundadır. Bir Dataset sınıfı torch.utils.data.Dataset isimli sınıftan türetilerek 
    oluşturulmaktadır. Programcı kendi dataset sınıfını oluşturacaksa bu torch.utils.data.Dataset sınıfından sınıf türetip __getitem__ metodunu 
    yazmalıdır. Ya da bu işlemi kendi içerisinde yapan hazır başka dataset sınıflarını da kullanabilir. PyTorch kütüphanesinde çeşitli 
    amaçlara denk düşen Dataset sınıfından türetilmiş özel dataset sınıfları da bulunmaktadır. Örneğin TensorDataset isimli hazır 
    dataset sınıfı kendi verilerimizi dataset kavramı biçiminde ifade etmek için pratik bir sınıftır. Bu sınıf bizden x ve y 
    verilerini alarak bize protokole uygun bir dayaset nesnesi vermektedir. Örneğin:

    from torch.utils.data import TensorDataset

    dataset = TensorDataset(training_dataset_x, training_dataset_y)

    Artık dataset nesnesi üzerinde [...] operatörü ile elemanlar elde edilebilir ve dilimlemeler yapılabilir. Ancak bu [...] operatörü
    bize iki elemanlı bir demet verecektir. Demetin birinci indeklere ilişkin x verilerinden ikinxi elemanı da y verilerinden oluşmaktadır. 
    Aslında TensorDataset nenesini yaratırken biz istediğimiz kadar argüman girebiliriz. Bu durumda [...] operatörü bize o uzunlukta bir demet verir. 
    Örneğin:

    dataset = TensorDataset(x, y, z)

    Tabii tipik olarak biz veri kümesi için x ve y değerlerini TensorDataset sınıfına veririz. 

    TensorDataset sınıfı biz ona hangi türden nesne verirsek bize [...] operatörü ile aynı türden neslerden oluşan demet vermektedir. 
    Örneğin biz bu sınıfa NumPy dizilerini versek bu sınıf bize NumPy dizilerini verir. Ancak PyTorch'ta çalışma tensörkerke yapılmaktadır. 
    Dolayısıyla bizim TensorDataset sınıfına x ve y değerlerindne oluşan Tensor nesnelerini vermemiz uygun olur. 
#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    Programcının PyTorch'da bir veri kümesi ile çalışmak için ilk yapacağı şey kendi veri kümesini bir Dataset nesnesi olarak ifade etmektir. 
    Yukarıda da belirtildiği gibi bu işlem için programcı Dataset sınıfından türetme yaparak kendi Dataset sınıfını oluşturabilir. 
    Ya da TensorDataset gibi hazır bir sınıftan da faydalanabilir. 

    Aşağıda "Boston Housing Prices" verilerinden hareketle oradaki verilerden PyTorch kütüphanesine uygun Dataset nesnesi elde edilmektedir. 
    Burada hazır TensorDataset sınıfından faydalanılmıştır.
#----------------------------------------------------------------------------------------------------------------------------
   
import numpy as np

dataset = np.loadtxt('housing.csv', dtype='float32')
dataset_x = dataset[:, :-1]
dataset_y = dataset[:, -1]

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.20)

import torch

training_tensor_x = torch.tensor(training_dataset_x)
training_tensor_y = torch.tensor(training_dataset_y)

test_tensor_x = torch.from_numpy(test_dataset_x)
test_tensor_y = torch.from_numpy(test_dataset_y)

from torch.utils.data import TensorDataset

training_dataset = TensorDataset(training_tensor_x, training_tensor_y)
test_dataset = TensorDataset(test_tensor_x, test_tensor_y)

#----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirttiğimiz gibi aslında PyTorch içerisinde popüler pek çok veri kümesi değişik paketler içerisinde bulunmaktadır. Bu veri kümeleri 
    zaten bize PyTorch kütüphanesinin istediği Dataset nesnesi biçiminde verilmektedir. Örneğin resimsel verilerin sınıflandırılması için yüksek seviyeli sınıflar
    ve veri kümeleri barındıran torchvision içerisindeki datasets modülünde pek çok popüler veri kümesine ilişkin hazır Dataset sınıfları bulunmaktadır.

    Örneğin torchvision.datasets modülündeki CIFAR10 isimli sınıf daha önce üzerinde çalışmış olduğuğumuz Cifar10 verilerini PyTorch kütüphanesinin gereksinim duyduğu 
    Dataset sınıfı biçiminde bize vermektedir. Bu nesne yaratılırken verilerin Internet'ten yerel makineye indirileceği makinemizdeki dizinin ismi root 
    parametresiyle girilmektedir. train parametresi True ise eğitim veri kümesi için False ise test veri kümesi için Dataset nesneleri oluşturulur. 
    download parametresi True geçilirse veriler Internet'ten indirilir. False geçilirse indirilmiş veriler doğurdan kullanılır. Tabii download=True 
    durumunda veriler zaten indirilmişse bir daha indirilmez. 
    
    Bu veri kümelerinin data isimli örnek öznitelikleri x verilerinin hepsini bize numpy dizisi olarak vermektedir. Benzer biçimde bu veri 
    kümelerinin targets örnek öznitelikleri de y değerlerini bize NumPy dizisi olarak vermektedir. 

    Bu biçimde hazır olarak elde ettiğimiz dataset nesnelerinin [...] operatör metodu bulunmaktadır. Ancak resimsel verilerde bu operatör metodu bize
    default durumda x verilerini PIL.Image (Python Image Library'deki Image sınıfı) nesnesi olarak verir. 
#----------------------------------------------------------------------------------------------------------------------------

from torchvision.datasets import CIFAR10

training_dataset = CIFAR10(root='cifar100-data', train=True, download=True)
test_dataset = CIFAR10(root='cifar10-data', train=False, download=True)

x, y = training_dataset[0]

print(type(x), type(y)) # <class 'PIL.Image.Image'> <class 'int'>

#----------------------------------------------------------------------------------------------------------------------------
    torchvision içerisindeki hazır veri kümelerini kullanırken bunların bazı önişlemlere sokulması gerekebilmektedir. Bunun için CIFAR10 gibi 
    hazır dataset veren sınıflarda transform ve target_transform isimli parametreler bulunmaktadır. Bu parametrelere __call__ metoduna sahip sınıf
    nesneleri girilir. Bu sınıflar da verileri indirdikten sonra parametrelerle belirtilen nesne ile __call__ metotlarını çağırırlar. Bu metotların geri dönüş 
    değerlerini bize nihai değer olarak verirler. Böylece veriler indirilirken aynı zamanda veriler üzerinde bazı önişlemeler de yapılmış olur. transform parametresi 
    x verileri için target_transform parametresi y verileri için belirtilen nesnelerin __call__ metotlarını çağırmaktadır. Örneğin biz buradaki resmi PIL.Image 
    sınıfından bir Tensor nesnesine dönüştüren bir "trasnformer" sınıf yazabiliriz:

    import torch
    from torchvision.datasets import CIFAR10
  
    import numpy as np
    class MyTransformer:    
        def __call__(self, image):
            return torch.tensor(np.array(image))
            
    training_dataset = CIFAR10(root='cifar10-data', train=True, download=True, transform=MyTransformer())
    test_dataset = CIFAR10(root='cifar10-data', train=False, download=True, transform=MyTransformer())

    x, y = training_dataset[0]

    print(type(x), type(y))

    Aslında örneğin yukarıdaki işlemi yapan yani PIL.Image nesnesindeki verileri Tensor haline getiren torchvision.transforms modülünde ToTensor
    isimli bir sınıf vardır. Aynı işlemi bu sınıfla da yapabilirdik:

    Bir grup önişlemi peşi sıra yapmak için ayrıca Compose isminde bir dekoratör sınıf da bulundurulmuştur. Programcı Compose sınıfı türünden bir nesne yaratıp bu 
    sınıfın __init__ metodunda transform nesnelerini bir liste ile sınıfa verir. Sınıfın __call__ metodu bu nesnelerin __call_ metotlarını çağırarak 
    orada belirtilen önişlemleri sırasıyla yapar. Compose sınıfı aşağıdakine benzer biçimde yazılmıştır:

    class Compose:
        def __init__(self, args):
            self.args = args
            
        def __call__(self, x):
            for arg in self.args:
                x = arg(x)
                
            return x;

    Örneğin:

    from torchvision.datasets import CIFAR10
    from torchvision.transforms import Compose, ToTensor, Normalize
        
    training_dataset = CIFAR10(root='cifar10-data', train=True, download=True, transform=Compose([ToTensor(), Normalize((0, 0, 0), (1, 1, 1))]))

    test_dataset = CIFAR10(root='cifar10-data', train=False, download=True, transform=Compose([ToTensor(), Normalize((0, 0, 0), (1, 1, 1))]))

    x, y = training_dataset[0]

    print(type(x), type(y))

#----------------------------------------------------------------------------------------------------------------------------

from torchvision.datasets import CIFAR10
from torchvision.transforms import Compose, ToTensor, Normalize
    
training_dataset = CIFAR10(root='cifar10-data', train=True, download=True, transform=Compose([ToTensor(), Normalize((0, 0, 0), (1, 1, 1))]))

test_dataset = CIFAR10(root='cifar10-data', train=False, download=True, transform=Compose([ToTensor(), Normalize((0, 0, 0), (1, 1, 1))]))

x, y = training_dataset[0]

print(type(x), type(y))

#----------------------------------------------------------------------------------------------------------------------------
   Dataset sınıfları veri kümesini temsil etmektedir. Veri kümesi eğitilirken verilerin batch batch elde edilmesi gerekmektedir. 
   İşte bunun için DataLoader sınıfları kullanılmaktadır. Bir DataLoader nesnesi torch.DataLoader sınıfı ile oluşturulabilir. 
   DataLoader nesnesi oluşturulurken Dataset nesnesi ve batch_size miktarı parametre olarak girilir. İstenirse shuffle=True parametresiyle 
   karıştırma da yapılbilir. DataLoader nesneleri dolaşılabilir (iterable) nesnelerdir. Nesne her dolaşıldığında x ve y olarak 
   batch_size kadar veri tensör nesnesi olarak elde edilmektedir. Dolaşım sırasında son parçada batch_size kadar bilgi kalmayabilir. 
   Bu durumda son yinelemede kalan miktarda veri elde edilir. Örneğin:

   from torch.utils.data import TensorDataset, DataLoader

    training_dataset = TensorDataset(training_tensor_x, training_tensor_y)
    test_dataset = TensorDataset(test_tensor_x, training_tensor_y)

    training_dataloader = DataLoader(training_dataset, batch_size=32, shuffle=True)
    test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)

    for x, y in training_dataloader:
        print(type(x), x.shape)
        
    Aşağıdaki örnekte "Boston Housing Prices" veri kümesi için DataLoader nesneleri oluşturulmuştur. Burada önce Boston veri kümesi 
    CSV dosyasından okunmuş sonra bu verilerden Dataset nesnesi oluşturulmuş ve nihayet bu dataset nesnesinden de DataLoader nesnesi 
    oluşturulmuştur. 
#----------------------------------------------------------------------------------------------------------------------------
   
import numpy as np

dataset = np.loadtxt('housing.csv', dtype='float32')
dataset_x = dataset[:, :-1]
dataset_y = dataset[:, -1]

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.20)

import torch

training_tensor_x = torch.tensor(training_dataset_x)
training_tensor_y = torch.tensor(training_dataset_y)

test_tensor_x = torch.from_numpy(test_dataset_x)
test_tensor_y = torch.from_numpy(test_dataset_y)

from torch.utils.data import TensorDataset, DataLoader

training_dataset = TensorDataset(training_tensor_x, training_tensor_y)
test_dataset = TensorDataset(test_tensor_x, training_tensor_y)

training_dataloader = DataLoader(training_dataset, batch_size=32, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)

for x, y in training_dataloader:
    print(type(x), x.shape)

#----------------------------------------------------------------------------------------------------------------------------
    Artık sıra yapay sinir ağını oluşturmaya gelşmiştir. PyTorch'ta yapay sinir ağı modeli torch.nn modülü içerisinde Module isimli
    bir sınıftan türetme yapılarak oluşturulmalıdır. (Module ismi Python için uygun bir isim olmayabilir. Çünkü Python'da "modül" terimi
    tamamen başka bir anlama gelmektedir.). Örneğin:

    from torch.nn import Module

    class MyModule(Module):
        pass

#----------------------------------------------------------------------------------------------------------------------------
 
#----------------------------------------------------------------------------------------------------------------------------
    Programcı Module sınıfından türettiği sınıfta iki metodu yazmalıdır: __init__ ve forward. forward metodu aslında bir callback 
    metot biçimindedir. Eğitim sırasında her batch işleminde dolaylı olarak bu forward metodu çağrılmaktadır. 

    Yapay sinir ağını temsil eden bu Module sınıfından türettiğimiz sınıfta bizim __init__ metodunda katman nesnelerini yaratıp 
    sınıfın örnek özniteliklerine atamamız gerekmektedir. Bu katman nesneleri daha sonra framework tarafından biriktirilip bazı işlemlere sokulacaktır.
    Örneğin:

    from torch.nn import Module

    class MyModule(Module):
        def __init__(self):
            super().__init__()
            
        def forward(self, batch_x):
            pass

#----------------------------------------------------------------------------------------------------------------------------
     
#----------------------------------------------------------------------------------------------------------------------------
    Pytorch'ta katman nesneleri için torch.nn modülünde çeşitli sınıflar bulundurulmuştur. Keras'taki Dense katmana en çok benzeyen katman 
    Linear isimli katmandır. Keras'ın Sequential isimli model nesnesi anımsanacağı gibi otomatik olarak önceki katmanın çıktısını 
    sonraki katmanın girdine bağlıyordu. Bu nedenle Keras'ta katman nesneleri yaratılırken yalnızca çıktı katmanındaki nöron sayısı 
    belirtiliyordu. Ancak PyTorch'ta katman nesnelerinde hem girdi nöron sayısı hem de çıktı nöron sayısı belirtilmektedir. 

    Anımsanacağı gibi nöronun girdileri girdi sayısı sayısı kadar w değerleriyle çarpılıp toplanıyordu (dot product). Katmanda n tane girdi m tane
    çıktı varsa bu n tane girdi m tane nörona bağlı olduğu için ve bu nöronların her birindeki w değerleri farklı olduğu için eğitilecek 
    parametrelerin sayısı n * m + m kadar oluyordu (buradaki m bias değerinden gelmeketedir.) Keras'ın Dense katmanında bu her nörondaki dot product değeri
    en sonunda bir aktivasyon fonksiyonuna sokuluyordu. Oysa PyTorch'ta Linear isimli katman yalnızca dot product işlemini yapmaktadır. 
    Bu dot product değerini aktivasyon fonksiyonuna sokmamaktadır. Zaten bu nedenle katmanın ismine Linear denmiştir. Başka bir deyişle
    nöronda elde edilen dot product değerinin aktivasyon fonksiyonuna sokulmaması aslında Linear aktivasyon fonksiyonuna sokulması ile 
    aynı anlamdadır. PyTorch'ta aktivasyon fonksiyonları farklı bir katman gibi düşünülmüştür. Yani PyTorch'taki aktivasyon katmanlarını 
    biz dot product yapmadan nöronun girdisini aktivasyon fonksiyonuna sokarak çıktıtya veren bir katman olarak düşünebiliriz. Aktivasyon katmanları eğitilebilir
    parametreye sahip olmadığı için içi sınıfın örnek özniteliklerinde saklanmak zorunda değildir. Eğer bazı katmanlar aynı aktivasyon fonksiyonuna
    sahipse her katman için ayrı bir aktivasyon katman nesnesinin de oluşturulmasına da gerek yoktur. 

    Türettiğimiz Module sınıfının __init__ metodunda katman nesnelerini birbirine bağlamamaktayız. __init__ metodunda yalnızca katman nesnelerini
    oluşturulup sınıfın örnek özniteliklerine atamalıyız. (Yukarıda belirttiğimiz gibi aktivasyon katman nesnelerinin sınıfın örnek özniteliklerine 
    atanması gerekmez.) Örneğin:

    from torch.nn import Module, Linear
    
    class MyModule(Module):
        def __init__(self, input_size):
            super().__init__()
            self.input_size = input_size
            
            self.hidden1 = Linear(input_size, 64)
            self.hidden2 = Linear(64, 64)
            self.output = Linear(64, 1)
                    
        def forward(self, batch_x):
            pass

    Katman nesnelerinin de dtype bilgisi vardır. Bu dtype bilgisi katman nesnelerinin içerisindeki w değerlerine ilişkindir. Eğer yukara da 
    yaptığımız gibi katman nesnelerinde dtype belirtmezsek default olarak torch.float32 alınmaktadır. Eğitim sırasında katman nesnelerinin 
    dtype türünün FataLoader nesnesinden elde edilen tensörlerin dtype türleriyle uyuşması gerekmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Module sınıflarının forward metotları eğitim sırasında her batch işlemi için callback metot biçiminde çağrılmaktadır. forward 
    metodu self parametresinin yanı sıra batch_x ile temsil edilen bir parametreye de sahiptir. Bu batch_x parametresine 
    veri kümesindeki bir batch kadar bilgi geçirilmektedir. Yani metot çağrıldığında buradaki batch_x parametresi batch_size kadar satırdan 
    ve veri kümesindeki özellik sayısı kadar sütundan oluşan bir Tensör görünümünde olacaktır.

    Pekiyi forward metodunda biz ne yapmalıyız? İşte bu metotta biz gerçekten yaratmış olduğumuz katman nesnelerini devreye sokarak 
    bir batch_size kadar bilgiyi yapay sinir ağına vererek çıktıyı elde etmeliyiz. forward metodunu biz son katmanın çıktısı ile
    geri döndürmeliyiz. Yani özetle forward metodunun batch_x parametresi bir batch kadar bilgiyi içeren bir tensördür. Bu bir batch'lik
    bilgiyi biz yapay sinir ağımızın katmanlarına sokarak çıktı elde etmeliyiz. Bu çıktıyla da forward metodunu geri döndürmeliyiz.

    Tıpkı Keras'ın fonksiyonel modelinde olduğu gibi PyTorch kütüphanesinde de ona benzer bir tasarım kullanılmıştır. PyTorch katman sınıflarının 
    __call__ metotları o katmanın yapması gereken işlemi yapmaktadır. Örneğin Linear sınıfının __call__ metodu dot product işlemi yapar. 
    ReLU sınıfının __call__ metodu relu aktivasyon fonksiyonun işlemini yapar. O halde biz forward metodonda x parametresi ile aldığımız 
    tensörü bu katman nesnelerinin __call__ metotlarına sokarak bu metotların geri dönüş değerlerini katman çıktısı olarak alırız. 
    Önceki katmanın çıkışını sonraki katmanın girişine vererek yapay sinir ağını işletiriz. Örneğin:

    from torch.nn import Module, Linear, ReLU
        
    class MyModule(Module):
        def __init__(self, input_size):
            super().__init__()
            self.input_size = input_size
            
            self.hidden1 = Linear(input_size, 64)
            self.hidden2 = Linear(64, 64)
            self.output = Linear(64, 1)
            
            self.relu = ReLU()
                    
        def forward(self, batch_x):
            x = self.hidden1(batch_x)
            x = self.relu(x)
            x = self.hidden2(x)
            x = self.relu(x)
            x = self.output(x)
                
            return x
            
    Aşağıda Boston Housing Prices veri kümesi için Modül sınıfınun oluşturulmasına bir örnek verilmiştir.    
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np

dataset = np.loadtxt('housing.csv', dtype='float32')
dataset_x = dataset[:, :-1]
dataset_y = dataset[:, -1]

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.20)

import torch

training_tensor_x = torch.tensor(training_dataset_x)
training_tensor_y = torch.tensor(training_dataset_y)

test_tensor_x = torch.from_numpy(test_dataset_x)
test_tensor_y = torch.from_numpy(test_dataset_y)

from torch.utils.data import TensorDataset, DataLoader

training_dataset = TensorDataset(training_tensor_x, training_tensor_y)
test_dataset = TensorDataset(test_tensor_x, training_tensor_y)

training_dataloader = DataLoader(training_dataset, batch_size=32, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)

from torch.nn import Module, Linear, ReLU
    
class MyModule(Module):
    def __init__(self, input_size):
        super().__init__()
        self.input_size = input_size
        
        self.hidden1 = Linear(input_size, 64)
        self.hidden2 = Linear(64, 64)
        self.output = Linear(64, 1)
        
        self.relu = ReLU()
                
    def forward(self, batch_x):
       x = self.hidden1(batch_x)
       x = self.relu(x)
       x = self.hidden2(x)
       x = self.relu(x)
       x = self.output(x)
        
       return x
        
mm = MyModule(training_tensor_x.shape[1])

#----------------------------------------------------------------------------------------------------------------------------
    Module sınıfları da __call__ metotlarına sahiptir. Yani elimizde Module sınıfı türünden bir nesne varsa biz o nesneyle 
    fonksiyon çağırma operatörünü kullanabiliriz. Bu durumda Module sınıfının __call__ metodu çağrılır. İşte Module sınıflarının __call__ metotları
    aslında kendi içerisinde forward metodunu çağırmakta ve bize forward metodunun geri döndürdüğü değeri vermektedir. 

    Aşağıdaki örnekte Module sınıfı türünden bir nesne yaratılıp bu nesne ile sınıfın __call__ metodu çağrılmıştır. __call_metodu da
    forwrad metodunun çağrılmasına yol açmakta ve forward metodunun geri dönüş değeri de __call__ metodunun geri dönüş değeri olarak verilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------
   
import torch
from torch.nn import Module, Linear, ReLU, Sigmoid

class MyModule(Module):
    def __init__(self):
        super().__init__()
        
        self.linear1 = Linear(10, 64)
        self.linear2 = Linear(64, 64)
        self.linear3 = Linear(64, 1)
        
        self.relu = ReLU()
        self.sigmoid = Sigmoid()
               
    def forward(self, x):
        x = self.linear1(x)
        x = self.relu(x)
        x = self.linear2(x)
        x = self.relu(x)
        x = self.linear3(x)
        x = self.sigmoid(x)
        
        return x
        
x = torch.rand(32, 10)

mm = MyModule()
result = mm(x)           # bu forward metodunun çağrılmasına yol açmaktadır ve forward metodunun geri dönüş değeri ile geri dönmektedir.

#----------------------------------------------------------------------------------------------------------------------------
    Aslında Module sınıfından türetme yaparak kendi modül sınıfımızı oluşturmak yerine doğrudan torch.nn modülü içerisindeki
    Sequential isimli sınıfı da kullanabiliriz. Bu Sequential sınıfının __init__ metodunda biz katman nesnelerini sırasıyla
    argüman olarak veririz. Sınıf da bunları nesnenin özniteliklerinde saklayıp forward metodunda bunları birbirine bağlamaktadır. 
    Örneğin:

    from torch.nn import Sequential

    sequential = Sequential(
        Linear(training_tensor_x.shape[1], 64), 
        ReLU(), 
        Linear(64, 64), 
        ReLU(), 
        Linear(64, 1))

    Biz burada bir modül nesnesi oluşturmuş olduk. Adeta bu Sequential sınıfı yukarıda belirttiğimiz şeyleri bizim için zaten 
    yapmaktadır. Sequential sınıfında argümanlar demetlerden oluşan bir sözlük (en uygunu OrderedDict kullanmak) olarak da girilebilir. 
    Bu durumda demetlerin ilk elemanı katman nesnesinin ismini, ikinci elemanı nesnenin kendisini içermelidir. Örneğin:

    from torch.nn import Sequential
    from collections import OrderedDict

    sequential = Sequential(OrderedDict([
        ('hidden1', Linear(training_tensor_x.shape[1], 64)), 
        ('relu1', ReLU()), 
        ('hidden2', Linear(64, 64)),
        ('relu2', ReLU()),
        ('output', Linear(64, 1))
        ]))
    
    Burada verdiğimiz isimler doğrudan sınıfın örnek özniteliklerinin isimleri olmaktadır. (Eskiden Python'da sözlük nesnelerinin 
    anahtarları elde edilirken anahtarlar herhangi bir sırada elde edilebiliyordu. Ancak Python 3.7 ile birlikte artık anahtarlar onların sözlüğe 
    eklenme sırasına göre elde edilmektedir. İşte eski versiyonlarda sözlük anahtarlarının eklenme sırasına göre elde edilebilmesini sağlamak için
    standart kütüphanede collections modülü içerisine OrderedDict sınıfı yerleştirilmişti. Burada Sequential sınıfının bu örnek özniteliklerini bizim verdiğimiz
    sırada elde etmesi gerekmektedir. Bu nedenle OrderedDict kullanılmıştır. Her ne kadar artık OrderedDict yerine Python 3.7 ve sonrasında 
    normal sözlükler kullanılabiliyorsa da PyTorch buna halen izin vermemektedir.)

    Aşağıda Boston Housing Prices veri kümesi için Modül sınıfından türetme yapmak yerine Sequential sınıfının kullanılmasına 
    örnek verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np

dataset = np.loadtxt('housing.csv')
dataset_x = dataset[:, :-1]
dataset_y = dataset[:, -1]

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.20)

import torch

training_tensor_x = torch.tensor(training_dataset_x)
training_tensor_y = torch.tensor(training_dataset_y)

test_tensor_x = torch.from_numpy(test_dataset_x)
test_tensor_y = torch.from_numpy(test_dataset_y)

from torch.utils.data import TensorDataset, DataLoader

training_dataset = TensorDataset(training_tensor_x, training_tensor_y)
test_dataset = TensorDataset(test_tensor_x, test_tensor_y)

training_dataloader = DataLoader(training_dataset, batch_size=32)
test_dataloader = DataLoader(test_dataset, batch_size=32)

from torch.nn import Sequential, Linear, ReLU
from collections import OrderedDict

sequential = Sequential(OrderedDict([
    ('hidden1', Linear(training_tensor_x.shape[1], 64)), 
    ('relu1', ReLU()), 
    ('hidden2', Linear(64, 64)),
    ('relu2', ReLU()),
    ('output', Linear(64, 1))
    ]))

#----------------------------------------------------------------------------------------------------------------------------
    Pekiyi Dataset nesnesi ve Dataloader nesnesini oluşturduk. Yapay sinir ağımızı bir Module sınıfı ile temsil ettik. 
    Şimdi ne yapacağız? İşte artık ağı eğitmemiz gerekmektedir. Anımsanacağı gibi ağın eğitilmesi için minimize edilmesi gereken bir
    fonksiyona ve minimizasyon işlemini yapan bir algoritmaya gereksinim vardır. Anımsayacağınız gibi biz Keras'ta minimize edilecek fonksiyona 
    "loss" fonksiyonu, bunu minimize etmek için kullanılacak alagoritmaya da "optimizer" diyorduk.

    O halde bizim eğitim için bir loss fonksiyonuna bir de optimizasyon algoritmasına ihtiyacımız vadır. PyTorch'ta loss fonksiyonları ve optimizasyon 
    algortimaları sınıflarla temsil edilmiştir. Loss fonksiyonlarına ilişkin PyTorch sınıflarının ismi XXXLoss biçimindedir. Loss sınıfları 
    türünden nesneler yaratıldıktan sonra bu nesnelerle loss sınıflarının __call__  metotları çağrıldığında bu metotlar bu loss değerini hesaplamaktadır. 
    Aşağıdaki örnekte BCELoss (Binary Cross Entorpy Loss) sınıfının nasıl kullanıldığına gösterilmiştir. Burada rastgele x ve y değerleri alınmıştır. 
    y değerleri ikili kategorik değerlerdir. loss nesnesinin __call__ metodu "Binary Cross Entropy" değerini bize vermektedir. 
#----------------------------------------------------------------------------------------------------------------------------

import torch
from torch.nn import BCELoss

loss = BCELoss()

yhat = torch.rand(64)
y = torch.randint(0, 2, (64, ), dtype=torch.float)

result = loss(yhat, y)
print(result)

#----------------------------------------------------------------------------------------------------------------------------
    Optimizer sınıfları torch.optim modülünde bulunmaktadır. Örneğin bu modüldeki Adam sınıfı Adam optimizasyonu yapmaktadır. Örneğin:

    from torch.optimn import Adam

    optimizer = Adam(params)

    Optimizasyon sınıfları birinci parametre olarak bizden güncellenecek w değerlerini istemektedir. Güncellenecek w değerleri aslında
    katman  nesnelerinin içerisindedir. Onları katman nesnelerinin içerisinden alıp optimizasyon sınıfına vermek gerekir. Ancak bu işlem kolay değildir. 
    İşte PyTorch'ta Module sınıfının parameters isimli metodu örnek özniteliklerine atanmış olan katman nesnelerinin içerisindeki w değerlerini
    alıp bir tensör biçiminde vermektedir. Tabii parameters metodu katman nesnelerinin içertisindeki w değerlerini kopyalayarak değil bir view
    nesnesi biçiminde vermektedir. (Yani burada yapılan değişiklikler gerçek kaynağı etkilemektedir.) O halde optimizasyon sınıflarına 
    ilişkin nesneler tipik olarak şöyle yaratılmalıdır:

    from torch.optimn import Adam

    optimizer = Adam(mm.parameters())

    Optimizer algoritma sınıflarının __init__ metotlarının çeşitli parametreleri vardır. En tipik parametre lr isimli "learning rate"
    belirten parametredir. Bazı sınıflarda bu lr parametresi defauşt değer almıştır. Bazı sınıflarda almamaıştır. Örneğin 
    SGD (Stochastic Gradient Descent) sınıfında biz lr parametresini girmek zorundayız:

    from torch.optim import SGD

    optimizer = SGD(sequential.parameters(), lr=0.001)

    Aşağıdaki örnekte Boston Housing Prices veri kümesi için MSELoss ve SGD sınıf nesneleri oluşturulmuştur.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np

dataset = np.loadtxt('housing.csv', dtype='float32')
dataset_x = dataset[:, :-1]
dataset_y = dataset[:, -1]

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.20)

import torch

training_tensor_x = torch.tensor(training_dataset_x)
training_tensor_y = torch.tensor(training_dataset_y)

test_tensor_x = torch.from_numpy(test_dataset_x)
test_tensor_y = torch.from_numpy(test_dataset_y)

from torch.utils.data import TensorDataset, DataLoader

training_dataset = TensorDataset(training_tensor_x, training_tensor_y)
test_dataset = TensorDataset(test_tensor_x, training_tensor_y)

training_dataloader = DataLoader(training_dataset, batch_size=32, shuffle=True)
test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=True)

from torch.nn import Linear, ReLU   
from torch.nn import Sequential

sequential = Sequential(
    Linear(training_tensor_x.shape[1], 64), 
    ReLU(), 
    Linear(64, 64), 
    ReLU(), 
    Linear(64, 1))

from torch.nn import MSELoss
from torch.optim import SGD

loss = MSELoss()
optimizer = SGD(sequential.parameters(), lr=0.001)

#----------------------------------------------------------------------------------------------------------------------------
    Yukarıda eğitim için gereken nesneleri oluşturmuş olduk. Şimmdi artık eğitimin kendisini gerçekletirmemiz gerekir. Eğitim 
    Keras'taki gibi tek bir metotla yapılmamaktadır. PyTorch bu anlamda daha düşük seviyeli bir kütüphanedir. Eğitimin döngü içerisinde
    programcının çabasıyla yapılması gerekmektedir. Eğitim için tipik olarak iç içe iki döngülü bir yapı kullanılır. Dıştaki döngü
    epoch döngüsüdür. Yani veri kümesinin kaç defa gözden geçirileceğini belirtir. İçteki döngü ise batch döngüsüdür. İçteki döngüde veri kümesi
    batch batch elde edilmeli, bir batch'lik bilgi sinir ağına sokulmalı ve buradan bir sonuç elde edilmelidir. Bu sonuç gerçek sonuçla loss fonksiyonuna 
    sokulmalı ve buradan da bir loss değer elde edilmelidir. Sonra bu değere dayalı olarak optimizasyon nesnesi yoluyla w değerleri güncellenmelidir.
    Tabii iç döngüde veri kümesini batch batch ele almak için DataLoader sınıfından faydalanılmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    PyTorch'ta sinir ağının eğitilmesi işlemi tipik olarak şöyle yapılmaktadır:

    - İç içe iki döngü oluşturulmalıdır. Döngülerden dıştaki epoch'ları oluşturmalı içteki ise o epoch'taki batch'leri oluşturmalıdr. 
    Örneğin:

    for epoch in range(EPOCHS):
        for x, y in dataloader:
            ...

    Burada iç döngüde DataLoader nesnesi dolaşılmıştır. Anımsanacağı gibi DataLoader nesnesi her dolaşıldığında bize bir batch'lik
    bilgiyi x ve y olarak vermektedir. Artık bizim iç döngü içerisinde bilgileri batch batch işleme sokmamız gerekir. 

    - Batch işlemleri yapılırken her zaman olmasa da çoğu zaman elde edilen gradient değerlerin kümülatif toplanmaması için yani 
    her döngüde sıfırlanması için optimizer nesnesi ile zero_grad metodu çağrılmalıdır:

    optimizer.zero_grad()

    PyTorch tensörler üzerinde otomatik gradient hesap yapabilmektedir. Optimizer nesnesi de default durumda bu gradient değerleri üst 
    üste toplar. Bu kümülatif toplam bazı ağ modellerinde gerekiyor olsa da çoğu modelde gerekmemektedir.

    Bundan sonra bir batch'lik x verisi sinir ağına sokulup oradan y değerleri elde edilmelidir. Anımssanacağı gibi modül nesnesi 
    fonksiyon çağırma operatörü ile çağrıldığında aslında sınıfın forward metdou çağrılmaktaydı. Bu fprward metodunun çıktısını 
    biz elde etmekteydik. Örneğin:

    pred_y = mm(x)

    - Bir batch'lik x değeri sinir ağına sokulduktan sonra buradan elde edilen y değeri ile gerçek y değeri loss fonksiyonuna 
    sokularak loss değeri hesaplanmalıdır:

    lossval = loss(pred_y.flatten(), y)

    Sinir ağının son katmanından nx1 biçiminde iki boyutlu bir y değeri elde edilmektedir. Halbuki loss fonksiyonları
    bizden tek boyutlu y değerlerini almak istemektedir. Bu nedenle ağdan elde edilen değer Tensor sınıfının flatten metodu 
    ile tek boyuta indirgenmiştir. 

    - Loss değeri elde edildikten sonra buradan optimizasyon için ilerlenecek doğrultunun elde edilmesi gerekmektedir. Başka bir 
    deyişle bu loss değerinden hareketle her bir özellik için gradient vektörlerinin hesaplanması gerekmektedir. Bu işlem Tensor sınıflarının 
    backward metotlarıyla yapılmaktadır. Örneğin:

    lossval.backward()

    Bu metot graf üzerinde geriye giderek gradient hesaplarını yaparak bu gradient değerleri saklamaktadır.

    - Artık w değerlerinin güncellenmesi aşamasına gelinmiştir. Bu işlem de optimizer sınıflarının step metoduyla yapılmaktadır. Örneğin:

    optimizer.step()  

    Böylece eğitim kodu aşağıdaki gibi bir çatıya sahip olacaktır:

    from torch.nn import MSELoss
    from torch.optim import Adam

    loss = MSELoss()
    optimizer = Adam(mm.parameters(), lr=0.001)

    EPOCHS = 1000

    for epoch in range(EPOCHS):
        for x, y in dataloader:
            optimizer.zero_grad()       # gradient'lerin kümülatif olmamasını sağlar
            
            pred_y = mm(x)
            lossval = loss(pred_y.flatten(), y)
            
            lossval.backward()          # gradient vektörleri hesaplar
            optimizer.step()            # modelin w parametrelerini günceller 

    Aşağıda Boston Housing Prices veri kümesi üzerinde bu işlemler yapılmıştırç.
#----------------------------------------------------------------------------------------------------------------------------
   
import numpy as np

EPOCHS = 100
BATCH_SIZE = 32

dataset = np.loadtxt('housing.csv', dtype='float32')
dataset_x = dataset[:, :-1]
dataset_y = dataset[:, -1]

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.20)

from sklearn.preprocessing import MinMaxScaler

mms = MinMaxScaler()
mms.fit(training_dataset_x)

scaled_training_dataset_x = mms.transform(training_dataset_x)
scaled_test_dataset_x = mms.transform(test_dataset_x)

import torch

training_tensor_x = torch.tensor(scaled_training_dataset_x)
training_tensor_y = torch.tensor(training_dataset_y)

test_tensor_x = torch.tensor(test_dataset_x)
test_tensor_y = torch.tensor(scaled_test_dataset_x)

from torch.utils.data import TensorDataset, DataLoader

training_dataset = TensorDataset(training_tensor_x, training_tensor_y)
test_dataset = TensorDataset(test_tensor_x, test_tensor_y)

dataloader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)

from torch.nn import Linear, ReLU   
from torch.nn import Module

class MyModule(Module):
    def __init__(self, input_size):
        super().__init__()
        self.input_size = input_size
        
        self.hidden1 = Linear(input_size, 64)
        self.hidden2 = Linear(64, 64)
        self.output = Linear(64, 1)
        
        self.relu = ReLU()
                
    def forward(self, x):
       x = self.hidden1(x)
       x = self.relu(x)
       x = self.hidden2(x)
       x = self.relu(x)
       x = self.output(x)
        
       return x
        
mm = MyModule(training_tensor_x.shape[1])
       
from torch.nn import MSELoss
from torch.optim import Adam

mse_loss = MSELoss()
optimizer = Adam(mm.parameters(), lr=0.001)

for epoch in range(EPOCHS):
    for x, y in dataloader:
        optimizer.zero_grad()       # gradient'lerin kümülatif olmamasını sağlar
        
        pred_y = mm(x)
        lossval = mse_loss(pred_y.flatten(), y)
        
        lossval.backward()          # gradient vektörleri hesaplar
        optimizer.step()            # modelin w parametrelerini günceller          
        
    print(epoch, end=' ')

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de elde ettiğimiz modeli test edelim. Modelin test edilmesi oldukça basittir. Test verilerini modül nesnesine sokarak tek 
    hamlede bütün değerleri tahmin edip metrik bir değer elde edebiliriz. Yukarıdaki örnekte iki metrik değeri elde etmek isteyelim. Bunlar
    "mean squared error" ve "mean absolute error" olsun. İşin bu kısmını scikit-learn kullanarak yapabiliriz. Ya da bu kısmını yine PyTorch 
    ile de yapabiliriz. "Mean Absolute Error" işlemi PyTorch'ta L1Loss isimli sınıfla temsil edilmiştir. 

    Aşağıdaki örnekte test sonucunda "mean squaared error" ve "mean absolute error" değerleri hem PyTorch sınıfları ile hem de scikit-learn
    fonksiyonları ile elde edilmiştir. PyTorch sınıflarının bizden tensör nesneleri istediğine halbuki sckit-learn fonksiyonlarının bizden NumPy 
    dizisi istediklerine dikkat ediniz.    
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np

EPOCHS = 100
BATCH_SIZE = 32

dataset = np.loadtxt('housing.csv', dtype='float32')
dataset_x = dataset[:, :-1]
dataset_y = dataset[:, -1]

from sklearn.model_selection import train_test_split

training_dataset_x, test_dataset_x, training_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.20)

from sklearn.preprocessing import MinMaxScaler

mms = MinMaxScaler()
mms.fit(training_dataset_x)

scaled_training_dataset_x = mms.transform(training_dataset_x)
scaled_test_dataset_x = mms.transform(test_dataset_x)

import torch

scaled_training_tensor_x = torch.tensor(scaled_training_dataset_x)
training_tensor_y = torch.tensor(training_dataset_y)

scaled_test_tensor_x = torch.tensor(scaled_test_dataset_x)
test_tensor_y = torch.tensor(test_dataset_y)

from torch.utils.data import TensorDataset, DataLoader

training_dataset = TensorDataset(scaled_training_tensor_x, training_tensor_y)
dataloader = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)

from torch.nn import Linear, ReLU   
from torch.nn import Module

class MyModule(Module):
    def __init__(self, input_size):
        super().__init__()
        self.input_size = input_size
        
        self.hidden1 = Linear(input_size, 64)
        self.hidden2 = Linear(64, 64)
        self.output = Linear(64, 1)
        
        self.relu = ReLU()
                
    def forward(self, x):
       x = self.hidden1(x)
       x = self.relu(x)
       x = self.hidden2(x)
       x = self.relu(x)
       x = self.output(x)
        
       return x
        
mm = MyModule(scaled_training_tensor_x.shape[1])
       
from torch.nn import MSELoss, L1Loss
from torch.optim import Adam

mse_loss = MSELoss()
optimizer = Adam(mm.parameters(), lr=0.001)

for epoch in range(EPOCHS):
    for x, y in dataloader:
        optimizer.zero_grad()       # gradient'lerin kümülatif olmamasını sağlar
        
        pred_y = mm(x)
        lossval = mse_loss(pred_y.flatten(), y)
        
        lossval.backward()          # gradient vektörleri hesaplar
        optimizer.step()            # modelin w parametrelerini günceller          
        
    print(epoch, end=' ')
    
print()

predict_y = mm(scaled_test_tensor_x)

mae_loss = L1Loss()

mse = mse_loss(test_tensor_y, predict_y.flatten()).item()
print(f'Mean Squared Error: {mse}')

mae = mae_loss(test_tensor_y, predict_y.flatten()).item()
print(f'Mean Absolute Error: {mae}')

from sklearn.metrics import mean_squared_error, mean_absolute_error

mse = mean_squared_error(test_dataset_y, predict_y.detach().numpy())
print(f'Mean Squared Error: {mse}')

mae = mean_absolute_error(test_dataset_y, predict_y.detach().numpy())
print(f'Mean Absolute Error: {mae}')

#----------------------------------------------------------------------------------------------------------------------------
    Biz yukarıdaki işlemlerde epoch'lar bittiğinde bir sınama (validation) işlemi yapmadık. Anımsanacağı gibi bu sınama işlemi 
    Keras'ta fit metodu tarafından otomatik yapılıyordu. PyTorch ve Tensorflow daha düşük seviyeli kütüphanelerdir. Bu işlemlerin 
    programcı tarafındna manuel bir biçimde yapılması gerekmektedir. 

    Sınama işlemleri için bizim sınama verilerini kendimizin oluşturması gerekir. Örneğin biz veri kümesini eğitim ve test olmak üzere 
    ikiye ayırdıktan sonra eğitim veri kümesini de yenidne ikiye ayırıp sınama kümesini oluşturabiliriz:

    dataset = np.loadtxt('housing.csv', dtype='float32')
    dataset_x = dataset[:, :-1]
    dataset_y = dataset[:, -1]

    from sklearn.model_selection import train_test_split

    temp_dataset_x, test_dataset_x, temp_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.20)
    training_dataset_x, validation_dataset_x, training_dataset_y, validation_dataset_y = train_test_split(temp_dataset_x, temp_dataset_y, test_size=0.20)

    from sklearn.preprocessing import MinMaxScaler

    mms = MinMaxScaler()
    mms.fit(training_dataset_x)

    scaled_training_dataset_x = mms.transform(training_dataset_x)
    scaled_validation_dataset_x = mms.transform(validation_dataset_x)
    scaled_test_dataset_x = mms.transform(test_dataset_x)
    
    Pekiyi bir epoch'taki sınama değeri nasıl elde edilmelidir? En normal durum epoch içerisindeki her batch'ten elde edilen 
    metirk değerin ortlamasının hesaplanmasıdır. Örneğin bir epoch'un 50 tane batch'ten oluştuğunu düşünelim. Bizim 50 batch'ten 
    tek tek elde ettiğimiz metrik değerlerin ortalamasını hesaplamamız gerekmektedir. Tabii her epoch'un metrik ortalamalarını da 
    bizim bir listede toplamamaız uygun olur. Çünkü epoch'lara metrik değerlerin grafiğini çizmek isteriz. Tabii Keras tüm bunları aynı 
    bu biçimde kendisi yapmaktadır. Keras'ta da aslında bir epoch sonucunda verilen metrik değerler o epoch'taki batch'lerden elde 
    edilen metrik değerlerin ortalamasıdır. 

    Şimdi sınama işleminin nasıl yapılması gerektiği üzerinde üzerinde duralım. Sınama işleminin eğitim ile birlikte değil epoch bittikten 
    sonra eğitimden bağımsız olarak yapılması gerekmektedir. Bu işlem PyTorch'ta iki adımda yürütülebilir:

    1) Önce tıpkı eğitim verilerinde yapıldığı gibi sınama verileri için de ayrı DataLoader nesnesi oluşturulur.

    2) Sonra ppoch döngüsünün içerisinde eğitim döngüsünün altında benzer bir sınama döngüsü oluşturulur. Tabii bu döngünün amacı eğitim yapmak 
    değil sınanama yapmaktır. Yani sınama verileriyle kestirim yapmaktır. Ancak model üzerinde sınama yapılırken loss fonksiyonları 
    da çalıştırılacaktır. İşte bu sırada model üzerinde bazı işlemlerin yapılmaması gerekir. PyTorch tarasımcıları modeli temsil eden Module 
    sınıfı için iki mod oluşturmuşlardır: train ve eval modları. Default durum train modudur. eval modunda modelin bazı kısımları disable edilmektedir. 
    Böylece modelin bozulması engellenmektedir. eval moduna geçmek için Module sınıfının eval metodu, tekrar train moduna geçmek için Module
    sınıfının train metodu kullanılmaktadır. Ayrıca bu geçişi kolaylaştırmak için torch modülünde no_grad isimli bir fonksiyon bulundurulmuştur. Bu fonksiyon bize
    bir bağlam yönetim nesnesi vermektedir. Bu nesnenin __enter__ metodu eval metodunu çağırmakta __exit__ metodu ise train metodunu çağırmaktadır. 

    with torch.no_grad():
        pass

    Pekiyi train ve eval modlarının anlamı nedir? İşte bazı işlemler eğitim sırasında yapılırken sınama sırasında yapılmamlıdır. Örneğin
    modelde dropout işlemleri eğitim sırasında yapılması gereken ancak sınama sırasında yapılmaması gereken işlemlerdir. Ayrıca PyTorch'ta 
    tensörler için otomatik gradient hesapları yapılmaktadır. Bu hesaplar hem zaman alır hem de eğitim için bazı durumlarda çakışma 
    oluşturabilmektedir. 

    Aşağıda Boston Housing Prices örneği PyTorch ile sınama işlemi de dahil edilerek gerçekleştirilmiştir. Burada sınama işlemi de 
    test işlemi de yine batch batch yapılmıştır. 
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np

EPOCHS = 100
BATCH_SIZE = 32

dataset = np.loadtxt('housing.csv', dtype='float32')
dataset_x = dataset[:, :-1]
dataset_y = dataset[:, -1]

from sklearn.model_selection import train_test_split

temp_dataset_x, test_dataset_x, temp_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.20)

training_dataset_x, validation_dataset_x, training_dataset_y, validation_dataset_y = train_test_split(temp_dataset_x, temp_dataset_y, test_size=0.20)

from sklearn.preprocessing import MinMaxScaler

mms = MinMaxScaler()
mms.fit(training_dataset_x)

scaled_training_dataset_x = mms.transform(training_dataset_x)
scaled_validation_dataset_x = mms.transform(validation_dataset_x)
scaled_test_dataset_x = mms.transform(test_dataset_x)

import torch

scaled_training_tensor_x = torch.tensor(scaled_training_dataset_x)
training_tensor_y = torch.tensor(training_dataset_y)

scaled_validation_tensor_x = torch.tensor(scaled_validation_dataset_x)
validation_tensor_y = torch.tensor(validation_dataset_y)

scaled_test_tensor_x = torch.tensor(scaled_test_dataset_x)
test_tensor_y = torch.tensor(test_dataset_y)

from torch.utils.data import TensorDataset, DataLoader

training_dataset = TensorDataset(scaled_training_tensor_x, training_tensor_y)
training_dl = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)

validation_dataset = TensorDataset(scaled_validation_tensor_x, validation_tensor_y)
validation_dl = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)

test_dataset = TensorDataset(scaled_test_tensor_x, test_tensor_y)
test_dl = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)

from torch.nn import Linear, ReLU   
from torch.nn import Module

class MyModule(Module):
    def __init__(self, input_size):
        super().__init__()
        self.input_size = input_size
        
        self.hidden1 = Linear(input_size, 64)
        self.hidden2 = Linear(64, 64)
        self.output = Linear(64, 1)
        
        self.relu = ReLU()
                
    def forward(self, x):
       x = self.hidden1(x)
       x = self.relu(x)
       x = self.hidden2(x)
       x = self.relu(x)
       x = self.output(x)
        
       return x
        
mm = MyModule(scaled_training_tensor_x.shape[1])
       
from torch.nn import MSELoss, L1Loss
from torch.optim import Adam

mse_loss = MSELoss()
optimizer = Adam(mm.parameters(), lr=0.001)

training_mse_list = []
validation_mse_list = []

training_count = np.ceil(len(training_dataset_x) / BATCH_SIZE)
validation_count = np.ceil(len(validation_dataset_x) / BATCH_SIZE)
test_count = np.ceil(len(test_dataset_x) / BATCH_SIZE)

for epoch in range(EPOCHS):
    mm.train()
    total_mse = 0
    for x, y in training_dl:
        optimizer.zero_grad()       # gradient'lerin kümülatif olmamasını sağlar
        
        pred_y = mm(x)
        lossval = mse_loss(pred_y.flatten(), y)
        total_mse += lossval.item()
        
        lossval.backward()          # gradient vektörleri hesaplar
        optimizer.step()            # modelin w parametrelerini günceller   
                
    training_mean_mse = total_mse / training_count
    training_mse_list.append(training_mean_mse )

    mm.eval()    
    total_mse = 0
    for x, y in validation_dl:
        pred_y = mm(x)
        lossval = mse_loss(pred_y.flatten(), y)
        total_mse += lossval.item()
    
    validation_mean_mse = total_mse / validation_count
    validation_mse_list.append(validation_mean_mse)
    
    print(f'#{epoch}: loss: {training_mean_mse}, validation loss: {validation_mean_mse}')            
    

import matplotlib.pyplot as plt

plt.plot(range(EPOCHS), training_mse_list)  
plt.plot(range(EPOCHS), validation_mse_list)  

plt.legend(['Training MSE', 'Validaition MSE'])
plt.show()

mae_loss = L1Loss()

total_mse = 0
total_mae = 0
for x, y in test_dl:
     pred_y = mm(x)
     lossval = mse_loss(pred_y.flatten(), y)
     total_mse += lossval.item()
     maeval = mae_loss(pred_y.flatten(), y)
     total_mae += maeval.item()
     
test_mean_mse = total_mse / test_count
test_mean_mae = total_mae / test_count

print(f'Test Mean Squared Error: {test_mean_mse}')
print(f'Test Mean Aboslute Error: {test_mean_mae}')
 
""" 
predict_y = mm(scaled_test_tensor_x)
mse = mse_loss(test_tensor_y, predict_y.flatten()).item()
print(f'Mean Squared Error: {mse}')

mae = mae_loss(test_tensor_y, predict_y.flatten()).item()
print(f'Mean Absolute Error: {mae}')
"""
#----------------------------------------------------------------------------------------------------------------------------
    PyTorch'ta kestirim nasıl yapılmaktadır? Aslında kestirim yapmak oldukça kolaydır. Tek yapılacak şey model nesnesi ile 
    __call__ metodunu çağırmaktır. 

    Aşağıdaki örnekte model eğitildikten sonra kestirim işlemi de yapılmıştır:
#----------------------------------------------------------------------------------------------------------------------------
import numpy as np

EPOCHS = 100
BATCH_SIZE = 32

dataset = np.loadtxt('housing.csv', dtype='float32')
dataset_x = dataset[:, :-1]
dataset_y = dataset[:, -1]

from sklearn.model_selection import train_test_split

temp_dataset_x, test_dataset_x, temp_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.20)

training_dataset_x, validation_dataset_x, training_dataset_y, validation_dataset_y = train_test_split(temp_dataset_x, temp_dataset_y, test_size=0.20)

from sklearn.preprocessing import MinMaxScaler

mms = MinMaxScaler()
mms.fit(training_dataset_x)

scaled_training_dataset_x = mms.transform(training_dataset_x)
scaled_validation_dataset_x = mms.transform(validation_dataset_x)
scaled_test_dataset_x = mms.transform(test_dataset_x)

import torch

scaled_training_tensor_x = torch.tensor(scaled_training_dataset_x)
training_tensor_y = torch.tensor(training_dataset_y)

scaled_validation_tensor_x = torch.tensor(scaled_validation_dataset_x)
validation_tensor_y = torch.tensor(validation_dataset_y)

scaled_test_tensor_x = torch.tensor(scaled_test_dataset_x)
test_tensor_y = torch.tensor(test_dataset_y)

from torch.utils.data import TensorDataset, DataLoader

training_dataset = TensorDataset(scaled_training_tensor_x, training_tensor_y)
training_dl = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)

validation_dataset = TensorDataset(scaled_validation_tensor_x, validation_tensor_y)
validation_dl = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)

test_dataset = TensorDataset(scaled_test_tensor_x, test_tensor_y)
test_dl = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)

from torch.nn import Linear, ReLU   
from torch.nn import Module

class MyModule(Module):
    def __init__(self, input_size):
        super().__init__()
        self.input_size = input_size
        
        self.hidden1 = Linear(input_size, 64)
        self.hidden2 = Linear(64, 64)
        self.output = Linear(64, 1)
        
        self.relu = ReLU()
                
    def forward(self, x):
       x = self.hidden1(x)
       x = self.relu(x)
       x = self.hidden2(x)
       x = self.relu(x)
       x = self.output(x)
        
       return x
        
mm = MyModule(scaled_training_tensor_x.shape[1])
       
from torch.nn import MSELoss, L1Loss
from torch.optim import Adam

mse_loss = MSELoss()
optimizer = Adam(mm.parameters(), lr=0.001)

training_mse_list = []
validation_mse_list = []

training_count = np.ceil(len(training_dataset_x) / BATCH_SIZE)
validation_count = np.ceil(len(validation_dataset_x) / BATCH_SIZE)
test_count = np.ceil(len(test_dataset_x) / BATCH_SIZE)

for epoch in range(EPOCHS):
    mm.train()
    total_mse = 0
    for x, y in training_dl:
        optimizer.zero_grad()       # gradient'lerin kümülatif olmamasını sağlar
        
        pred_y = mm(x)
        lossval = mse_loss(pred_y.flatten(), y)
        total_mse += lossval.item()
        
        lossval.backward()          # gradient vektörleri hesaplar
        optimizer.step()            # modelin w parametrelerini günceller   
                
    training_mean_mse = total_mse / training_count
    training_mse_list.append(training_mean_mse )
        
    mm.eval()
    total_mse = 0
    for x, y in validation_dl:
        pred_y = mm(x)
        lossval = mse_loss(pred_y.flatten(), y)
        total_mse += lossval.item()
    
    validation_mean_mse = total_mse / validation_count
    validation_mse_list.append(validation_mean_mse)
    
    print(f'#{epoch}: loss: {training_mean_mse}, validation loss: {validation_mean_mse}')            
    
import matplotlib.pyplot as plt

plt.plot(range(EPOCHS), training_mse_list)  
plt.plot(range(EPOCHS), validation_mse_list)  

plt.legend(['Training MSE', 'Validaition MSE'])
plt.show()

mae_loss = L1Loss()

total_mse = 0
total_mae = 0
for x, y in test_dl:
     pred_y = mm(x)
     lossval = mse_loss(pred_y.flatten(), y)
     total_mse += lossval.item()
     maeval = mae_loss(pred_y.flatten(), y)
     total_mae += maeval.item()
     
test_mean_mse = total_mse / test_count
test_mean_mae = total_mae / test_count

print(f'Test Mean Squared Error: {test_mean_mse}')
print(f'Test Mean Aboslute Error: {test_mean_mae}')
 
""" 
predict_y = mm(scaled_test_tensor_x)
mse = mse_loss(test_tensor_y, predict_y.flatten()).item()
print(f'Mean Squared Error: {mse}')

mae = mae_loss(test_tensor_y, predict_y.flatten()).item()
print(f'Mean Absolute Error: {mae}')
"""

import numpy as np

predict_data = np.array([[0.11747, 12.50, 7.870, 0, 0.5240, 6.0090, 82.90, 6.2267, 5, 311.0, 15.20, 396.90, 13.27]])
scaled_predict_tensor = torch.tensor(mms.transform(predict_data), dtype=torch.float32)

predict_result = mm(scaled_predict_tensor).item()
print(predict_result)

#----------------------------------------------------------------------------------------------------------------------------
    Tabii biz Module sınıfınından sınıf türetmeden de aynı işlemleri hazır Sequential isimli modül sınıfıyla da yapabiliriz. 
    Aşağıda buna örnek verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import numpy as np

EPOCHS = 100
BATCH_SIZE = 32

dataset = np.loadtxt('housing.csv', dtype='float32')
dataset_x = dataset[:, :-1]
dataset_y = dataset[:, -1]

from sklearn.model_selection import train_test_split

temp_dataset_x, test_dataset_x, temp_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.20)

training_dataset_x, validation_dataset_x, training_dataset_y, validation_dataset_y = train_test_split(temp_dataset_x, temp_dataset_y, test_size=0.20)

from sklearn.preprocessing import MinMaxScaler

mms = MinMaxScaler()
mms.fit(training_dataset_x)

scaled_training_dataset_x = mms.transform(training_dataset_x)
scaled_validation_dataset_x = mms.transform(validation_dataset_x)
scaled_test_dataset_x = mms.transform(test_dataset_x)

import torch

scaled_training_tensor_x = torch.tensor(scaled_training_dataset_x)
training_tensor_y = torch.tensor(training_dataset_y)

scaled_validation_tensor_x = torch.tensor(scaled_validation_dataset_x)
validation_tensor_y = torch.tensor(validation_dataset_y)

scaled_test_tensor_x = torch.tensor(scaled_test_dataset_x)
test_tensor_y = torch.tensor(test_dataset_y)

from torch.utils.data import TensorDataset, DataLoader

training_dataset = TensorDataset(scaled_training_tensor_x, training_tensor_y)
training_dl = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)

validation_dataset = TensorDataset(scaled_validation_tensor_x, validation_tensor_y)
validation_dl = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)

test_dataset = TensorDataset(scaled_test_tensor_x, test_tensor_y)
test_dl = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)

from torch.nn import Linear, ReLU, Sequential
        
mm = Sequential(Linear(dataset_x.shape[1], 64),  ReLU(),  Linear(64, 64), ReLU(),  Linear(64, 1))
       
from torch.nn import MSELoss, L1Loss
from torch.optim import Adam

mse_loss = MSELoss()
optimizer = Adam(mm.parameters(), lr=0.001)

training_mse_list = []
validation_mse_list = []

training_count = np.ceil(len(training_dataset_x) / BATCH_SIZE)
validation_count = np.ceil(len(validation_dataset_x) / BATCH_SIZE)
test_count = np.ceil(len(test_dataset_x) / BATCH_SIZE)

for epoch in range(EPOCHS):
    mm.train()
    total_mse = 0
    for x, y in training_dl:
        optimizer.zero_grad()       # gradient'lerin kümülatif olmamasını sağlar
        
        pred_y = mm(x)
        lossval = mse_loss(pred_y.flatten(), y)
        total_mse += lossval.item()
        
        lossval.backward()          # gradient vektörleri hesaplar
        optimizer.step()            # modelin w parametrelerini günceller   
                
    training_mean_mse = total_mse / training_count
    training_mse_list.append(training_mean_mse )
        
    mm.eval()
    total_mse = 0
    for x, y in validation_dl:
        pred_y = mm(x)
        lossval = mse_loss(pred_y.flatten(), y)
        total_mse += lossval.item()
    
    validation_mean_mse = total_mse / validation_count
    validation_mse_list.append(validation_mean_mse)
    
    print(f'#{epoch}: loss: {training_mean_mse}, validation loss: {validation_mean_mse}')            
    
import matplotlib.pyplot as plt

plt.plot(range(EPOCHS), training_mse_list)  
plt.plot(range(EPOCHS), validation_mse_list)  

plt.legend(['Training MSE', 'Validaition MSE'])
plt.show()

mae_loss = L1Loss()

total_mse = 0
total_mae = 0
for x, y in test_dl:
     pred_y = mm(x)
     lossval = mse_loss(pred_y.flatten(), y)
     total_mse += lossval.item()
     maeval = mae_loss(pred_y.flatten(), y)
     total_mae += maeval.item()
     
test_mean_mse = total_mse / test_count
test_mean_mae = total_mae / test_count

print(f'Test Mean Squared Error: {test_mean_mse}')
print(f'Test Mean Aboslute Error: {test_mean_mae}')
 
""" 
predict_y = mm(scaled_test_tensor_x)
mse = mse_loss(test_tensor_y, predict_y.flatten()).item()
print(f'Mean Squared Error: {mse}')

mae = mae_loss(test_tensor_y, predict_y.flatten()).item()
print(f'Mean Absolute Error: {mae}')
"""

import numpy as np

predict_data = np.array([[0.11747, 12.50, 7.870, 0, 0.5240, 6.0090, 82.90, 6.2267, 5, 311.0, 15.20, 396.90, 13.27]])
scaled_predict_tensor = torch.tensor(mms.transform(predict_data), dtype=torch.float32)

predict_result = mm(scaled_predict_tensor).item()
print(predict_result)

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi ikili sınıflandırma işlemi için kestirim yapalım. Aşağıda daha önce üzerinde çalışmış olduğumuz "Breast Cancer Winconsin" 
    verileri üzerinde ikili sınıflandırma örneği verilmiştir. İkili sınıflandırma problemleri için kullanılacak loss fonksiyonun 
    genel olarak "binary cross entropy" alındığına dikkat ediniz. PyTorch'ta bu loss fonksiyonu BCELoss sınıfı ile temsil edilmiştir. 
    Accuracy ölçümü basit bir biçimde manuel ya da sckit-learn kullanılarak yapılabilir. Ancak biz burada PyTorch ekosistemi 
    içerisindeki torchmetrics isimli pakette bulunan Accuracy sınıfınından faydalandık. torchmetrics paketinin ayrıca aşağıdaki
    gibi yüklenmesi gerekmektedir:

    pip install torchmetrics
#----------------------------------------------------------------------------------------------------------------------------
EPOCHS = 200
BATCH_SIZE = 32

import pandas as pd

dataset_df = pd.read_csv('breast-cancer-data.csv')
dataset_x = dataset_df.iloc[:, 2:-1].to_numpy(dtype='float32')
dataset_y = (dataset_df['diagnosis'] == 'M').to_numpy(dtype='float32')

from sklearn.model_selection import train_test_split

temp_dataset_x, test_dataset_x, temp_dataset_y, test_dataset_y = train_test_split(dataset_x, dataset_y, test_size=0.15)

training_dataset_x, validation_dataset_x, training_dataset_y, validation_dataset_y = \
        train_test_split(temp_dataset_x, temp_dataset_y, test_size=0.15)

from sklearn.preprocessing import MinMaxScaler

mms = MinMaxScaler()
mms.fit(training_dataset_x)

scaled_training_dataset_x = mms.transform(training_dataset_x)
scaled_validation_dataset_x = mms.transform(validation_dataset_x)
scaled_test_dataset_x = mms.transform(test_dataset_x)

import torch

scaled_training_tensor_x = torch.tensor(scaled_training_dataset_x)
training_tensor_y = torch.tensor(training_dataset_y)

scaled_validation_tensor_x = torch.tensor(scaled_validation_dataset_x)
validation_tensor_y = torch.tensor(validation_dataset_y)

scaled_test_tensor_x = torch.tensor(scaled_test_dataset_x)
test_tensor_y = torch.tensor(test_dataset_y)

from torch.utils.data import TensorDataset, DataLoader

training_dataset = TensorDataset(scaled_training_tensor_x, training_tensor_y)
training_dl = DataLoader(training_dataset, batch_size=BATCH_SIZE, shuffle=True)

validation_dataset = TensorDataset(scaled_validation_tensor_x, validation_tensor_y)
validation_dl = DataLoader(validation_dataset, batch_size=BATCH_SIZE, shuffle=True)

test_dataset = TensorDataset(scaled_test_tensor_x, test_tensor_y)
test_dl = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)

from torch.nn import Linear, ReLU, Sigmoid, Sequential
        
model = Sequential(Linear(dataset_x.shape[1], 64),  ReLU(),  Linear(64, 64),  ReLU(), Linear(64, 1), Sigmoid())

from torch.nn import BCELoss, L1Loss
from torch.optim import Adam
from torchmetrics import Accuracy
import numpy as np
bce_loss = BCELoss()
optimizer = Adam(model.parameters(), lr=0.001)

training_bce_list = []
validation_bce_list = []

training_count = np.ceil(len(training_dataset_x) / BATCH_SIZE)
validation_count = np.ceil(len(validation_dataset_x) / BATCH_SIZE)
test_count = np.ceil(len(test_dataset_x) / BATCH_SIZE)

for epoch in range(EPOCHS):
    model.train()
    total_bce = 0
    for x, y in training_dl:
        optimizer.zero_grad()       # gradient'lerin kümülatif olmamasını sağlar
        
        pred_y = model(x)
        lossval = bce_loss(pred_y.flatten(), y)
        total_bce += lossval.item()
        
        lossval.backward()          # gradient vektörleri hesaplar
        optimizer.step()            # modelin w parametrelerini günceller   
                
    training_mean_bce = total_bce / training_count
    training_bce_list.append(training_mean_bce )
        
    model.eval()
    total_mse = 0
    for x, y in validation_dl:
        pred_y = model(x)
        lossval = bce_loss(pred_y.flatten(), y)
        total_mse += lossval.item()
    
    validation_mean_bce = total_mse / validation_count
    validation_bce_list.append(validation_mean_bce)
    
    print(f'#{epoch}: loss: {training_mean_bce}, validation loss: {validation_mean_bce}')            
    
import matplotlib.pyplot as plt

plt.plot(range(EPOCHS), training_bce_list)  
plt.plot(range(EPOCHS), validation_bce_list)  

plt.legend(['Training MSE', 'Validaition MSE'])
plt.show()

accuracy = L1Loss()
accuracy = Accuracy(task='binary')

total_bce = 0
total_accuracy = 0
for x, y in test_dl:
     pred_y = model(x)
     lossval = bce_loss(pred_y.flatten(), y)
     total_bce += lossval.item()
     accuracy.update(pred_y.flatten(), y)
     total_accuracy += accuracy.compute()
         
test_mean_bce = total_bce / test_count
test_mean_accuracy = total_accuracy / len(test_dl)

print(f'Test Mean BCE Loss: {test_mean_bce}')
print(f'Test Accuracy: {test_mean_accuracy}')
 
#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de evrişim içeren bir resim sınıflandırma örneği verelim. CIFAR-10 veri kümesini daha önce birkaç kez kullanmıştık Bu veri 
    kümesinde her biri 32x32'lik RGB resimler bulunuyordu. Bu resimler aşağıdaki nesnelerden birine ilişkindir:

    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

    Bu tür veri kümeleri torchvision içerisinde hazır bir biçimde bulunmaktadır. Gerçekten de torchvision.datasets içerisindeki CIFAR10 sınıfı 
    bu verileri indirerek bize Dataset nesnesi biçiminde veriyordu.

    Aşağıdaki örnekte kritik birkaç nokta üzerinde durmak istiyoruz:

    1) Bu örnekte evrişim katmanı kullanılmamıştır. Linear katmanlar iki boyutlu tensörlerle çalışmaktadır. Halbuki CIFAR10 sınıfı ile bize 
    verilen resimler 32X32X3 boyutlarındadır. Bu nedenle biz forward metodunun başında bunu Linear katmanına uygun biçimde iki boyut haline getirdik.

    2) Softmax sınıfı yine toplamları 1 olan örneğimizde 10 tane değerleri bie vermektedir. Yani ağımızın çıktısı her batch işleminde
    BATCH_SIZE X 10 biçiminde bir tensörü bize vermektedir. 

    3) loss fonksiyonu olarak CrossEntropyLoss alınmıştır. Bu Keras'taki "categorical_crossentropy" loss fonksiyonuna karşılık gelmektedir. loss 
    fonksiyonu çağrılırken softmax değerlerini ve label değerlerini parametre olarak almaktadır. 

    4) Eğitim sırasında validation yapılmamıştır. Test işlemi yine CIFAR10 sınıfının bize verdiği test dataset nesnesi yoluyla yapılmıştır. Test işlemi sırasında
    her batch işlemindeki isabet sayıları toplanıp toplam test veri  sayısına bölünmüştür. 
#----------------------------------------------------------------------------------------------------------------------------
   
BATCH_SIZE = 32
EPOCHS = 5

import ssl
ssl._create_default_https_context = ssl._create_unverified_context

from  torchvision.datasets import CIFAR10

from torchvision.transforms import Compose, Normalize, ToTensor

compose = Compose([ToTensor(), Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])
         
from torchvision.transforms import ToTensor

training_dataset = CIFAR10(root='cifar10x-data', train=True, download=True, transform=compose)
test_dataset = CIFAR10(root='cifar10-data', train=False, download=True, transform=compose)

from torch.utils.data import DataLoader

training_dl = DataLoader(training_dataset, batch_size=BATCH_SIZE)
test_dl = DataLoader(test_dataset, batch_size=BATCH_SIZE)

from torch.nn import Module, Linear, ReLU, Softmax, CrossEntropyLoss

class CifarModule(Module):
    def __init__(self):
        super().__init__()
        
        self.linear1 = Linear(32 * 32 * 3, 128)
        self.linear2 = Linear(128, 128)
        self.linear3 = Linear(128, 10)
        self.relu = ReLU()
        self.softmax = Softmax(dim=1)
        
    def forward(self, x):
        x = x.view(x.shape[0], -1)      # x = torch.flatten(x, 1)
        x = self.linear1(x)
        x = self.relu(x)
        x = self.linear2(x)
        x = self.relu(x)
        x = self.linear3(x)
        x = self.softmax(x)
        
        return x
     
from torch.optim import Adam
import torch
    
cm = CifarModule()
        
loss = CrossEntropyLoss()
optimizer = Adam(cm.parameters())

epoch_losses = []

for epoch in range(EPOCHS):
    losses = []
    for x, y in training_dl:
        optimizer.zero_grad()
        
        pred_y = cm(x)
        lossval = loss(pred_y.type(torch.float32), y)
        
        lossval.backward()
        optimizer.step()
        
        losses.append(lossval.item())
        
    mean_epoch_loss = sum(losses) / len(losses)
    epoch_losses.append(mean_epoch_loss)
    
    print(f'Epoch #{epoch}, MSELoss: {mean_epoch_loss}')
        
total = 0
for x, y in test_dl:
    pred_y = cm(x)
    result = pred_y.argmax(dim=1)
    total += torch.sum(result == y)
    
accuracy = total / len(test_dataset)

#----------------------------------------------------------------------------------------------------------------------------
    Aslında biz torchvision içerisindeki CIFAR10 sınıfını kullanmak yerine verilerin Dataset sınıfı haline getirilmesini numpy ve
    sklearn kütüphanelerini kullanarak da yapabilirdik. Aşağıda bu işlemler uygulanmıştır.
#----------------------------------------------------------------------------------------------------------------------------
   
BATCH_SIZE = 32
EPOCHS = 5

import numpy as np

training_dataset = np.loadtxt('cifar10-train.csv', delimiter=',', skiprows=1, dtype=np.uint8)
training_dataset_x = training_dataset[:, :-1]
training_dataset_y = training_dataset[:, -1]

from sklearn.preprocessing import MinMaxScaler

mms = MinMaxScaler()
training_dataset_x = mms.fit_transform(training_dataset_x).astype('float32')

import torch

training_dataset_x = torch.from_numpy(training_dataset_x)
training_dataset_y = torch.from_numpy(training_dataset_y)

from torch.utils.data import TensorDataset, DataLoader

training_dataset = TensorDataset(training_dataset_x, training_dataset_y)
training_dl = DataLoader(training_dataset, batch_size=BATCH_SIZE)


from torch.nn import Module, Linear, ReLU, Softmax, CrossEntropyLoss

class CifarModule(Module):
    def __init__(self):
        super().__init__()
        
        self.linear1 = Linear(32 * 32 * 3, 128)
        self.linear2 = Linear(128, 128)
        self.linear3 = Linear(128, 10)
        self.relu = ReLU()
        self.softmax = Softmax(dim=1)
        
    def forward(self, x):
        x = x.view(x.shape[0], -1)      # x = torch.flatten(x, 1)
        x = self.linear1(x)
        x = self.relu(x)
        x = self.linear2(x)
        x = self.relu(x)
        x = self.linear3(x)
        x = self.softmax(x)
        
        return x
     
from torch.optim import Adam
import torch
    
cm = CifarModule()
        
loss = CrossEntropyLoss()
optimizer = Adam(cm.parameters())

epoch_losses = []

for epoch in range(EPOCHS):
    losses = []
    for x, y in training_dl:
        optimizer.zero_grad()
        
        pred_y = cm(x)
        lossval = loss(pred_y.type(torch.float32), y)
        
        lossval.backward()
        optimizer.step()
        
        losses.append(lossval.item())
        
    mean_epoch_loss = sum(losses) / len(losses)
    epoch_losses.append(mean_epoch_loss)
    
    print(f'Epoch #{epoch}, MSELoss: {mean_epoch_loss}')
        
#----------------------------------------------------------------------------------------------------------------------------
    CIFAR1-10 örneğini şimdi de evrişim  katmanlarını kullanarak gerçekleştirelim. 
    
    Aşağıdaki örnekte iki evrişim katmanı kullanılmıştır. Pytorch'ta evrişim katmanı Conv2D sınıfyla temsil edilmiştir. Bu sınıfın 
    __init__ metodunun ilk parametresi resimdeki "channel sayısını" belirtir. Eğer resim RGB ise ilk evrişim katmanında bu ilk parametre 3 olarak girilmelidir. 
    Metodun ikinci parametresi kullanılacak filtre sayısını ve üçüncü parametresi kullanılacak filtrenin boyutlarını (kernel size) belirtmektedir. 
    Bu üçüncü parametre iki elemanlı bir demet olarak girilebilir ya da tek bir değer olarak girilebilir. Tek değer olarak girilirse en ve boy aynı olmak 
    üzere bu değerde olur. Metodun dördüncü parametresi yine kaydırma değerini belirten stride parametresidir. Bu parametrenin default değeri 1'dir.

    Aşağıdaki örnekte sınama işlemi yapılmamıştır.  
    
#----------------------------------------------------------------------------------------------------------------------------
   
EPOCHS = 20
BATCH_SIZE = 32

import pickle
import glob

x_lst = []
y_lst = []

for path in glob.glob('cifar-10-batches-py/data_batch_*'):
    with open(path, 'rb') as f:
        d = pickle.load(f, encoding='bytes')
        x_lst.append(d[b'data'])
        y_lst.append(d[b'labels'])     

import numpy as np
        
training_dataset_x = np.concatenate(x_lst)
training_dataset_y = np.concatenate(y_lst)

with open('cifar-10-batches-py/test_batch', 'rb') as f:
    d = pickle.load(f, encoding='bytes')
    test_dataset_x = d[b'data']
    test_dataset_y = d[b'labels']

training_dataset_x = training_dataset_x / 255
test_dataset_x = test_dataset_x / 255

training_dataset_x = training_dataset_x.reshape(-1, 3, 32, 32)

from tensorflow.keras.utils import to_categorical

ohe_training_dataset_y = to_categorical(training_dataset_y)
ohe_test_dataset_y = to_categorical(test_dataset_y)

import torch
from torch.utils.data import TensorDataset, DataLoader

training_dataset_tensor_x = torch.tensor(training_dataset_x, dtype=torch.float32)
training_dataset_tensor_y = torch.tensor(ohe_training_dataset_y, dtype=torch.float32)
training_dataset = TensorDataset(training_dataset_tensor_x, training_dataset_tensor_y)
training_dl = DataLoader(training_dataset, batch_size=BATCH_SIZE)

class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']

from torch.nn import Sequential, Conv2d, Linear, ReLU, Flatten, Softmax, Module 

class MyModule(Module):
    def __init__(self):
        super().__init__()
        self.layer1 = Conv2d(3, 32, kernel_size=(3, 3), padding=1)
        self.layer2 = Conv2d(32, 64, kernel_size=(3, 3), padding=1)
        self.layer3 = Flatten()
        self.layer4 = Linear(65536, 10)
        self.layer5 = Softmax(dim=1)
        
        self.relu = ReLU()
        
    def forward(self, x):
        #print(x.shape)
        x = self.layer1(x)
        #print(x.shape)
        #x = self.relu(x)
        #print(x.shape)
        x = self.layer2(x)
        #print(x.shape)
        x = self.relu(x)
        #print(x.shape)
        x = self.layer3(x)
        #print(x.shape)
        x = self.layer4(x)
        #print(x.shape)
        x = self.layer5(x)
        #print(x.shape)
           
        return x
     
model = MyModule()

"""
model = Sequential(
    Conv2d(3, 32, kernel_size=(3, 3), padding=1), 
    ReLU(), 
    self.layer2 = Conv2d(32, 64, kernel_size=(3, 3), padding=1), 
    ReLU(), 
    Flatten(), 
    Linear(84480, 10),
    Softmax(dim=1)
)
"""
   
from torch.optim import Adam
from torch.nn import CrossEntropyLoss
 
optimizer = Adam(model.parameters(), lr=0.001)
ce_loss = CrossEntropyLoss()
training_ce_list = []

training_count = np.ceil(len(training_dataset_x) / BATCH_SIZE)

for epoch in range(EPOCHS):
    model.train()
    total_ce = 0
    count = 0
    for x, y in training_dl:
        optimizer.zero_grad()       # gradient'lerin kümülatif olmamasını sağlar
        
        pred_y = model(x)
        lossval = ce_loss(pred_y.flatten(), y.flatten())
        total_ce += lossval.item()
        
        lossval.backward()          # gradient vektörleri hesaplar
        optimizer.step()            # modelin w parametrelerini günceller   
        count += 1
        print(f'\x1b[1JEpoch {epoch + 1}: {int(count/training_count* 100)}%', end='')
                
    training_mean_ce = total_ce / training_count
    training_ce_list.append(training_mean_ce)
        
    print(f'#{epoch}: loss: {training_mean_ce}')                

import matplotlib.pyplot as plt
import glob

for path in glob.glob('test-images/*.jpg'):
    image_data = plt.imread(path)
    image_data = image_data / 255

    image_data = image_data.reshape(1, 32, 32, 3)
    image_data = np.transpose(image_data, [0, 3, 1, 2])
    image_tensor_data = torch.tensor(image_data, dtype=torch.float32)
    predict_result = model(image_tensor_data)
    
    result = predict_result.argmax()
    print(f'{path}: {class_names[result]}')

#----------------------------------------------------------------------------------------------------------------------------
    TensorFlow kütüphanesi Google öncülüğünde açık kaynak kodlu biçimde oluşturulmuş bir kütüphanedir. Makine öğrenmesi ile ilgili 
    pek çok yüksek seviyeli kütüphane TensorFlow kullanılarka yazılmış durumdadır. Tensorflow kütüphanesinin ilk sürümü 2015 yoılında
    oluşturulmuştur. Ancak kütüphanenin 2'li verisyonlarıyla birlikte önemli tasarım değişiklikleri göze çarpmaktadır. Kütüphanenin 1'li versiyonları
    nispeten uzun süredir kullanılan versiyonlarıdır. 2'li versiyonlar ise nispeten yenidir. 

    Kütüphanenin 1'li versiyonları metaprogramlama tekniğini kullanıyordu. Yani bu 1'li versiyonlarda önce yapılacak işlemler belirtiliyor.
    Böylece bir graf oluşturuluyor sonra bu graf çalıştırılıyordu. Ancak bu biçimdeki çalışma sistemi programcılar için tanıdık değildi ve
    bu biçimdeki kullanım zordu. Ancak kütüphanein 2'li versyionlarıyla birlikte bu graf oluşturma modeli "isteğe bağlı" hale getirildi. 
    Bu yeni çalışma modeli "eager execution" biçiminde isimlendirildi. 

    Kütüphanenin 1'li versiyonlarında kullanılan graf sistemi optimizasyon bakımından faydalar sağlayabilmektedir. Ancak yukarıda da 
    belirttiğimiz gibi zor bir kullanıma yol açmaktadır. Kütüphanein 2'li versiyonları model olarak PyTorch'a oldukça benzemektedir. 

    Eskiden Keras kütüphanesi TenserFlow ile yazılmış yüksek seviyeli bir kütüphane idi. Ancak daha sonra 2'li versiyonlarla Keras TenserFlow 
    kütüphanesinin kendi bünyesine katıldı. Dolayısıyla eskiden tamamen Kers olmadan TensorFlow ile işlem yapan uygulamacılar artık işin büyük kısmında 
    Keras kullanmaya başladılar. Tabii Keras neticede TensorFlow kullanılarak yazıldığı için Keras ile TensorFlow kütüphanelerinin bir uyumu 
    vardır. Programcılar artık yüksek seviyeli pek çok şeyi Keras'ta yapıp bazı durumlarda TensorFlow kütüphanesinin tensör olanaklarından 
    faydalanmaktadır. 

    TensorFlow kütüphanesine yeni başlayanlar artık eski graf sistemi yerine bu kütüphanenin 2'li versiyonlarının sunduğu özellikleri öğrenmelidir. 
    Ancak eski graf sistemi yine de işlemlerin daha hızlı yapılmasını sağlamak amacıyla programcılar tarafından kullanılabilmektedir. 

    Biz daha önce Keras kullanarak sinir ağlarını oluşturmuştuk. Keras modelini oluşturduğumuzda bunların eğitilmesi ve test işlemlerinde 
    NumPy dizilerini kullandık. Aslında Keras kütüphanesi kendi içerisinde TensorFlow kullandığı için işlemleri NumPy dizileri ile değil 
    TensorFlow kütüphanesinin Tensor nesneleriyle yapmaktadır. Dolayısıyla biz Keras'ta çeşitli metotlara (fit gibi, evalutae gibi, predict gibi) 
    NumPy dizileri verdiğimizde aslında Keras bunları Tensor nesnelerine dönüştürüp işlemlerini yapmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------
    TensorFlow kütüphanesinde de tıpkı PyTorch'ta olduğu gibi ana veri yapısı Tensor denilen nesnelerdir. Tensor nesneleri NumPy dizilerine 
    benzemekle birlikta yapay sinir ağları için özel bir biçimde tasarlanmıştır ve paralel programlamaya olanak sağlamaktadır.
#------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------
    Tensorflow kütüphanesinin son versiyonu aşağıdaki gibi kurulabilir:

    pip install tensorflow

    Kütüphane genellikle tf ismiyle aşağıdaki gibi import edilmektedir:

    import tensoflow as tf

#------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------
    Tensör yaratmanın en yaygın yollarından biri tf.constant fonksiyonunun kullanılmasıdır. Yaratım yapılırken dtype belirtilebilir.
    Eğer dtype belirtilmezse default olarak dtype türü tamsayılar için tf.int32, noktalı sayılar için tf.float32 biçiminde alınmaktadır.

    TensorFlow kütüphanesinde dtype türü için NumPy dtype türleri değil TensorFlow içerisindeki dtype türleri 
    kullanılmaktadır. Bu dtype türleri de yine C Programlama Dilindeki türlerden oluşturulmuştur. Zaten TensorFlow kütüphanesi 
    büyük ölçüde C/C++ kullanılarka yazılmış durumdadır. Tensorflow dtype türleri şunlardır:

    tf.float32
    tf.float64
    tf.int8
    tf.int16
    tf.int32
    tf.int64
    tf.uint8
    tf.string
    tf.bool

    dtype türleri yine istenirse isimsel biçimde de belirtilebilmektedir. Örneğin:

    import tensorflow as tf

    t = tf.constant([[1, 2, 3], [4, 5, 6]], dtype='float32')
    
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.int32)
print(t)

#------------------------------------------------------------------------------------------------------------------
    Tabii dtype yine numpy kütüphanesinde olduğu gibi isimsel biçimde verilebilir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype='float32')
print(t)

#------------------------------------------------------------------------------------------------------------------
   tf.constant fonksiyonunda dolaşılabilir nesneden belli bir boyutta tensör nesnesi de oluşturulabilir. Bunun için
   shape parametresi kullanılmaktadır.
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant([1, 2, 3, 4, 5, 6, 7, 8], shape=(2, 4), dtype='float32')
print(t)

#------------------------------------------------------------------------------------------------------------------
   tf.constant fonksiyonunda girilen listenin ya da demetin boyutu ne olursa olsun biz shape parametresi yoluyla onun 
   boyutlarını ayarlayabiliriz. Örneğin:

   t = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]] , shape=(9, ), dtype='float32')
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]], shape=(9, ), dtype='float32')
print(t)

#------------------------------------------------------------------------------------------------------------------
    NumPy'da olduğu gibi skaler değerlerin boyutsal bir özellikleri yoktur. Yani bunlar için shape=() biçimndedir.
    Örneğin:
    
    t = tf.constant(10 , dtype='float32')
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant(10, dtype='float32')
print(t)

#------------------------------------------------------------------------------------------------------------------
    Tabii biz istersek bir NumPy dizisinden de tensöt yaratabiliriz. Bu durumda tensör nesnesinin dtype türü NumPy dizisinden 
    alınacaktır. Örneğin:

    a = np.array([1, 2, 3, 4, 5], dtype=np.float32)

    t = tf.constant(a)

#------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------
    tensör yaratmanın diğer bir yolu da tf.convert_to_tensor fonksiyonunu kullanmaktır. Buradan da yine "constant" bir 
    tensör elde edilmektedir. Örneğin:

    t = tf.convert_to_tensor([1, 2, 3, 4, 5], dtype=tf.float32)

    print(t2)
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf
import numpy as np

a = np.random.random((5, 5))
t = tf.convert_to_tensor(a)
print(t)

#------------------------------------------------------------------------------------------------------------------
    tf.zeros fonksiyonu tıpkı np.zeros fonksiyonu gibi içi 0 ile dolu olan bir tensör oluşturmaktadır. dtype da belirtilebilir.
    Ancak default dtype=tf.float32'dir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.zeros((5, 5))
print(t)

#------------------------------------------------------------------------------------------------------------------
   tf.ones fonksiyonu da np.ones gibi içi 1'lerden oluşan bir tensör yaratmaktadır. dtype da belirtilebilir.
    Ancak default dtype=tf.float32'dir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.ones((5, 5))
print(t)

#------------------------------------------------------------------------------------------------------------------
   tf.fill fonksiyonu da np.fill fonksiyonuna benzemektedir. Belli bir değerden bir tensör oluşturmaktadır. 
   Bu fonksiyonun dtype parametresi yoktur. dtype doldurulacak değerin türünden hareketle belirlenmektedir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.fill((5, 5), 10.)
print(t)

#------------------------------------------------------------------------------------------------------------------
   tf.range isim olarak Python'daki range fonksiyonuna benzese de işlev olarak Numpy'daki np.arange fonksiyonuna 
   benzemektedir. Belli bir aralıkta değerlerden oluşan tensor yaratır. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.range(20)
print(t)

t = tf.range(10, 20, 0.2)
print(t)

#------------------------------------------------------------------------------------------------------------------
    tf.linspace fonksiyonu da Numpy'daki np.linspace fonksiyonuna benzemektedir. Ancak dtype parametresi almamaktadır.
    default durumda dtype=tf.float64 alınmaktadır.
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.linspace(-10, 10, 50)
print(t)

#------------------------------------------------------------------------------------------------------------------
   Bir tensör nesnesinin dtype bilgisi dtype isimli örnek özniteliği ile, shape bilgisi ise shape isimli örnek 
   özniteliği ile elde edilebilir. shape örnek özniteliği bize boyut bilgisini TensorShape isimli bir sınıf türünden 
   vermektedir. TensorShape bir tensör nesnesi değildir. Biz shape örnek özniteliği ile boyutları aldıktan sonra bu
   TensorShpape sınıfının [...] operatörü ile belli bir boyutun uzunluğunu elde edebiliriz. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant([1, 2, 3, 4, 5], dtype=tf.float32)
print(t.dtype)
print(t.shape)

#------------------------------------------------------------------------------------------------------------------
    Bir tensörün boyut bilgisi istenirse tf.shape fonksiyonuyla da elde edilebilir. shape örnek özniteliğinden farklı olarak
    tf.shape fonksiyonu boyut bilgisini bize Tensor nesnesi olarak vermektedir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant([1, 2, 3, 4, 5], dtype=tf.float32)
shape = tf.shape(t)
print(shape)

#------------------------------------------------------------------------------------------------------------------
   tf.rank fonksiyonu tensörün boyut sayısını bize vermektedir. Böyle bir  örnek özniteliği versiyonu yoktur.
   Boyut sayısı bir tensör nesnesi olarak verilmektedir.
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant([1, 2, 3, 4, 5], dtype=tf.float32)
rank = tf.rank(t)
print(repr(rank))

#------------------------------------------------------------------------------------------------------------------
    skaler değerlerin rank'leri 0'dır.
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant(10, dtype=tf.float32)
rank = tf.rank(t)
print(repr(rank))

#------------------------------------------------------------------------------------------------------------------
   Bir tensörün boyutsal bilgisini değiştirmek için tf.reshape fonksiyonu kullanılmaktadır. Numpy'daki gibi bir reshape
   metodu yoktur.
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant([[1, 2, 3, 4], [5, 6, 7, 8]], dtype=tf.float32)
k = tf.reshape(t, shape=(2, 4))
print(t)
print(k)

#------------------------------------------------------------------------------------------------------------------
    tf.reshape fonksiyonuna örnek
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.reshape(tf.range(30), (6, 5))
print(t)

#------------------------------------------------------------------------------------------------------------------
    Bir tensör nesnesinin elemanlarına köşeli parantez operatörüyle erişilebilir. Bu durumda elde edilen değer yine bir 
    tensör nesnesi olmaktadır. Tensör nesneleri üzerinde tıpkı Numpy'da olduğu gibi dilimlemeler yapılabilir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.reshape(tf.range(30), (6, 5))

k = t[1, 0]
print(k)

k = t[2:4, 1:3]
print(k)

#------------------------------------------------------------------------------------------------------------------
   tf.size fonksiyonu ile tensördeki toplam eleman sayısı bir tensör nesnesi biçiminde elde edilebilir. size fonksiyonun da
   örnek özniteliği ya da metot karşılığı yoktur. Bu tensor nesnesinin içerisindeki değer numpy() metodu ile düze bir sayı 
   olarak elde edilebilir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.reshape(tf.range(30), (6, 5))
size = tf.size(t)
print(size)
print(size.numpy())

#------------------------------------------------------------------------------------------------------------------
   Bir tensör nesnesinin içerisindeki değrler numpy metodu ile numpy dizisi biçiminde elde edilebilir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.reshape(tf.range(30), (6, 5))
a = t.numpy()
print(t)

#------------------------------------------------------------------------------------------------------------------
   Anımsanacağı gibi Tensorflow'da temel olarak içeriği değiştirilemeyen ve içeriği değiştirilebilen biçimde iki çeşit tensör 
   nesneleri bulunuyordu. Biz tf.constant fonksiyonuyla ya da tf.convert_to_tensor fonksiyonuyla tensor yarattığımız zaman bu 
   içeriği değiştirilemeyen tensör oluşturuyordu. İçeriği değiştirilebilen tensörler fonksiyonla değil tf.Variable isimli bir 
   sınıf ile yaratılmaktadır. İçeriği değiştirilen tensörler tipik olarak sinir ağlarındaki W ve bias değerleri için kullanılmaktadır. 
   Eğitim sırasında bu tensör nesneleri kendi içlerinde tıpkı PyTorch'ta olduğu gibi gradient değerleri tutup bunların güncellenmesine 
   olanak sağlamaktadır. 
   
   tf.Variable nesnesi tf.Variable sınıfının __init__ metoduyla yaraılabilir. Yine yaratım sırasında tensöre ilkdeğerleri 
   bir liste biçiminde ya da NumPy dizisi biçiminde verilebilmektedir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.Variable([1, 2, 3, 4, 5], dtype=tf.float32)
print(t)

#------------------------------------------------------------------------------------------------------------------
    Variable sınıfıyla yaratılan tensör nesnelerine sınıfın assign isimli metoduyla değer atanabilir. Ancak atanacak değerin 
    aynı shape özelliğine sahip olması gerekir. Yani tensörün bir kısmı değil hepsi değiştirilmektedir. assign metodu ile 
    atanacak olanan değer assign metoduna bir Python listesi, NumPy dizisi biçiminde verilebilir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.Variable([[1, 2, 3], [4, 5, 6], [7, 8, 9]], dtype=tf.float32)
print(t)

t.assign([[10, 20, 30], [40, 50, 60], [70, 80, 90]])
print(t)

#------------------------------------------------------------------------------------------------------------------
    assign metodu ile atanacak olanan değer assign metoduna bir Python listesi, NumPy dizisi biçiminde verilebilir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf
import numpy as np

vt = tf.Variable([[1, 2, 3], [4, 5, 6], [7, 8, 9]], shape=(3, 3), dtype=tf.float32)

print(vt)

a = np.random.randint(0, 100, (3, 3))

vt.assign(a)
print(vt)


#------------------------------------------------------------------------------------------------------------------
   assign metodu ile atama yapılırken atanacak değer bir tensör nesnesi de olabilir.     Ancak atama sırasında dtype 
   türlerinin uyuşması gerekmektedir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf
import numpy as np

vt = tf.Variable([[1, 2, 3], [4, 5, 6], [7, 8, 9]], shape=(3, 3), dtype=tf.float32)

print(vt)

ct = tf.constant(np.random.randint(0, 100, (3, 3)), dtype=tf.float32)

vt.assign(ct)
print(vt)

#------------------------------------------------------------------------------------------------------------------
    Variable nesnesi de bir skaler biçiminde olabilir. Biz bu skaler nesneye yine assign metodu ile değer atayabiliriz. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

v = tf.Variable(1)
print(v)

v.assign(2)
print(v)

#------------------------------------------------------------------------------------------------------------------
   Variable tensör içerisindeki değeri toplayarak ve çıkartarak atayabiliriz. Bunlar için assign_add ve assign_sum metotları
   kullanılmaktadır. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

vt = tf.Variable([1, 2, 3, 4, 5], dtype=tf.float32)

vt.assign_add([10, 20, 30, 40, 50])

print(vt)

#------------------------------------------------------------------------------------------------------------------
    Aşağıdaki örnekte de skaler bir Variable tensör nesnesi üzerinde assign_add ve assign_sub metotları kullanılmıştır. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

v = tf.Variable(1)
print(v)

v.assign_add(10)
print(v)

v.assign_sub(3)
print(v)

#------------------------------------------------------------------------------------------------------------------
    Rassal sayılardan oluşan tensörler elde etmek için tf.random modülündeki fonksiyonlar kullanılmaktadır. Örneğin
    tf.random.uniform fonksiyonu iki aralık içerisinde belli boyutlarda rastgele sayılardan oluşan tensör yaratmaktadır.  
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.random.uniform((5, 5), 0, 10)
print(t)

t = tf.random.uniform((5, 5), 0, 10, dtype=tf.int32)
print(t)

#------------------------------------------------------------------------------------------------------------------
   tf.random.normal fonksiyonu belli bir ortalama ve standart sapmaya ilişkin belli boyutta rassal değerlerden oluşan
   tensör oluşturmaktadır.
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.random.normal((5, 5), 0, 3)
print(t)

#------------------------------------------------------------------------------------------------------------------
    tf.random.shuffle fonksiyonu bizden bir tensör alır, onu karıştırarak yeni bir tensör verir. Karıştırma işlemi
    her zaman ilk eksene göre yapılmaktadır. (Yani bir matris karıştılacaksa satırlar yer değiştirilmektedir.)
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant([1, 2, 3, 4, 5])
print(t)
k = tf.random.shuffle(t)
print(k)

t = tf.random.uniform((5, 5), 0, 10, dtype=tf.int32)
print(t)

k = tf.random.shuffle(t)
print(k)

#------------------------------------------------------------------------------------------------------------------
    Tensör sınıflarında temel operatörlere ilişkin operatör metotları yazılmış durumdadır. Dolayısıyla biz iki tensörü
    artimetik işlemlere sokabiliriz. Bu durumda tıpkı Numpy'da olduğu gibi karşılıklı elemanlar işleme sokulur.
    Ancak işleme sokulacak tensörlerin dtype türlerinin aynı olması gerekmektedir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
b = tf.constant([[1, 3, 5], [2, 4, 6], [1, 2, 3]])

c = a + b
print(c)

c = a * b
print(c)

#------------------------------------------------------------------------------------------------------------------
   Yine aritmetik işlemlerde Numpy'da olduğu gibi "broadcasting" uygulanmaktadır.
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
b = tf.constant([1, 3, 5])

c = a + b
print(c)

#------------------------------------------------------------------------------------------------------------------
   Matrisel çarpım tıpkı Numpy'da olduğu gibi matmul fonksiyonuyla ya da @ operatörüyle yapılmaktadır. 
   Tabii tf.matmul fonksiyonunda iki boyutlu matrislerin uygun şekillerde olması gerekmektedir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
b = tf.constant([[1], [3], [5]])

c = tf.matmul(a, b)
print(c)

b = tf.constant([[1, 2, 3]])
c = tf.matmul(b, a)
print(c)

#------------------------------------------------------------------------------------------------------------------
    Tabii iki tensör tıpkı Numpy'da olduğu gibi karşılaştırma operatörleriyle de işlemlere sokulabilir. Bu durumda
    bool bir vektör elde edilir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
b = tf.constant([[4, 5, 6], [7, 3, 2], [4, 9, 8]])

c = a > b
print(c)

c = a == b
print(c)

#------------------------------------------------------------------------------------------------------------------
    Yine Tensorflow'da da bool indeksleme yapılabilmektedir. Bu sayede biz matris değerlerini filtreleyebiliriz. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

a = tf.constant([8, 12, 43, 23, 19])
result = a > 20

b = a[result]
print(b)

#------------------------------------------------------------------------------------------------------------------
   Matematiksel işlemlerin önemli bölümü tf.math modülündeki fonksiyonlarla yapılmaktadır. Bu modüldeki reduce_xxx biçiminde
   isimlendirilmiş olan fonksiyonlar axis parametresi almaktadır. Buradaki axis parametresi Numpy'daki axis parametresiyle
   aynı anlama sahiptir. Başı reduce öneki ile başlamayan fonksiyonlar axis parametresi almamaktadır. Örneğin reduce_sum, 
   reduce_mean, reduce_std, reduce_min, reduce_max axis parametresi alab önemli fonksiyonlardır. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
print(a)

b = tf.math.reduce_sum(a, axis=0)   # np.sum(a, axis=0)
print(b)

b = tf.math.reduce_sum(a, axis=1)   # np.sum(a, axis=1)
print(b)

b = tf.reduce_mean(a, axis=0)       # no.mean(a, axis=0)
print(b)

#------------------------------------------------------------------------------------------------------------------
    tf.math modülündeki bazı fonksiyonlar ilgili operatör metotlarının fonksiyon biçimleridir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

a = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
print(a)

b = tf.constant([[3, 2, 1], [7, 4, 6], [1, 3, 5]])
print(a)

c = tf.add(a, b)        # c = a + b
print(c)

c = tf.multiply(a, b)        # c = a * b
print(c)

#------------------------------------------------------------------------------------------------------------------
    dot product işlemi için birkaç benzer fonksiyon bulundurulmuştur. tf.tensordat fonksiyonu iki tensör üzerinde dot product
    işlemi yapar. Fonksiyondaki axes parametresi tipik olarak 1 biçiminde geçilir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

x = tf.constant([1, 2, 3, 4, 5], dtype=tf.float32)
y = tf.constant([1, 2, 3, 4, 5], dtype=tf.float32)

z = tf.tensordot(x, y, axes=1)
print(z)

#------------------------------------------------------------------------------------------------------------------
   tf.math modülünde segment_xxx biçiminde isimlendirilmiş olan fonksiyonlar tensörü segment'teki aynı değerler dikkate alınarak
   blümlere ayırıp o bölümleri işleme sokmaktadır. Bölümleme 0'dan başlayarak artırımlı bir bir biçimde yapılmaktadır.
   Örneğin:

   t = tf.constant([1, 2, 3, 4, 5, 6, 7, 8])
   segment = tf.constant([0, 0, 1, 1, 1, 2, 2, 2])

    Burada 0'lara karşılık gelen indekslerdeki elemanlar ayrı bir bölümü 1'lere karşılık gelen indeksteki elemanlar ayrı bir bölümü
    ve 2'lere karşılık gelen indekslerdeki elemanlar ise ayrı bir bölümü oluşturmaktadır. Dolayısıyla şu bölümler elde edilmiştir:

    1 2
    3 4 5
    6 7 8

#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant([1, 2, 3, 4, 5, 6, 7, 8])
segment = tf.constant([0, 0, 1, 1, 1, 2, 2, 2])

result = tf.math.segment_sum(t, segment)
print(result)

#------------------------------------------------------------------------------------------------------------------
    segment'li işlemlere örnek
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant([1, 2, 3, 4, 5, 6, 7, 8])
segment = tf.constant([1, 1, 1, 2, 2, 2, 3, 3])

result = tf.math.segment_sum(t, segment)
print(result)

#------------------------------------------------------------------------------------------------------------------
    Çok boyutlu diziler üzerinde de segment'li işlemler yapılabilir 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant([[1, 2, 3], [4, 5, 6], [7, 8, 9], [3, 2, 1]])
segment = tf.constant([0, 0, 1, 1])

result = tf.math.segment_sum(t, segment)
print(result)

#------------------------------------------------------------------------------------------------------------------
    segment_xxx fonksiyonlarında bölüm belirten numaraların sırayı dizilmiş bir biçimde bulunması gerekir. Ancak eğer bölüm belirten
    numaralar sıraya dizilmiş değilse unsorted_segment_xxx fonksiyonları kullanılmalıdır. Ancak bu fonksiyonların ayrıca num_segments 
    isimli zorunlu bir parametresi de vardır. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant([1, 2, 3, 4, 5, 6, 7, 8])
segment = tf.constant([0, 0, 1, 1, 1, 2, 1, 0])

result = tf.math.unsorted_segment_sum(t, segment, num_segments=3)
print(result)

#------------------------------------------------------------------------------------------------------------------
   unsorted_segment_xxx fonksiyonlarınun kullanımına bir örnek
#------------------------------------------------------------------------------------------------------------------

,import tensorflow as tf

t = tf.constant([1, 2, 3, 4, 5, 6, 7, 8])
segment = tf.constant([2, 2, 2, 1, 1, 1, 3, 3])

result = tf.math.unsorted_segment_sum(t, segment, num_segments=5)
print(result)

#------------------------------------------------------------------------------------------------------------------
    math modülündeki argmax ve argmin NumPy'daki gibi en büyük ve en küçük elemanların kendilerini değil indeks numaralarını
    elde etmektedir. 
#------------------------------------------------------------------------------------------------------------------

import tensorflow as tf

t = tf.constant([10, 21, 32, 42, 5, 6, 72, 8])

result = tf.argmax(t)
print(result)

result = tf.argmin(t)
print(result)

#----------------------------------------------------------------------------------------------------------------------------
    Yapay zeka ve makine öğrenmesi uygulamaları için çeşitli kurumlar tarafından cloud temelli hizmetler sunulmaktadır. Bu cloud 
    hizmetlerinin en yaygın kullanılanları şunlardır:

    - Goodle Cloud Platform (Vertex AI)
    - Amazon Web Services (Sage Maker)
    - Microsodt Azure
    - IBM Watson

    Bu servislerin hepsinin ortak birtakım özellikleri ve amaçları vardır:

    - Bu platformlar bize CPU ve bellek sağlamaktadır. Dolayısıyla bizim makine öğrenmesi işlemleri için ayrı bir makine tahsis 
    etmemize gerek kalmaz. Pek çok modelin eğitimi günlerce sürebilmektedir. Bunun için makinenin evde tutulması uygun olamayabilir. 
    
    - Bu platformlar "ölçeklenebilir (scalable)" çözümler sunmaktadır. Yani kiralanan birimler büyütülük küçültülebilmektedir. 

    - Bu platformlar "deployment" için kullanılabilmektedir. Yani burada eğitilen modellerle ilgili işlemler Web API'leriyle
    uzaktan yapılabilmektedir. (Örneğin biz makine öğrenmesi uygulamasını buralarda konuşlandırabiliriz. predict işlemlerini 
    cep telefonumuzdaki uygulamalardan yapabiliriz. Böylece uygulamamız mobil aygıtlardan da web tabanlı olarak kullanılabilir 
    hale gelmektedir.)

    - Bu platformlar kendi içerisinde "Automated ML" araçlarını da bulundurmaktadır. Dolayısıyla aslında konunun teorisini bilmeyen 
    kişiler de bu Automated ML araçlarını kullanarak işlemlerini yapabilmektedir. 

    Yukarıdaki platformlar (IBM Watson dışındaki) aslında çok genel amaçlı platformlardır. Yani platformlarda pek çok değişik hizmet de 
    verilmektedir. Bu platformalara "yapay ze makine öğrenmesi" unsurları son 10 senedir eklenmiş durumdadır. Yani bu platformlardaki 
    yapay zeka ve makine öğrenmesi kısımşları bu platformların birer alt sistemi gibidir. Bu platformların pek çok ayrıntısı olduğunu 
    hatta bunlar için sertifikasyon sınavlarının yapıldığını belirtmek istiyoruz. 

    Tabii yukarıdaki platformlar ticari platformlardır. Yani kullanım için ücret ödenmektedir. Ücret ödemesi "kullanım miktarı ile"
    ilişkilidir. Yani ne kadar kullanılırsa o kadar ücret ödenmektedir. (Bu bakımdan modellerin eğitimini unutursanız, bu eğitimler
    bu platformun kaynaklarını kullandığı için ücretlendirilecektir. Denemeler yaparken bu tür hesaplamaları durdurduğunuzdan emin 
    olmalısınız.) Tabii bu platformlarda da birtakım işlemler bedava yapılabilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Bütün cloud sistemlerinde makine öğrenmesi işlemleri yapılırken birbirleriyle ilişkili üç etkinlik yürütülür: 
    
    Data + Model + Hesaplama 

    Üzerinde çalışacağımız veriler genellikle bu cloud sistemlerinde onların bu iş için ayrılan bir servisi yoluyla upload 
    edilir. Model manuel ya da otomatik bir biçimde oluşturulmaktadır. Cloud sistemleri kendi içerisindeki dağıtık bilgisayar
    sistemleri yoluyla model üzerinde eğitim, kestirim gibi işlemler yapmamıza olanak vermektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
   Google Cloud Platform (kısaca GCP) Amazon AWS ve Microsoft Azure platformlarının doğrudan rekabetçisi konumundadır. 
   GCP 2008’de kurulmuştur. Aslında diğer platformlarda olan servislerin tamamen benzeri GCP’de bulunmaktadır. 
   GCP’ye erişmek için bir Google hesabının açılmış olması gerekir. 

    GCP’nin ana sayfası şöyeldir:

    https://cloud.google.com/

    GCP işlemlerini yapabilmek için kontrol panele (konsol ortamına) girmek gerekir. Kontrol panel adresi de şöyledir:

    https://console.cloud.google.com

#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
   GCP’de tüm işlemler bir proje eşliğinde yapılmaktadır. Çünkü işletmeler değişik projeler için değişik hizmetler alabilmektedir. 
   Projenin yaratımı hemen konsole sayfasından yapılabilmektedir. Projeyi yarattıktan sonra aktif hale getirmek (select etmek) gerekir. 
   Proje aktif hale geldiğinde proje sayfasına geçilmiş olur. Tabii proje yaratmak için bizim Google'a kredi kartımızı vermiş olmamız
   gerekir. Yukarıda da belirttiğimiz gibi biz kredi kartını vermiş olsak bile Google kullanım kadar para çekmektedir. 
   Projenin "dashboard" denilen ana bir sayfası vardır. Burada projeye ilişkin pek çok özet bilgi ve hızlı erişim bağlantıları 
   bulunmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    GCP’nin -tıpkı diğer platformlarda olduğu gibi- “CPU + RAM” kiralaması yapan ve “Compute Engine” denilen bir servisi vardır. 
    Benzer biçimde yine veritablarını host etmek için ve birtakım dosyaları saklamak için kullanılabilecek “Cloud Storage” hizmeti 
    bulunmaktadır. 

    GCP içerisinde birtakım servislerin erişebileceği bir storage alanına gereksim duyulmaktadır. Bunun için “Cloud Storage” 
    hizmetini seçmek gerekir. Ancak Google bu noktada sınırlı bedava bir hizmet verecek olsa da kredi kartı bilgilerini istemektedir. 
    Tıpkı AWS’de olduğu gibi burada da “bucket” kavramı kullanılmıştır. Kullanıcının önce bir “bucket yaratması” gerekmektedir.
    Bucket adeta cloud alanı için bize ayrılmış bir disk ya da klasör gibi düşünülebilir. Dosyalar bucket'lerin içerisinde bulunmaktadır.   
    Bucket yaratılması sırasında yine diğerlerinde olduğu gibi bazı sorular sorulmaktadır. Örneğin verilere hangi bölgeden erişileceği, 
    verilere hangi sıklıkta erişileceği gibi. Bucket’e verilecek isim yine AWS’de olduğu gibi GCP genelinde tek (unique) olmak zorundadır. 
    Bir bucket yaratıldıktan sonra artık biz yerel makinemizdeki dosyaları bucket'e aupload edebiliriz. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Aslında GCP üzerinde işlem yapmak için çeşitli komut satırı araçları da bulundurulmuştur. Biz bu komut satırı araçlarını 
    yerel makinemize install edip işlemleri hiç Web arayüzünü kullanmadan bu araçlarla da yapabilmekteyiz. Bu araçlar bizim 
    istediğimiz komutları bir script biçiminde de çalıştırabilmektedir. Aslında bu komut satırı araçları "Cloud Shell" ismiyle
    Web tabalı olarak uzak makinede de çalıştırılabilmektedir. 

    Yerel makinemize aşağıdkai bağlantıyı kullanarak gsutil programını kurabiliriz:

    https://cloud.google.com/storage/docs/gsutil_install

    Örneğin gsutil programı ile yerel makinemizdeki "cvid.csv" dosyasını GCP'deki bucket'imiz içerisine şöyle kopyalayabiliriz:

    gsutil cp covid.csv gs:/kaanaslan-test-bucket
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    GCP içerisindeki Auto ML aracına "Vertex AI" denilmektedir. Vertex AI aracına erişmek için GCP kontrol panelindeki ana menüyü
    kullanabilirisniz. Vertex AI'ın ana kontrol sayfasına "Dashboard" denilmektedir. Dolayısıyla bizim Dashboard'a geçmemiz gerekir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Tipik olarak Vertex-AI'da işlem yapma aşamaları şöyledir:

    1) Veri kümesi bucket içerisine upload edilir. (Bu işlem Dataset oluşturulurken de yapılabilmektedir.)
    2) Dataset oluşturulur.
    3) Eğitim işlemi yapılır
    4) Deployment ve Test işlemleri yapılır
    5) Kestirim işlemleri yapılır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Vertex AI'da ilk yapılacak şey bir "Dataset" yaratmaktır. Bunun için Vertex AI sayfasındaki "Datasets" sekmesi seçilir. 
    Buradan Create düğmesine basılır. Burada Dataset için bölge seçilir. (Bu bölgenin bucket ile aynı bölgede olması gerekmez
    ancak aynı bölgede olması daa uygundur.) Dataset'e bir isim verilir. Sonra problemin türü seçilir. Bir CSV dosyasından hareketle
    kestirim yapacaksak "Tabular" sekmesinden "Regression/Classification" seçilmelidir. Daytaset yaratıldıktan sonra artık bu dataset'in
    bir CSV dosyası ilişkilendirilmesi gerekmektedir. Ancak Vertex AI backet'teki CSV dosyalarını kullanabilmektedir. Burada üç seçenek 
    bulunmaktadır:

    * Upload CSV files from your computer
    * Select CSV files from Cloud Storage
    * Select a table or view from BigQuery

    Biz yerel bilgiyasarımızdaki bir CSV dosyasını seçersek zaten bu CSV dosyası önce bucket içerisine kopyalanmaktadır. 
    Eğer zaten CSV dosyasımız bir bucket içerisindeyse doğrudan bucket içerisindeki CSV dosyasını belirtebiliriz. BigQuery
    GCP içerisindeki veritabanı biçiminde organize edilmiş olan başka bir depolama birimidir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Dataset oluşturulduktan sonra artık eğitim işlemine geçilebilir. Bunun için Vertex AI içerisindeki "Traning" sekmesi kullanılmaktadır. 
    Training sayfasına geçildiğinde "Create" düğmesi ile eğitim belirlemelerinin yapıldığı bölüme geçilebilir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Training işleminde peşi sıra birkaç aşamadan geçilmektedir. "Traingng method" aşamasında bize hangi veri kümesi için eğitim 
    yapılacağı ve problemin bir "sınıflandırma problemi mi yoksa regresyon problemi mi" olduğu sorulur. Bundan sonra "Model details" 
    aşamasına geçilir. Bu aşamada bize veri kümesindeki kestirilecek sütunun hangisi olduğu sorulmaktadır. Bu aşamada "Advanced 
    Options" düğmesine basıldığında test ve sınama verilerinin miktarları belirlenebilmektedir. Default durumda test verileri ve 
    sınama verileri veri kümesinin %10'u biçiminde alınmaktadır. "Join featurestore" aşamasından doğrudan "Continue" ile geçilebilir. 
    Bundan sonra karşımıza "Training options" aşaması gelecektir. Burada eğitimde hangi sütunların kullanılacağı bize sorulmaktadır. 
    Yine bu aşamada da "Advanced Options" seçeneği vardır. Burada bize Loss fonksiyonu sorulmatadır. Tabii bunlar default değerlerle 
    geçilebilir. En sonunda "Compute and pricing" aşamasına gelinir. Burada dikkat etmek gerekir. Çünkü Google eğitimde harcanan
    zamanı ücretlendirmektedir. Google'ın ücretlendirme yöntemi aşağıdaki bağlantıdan imncelenebilir:

    https://cloud.google.com/vertex-ai/pricing

    Burada "Budget" eğitim için maksimum ne kadar zaman ayrılacağını belirtmektedir. Klasik tabular verilerde en az zaman 1 
    saat olarak, resim sınıflandırma gibi işlemlerde en az zaman 3 olarak girilebilmektedir. 

    En sonunda "Start Training" ile eğitim başlatılır. Eğitimler uzun sürebildiği için bitiminde e-posta ile bildirm yapılmaktadır. 

    Eğitim bittikten sonra biz eğitim hakkında bilgileri Training sekmesinden ilgili eğitimin üzerine tıklayarak görebiliriz. 
    Eğer problem regresyon problemi ise modelin başarısı çeşitli metrik değerlerle gösterilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Kesitirim işlemlerinin yapılabilmesi için önce modelin "deploy edilmesi ve bir endpoint oluşturulması" gerekmektedir. 
    Modelin deploy edilmesi demek cloud sistemi içerisinde dışarıdan kullanıma hazır hale getirilmesi demektir. Böylece biz 
    kestirimi uzaktan programlama yoluyla da yapabiliriz. Deployment işlemi "Prediction" sekmesinden girilerek yapılabileceği gibi 
    "Model Registry" sekmesninden de yapılabilmektedir. EndPoint yaratımı sırasında bize Endpoint için bir isim sorulmaktadır. Sonra 
    model için bir isim verilmekte ve ona bir versiyon numarası atanmaktadır. Buradaki "Minimum number of compute nodes" ne kadar yüksek 
    tutulursa erişim o kadar hızlı yapılmaktadır. Ancak node'ların sayısı doğrudna ücretlendirmeyi etkilemektedir. Dolayısıyla burada 
    en düşük sayı olan 1 değerini girebilirsiniz. Daha sonra bize modelin deploy edileceği makinenin özellikleri sorulmaktadır. 
    Burada eğitimin başka bir makinede yapıldığına ancak sonucun kestirilmesi için başka bir makinenin kullanıldığına dikkat ediniz. 
    Modelimiz deploy edildikten sonra kullanım miktarı kadar ücretlendirme yapılmaktadır. Dolaysıyla denemelerinizden sonra 
    bu deployment işlemini silebilirsiniz. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Deployment işleminden sonra artık predict işlemi yapılabilir. Bu işlem tamamen görsel arayüzle yapılabileceği gibi 
    Web API'leriyle ya da bunları kullanan Python koduyla da yapılabilmektedir. Eğer deploy edilmiş modelde kestirim 
    işlemini programlama yoluyla yapacaksanız bunun için öncelikle aşağıdaki paketi kurmanız gerekmektedir:

    pip install google-cloud-aiplatform

    Bundan sonra aşağıdaki import işlemini yapıp modüldeki init fonksiyonunun uygun parametrelerle çağrılması gerekmeketdir:

    from google.cloud import aiplatform

    aiplatform.init(....)

    predict işlemi için Training sekmesinden Deploy & Test sekmesini kullanmak gerekir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Birden fazla predict işlemi "batch predict" denilen sekme ile yapılmaktadır. Uygulamacı kestirim için yine bir CSV dosyası 
    oluşturur. Bu CSV dosyasına bucket'e upload eder. Sonra "Batch predict" sekmesinden bu CSV dosyasına referans ederek 
    işlemi başlatır. Sonuçlar yine bu işlem sırasında belirlenen bucket'ler içerisinde CSV dosyaları biçiminde oluşturulmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Şimdi de Vertex AI ile resim sınıflandırma işlkemi yapalım. Resim sınıflandırma gibi bir işlem şu aşamalardan geçilerek 
    gerçekleştirilmektedir:

    1) Resimler Google cloud'ta bir bucket'e upload edilir. 
    2) Resimler bir CSV dosyası haline getirilir. Tabii burada resmin içerisindeki data'lar değil onun bucket'teki yeri 
    kullanılmaktadır. 
    3) Bu CSV dosyasından hareketle Dataset oluşturulur. 
    4) Training işlemi yapılır.
    5) Deployment ve EndPoint ataması yapılır 
    6) Kestirim işlemi görsel atayüz yoluyla ya da WEB API'leri ya da Pythonkoduyla yapılır.

    Burada Dataset oluşturulurken bizden bir CSV dosyası istenmektedir. Bu CSV dosyası aşağıdaki gibi bir formatta oluşturulmalıdır:

    dosyanın_bucketteki_yeri,sınıfı
    dosyanın_bucketteki_yeri,sınıfı
    dosyanın_bucketteki_yeri,sınıfı
    dosyanın_bucketteki_yeri,sınıfı

    Örneğin:

    gs://kaanaslan-test-bucket/ShoeVsSandalVsBootDataset/Boot/boot (1).jpg,boot
    gs://kaanaslan-test-bucket/ShoeVsSandalVsBootDataset/Boot/boot (10).jpg,boot
    gs://kaanaslan-test-bucket/ShoeVsSandalVsBootDataset/Boot/boot (100).jpg,boot
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Metin sınıflandırmaları da nemzer biçmde yapılabilmektedir. Burada iki seçenek söz konusudur. Metinler ayrı dosyalarda 
    bulunudurulup dosyalar bucket içerisine upload edilebilir yine resim sınıflandırma örneğinde olduğu gibi CSV dosyası 
    metinlere ilişkin dosyalardan ve onların sınıflarından oluşturulabilir. Ya da doğrudan metinlerin kendisi ve onların sınıfları da
    CSV dosyasının içerisinde bulunabilir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Amazon firması Cloud paltformlarına ilk giren büyük firmalardandır. Amazon'un cloud platformuna AWS (Amazon Web Services)
    denilmektedir. AWS iki yüzün üzerinde servis barındıran dev bir platformdur. Platformun pek çok ayrıntısı vardır. Bu nedenle 
    platformun öğrenilmesi ayrı bir uzmanlık alanı haline gelmiştir. Biz kurusumuzda platformun yapay zeka ve makine öğrenmesi 
    için nasıl kullanılacağı üzerinde özet bir biçimde duracağız. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    AWS ortamında makine öğrenmesi etkinlikleri işleyiş olarak aslında daha önce görmüş olduğumuz Google Cloud Platform'a 
    oldukça benzemektedir.  Google Cloud Platform'daki "Vertex AI" servisinin Amazonda'ki mantıksal karşılığı "SageMaker"
    isimli servistir.  
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    AWS'nin ana kontrol paneline aşağıdaki bağlantı ile erişilebilir:
    
    console.aws.amazon.com

    Tabii AWS hizmeti almak için yine bir kayıt aşaması gerekmektedir. AWS kaydı sırasında işlemlker için bizden kredi kartı 
    bilgileri istenmektedir. Ancak AWS diğerlerinde olduğu gibi "kullanılan kadar paranın ödendiği" bir platformdur.

    AWS'nin konsol ekranına giriş yapıldığında zaten bize son kullandığmız servisleri listelemektedir. Ancak ilk kez giriş 
    yapıyorsanız menüden "SageMaker" servisini seçmelisiniz. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    SageMaker'a geçildiğinde onun da bir "dash board" denilen kontrol paneli vardır. Burada biz notebook'lar yaratıp uzaktan 
    manuel işlemler yapabiliriz. Ancak SageMaker'ın Auto ML aracına "AutoPilot" denilmektedir. SageMaker'ı görsel olarak daha
    zahmetsiz kullanabilmek için ismine "Studio" denilen Web tabanlı bir IDE geliştirilmiştir. Son yıllarda "Google'ın collab'ına"
    benzer "Studio Lab" denilen bedava bir ortam da eklenemiştir. Kullanıcılar genellikle işlemlerini bu Studio IDE'siyle yapmaktadır. 
    SageMaker içerisinde "Studio"ya geçebilmek için en az bir "kullanıcı profilinin (user profile)" yaratılmış olması gerekir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    AWS'nin veri saklamak için çeşitli servisleri vardır. Makine öğrenmesiş için en önemli depolama servisi S3 denilen servistir. 
    S3 servisinde de tıpkı GCP'de olduğu gibi "bucket" adı altında bir çeşit folder'lar oluşturulmaktadır. Sonra bu bucket'lere 
    dosyalar upload edilmektedir. Amazon "veri merkezlerini (data centers)" "bölge (zone)" denilen alnlarla bölümlere ayırmıştır. 
    Server'lar bu bölgelerin içerisindeki veri merkezlerinin içerisinde bulunmaktadır. Tıpkı GCP'de olduğu her bölgede her türlü 
    servis verilmeyebilmetedir. Kullanıcılar coğrafi bakımdan kendilerine yakın bölgeri seçerlerse erişim daha hızlı olabilmektedir. 

    Bir bucket yaratmak için ona "dünya genelinde tek olan (unique)" bir isim vermek gerekir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    SageMaker Studio'da Auto-ML etkinlikleri için Autopilot denilen uygulama kullanılmaktadır. Dolayısıyla Auto-ML işlemi için 
    AutoML seçilebilir. Autopilot'ta bir Auto-ML çalışması yapmak için bir "experiment" oluşturmak gerekir. Experiment 
    oluşturabilmek için "File/New/Create AutoML Experiment" seçilebilir ya da doğrudan Auto ML (Autopilot) penceresinde de 
    "Create Autopilot Experiment" seçilebilir. Yeni bir experiment yaratılırken bize onun ismi ve CSV dostasının bucket'teki 
    yeri sorulmaktadır. Sonra Next tuşuna basılarak bazı gerekli öğeler belirlenir. Örneğin tahmin edilecek hedef sütun ve 
    kestirimde kullanılacak sütunlar bu aşamada bize sorulmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Eğitim işlemi bittiğinde veri dosyanın bulunduğu bucket içerisinde bir klasör yaratılır ve bu klasör içerisinde model ile 
    ilgili çeşitli dosyalar bulundurulur. Buradaki iki dosya önemlidir:

    SageMakerAutopilotDataExplorationNotebook.ipynb
    SageMakerAutopilotCandidateDefinitionNotebook.ipynb
    
    Buradaki "SageMakerAutopilotDataExplorationNotebook.ipynb" dosyası içerisinde veriler hakkında istatistiksel bşrtakım özellikler 
    raporlanır. "SageMakerAutopilotCandidateDefinitionNotebook.ipynb" dosyasının içerisinde ise Autopilot'ın bulduğu en iyi modellerin
    nasıl işleme sokulacağına ilişkin açıklamalar bulunmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Kestirim yapabilmek için EndPoint oluşturulmuş olması gerekmektedir. Tıpkı GCP'de olduğu gibi modelin çalıştırılabilmesi için 
    bir server'a deploy edilmesi egrekmektedir. Deploy işlemi sonucunda bize bir EndPoint verilir. Biz de bu EndPoint'i kullanarak 
    Web arayüzü ile ya da Python programı ile uzaktan kestirimde bulunabiliriz. 
    
    AWS'de uzaktan Python ile işlem yapabilmek için "sagemaker" ve "boto3" gibi kütüphaneler oluşturulmuştur. Kütüphaneler şöyle yüklenebilir.  

    pip install sagemaker
    pip install boto3

    sagemaker kütüphanesi Web arayüzü ile yapılanları programlama yoluyla yapabilmekt için boto3 kütüphanesi ise uzaktan
    kesitirm (prediction) gibi işlemleri yapabilmek için kullanılmaktadır. 

    sagemaker kütüphanesi ile uzaktan işlemlerin yapılması kütüphanenin dokümantasyonlarında açıklanmıştır. Aşağıdaki 
    bağlantıyı kullanarak kodlar üzerinde değişiklikler yaparak ve kodlarda ilgili yerleri doldurarak uzaktan işlemler yapabilirsiniz:

    https://sagemaker.readthedocs.io/en/stable/overview.html
    
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
   boto3 kütüphanesi ile uzaktan işlemler yapılırken önce bir Session nesnesinin yaratılması gerekmektedir. Sessin nesnesi yaratılırken 
   bizim AWS kaynaklarına ulaşabilmemiz için iki parola bilgisine sahip olmamız gerekir. Birincisi “aws_access_key_id” ve 
   ikincisi de “aws_secret_access_key”. Amazon servisleri uzaktan erişimler için “public key/private key” kriptografi uygulamaktadır. 
   Bu parola bilgileri Session nesnesi yaratılırken aşağıdaki verilebilir:

    import boto3

    session = boto3.Session(aws_access_key_id=XXXXX', aws_secret_access_key='YYYYY')

    Session nesnesi yaratıldıktan sonra hangi servisin kullanılacağını belirten bir kaynak nesnesi yaratılır. Örneğin:

    s3 = session.resource('s3')

    Aslında bu kaynak nesneleri session nesnesi yaratılmdan doğrudan da yaratılabilmektedir. Ancak parolaların bu durumda 
    “~/.aws/credentials” dosyasına aşağıdaki formatta yazılması gerekir:

    [default]
    aws_access_key_id = YOUR_ACCESS_KEY
    aws_secret_access_key = YOUR_SECRET_KEY

    Burada yukarıdaki iki anahtarı elde etme işlemi sırasıyla şu adımlarla yapılmaktadır:

    1) https://console.aws.amazon.com/iam/ Adresinden IAM işlemlerine gelinir. 
    2) Users sekmesi seçilir
    3) Kullanıcı ismi seçilir
    4) "Security credentials" sekmesi seçilir. 
    5) Buradan Create Acces Key seçilir. 

    İşlemler sırasında eğer yukarıdaki anahtarlar girilmek istenmiyorsa (bu amahtarların görülmesi istenmeyebilir) yukarıda da belirttiğimiz
    gibi bu anahtarlar özel bir dosyanın içerisine yazılabilir. Oradan otomatik alınabilir. Eğer bu anahtarlar ilgili dosyanın 
    içerisine yazılmışsa Session nesnesi yaratılırken parametre bu iki anahtarı girmemize gerek kalmaz. Örneğin:

    session = boto3.Session()

    Bu dosya bu bilgiler Amazon'un komut satırından çalışan aws programıyla da girilebilmektedir. Amazon'un komut satırından çalışan aws programını aşağıdaki 
    bağlantıdan inmdirerek kurabilirsiniz:

    https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html

    Bu iki anahtarı ilgili dosyaya yazmak için aws programı şöyle kullanılabilir:

    aws configure

    Biz programlama yoluyla uzaktan bu bucket işlemlerini yapabiliriz. Örneğin tüm bucket'lerin isimleri aşağıdaki gibi elde edilebilir:

    for bucket in s3.buckets.all():
        print(bucket.name)
    
    Belli bir bucket'teki dosya aşağıdaki gibi download edilebilmektedir:

    s3 = boto3.client('s3')
    s3.download_file('kaanaslan-test-bucket', 'x.txt', 'y.txt')

    Burada söz konusu bucket içerisindeki "x.txt" dosyası "y.txt" biçiminde download edilmiştir. 

    Uzaktan predict işlemi yine boto3 kütüphanesi ile yapılabilmektedir. Aşağıda buna bir ilişkin bir örnek verilmiştir:

    import boto3

    session = boto3.Session(aws_access_key_id='AKIAWMMTXFTMCYOF352A',aws_secret_access_key='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', region_name='eu-central-1')

    predict_data = '''6,148,72,35,0,33.6,0.627,50
    1,85,66,29,0,26.6,0.351,31'
    '''

    client = session.client('runtime.sagemaker')
    response = client.invoke_endpoint(EndpointName='diabetes-test', ContentType='text/csv', Accept='text/csv', Body=predict_data)

    result = response['Body'].read().decode()
    print(result)

    Burada Session sınıfının client metodu kullanılarak bir sagemaker nesnesi elde edilmiştir. Sonra bu nesne üzerinde invoke_endpoint
    metodu çağrılmıştır. Tabii arka planda aslında işlemler Web Servisleriyle yürütülmektedir. Bu boto3 kütüphanesi bu işlemleri kendi 
    içerisinde yapmaktadır. Gelen mesajdaki Body kısmının elde edilip yazdırıldığında dikkat ediniz. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
   Microsoft Azure 2009 yılında kurulan bir bulut sistemidir. 2014 yılında Microsoft bu Azure sistemine yapay zeka ve makine 
   öğrenmesine ilişkin servisleri eklemiştir. Microsoft Azure daha önce görmüş olduğumuz Google Cloud Platform ve Amazon AWS 
   sistemine benzetilebilir. Benzer hizmetler Azure üzerinde de mevcuttur. Azure ML de hiç kod yazmadan fare hareketleriyle 
   ve Auto MLaraçlarıyla kullanılabilmektedir. Tıpkı Google Cloud Platform ve Amazon SageMaker’da olduğu gibi bir SDK eşliğinde 
   tüm yapılan görsel işlemler programlama yoluyla da yapılabilmektedir. Microsoft Azure ML için tıpkı GCP ve AWS’de olduğu gibi 
   sertifikasyon süreçleri oluşturmuştur. Bu konuda sertifika sınavları da yapmaktadır. Yani Azure sistemi bütün olarak bakıldığında 
   çok ayrıntılara sahip bir sistemdir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Azure kullanımı için ilk yapılacak şey bir e-posta ile Microsoft hesabı açmaktır. Sonra bu hesap kullanılarak Azure hesabı 
    açılmalıdır. Azure hesabı açılırken "bedava" ve "ödediğn kadar kullan" biçiminde seçenekler karşımıza gelmektedir. Bedava 
    kullanımın pek çok kısıtları vardır. Bu nedenle deneme hesabınızı "ödediğin kadar kullan" seçeneği ile oluşturabilirisiniz. 
    Ancak kullanmadığınız servisleri her ihtimale karşı kapatmayı unutmayınız. Azure sistemine abona olunduktan sonra bir 
    kullajıcı için "abone ismi" oluşturulmaktadır. 
        
    Azure sistemini e-posta ve parola ile girildikten sonra ana yönetim sayfası portal sayfasıdır. Portal sayfasına 
    doğrudan aşağıdaki bağlantı ile girilebilmektedir:
    
    https://portal.azure.com

    Azure'ün ana sayfasına geçtikten sonra buradan Yapay Zeka ve Makine Öğrenmesi için "Azure Machine Leraning" seçilmelidir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Azure Machine Learning sayfasına geçildiğinde önce bir "Workspace" seçiminin yapılması gerekmektedir. Workspace yapılacak çalışmalar 
    için bir klasör gibi bir organizasyon oluşturmaktadır. Yeni bir Workspace oluşturabilmek için "Oluştur (Create)" düğmesine basılır. 
    Ancak bir "workspace" oluştururken bizim bir "kaynak grubuna (resource group)" ihtiyacımız vardır. Bu nedenle önceden bir 
    kaynak grubu oluşturulmuş olmalıdır. Kaynak grubu oluşturabilmek için ana menüden (hamburger menüden) "Kaynak Grupları (Resource Gropus)"
    seçilir. Kaynak grubu birtakım kaynakların oluşturduğu gruptur. Workscpace de bir kaynaktır. Dolayısıyla workspace'ler 
    kaynak gruplarının (resource groups) bulunurlar. Kaynak Grupları menüsünden "Oluştur (Create)" seçilerek kaynak grubu oluşturma
    sayfasına geçilir. Yaratılacak kaynak grubuna bir isim verilir. Bütün bu isimler dünya genelinde tek olmak zorundadır. 
    Kaynak Grupları diğer cloud sistemlerind eolduğu gibi bölgelerle ilişkilendirilmiştir. Bu nedenle kaynak grubu yaratılırken 
    o kaynak grubunun bölgesi de belirtilir. 

    Workspace oluştururken bizden bazı bilgilerin girilmesi istenmektedir. Ancak bu bilgiler default biçimde de oluşturulabilmektedir. 
    Ancak bizim workspace'e bir isim vermemiz ve onun yer alacağı kaynak grubunu (resource group) belirtmemiz gerekir. Bu adımlardan 
    sonra nihayet workspace oluşturulacaktır. Tabii bir workspace oluşturduktan saonra tekrar tekrar workspace oluşturmaya genellikle 
    gerek yoktur. Farklı çalışmaları aynı workspace içerisinde saklayabiliriz. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Microsoft da tıpkı Amazon'da olduğu gibi makine öğrenmesiişlemleri için Web tabanlı bir IDE benzeri sistem oluşturmuştur. 
    Buna "Machine Learning Studio" ya da kısaca "Studio" denilmektedir. Workspace'i seçip "Studio düğmesine basarak Studi IDE'sine 
    geçebiliriz. Auto ML işlemleri için Studio'da "Automated ML" sekmesine tıklanılır. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Machine Learning Studio'da Auto ML işlemlerini başlatmak için "Automated ML" sayfasında "New Automated ML Job" seçilir. 
    Daha önceden de gördüğümüz gibi bu tür Cloud Platformlarında dört ana unsur vardır:

    1) Storage (Eğitim için veri kümesisi barındırmak için ve eğitim sonucunda oluşturulacak dosyaları barındırmak için)
    2) CPU (Eğitimi yapabilmek için gereken makine)
    3) Model (Çeşitli yöntemlerle veri kümesine uygun en iyi ML modeli)
    4) Deployment ya da EndPoint (Hedef modelin konuşlandırılması ve Web Servisler yoluyla uzaktan kullanılabilir hale getirilmesi)

    Microsoft Azure sisteminde de "New Automated ML Job" işleminin ilk aşamasında bizden hangi veri kümesi üzerinde ML çalışması yapılacağı 
    sorulmaktadır. Biz bu aşamada yeni bir veri kümesini Azure'ün Storage sistemine upload edebiliriz. Ya da bu upload etme işlemi 
    daha önceden oluşturulabilir. Azure sisteminde upload edilmiş veri kümelerine "data asset" denilmektedir. "New Automated ML Job"
    işleminde toplam dört aşama bulunmaktadır:

    1) Select data asset: Bu aşamada üzerinde çalışılacak veri kümesi belirtilir. Yukarıda söz ettiğimiz gibi bu veri kümesi daha 
    önceden "data asset" biçiminde oluşturulmuş olabilir ya da bu aşamada oluşturulabilir. 

    2) Configure job: Burada işlem için önemli bazı belirlemeler yapılmaktadır. Örneğin yapılacak işleme bir isim verilmektedir. 
    Veri kümesindeki tahmin edilecek hedef sütun belirtilmektedir. Eğitim için kullanılacak makinenin türü de bu aşamada 
    sorulmaktadır. Makine türü için "Compute Instance" seçilebilir. Tabii bizim daha önceden yaratmış olduğumuz bir hesapalama 
    maknesi (compute instance) bulunmuyor olabilir. Bu durumda bir hesaplama makinesinin (yani eğitimde kullanılacak makinenin)
    yaratılması gerekecektir. Tabii aslında bir hesaplama makinesini (compute instance) daha önce de yaratmış olabiliriz. Hesaplama 
    makinesini daha önceden bu işlemden bağımsız olarak yaratmak için Manage/Compute sekmesi kullanılmaktadır. 

    3) Select task and settings: Burada bize problemin türü sorulmaaktadır. Tabii Azure hedef sütundan hareketle aslında problemin
    bir sınıflandırma (lojistik regresyon) problemi mi yoksa regresyon problemi mi olduğunu belirleyebilmektedir. 

    4) Hyperparameter Configuration: Bu aşamad bize sınama yönteminin ne olacağı ve test verilerinin nasıl oluşturulacağı sorulmaktadır.

    Bu aşamalardan geçildikten sonra Auto-ML en iyi modelleri bulmak için işlemleri başlatır. İşlemler bitince yine bize bildirimde bulunulmaktadır. 

#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Auto-ML aracı işini bitirdikten sonra EndPoint oluşturulmultur. Biz Studo'da EndPoints sekmesine gelerek ilgili endpoint'in 
    üzerine tıkladığımızda yukarıdaki menüde "Details", "Test", "Consume" gibi seçenekler bulunur. Burada "Test" seçildiğinde 
    GUI'den kestirim yapılabilmektedir. "Consume" kısmında Web servisleri ile predict işlemi yapan bir Python kodu bulundurulmaktadır. 
    Ancak bu kodda api_key kısmı boş bir string'tir. Buradaki API key "Consume" sekmesinden "Primary Key" kısmından alınabilir. 

    Örneğin burada Consume sekmesindeki kod aşağıdaki gibidir. Ancak bu kodlarda dikkat edilmesi gereken nokta şudur: Bu kodlarda
    hesaba erişim için gereken "api key" boş bırakılmıştır. Bizim bu API key'i alıp buraya kopyalamamız gerekir. Daha önceden de 
    belirttiğimiz gibi bu API key Consume sekmesinden Primary Key alanından elde edilebilmektedir.  Buradaki "consume kodu" şaşağıda
    verilmiştir.
#----------------------------------------------------------------------------------------------------------------------------

import urllib.request
import json
import os
import ssl

def allowSelfSignedHttps(allowed):
    # bypass the server certificate verification on client side
    if allowed and not os.environ.get('PYTHONHTTPSVERIFY', '') and getattr(ssl, '_create_unverified_context', None):
        ssl._create_default_https_context = ssl._create_unverified_context

allowSelfSignedHttps(True) # this line is needed if you use self-signed certificate in your scoring service.

# Request data goes here
# The example below assumes JSON formatting which may be updated
# depending on the format your endpoint expects.
# More information can be found here:
# https://docs.microsoft.com/azure/machine-learning/how-to-deploy-advanced-entry-script
data =  {
  "Inputs": {
    "data": [
      {
        "age": 0,
        "sex": "example_value",
        "bmi": 0.0,
        "children": 0,
        "smoker": "example_value",
        "region": "example_value"
      }
    ]
  },
  "GlobalParameters": 0.0
}

body = str.encode(json.dumps(data))

url = 'https://kaanaslantestworkspace-wyndx.northeurope.inference.ml.azure.com/score'
# Replace this with the primary/secondary key or AMLToken for the endpoint
api_key = ''
if not api_key:
    raise Exception("A key should be provided to invoke the endpoint")

# The azureml-model-deployment header will force the request to go to a specific deployment.
# Remove this header to have the request observe the endpoint traffic rules
headers = {'Content-Type':'application/json', 'Authorization':('Bearer '+ api_key), 'azureml-model-deployment': 'automl457b251af41-1' }

req = urllib.request.Request(url, body, headers)

try:
    response = urllib.request.urlopen(req)

    result = response.read()
    print(result)
except urllib.error.HTTPError as error:
    print("The request failed with status code: " + str(error.code))

    # Print the headers - they include the requert ID and the timestamp, which are useful for debugging the failure
    print(error.info())
    print(error.read().decode("utf8", 'ignore'))

#----------------------------------------------------------------------------------------------------------------------------
    Aslında Microaoft tarafından hazırlanmış olan azureml isimli başka bir kütüphane daha bulunmaktadır. İşlemler bu kütüphane ile
    daha az kod yazarak da yapılabilmektedir. Bu kütüphane için aşağıdaki paketlerin yüklenmesi gerekmektedir:

    pip install azureml
    pip install azureml-core
    pip install azureml-data

    Aşağıda azureml kullanılarak kestirim işlemine örnek verilmiştir. 
#----------------------------------------------------------------------------------------------------------------------------

import json
from pathlib import Path
from azureml.core.workspace import Workspace, Webservice
 
service_name = 'automl245eb70546-1',
ws = Workspace.get(
    name='KaanWorkspace',
    subscription_id='c06cf27d-0995-4edd-919a-47fd40f4a7ae',
    resource_group='KaanAslanResourceGroup'
)
service = Webservice(ws, service_name)
sample_file_path = '_samples.json'
 
with open(sample_file_path, 'r') as f:
    sample_data = json.load(f)
score_result = service.run(json.dumps(sample_data))
print(f'Inference result = {score_result}')

#----------------------------------------------------------------------------------------------------------------------------
    Azure'ün Machine Learning servisinde diğerlerinde henüz olmayan "designer" özelliği de bulunmaktadır. Bu designed sayesinde 
    sürükle bırak işlemleriyle hiç kod yazmadan makşne öğrenmesi modeli görsel biçimde oluşturulabilmektedir. Bunun için 
    Machine Learning Stdudio'da soldaki "Designer" sekmesi seçilir. Bu sekme seçildiğinde karşımıza bazı seçenekler çıkacaktır. 
    Biz hazır bazı şablonlar kullanarak ve şablonları değiştirerek işlemler yapabiliriz ya da sıfırdan tüm modeli kendimiz 
    oluşturabiliriz. 

    Model oluştururken sol taraftaki pencerede bulunan iki sekme kullanılmaktadır. Data sekmesi bizim Azure yükledeiğimiz veri 
    kümelerini göstermektedir. Component sekmesi ise sürüklenip bırakılacak bileşnleri belirtmektedir. Her bileşen dikdörtgensel 
    bir kutucuk ile temsil edilmiştir. Kod yazmak yerine bu bileşenler tasarım ekranına sürüklenip bırakılır. Sonra da bu bileşenler
    birbirlerine bağlanır. Sürüklenip bırakılan bileşenlerin üzerine tıklanıp farenin sağ tuşu ile bağlam menüsünden bileşene özgü 
    özellikler görüntülenebilir. Bu bağlam menüsünde pek çok bileşen için en önemli seçenek "Edit node name" seçenğidir. Bu seçenekte
    bileşene ilişkin özenmli bazı özellikler set edilmektedir. 

    Eğer model için şablon kullanmayıp sıfırdan işlemler yapmak istiyorsak işlemlere Data sekmesinde ilgili veri kümesini sürükleyip
    tasarım ekranına bırakmakla başlamalıyız. 

    Veri kümesini belirledikten sonra biz veri kümesindeki bazı sütunlar üzerinde işlem yapmak isteyebiliriz. Bunun için 
    "Select Columns in Dataset" bileşeni seçilir. Veri kümesinin çıktısı bu bileşene fare hareketi ile bağlanır. Sonra 
    "Select Columns in Dataset" bileşeninde bağlam menüsünden "Edit node name" seçilir. Buradan da "Edit columns" seçilerek 
    sütunlar belirlenir. 

    Bu işlemden sonra eksik veriler üzerinde işlemlerin yapılması isteniyorsa "Clean Missing Data" bileşni seçilerek tasarım 
    ekranına bırakılır. 

    Bundan sonra veri kümesini eğitim ve test olmak üzere ikiye ayırabiliriz. Bunun için "Split Data" bileşeni kullanılmaktadır. 
    Bu bileşende "Edit node names" yapıldığında bölmenin yüzdelik değerleri ve bölmenin nasıl yapılacağına yönelik bazı 
    belirlemeler girilebilir. 

    Bu işlemden sonra "Özellik Ölçeklemesi (Feature Scaling)" yapılabilir. Bunun için "Normalize Data" bileşeni seçilir. 
    Bu bileşende "Edit node names" seçildiğinde biz ölçekleme üzerinde belirlemeleri yapabilecek duruma geliriz. 

    Bu aşamalardan sonra artık sıra modelin eğitimine gelmiştir. Modelin eğitimi için "Train Model" bileşeni kullanılmaktadır. 
    Bu bileşenin iki girişi vardır. Girişlerden biri "Dataset" girişidir. Bu girişe veri test veri kümesi bağlanır. Bileşenin
    birinci girişi olan "Untrained model" girişine ise problemin türünü belirten bir bileşen bağlanır. Çeşitli problem türleri 
    için çeşitli bileşenler vardır. Örneğin ikili sınıflandırma problemleri için "Two class logistic regression" bileşeni kullanılır. 
    Eğitime ilişkin hyper parametreler bu bileşende belirtilmektedir. 

    Eğtim işleminden sonra sıra modelin test edilmesine gelmiştir. Modelin testi için "Score Model" bileşeni kullanılır. Score Model
    bileşeninin iki girişi vardır: "Trainded Model" ve "Dataset" girişleri. "Train Model" bleşeninin çıkışı "Trained Model" girişine, 
    "Split Data" bileşeninin ikinci çıkışı ise "Dataset" girişine bağlanır.

    Model Designer'da oluşturulduktan sonra artık sıra modelin eğitilmesine gelmiştir. "Configure & Submit" düğmesine basılır. 
    Burada artık eğitim için kullanılacak CPU kaynağı belirlenir. (Anımsayacağınız gibi Automated araçlarda bizim belirlememiz
    gereken üç unsur "Data" + "Model" + "CPU" biçimindeydi.) 

    Nihayet işlemleri başlatıp deployment işlemi için "Inference Pipeline"" seçeneği seçilmelidir. 

    Azure Designer'daki tüm bileşenler (components) aşağıdaki Microsoft bağlantısında dokümante edilmiştir:

    https://learn.microsoft.com/en-us/azure/machine-learning/component-reference/component-reference?view=azureml-api-2


    Biz Inference Pipeline işlemini yaptığımızda Azure bize modelimizi kestirimde kullanılabecek hale getirmektedir. Bunun 
    için model bir "Web Service Output" bileşeni eklemektedir. Bu "Web Service Output" bileşeni kestirim çıktılarının 
    bir web servis biçiminde verileceği anlamına gelmektedir. Eskiden Azure aynı zamanda "Inference Pipeline" seçildiğinde
    modelimize bir "Web Service Input" bileşeni de ekliyordu. Bu bileşen de girdilerin web service tarafından alınacağını
    belirtmekteydi. Designer'ın yeni versiyonlarında "Infererence Pipeline" yapıldığında bu "Web Service Input" bileşeni artık
    eklenmemektedir. Web Service Input bileşeni eklendikten sonra artık bizim "Select Columns in Dataset" bileşeninden 
    kestirilecek sütunu çıkartmamız gerekmektedir. Ayrıca bu Web Service Input bileşeninin çıktısının artık "Select Columns in Dataset"
    bileşenine değil doğrudan ApplyTransformation bileşenine bağlanması gerekmektedir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Desginer'ın aytıntılı kullanımı için Microsoft dokümanlarını inceleyebilirsiniz. Örneğin aşağıdaki dokümanda lojistik olmayan 
    regresyon probleminin adım adım designer yardımıyla oluşturulması anlatılmaktadır:

    https://learn.microsoft.com/en-us/azure/machine-learning/tutorial-designer-automobile-price-train-score?view=azureml-api-1

#----------------------------------------------------------------------------------------------------------------------------
    IBM'in Cloud Platformu da en çok kullanılan platformlardan biridir. İşlevsellik olarak diğerlerine benzemektedir. IBM'de 
    cloud platformu içerisinde makine öğrenmesine ilişkin servisler bulundurmaktadır. Genel olarak IBM'in bu servislerine
    Watson denilmektedir. 
#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    IBM Cloud platformu için yine bir hesap açılması gerekir. Hesap açma ve sign in işlemleri cloud.ibm.com adresinden 
    yapılmaktadır. Hesap açılırken girilen e-posta adresi aynı zmaanda "IBMid" olarak kullanılmaktadır. IBMid cloud platformunda
    "user id" gibi kullanılmaktadır. 
#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    IBM Cloud platformuna login olunduktan sonra karşımıza bir "Dashboard" sayfası çıkmaktadır. Burada ilk yapılacak şey 
    "Create Resource" seçilerek kaynak yaratılmasıdır. Buradan "Watson Studio" seçilir. Bedava hesp ile ancak bir tane "Watson Studio"
    kaynağı oluşturulabilmektedir. Kaynak oluşturulduktan sonra "Launch in IBM Cloud Pak for Data" düğmesine basılarak
    "IBM Watson Studio" ortamına geçilmektedir. IBM Watson Studio bir çeşit "Web Tabanlı IDE" gibi düşünülebilir. 
#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    IBM Watson Studio'ya geçildiğinde öncelikle bir projenin yaratılması gerekmektedir. Bunun için "New Project" seçilir. 
    Proje bir isim verilir. Sonra projenin yaratımı gerçekleşir. 
#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    Proje yaratıldıktan sonra "New Asset" düğmesi le yeni bir proje öğesi (asset) oluşturulmalıdır. Burada Otomatik ML işlemleri 
    için "Auto AI" seçilebilir.
#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    Auto AI seçildiğinde yaratılacak işlem (experiment) için bir isim verilmelidir. Sonra bu işlem (experiment)" bir ML servisi 
    ile ilişkilendirilmelidir. 
#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    Watson Studio'da Auto AI projesinde bizden öncelikle veri kümesinin yüklenmesi istenmektedir. Veri kümesi yüklendikten sonra 
    bu veri kümesinin ardışık "time series" verilerinden oluşup oluşmadığı bize sorulmaktadır. Bundan biz kesitim yapılacak sütun
    belirleriz. Uygulamacı problemin türüne göre problemin çeşitli meta parametrelerini kendisi set edebilmektedir. Bu işlem 
    "Experiment Settings" düğmesiyle yapılmaktadır. Nihayet uygulamacı "Run Experiment" seçeneği ile eğitimi başlatır. 
#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    Modeller oluşturulduktan sonra bunlar performansa göre iyiden kötüye doğru sıralanmaktadır. Bu modeller save edilebilir. 
    Modeller save edilirken istenirse model kodları bir Jupyter Notebook olarak da elde edilebilmektedir. Bu notebook yerel makineye
    çekilip IBM Python kütüphanesi kurulduktan sonra yerel makinede de çalıştırılabilir. 
#----------------------------------------------------------------------------------------------------------------------------

#----------------------------------------------------------------------------------------------------------------------------
    Deployment işlemi için önce bir "deployment space" yaratılır. Ancak bu deployment space'te Assets kısmında deploy edilecek 
    modelin çıkması için dah önceden Model sayfasında "Promote to Deployment Space" seçilmelildir. Bundan sonra Deployment Space'te
    Assets kısmında ilgili model seçilerek "Create Deployment" düğmesi ile deployment işlemi yapılır. 
#----------------------------------------------------------------------------------------------------------------------------
   
#----------------------------------------------------------------------------------------------------------------------------
    Deployment sonrası yine Wen Servisleri yoluyla model kullanılabilmektedir. Bu işlem Watson Web API'leriyle yapılabilecğei gibi
    diğer cloud platfotrmlarında olduğu gibi bu Web API'lerini kullanan Python kütüphaneleriyle de yapılabilmektedir. Kütüphane 
    aşağıdaki gibi install edilebilir:

    pip install ibm-watson-machine-learning   
#----------------------------------------------------------------------------------------------------------------------------



