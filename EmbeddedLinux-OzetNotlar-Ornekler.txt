/*-----------------------------------------------------------------------------------------------------------------------------

                                            C ve Sistem Programcıları Derneği

                                   Gömülü Linux Sistemleri - Geliştirme ve Uygulama Kursu

                                        Sınıfta Yapılan Örnekler ve Özet Notlar

                                                  Eğitmen: Kaan ASLAN

          Bu notlar Kaan ASLAN tarafından oluşturulmuştur. Kaynak belirtmek koşulu ile her türlü alıntı yapılabilir.

                    (Notları sabit genişlikli font kullanan programlama editörleri ile açınız.)
                        (Editörünüzün "Line Wrapping" özelliğini pasif hale getiriniz.)

                                            Son Güncelleme: 13/05/2025 - Salı

-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												1. Ders 05/03/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Kurs için gerekli olabilecek malzemeler şunlardır:

    - Raspberry Pi SBC (Single Board Computer): Version 3, 4 ya da 5 olabilir. Yeni satın alacakların Raspberry Pi 5 almalarını 
    tavsiye ediyoruz.

    - Raspberry Pi 5 alınacaksa soğutucu ya da soğutuculu kılıf da alınmalı. Raspberry Pi 3 ve 4 için soğutucu alınmayabilir.

    - Raspberry Pi için Micro SD Kart: 64 GB yüksek hızlı micro SD kart tavsiye ediyoruz. 32 GB de olabilir. Ancak 32 GB'den 
    düşüğü tavsiye etmiyoruz.

    - Raspberry Pi 4 ve Raspberry Pi 5 için "Micro HDMI -> HDMI Kablosu", Raspberry Pi 3 için "HDMI -> HDMI" Kablosu.

    - USB Kombo Klavye + Mouse

    - Raspberry Pi için GPIO Breadboard Aktarma Kablosu

    - Raspberry Pi için Güç Kaynağı Adaptörü: Raspberry Pi 3 ve 4 için 5V/3A, Raspberry Pi 5 için 5V/5A (27W). Raspberry Pi 4 
    ve 5 USB Type C kullanıyor. Raspberry Pi 3 Micro USB kablosu kullanıyor.

    - BeagleBone Black SBC (Single Board Computer): Yeni satın alacak olanlar "BeagleBone Black 4G" ya da BeagleBone Black Wireless" 
    alabilirler. Stokları kontrol etmek gerekiyor.

    - BeagleBone Black için Güç Kaynağı: Mini USB ile 5V/500mA güç adaptörü ya da yuvarlak girişli (DC Jack) 5V/1A güç adaptörü. 
    Ancak BeagleBone Black USB kablo ile PC’den de güç alabilmektedir.

    - BeagleBone Black için Micro SD Kart (16GB olabilir).

    - BeagleBone Black için "Micro HDMI -> HDMI" Dönüştürücü.

    - Standart Boy Breadboard ve İsteğe Bağlı Küçük Boy Breadboard'lar da olabilir.

    - Jumper Kablo seti

    - "USB -> UART" Dönüştürücü (CP2102 çevirici modül olabilir)

    - USB Uzatma Kablosu Gerekebilir.

    - Ethernet RJ45 Kablosu: Eğer SBC'nin wireless özelliği varsa buna gerek duymayabilirsiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												2. Ders 07/03/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Kursumuzun giriş bölümünde çeşitli kavramları ve terimleri açıklayacağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Asıl amacı bilgisayar olmayan fakat bilgisayar devresi içeren sistemlere genel olarak gömülü sistemler (embedded systems) 
    denilmektedir. Yani gömülü sistemler başka amaçları gerçekleştirmek için tasarlanmış olan aygıtların içerisindeki bilgisayar
    sistemleridir. Örneğin elektronik tartılar, biyomedikal aygıtlar, GPS cihazları, turnike geçiş sistemleri (validatörler), 
    müzik kutuları, kapı güvenlik aygıtları, otomobiller içerisindeki kontrol panelleri birer gömülü sistemdir. Gömülü 
    sistemlerde en çok kullanılan programlama dili C'dir. Ancak genel amaçlı işletim sistemlerinin yüklenebildiği SBC'lerde 
    (Single Board Computer) diğer programlama dilleri de kullanılabilmektedir.

    Gömülü sistemler gömüldüğü aygıtta belli işlevleri sağlamak için kullanılmaktadır. Örneğin buzdolaplarının, çamaşır 
    makinelerinin içerisine yerleştirilen bilgisayar devreleri ve yazılımlar onların önemli etkinlerini yönetmekte, kullanıcı 
    ile arayüz oluşturabilmektedir. Günümüzde bilgisayar sistemi içeren aygıtlar artık her yeri sarmıştır. Bu nedenle gömülü 
    sistemler üzerinde geliştirme faaliyetleri de önemli bir iş alanı haline gelmiştir.

    Gömülü sistemlerin tipik özellikleri şunlardır:

    - Gömülü sistemler "genel değil belirli (specific) amaca yönelik" işlemleri gerçekleştirmektedir. Yani genel amaçlı değil, 
    özel amaçlı donanım ve yazılım hizmeti sunmaktadır. Bu sistemlerdeki yazılımlar da genel amaçlı değil, belli bir amacı 
    gerçekleştirmeyi hedeflemektedir.

    - Gömülü sistemler genellikle daha düşük bir bilgi işlem kapasitesine sahip bilgisayar devreleridir. Örneğin bu sistemlerde 
    kullanılan işlemciler genel amaçlı masaüstü işlemcilerden genellikle daha yavaş olma eğilimindedir. Bu sistemlerdeki bellek
    miktarları (birincil ve ikinci bellekler) genel amaçlı bilgisayar sistemlerine göre daha düşük olma eğilimindedir. Dolayısıyla 
    gömülü sistemlerin maliyetleri de genel amaçlı bilgisayar sistemlerine göre oldukça düşüktür.

    - Gömülü sistemler genellikle (fakat her zaman değil) daha düşük güç harcamaktadır. Bu durum onların bataryalarla beslenebilmesini 
    dolayısıyla fiziksel taşınabilirliğini de artırmaktadır. Tabii genel olarak gömülü sistemler düşük güç harcama eğiliminde olan 
    sistemler olsalar da bu durum her zaman böyle olmak zorunda değildir. Bazı gömülü sistemlerin gömüldüğü sistemlerde bir güç 
    kullanma sorunu yoktur. (Örneğin araba kantarı zaten bu işlevi gerçekleştirmek için önemli bir güç harcamaktadır. Dolayısıyla 
    bu sistemdeki gömülü sistemin harcadığı gücün önemi olmayabilir.)

    - Gömülü sistemlerin önemli bir bölümü "gerçek zamanlı (real time)" olaylarla ilişkilidir. Bu sistemlerin belli bir bölümü 
    dış dünyadaki değişimlere karşı bir yanıt oluşturmaya çalışmaktadır. Örneğin bir gömülü sistem ottamdaki ısı belli bir kritik 
    düzeye geldiğinde bir işlemi başlatabilir. Ya da bir gömülü sistem kalp ritmi bozulduğunda kalbe uyarılar göndererek ritim 
    bozukluğunu düzeltmeye çalışabilir. Hava araçlarındaki gömülü sistemler o anki hava şartlarına göre bir otomatik kumanda sistemi 
    işlevini görüyor olabilir. Tabii gömülü sistemlerin bu gerçek zamanlı işlem doğası bazı uygulamalarda "çok katı (hard realtime)" 
    olurken bazı uygulamalarda "daha gevşek (soft realtime)" olabilmektedir.

    - Gömülü sistemlerin bazılarında hiç girdi/çıktı birimi olmayabilir. Bazılarında ise girdi/çıktı birimi olarak "düğmeler", 
    basit tuş takımları, küçük LCD'ler olabilir. Oysa genel amaçlı bilgisayar sistemlerinde genellikle girdi/çıktı birimi olarak 
    klavye, fare ve gelişmiş monitörler kullanılmaktadır. Başka bir deyişle gömülü sistemler kullanıcı arayüzü bakımından minimal 
    olma eğilimindedir.

    - Gömülü sistemlerdeki donanım birimleri nispeten ucuz olma eğilimindedir. Genel amaçlı bilgisayarlara göre bunlar çok daha ucuz
    olarak temin edilebilmektedir.

    Gömülü sistemler “işlevsel gereksinimlere göre” ve “performans gereksinimlerine” göre de sınıflandırılabilmektedir:

    1) İşlevsel Gereksinimlere Göre Sınıflandırma:

        a) Gerçek Zamanlı Olan ya da Gerçek Zamanlı Olmayan Gömülü Sistemler: Bunlar "hard" ya da "soft" real-time olabilmektedir.
        b) Bağımsız (Stand-alone) Olan ya da Bağımsız Olmayan Sistemler
        Örneğin hesap makineleri, kapı güvenlik sistemleri, MP3 çalarlar gibi.
        c) Ağ (Network) Üzerinde İşlem Yapan Gömülü Sistemler: Bunlar ağ işlemleri yapmak için oluşturulmuş gömülü sistemlerdir.
        ATM makinelerini, ADSL Router gibi aygıtları bunlara örnek verebiliriz.
        d) Mobil Aygıtlarda Kullanılan Gömülü Sistemler: Bunlar küçük, taşınabilir aygıtlarda kullanılan gömülü sistemlerdir.
        Telefonlar, GPS cihazları, dijital kameralar bunlara örnek verilebilir.

    2) Performans Gereksinimlerine Göre Sınıflandırma:

        a) Küçük Ölçekli (Small Scale) Gömülü Sistemler
        b) Orta Ölçekli (Medium Scale) Gömülü Sistemler
        c) Büyük Ölçekli (Large Scale) Gömülü Sistemler

    Biz burada "https://www.ultralibrarian.com/2022/06/28/types-of-embedded-systems-characteristics-classifications-ulc"
    bağlantısındaki sınıflandırmayı kullandık. Ancak başka kaynaklarda başka türlü sınıflandırmalar da yapılabilmektedir.

    Gömülü sistemlerde bilgisayar birimi olarak genellikle mikrodenetleyiciler (microcontrollers) kullanılmaktadır. Ancak entegre
    devre teknolojisinin gelişmesiyle artık içlerine standart işletim sistemi yüklenebilen çok daha gelişmiş donanımlar da 
    gömülü sistemlerde kullanılabilmektedir.

    Gömülü sistem yazılımlarının önemli bir bölümü bir işletim sistemi olmadan çalışacak biçimde (bare-metal) olarak geliştirilmektedir. 
    Bunun önemli nedenlerinden biri bunların kapasitelerinin nispeten düşük olması diğeri de belirli bir amacı gerçekleştirecek
    biçimde tasarlanmış olmalarıdır. Gömülü sistemlerin bir bölümünde "gerçek zamanlı işletim sistemleri" bir bölümünde ise "genel 
    amaçlı işletim sistemleri" kullanılmaktadır.

    Gömülü sistemlerde genel olarak üç işlem birimi kullanılmaktadır:

    1) Mikrodenetleyiciler
    2) Mikroişlemciler
    3) DSP'ler
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bir bilgisayar sisteminde aritmetik, mantıksal, bitsel işlemler ve karşılaştırma gibi bilgi işlem faaliyetleri işlemleri 
    "mikroişlemci (microprocessor)" denilen birim tarafından yapılmaktadır. Mikroişlemciler entegre devre biçiminde üretilmişlerdir. 
    Mikroişlemcilere kavramsal olarak CPU (Central Processing Unit) de denilmektedir. Aslında genel amaçlı bir bilgisayar sisteminde 
    komut çalıştıran pek çok işlemci bulunabilmektedir. CPU bu işlemcileri de programlayan "merkezi (central)" işlemcidir. Bilgisayar 
    sisteminde yerel bazı işlemlerden sorumlu yardımcı işlemciler de vardır. Örneğin "kesme denetleyicisi (interrupt controller)", 
    "disk denetleyicisi (disk controller)", "DMA denetleyicisi (DMA controller)" gibi.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Mikrodenetleyiciler tek bir chip içerisine yerleştirilmiş bir bilgisayar sistemi gibi düşünülebilirler. Tipik olarak bir 
    mikrodenetleyicide bir "işlemci (processor)", kendi içerisinde "RAM ve Flash EPROM", dış dünya ile haberleşmek için kullanılan 
    "Giriş/Çıkış (IO) birimleri" ve bazı "çevre birimleri (peripherals)" bulunmaktadır. Mikrodenetleyicilere İngilizce "Microcontroller" 
    ya da "Microcontroller Unit (MCU)" da denilmektedir.

    Mikrodenetleyicilerin işlem kapasiteleri ve içerdikleri bellek miktarları düşük olma eğilimindedir. Ancak bunlar çok kolay 
    programlanıp uygulamaya sokulabilmektedir. Mikrodenetleyicilere "tek çiplik bilgisayar (single chip computer)" da denilmektedir. 
    Mikrodenetleyiciler özellikle gömülü sistemlerde tercih edilmektedir. Bunların düşük güç harcaması ve ucuz olmaları en büyük 
    avantajlarındandır. Gömülü uygulamalarda kullanılan pek çok mikrodenetleyici ailesi vardır. Örneğin:

    - Microchip PIC Mikrodenetleyici Ailesi (Microchip)
    - Renesas Mikrodenetleyici Ailesi (Renesas)
    - ARM Mikrodenetleyici Ailesi (Tasarımcısı ARM Holding, ancak çok çeşitli firmalar tarafından üretiliyor)
    - AVR Mikrodenetleyici Ailesi (Atmel, ancak Atmel firması 2016'da Microchip tarafından satın alındı)
    - MSP Mikrodenetleyici Ailesi (Texas Instruments)
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bazı firmalar ayrı birimler olarak tasarlanmış mikroişlemcileri, RAM'leri, ROM’ları ve diğer bazı çevre birimlerini tek bir 
    entegre devrenin içerisine sıkıştırmaktadır. Bunlara genel olarak "SoC (System on Chip)" denilmektedir. SoC mikrodenetleyicilere 
    benzese de aslında onlardan farklıdır. SoC’lar içerisindeki işlemcilerin ve belleklerin kapasiteleri yüksektir. Bunlar özel 
    amaçlı üretilirler ve bunların devrelerde kullanılmaları mikrodenetleyiciler kadar kolay değildir. Bunların en önemli avantajları 
    az yer kaplamasıdır. Örneğin Raspberry Pi kitlerinde Broadcom isimli firmanın 2835, 2836, 2837, 2711, 2712 numaralı SoC 
    çipleri kullanılmıştır. SoC'ların RAM ve ROM bellek içermesi zorunlu değildir. Bazı SoC'lar RAM içerirken bazıları içermeyebilmektedir. 
    Örneğin Raspberry Pi 1, 2, 3 modellerinde kullanılan SoC'lar RAM içerirken Raspberry Pi 4 ve 5 modellerinde kullanılan SoC'lar 
    RAM içermemektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    SoC kavramına benzer diğer bir kavram da "SoM (System on Module)" kavramıdır. SoM bir işlemci ve onunla ilişkili bazı birimlerin
    monte edildiği kartları belirtmek için kullanılmaktadır. SoM'lar SoC'ları içerebilir. Ancak başka birimleri de içerebilir. 
    Örneğin bir SoM bir işlemci, buna ilişkin RAM, IO denetleyicisi (IO controllers) içeren bir kart olabilir. Örneğin "Raspberry Pi
    Pico" ve "Raspberry Pi Compute Module" birer SBC'den ziyade birer SoM olarak ele alınabilir. SoM kavramını zihninizde SoC ile 
    SBC arasında bir yerde konumlandırabilirsiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Küçük bir kit (baskılı devre) üzerine monte edilmiş bilgisayarlara SBC (Single Board Computer) denilmektedir. Genellikle 
    bu kitlerde SoC'lar, RAM'ler, başka çevre birimleri ve IO işlemleri için uçlar bulunmaktadır. Örneğin Raspberry Pi’lar,
    Beagleboard’lar SBC'lere örnek verilebilir. SBC'ler klavye, fare ve monitör takılarak bir masaüstü bilgisayar gibi 
    kullanılabilmektedir. SBC'ler masaüstü bilgisayarlar gibi de kullanılabildiğinden bunlara Linux başta olmak üzere, Android 
    ve Windows gibi işletim sistemleri yüklenebilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Mikroişlemcileri tasarım mimarilerine göre CISC (Complex Instruction Set Computers) ve RISC (Reduced Instruction Set Computers) 
    olmak üzere iki kısma ayırabiliriz. CISC ailesi işlemcilere Intel firmasının x86 ailesi işlemcilerini örnek verebiliriz. 
    ARM, MIPS, PowerPC, Itanium gibi işlemciler ise tipik RISC işlemcileridir. Her ne kadar CISC ve RISC isimleri komut kümesi 
    ile ilgili biçimde uydurulmuşsa da CISC ve RISC tasarımları başka bakımlardan da farklılık göstermektedir.

    Önceleri işlemcilerin (makro ve mikro) fazla sayıda makine komutuna sahip olması bir avantaj olarak görülüyordu. Ancak daha 
    sonraları bunun avantajdan ziyade dezavantaj oluşturduğu anlaşıldı. Belli bir süreden sonra artık RISC mimarisinin CISC 
    mimarisinden toplamda daha iyi bir tasarım olduğu kabul görmüştür. Bu nedenle son dönem mikroişlemci tasarımlarında hep RISC 
    mimarisi kullanılmıştır.

    CISC ve RISC işlemci mimarisi arasındaki temel farklılıklar şunlardır:

    1) CISC işlemcilerinde fazla sayıda makine komutu bulunmaktadır. Bu işlemcilerde bazı komutlar temel işlemleri yaparken 
    bazıları karmaşık işlemler yapmaktadır. Halbuki RISC işlemcilerinde az sayıda temel makine komutları bulunmaktadır. Bu 
    makine komutları da daha fazla transistör kullanılarak daha hızlı çalışacak biçime getirilmiştir. Dolayısıyla CISC işlemcilerindeki 
    bazı komutlar RISC işlemcilerinde birkaç komutla karşılanabilmektedir. Ancak bu durum sanıldığının tersine daha hızlı bir 
    çalışma sağlama potansiyelindedir.

    2) CISC işlemcilerinde az sayıda yazmaç (register), RISC işlemcilerinde ise fazla sayıda yazmaç bulunma eğilimindedir. Yazmaç 
    sayıları az olunca yazmaçların tekrar tekrar aynı değerlerle yüklenmesi gerekebilmektedir. Bu da derleyicinin nesneleri 
    daha kısa sürede yazmaçlarda tutmasına yol açmaktadır. Yine CISC işlemcilerindeki bazı komutlar ancak bazı özel yazmaçlarla 
    kullanılmaktadır. (Örneğin Intel x86 işlemcilerinde MUL ve DIV komutlarının bir operandı EAX ya da RAX yazmacında bulunmak 
    zorundadır.) Oysa RISC işlemcilerinde her işlem her yazmaçla yapılabilmektedir.

    3) CISC işlemcilerinde komutlar farklı uzunluklarda olabilmektedir. Örneğin Intel'in x86 ailesinde 1 byte olan makine komutları 
    da vardır, 5 byte olan makine komutları da vardır, 11 byte olan hatta 15 byte olan makine komutları da vardır. Halbuki RISC 
    işlemcilerinde genel olarak tüm makine komutları eşit uzunluktadır. Örneğin ARM işlemcilerinde her makine komutu 4 byte 
    uzunluktadır. Böylece işlemci komutları bellekten daha etkin bir biçimde çekip (fetch işlemi) onları daha çabuk anlamlandırmaktadır. 
    Belli bir sayı sonraki ya da önceki makine komutlarının yerini belirleyebilmektedir.

    4) RISC işlemcilerinde pipeline mekanizması CISC işlemcilerine göre daha iyi gerçekleştirilmektedir. Pipeline işlemcinin
    bir makine komutunu çalıştırırken sonraki komutlar üzerinde hazırlık işlemlerini yapması anlamına gelmektedir. RISC tasarımı
    olarak pipeline mekanizmasının daha iyi yürütülmesine olanak sağlamaktadır.

    5) RISC işlemcileri load/store tarzı makine komutları kullanmaktadır. Bu işlemcilerde belleğe erişim yapan makine komutlarıyla
    aritmetik, mantıksal ve bitsel işlem yapan makine komutları birbirinden ayrılmıştır. Örneğin RISC işlemcilerinde ADD, SUB gibi
    makine komutlarının her iki operandı da yazmaç olmak zorundadır. Halbuki CISC işlemcilerinde bu tür makine komutlarının bir 
    operandı yazmaç bir operandı bellek olabilmektedir. Örneğin:

    a = b + c;

    gibi bir işlem CISC işlemcisi ile şu makine komutlarıyla yapılabilmektedir:

    - b'yi yazmaca çeken makine komutu
    - Yazmaçtaki b ile bellekteki c'yi toplayan makine komutu
    - Yazmaçtaki toplamı a'ya yerleştiren makine komutu

    Oysa aynı işlem RISC işlemcilerinde şöyle gerçekleştirilmektedir:

    - b'yi yazmaca çeken makine komutu
    - c'yi yazmaca çeken makine komutu
    - Yazmaçlardaki b ile c'yi toplayan makine komutu
    - Yazmaçtaki sonucu a'ya yerleştiren makine komutu

    Belleğe erişim komutlarıyla diğer komutların birbirinden ayrıldığı işlemcilere "load/store" işlemciler ya da "register-register"
    işlemciler de denilmektedir.

    6) RISC işlemcileri genel olarak (ancak hepsi değil) üç operandlı makine komutlarını kullanmaktadır. Oysa CISC işlemcileri 
    genellikle iki operand'lı makine komutlarını kullanır. İki operand'lı makine komutlarında işlemin sonucu operand olan yazmaçlardan
    birine yerleştirildiği için o yazmaç bozulmaktadır. Böylece derleyici o yazmaçtaki değeri yeniden kullanmak istediğinde 
    onu yeniden yüklemek zorunda kalmaktadır. Örneğin a = b + c işlemi 32 bit Intel işlemcilerinde tipik olarak şöyle 
    gerçekleştirilmektedir:

    MOV EAX, <a'nın adresi>
    ADD EAX, <b'nin adresi>
    MOV <c'bin adresi>, EAX

    Burada EAX işlemcinin bir yazmacıdır. ADD makine komutu bu yazmaçtaki değer ile bellekteki b'yi toplamakta ve sonucu yine
    EAX yazmacına yerleştirmektedir. Dolayısıyla EAX yazmacındaki a değeri artık kaybolacaktır. Bu değer yeniden kullanılmak 
    istendiğinde ise yeniden yüklemenin yapılması gerekecektir. Şimdi aynı işlemi ARM işlemcilerinde yapacak olalım:

    LDR R0, <a'nın bellek adresi>
    LDR R1, <b'nin bellek adresi>
    ADD R2, R1, R0
    STR R2, <c'nin bellek adresi>

    Burada R0, R1 ve R2 işlemcinin yazmaçlarıdır. Görüldüğü gibi ARM işlemcilerinde load/store komutları dışındaki komutlar 
    üç operand'lıdır. Bu da yazmaçlardaki değerlerin gerektiğinde bozulmamasına yol açmaktadır.

    7) RISC işlemcileri yukarıda belirttiğimiz tasarım prensiplerinden dolayı toplamda daha az güç harcama eğilimindedir. Bu da
    onların mobil aygıtlarda kullanılmasının önemli bir gerekçesini oluşturmaktadır.

    8) RISC işlemcilerinde makine komutlarının çalışma süreleri birbirine yakındır. Ancak CISC işlemcilerinde makine komutlarının 
    çalışma süreleri arasında önemli farklılıklar olabilmektedir. Örneğin ARM işlemcilerinde toplama, çıkartma, çarpma gibi 
    makine komutları 1 cycle'da yapılmaktadır. Ancak load/store komutlarının, jump komutlarının ve özel bazı komutların çalışma 
    süreleri 1 cycle'dan fazla olabilmektedir. Oysa örneğin Intel x86 işlemcilerinde komut süreleri değişik faktörlere bağlı olarak
    birbirinden çok farklılaşmaktadır.

    RISC ve CISC mimarilerini bir spektrum olarak düşünmek gerekir. Örneğin MIPS işlemcileri ARM işlemcilerine göre bu spektrumun 
    daha fazla RISC tarafındadır. Intel'in x86 işlemcilerini kategori olarak CISC grubu işlemciler olarak ele alsak da Pentium 
    işlemcileri ile birlikte bu işlemcilerde de RISC prensipleri gittikçe daha fazla kullanılır hale gelmiştir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												3. Ders 12/03/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    ARM işlemcilerinin tarihi "Acorn Computer" isimli İngiliz firmasına dayanmaktadır. Bu firma 80’li yılların başlarında 
    "BBC Micro" isimli 64K’lık ev bilgisayarlarını yapmıştı. Bu bilgisayarlarda Rockwell’in 8 bitlik 6502 işlemcileri kullanılıyordu. 
    Firma daha sonra "Berkeley RISC" projesinden etkilenerek kendi RISC işlemcilerini yapmaya odaklandı. Böylece ilk ARM modelleri 
    tasarlanmış oldu. Şirket 1990’da "Apple" ve "VLSI Technology" şirketleriyle ortaklıklar da kurarak ARM ismini aldı. (Eskiden 
    ARM "Acorn RISC Machine" isminden kısaltlıyordu. Fakat daha sonra bu firma kurulunca bu kısaltma "Advanced RISC Machine" haline 
    getirildi.) Apple firması bu yeni firmaya maddi destek sağlamıştır. "VLSI Technology" firması ise ekipman tedarik etmiştir.
    Acorn ise az sayıda tasarım mühendisini bu yeni firmaya aktarmıştır. 2016 yılında "SoftBank Group" ARM hisselerinin önemli bir 
    bölümünü aldı. 2018'de ARM'ın Çin şubesinin yarısından fazlasını "Chine Investment" şirketine sattı. 2020'de "NVidia", ARM'ı 
    SoftBank Group'tan satın almak istediyse de satış gerçekleşmedi. Bugün "SoftBank Group" ARM'ın %90 civarındaki hisselerine 
    sahiptir. Geri kalan hisseleri kurucu ortaklarda ve halka arzdadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    ARM (İngilizce'de de "ey ar em" biçiminde değil "arm" biçiminde okuyorlar) bir tasarım firmasıdır. Yani fabrikalara sahip 
    değildir. ARM yaptığı tasarımları lisanslandırarak üretici firmalara satmaktadır. ARM'ın uyguladığı dört tür lisans vardır:

    Entegre Devre Lisansı (Full Custom License): Bu lisans müşterinin mikrodenetleyici tasarımını kendi özel ihtiyaçlarına 
    göre özelleştirmesine ve optimize etmesine olanak tanır. Örneğin Apple gibi, Qualcomm gibi, Samsung gibi firmalar bu 
    lisansa sahiptir.

    Mimari Lisans (Architecture License): Bu lisans ARM'nin genel mikroişlemci mimarisine erişim sağlayan bu lisanstır. Ancak, 
    bu lisans müşterinin mikrodenetleyiciyi özelleştirmesine izin vermez. Yani bu lisansa sahip olanlar işlemci tasarımını
    kullanarak üretim yapabilirler ancak onu özelleştiremezler.

    Çekirdek Lisansı (Processor IP License): Bu lisans ile ancak müşteri belli bir ARM işlemcisini (core) üretebilmektedir.

    Geliştirici Lisansı (Development License): Bu lisans ARM'nin tasarım araçlarına erişim sağlayan bir lisanstır. Müşteri 
    bu araçları kullanarak kendi işlemcilerini tasarlayabilir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    ARM dünyasında çalışmak için bazı terimler hakkında bilgi sahibi olmak gerekir. ARM firması kendine özgü terimler uydurmuştur.
    Bu dünyada en çok karşılaşılan terimler "core", "cortex" ve "version" terimleridir.

    ARM dünyasında "core" terimi belli bir mikroişlemci tasarımını belirtmektedir. Bu tasarım üretici firmalar tarafından 
    fiziksel hale getirilmektedir. Bir grup "core" bir araya getirildiğinde ve işlemciyle ilişkili birtakım birimler de bunlara 
    eklendiğinde "cortex'ler" oluşmaktadır. ARM firması ARM'ın klasik versiyonlarında "cortex" terimini kullanmamıştır. Cortex
    terimi ARM11'den sonra kullanılmaya başlanmıştır. Bir cortex belli sayıda "core" içerebilir. Bu "core"lar noktalı sayılara
    (floating point) ilişkin işlem yapan birimlere sahip olabilirler. Cortex içerisindeki core'ların belli hızları vardır. Core 
    ve cortex terimleri daha çok çip düzeyindeki mimariyi belirtmektedir. Cortex'lerdeki işlemcilerin (core'ların) sistem programcısını 
    ilgilendiren "komut kümeleri (instruction sets)" de vardır. Böylece bir grup cortex belli bir komut kümesi ile kullanılabilecek 
    biçimde tasarlanmıştır. Komut kümesi mimarisine "ARM Versiyonları" ya da İngilizcesiyle "ARM ISA (Instruction Set Architecture)" 
    denilmektedir. Biz sistem programcısı olarak elimizdeki cortex'in hangi komut kümesini kullanan ARM versiyonuna ilişkin olduğunu 
    bilmek durumundayız. Burada dikkat edilmesi gereken nokta "Cortex teriminin donanımsal mimariyi, versiyonun ise yazılımsal mimariyi 
    belirtiyor" olmasıdır. O halde gömülü sistem geliştiricisi olarak bizim ilgilendiğimiz ARM içeren kart ile ilgili şu iki özelliği 
    biliyor olmamız gerekir:

    1) Kartımızda ARM'ın hangi cortex'i kullanılmıştır?
    2) Bu cortex'in ilişkin olduğu versiyon numarası nedir?

    Yukarıda da belirttiğimiz gibi farklı cortex'ler aynı versiyon numarasını kullanabilmektedir.

    ARM dünyasında üç mimari profili (profile) bulunmaktadır:

    1) A (Application) Profili
    2) R (Realtime) Profili
    3) M (Microcontroller) Profili

    Bu profiller ilgili cortex'lerin hangi tür uygulamalarda ideal olarak kullanılabileceğini belirtmektedir. Profil isimleri 
    cortex'lerde ve versiyon numaralarında '-' karakterinden sonra A, R, M harfleriyle belirtilmektedir. Örneğin "Cortex-A8" ve 
    "ARMv7-A" gibi. A profilleri masaüstü işletim sistemlerinin çalıştırılabileceği, tamamen kişisel bilgisayar olarak kullanılabilecek 
    cortex'leri belirtmektedir. Biz kursumuzda gömülü Linux programcısı olarak bu "A" profilleriyle çalışacağız. R profilleri
    "gerçek zamanlı (realtime)" uygulamalar için daha uygun olabilecek cortex'leri belirtmektedir. R profilleri ile A profilleri 
    birbirlerine benzemektedir. R profilleri A profillerine göre çok daha seyrek kullanılmaktadır. M profilleri ARM'ın mikrodenetleyici
    olarak kullanılan cortex'lerini belirtmektedir. Bu cortex'ler Linux işletim sisteminin yüklenmesine izin vermemektedir. Bu cortex'ler 
    genellikle "bare-metal" programlarla ya da gerçek zamanlı işletim sistemleriyle kullanılmaktadır.

    ARM'ın iki önemli versiyonu ARMv7-A ve ARMv8-A dır. ARMv7'ler 32 bitlik bir arayüz sunmaktadır. Dolayısıyla bu komut mimarisini 
    kullanan cortex'ler 32 bitlik işlemciler içermektedir. ARMv8-A versiyonları ise 64 bitlik arayüz sunmaktadır. Dolayısıyla bu 
    versiyonları kullanan cortex'ler 64 bitlik işlemcilere ilişkindir. Ancak ARM cortex'lerinin bir grubu hem 32 bit hem de 64 
    bit olarak kullanılabilmektedir. Bu cortex'lerdeki işlemcileri kullanan işletim sistemleri 32 bitlik ve 64 bitlik programları 
    zaman paylaşımlı olarak bir arada çalıştırabilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Mikroişlemciler ilk çıktığında 8 bit işlemleri yapabiliyordu (örneğin 8080, 6800 gibi işlemciler). Bunlara 8 bitlik mikroişlemci 
    deniyordu. Sonra 16 bitlik mikroişlemciler çıktı (örneğin Intel'in 8086, 8088 işlemcileri gibi). Bunu 32 bit işlemciler izledi. 
    Günümüzde artık ağırlıklı olarak 64 bit işlemciler kullanılmaktadır. Pekiyi bir işlemcinin N bitlik olmasının anlamı nedir? 
    Bu soruya yanıt verelim:

    - N bitlik bir işlemcide tek hamlede (yani tek bir makine komutuyla) N bit üzerinde işlem yapılabilmektedir. Örneğin 32 bitlik 
    bir mikroişlemcide tek bir makine komutu ile 32 bitlik iki sayıyı toplayıp çarpabiliriz.

    - N bitlik bir mikroişlemciler genellikle (ama her zaman değil) 2^N uzunlukta bir fiziksel RAM'i adresleyebilmektedir. Örneğin
    32 bitlik bir mikroişlemciye biz tipik olarak 2^32 = 4 GB'lik bir RAM bağlayabiliriz. Elimizdeki RAM 64 GB olsa bile 32 bit
    bir mikroişlemci bu RAM'in ancak ilk 4 GB'sini kullanabilmektedir. Tabii bu durum her zaman böyle değildir. Örneğin 8086 
    işlemcisi 16 bit olduğu halde 2^16 değil 2^20 uzunluğunda (1 MB) fiziksel belleği adresleyebiliyordu. Benzer biçimde 64 bitlik 
    Intel ve AMD işlemcileri 2^64 değil 2^48 uzunluğundaki RAM'leri adresleyebilmektedir.

    - N bitlik bir mikroişlemcide genellikle işlemci ile RAM arasında transfer N bit olarak yapılmaktadır. Örneğin 32 bitlik
    bir mikroişlemcide tek bir makine komutuyla RAM'den CPU'ya 32 bitlik bir veri transfer edilebilir. Ancak bu durum her zaman 
    böyle değildir. örneğin 16 bitlik Intel 8086 işlemcisi bellek transferlerini 16 bit olarak yaparken 8088 işlemcisi 8 bit 
    yapıyordu.)

    8 bitten 16 bite geçişte ve 16 bitten 32 bite geçişte çok fark edilir bir hızlanma yaşanmıştır. Ancak 32 bitten 64 bite 
    geçişte hızlanma öncekiler kadar olmamıştır. Bunun nedeni 64 bitlik işlemlerin aslında yoğun olarak yapılmadığındandır. Ancak 
    32 bitten 64 bite geçişin en önemli etkisi işlemciye bağlanabilecek RAM miktarı üzerinde olmuştur. Örneğin elimizde 8 GB 
    RAM'li Raspberry Pi 5 olsun. Buradaki ARM cortex'i hem 32 bit hem de 64 bit işlemci gibi çalışabilmektedir. Dolayısıyla biz 
    bu kartımıza 32 bitlik de 64 bitlik de Linux yükleyebiliriz. Ancak 32 bitlik Linux işletim sistemi işlemciyi 32 bit modda 
    çalıştıracağı için işletim sistemi 8 GB RAM'in ancak 4 GB'sini kullanabilecektir. Bu 8 GB RAM'in tamamından istifade edebilmemiz 
    için işlemcinin 64 bit modunda çalıştırılması dolayısıyla da işletim sisteminin 64 bit olması gerekecektir.

    Pekiyi 128 bitlik işlemciler tasarlansa, bunlar daha hızlı bir çalışma sunmaz mı? Neden 128 bitlik işlemciler tasarlanmıyor? 
    İşte 128 bitlik tamsayı işlemlerine çok nadir gereksinim duyulmaktadır. 2^128 uzunluğunda RAM zaten şu an için erişilmesi 
    imkansız bir RAM miktarıdır. O halde işlemcilerin 64 bitten 128 bite çıkartılmasının şu an için önemli bir faydası olmayacaktır.
    Ancak tabii gelecekte böyle bir ihtiyaç ortaya çıkabilecektir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Popüler ürünlerde kullanılan ARM cortex'leri şunlardır:

    iPhone 14: Apple'ın A15 isimli SoC'unu kullanmaktadır. Bu SoC'un içerisinde Apple'ın ARMv8.6‑A versiyonunu kullanan Avalanche 
    Cortex'i vardır. Buradaki core'lar yalnızca 64 biti desteklemektedir.

    iPhone 15: Apple'ın A16 isimli SoC'unu kullanmaktadır. Bu SoC'un içerisinde Apple'ın ARMv8.6‑A versiyonunu kullanan Everest
    Cortex'i vardır. Buradaki core'lar yalnızca 64 biti desteklemektedir.

    Apple M1 SoC: Apple'ın ARMv8.4‑A versiyonunu kullanan FireStorm isimli Cortex'i vardır. Buradaki core'lar yalnızca 64 biti 
    desteklemektedir.

    Apple M2 SoC: Apple'ın ARMv8.6‑A versiyonunu kullanan Avalanche ve Blizzard isimli Cortex'leri vardır. Buradaki Core'lar
    yalnızca 64 biti desteklemektedir.

    Apple M3 SoC: Apple'ın ARMv8.6‑A versiyonunu kullanan Avalanche ve Blizzard isimli Cortex'leri vardır. Buradaki core'lar
    yalnızca 64 biti desteklemektedir.

    Samsung Galaxy S24: Qualcomm firmasının Snapdragon-8 SoC'unu kullanmaktadır. Bu SoC içerisinde ARMv9-A versiyonunu kullanan 
    Cortex A715 bulunmaktadır.

    Redmi Note 11: Xiaomi firmasının ürünüdür. Qualcomm Snapdragon-685 SoC'unu kullanmaktadır. Bu SoC'un içerisinde ARMv8.2-A 
    versiyonuna ilişkin Cortex A78 bulunmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bu kursta kullanacağımız SBC'lerin üzerinde bulunan ARM cortex'leri ve bunların versiyon numaraları da şöyledir:

    Raspberry Pi 3: BCM2837 SoC'u kullanılmıştır. Bu SoC'un içerisinde ARMv8-A versiyonuna ilişkin Cortex-A53 bulunmaktadır. Bu 
    cortex'teki işlemciler hem 32 bit hem de 64 bit modda çalışabilmektedir. Dolayısıyla bunlara 32 bit ve 64 bit Linux sistemleri 
    yüklenebilmektedir.

    Raspberry Pi 4: BCM2711 SoC kullanılmıştır. Bu SoC'un içerisinde ARMv8-A versiyonuna ilişkin Cortex-A72 bulunmaktadır. Bu 
    cortex'teki işlemciler hem 32 bit hem de 64 bit modda çalışabilmektedir. Dolayısıyla bunlara 32 bit ve 64 bit Linux sistemleri 
    yüklenebilmektedir.

    Raspberry Pi 5: BCM2712 Bu SoC'un içerisinde ARMv8.2-A versiyonuna ilişkin Cortex-A76 bulunmaktadır. Bu cortex'teki 
    işlemciler hem 32 bit hem de 64 bit modda çalışabilmektedir. Dolayısıyla bunlara 32 bit ve 64 bit Linux sistemleri 
    yüklenebilmektedir.

    BeagleBone Black 4G ve BeagleBone Black Wireless: Texas Instruments firmasının Sitara-AM3358 SoC'unu kullanmaktadır. Bu SoC'un 
    içerisinde Cortex-A8 kullanılmıştır. Bu cortex 32 bit işlemcilerden oluşmaktadır. Bunların kullandığı komut mimarisi de 
    ARMv7-A'dır. BeagleBone Black'ler 32 bit ARM işlemcilerini kullandığı için bunlara yalnızca 32 bit Linux sistemleri
    yüklenebilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												4. Ders 14/03/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de Raspberry Pi 5 donanımını inceleyelim. Kartın üzerinde BCM2712 SoC'u hemen dikkati çekmektedir. Bu SoC'un hemen 
    yanında RAM chip'i bulunmaktadır. Raspberyy Pi 5'in 1 GB, 2 GB, 4 GB ve 8 GB RAM'li modelleri vardır. Raspberry Pi 5 modelinde 
    toplam 4 USB soketi bulunmaktadır. Bunlardan iki tanesi USB 2.0, diğer 2 tanesi de USB 3.0'dır. Klavye ve fare gibi 
    yavaş aygıtları USB 2.0 girişlerine bağlayabilirsiniz. Bunların hemen yanında Ethernet girişi, kenarlarda toplam 40 tane 
    (20'lik iki sıra) GPIO uçları bulunmaktadır. Bu GPIO uçları aygıtın dış dünya ile elektriksel olarak haberleşmesi için 
    kullanılmaktadır. Raspberry Pi 5'te iki micro HDMI girişi bulunmaktadır. Bu uçlardan birine monitörümüzü bağlayabiliriz. 
    Raspberry Pi 5 modelinde arka tarafta SD kart girişine yakın bir bölgede çok küçük ON/OFF düğmesi bulunmaktadır. Bu düğme 
    bilgisayarlarımızdaki "Power Off" düğmesi gibidir. Ayrıca kamera ve LCD bağlamak için iki adet MIP DSI/CSI ve kartın arka 
    tarafında da bir micro SD kart girişi bulunmaktadır. Buraya disk görevini görecek olan micro SD kart takılmaktadır. Giriş 
    kısmında da belirttiğimiz gibi kursun yapıldığı zaman diliminde 64 GB'lik SD kartlar fiyat bakımından uygun bir büyüklüktür. 
    Ancak denemeler için birden fazla SD kart (bunlar daha küçük de olabilir) kullanabilirsiniz. Kart üzerindeki diğer bileşenlerin 
    bazılarını ilerleyen bölümlerde ayrıca ele alacağız.

    Kart üzerindeki bileşenleri inceleyebilmek için aşağıdaki bağlantıyı kullanabilirsiniz:

    https://grobotronics.com/raspberry-pi-5-4gb.html

    Raspberry Pi'ın resmi iki sitesi raspberrypi.com ve raspberrypi.org siteleridir. Raspberry Pi ile ilgili tüm dokümanlar 
    https://www.raspberrypi.com/documentation/ bağlantısından elde edilebilir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Raspberry Pi bir proje olarak özellikle az gelişmiş ülkelerde düşük fiyatlı bilgisayar oluşturmayı hedeflemiştir. Dolayısıyla
    biz Raspberry Pi'ı tamamen Linux tabanlı bir kişisel bilgisayar olarak kullanabiliriz. Kursumuzda önce Raspberry Pi'ın 
    kişisel bilgisayar olarak nasıl kullanıldığı üzerinde duracağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Raspberry Pi için birkaç işletim sistemi oluşturulmuştur. Ancak bunlardan en yaygın kullanılan ikisi Linux'un "Raspberry Pi 
    OS (eski ismiyle Raspbian)" ve "Ubuntu" dağıtımlarıdır. Raspberry Pi ile tam uyum içinde olan ana dağıtım "Raspberry Pi OS"
    dağıtımıdır. Biz sizlerinde de "Raspberry Pi OS" ve "Ubuntu" dağıtımlarını ayrı micro SD kartlara yüklemenizi tavsiye ediyoruz.

    Bir bilgisayar sistemini reset ettiğimizde işletim sisteminin (ya da bu görevdeki yazılımın) yüklenmesini sağlayan yazılımlara
    "boot loader" denilmektedir. Gömülü sistemlerde kullanılan "boot loader" yazılımları kursumuzun ayrı bir konusunu oluşturmaktadır. 
    Ancak kabaca boot işlemi şöyle gerçekleşmektedir: Biz mikroişlemciyi reset ettiğimizde çalışma belli bir adresten başlatılmaktadır. 
    Yani işlemci reset edildiğinde çalıştırılacak kodun önceden hazır bir biçimde kalıcı bir bellekte (bugün bunlar için flash 
    EPROM'lar kullanılmaktadır) bulunuyor olması gerekir. Buradaki kod çeşitli donanım birimlerini programlar ve onları kullanıma 
    hazır hale getirir. Sonra boot loader'ın işletim sisteminin yüklenmesinden sorumlu olan kısmı RAM'e yüklenir. Boot loader'ın 
    bu kısmı işletim sistemini yükler. Zaten bu konular ileride ayrıntılarıyla ele alınacaktır. Bizim bu aşamada bilmemiz gereken 
    şey işletim sistemimizin micro SD karta nasıl yükleneceğidir. Çünkü bu işlem yapıldıktan sonra artık her şey otomatik 
    gerçekleşmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Micro SD kartımıza işletim sisteminin yüklenmesi gelişi güzel yapılacak bir işlem değildir. Çünkü belli programların disk 
    üzerinde belli sektörlerde bulunuyor olması gerekmektedir. Bunu sağlamanın basit bir yolu önceden hazırlanmış bir imaj dosyasını 
    micro SD kartımıza aktarmaktır. Raspberry Pi için bu imaj dosyaları hazır bir biçimde zaten bulunmaktadır. O halde bizim 
    tek yapacağımız şey bu imaj dosyalarını indirip micro SD kartımızın içerisine aktarmaktır. Ancak son birkaç yıldır bu işlemin
    kolaylaştırılması için Raspberry Pi ekibi "Raspberry Pi Imager" denilen bir program geliştirmiştir. Bu program menüler
    eşliğinde kullanıcının istediği işletim sisteminin imaj dosyasını indirip micro SD karta bunları yazmaktadır. Dolayısıyla 
    bu program işimizi hepten kolaylaştırmaktadır. Raspberry Pi Imager programını aşağıdaki bağlantıdan indirebilirsiniz:

    https://www.raspberrypi.com/software/

    Raspberry Pi Imager programı indirilip kurulup çalıştırılınca program bize üç şey sormaktadır?

    1) Hangi Rasperry Pi modelini kullandığımızı
    2) Hangi işletim sistemini yükleyeceğimizi
    3) Hangi micro SD karta yüklemeyi yapacağımızı

    Bu sorulara yanıt verdikten sonra yüklenecek Linux üzerinde bazı basit konfigürasyon işlemleri de "Edit Setting" seçeneği ile 
    yapılabilmektedir. Tabii bunları yükleme işleminden sonra da yapabiliriz.

    Raspberry Pi Imager her şeyi kendisi yapmaktadır. Program önce ilgili imajı yerel makineye indirir, sonra da micro SD karta 
    yazma yapar.

    Tabii biz Raspberry Pi Imager programını kullanmak zorunda değiliz. Zaten bu program eskiden yoktu. Eğer bu programı kullanmayacaksak
    işletim sistminin SD kart imajını indirip SD karta yazma yapan bir programla onu karta aktarmamız gerekir. SD karta aktarma 
    yapan pek çok bedava program vardır. Bunlardan en popüler iki tanesi "Rufus" ve "Etcher" programlarıdır. Manuel kurulum 
    için işletim sistemi imajlarını aşağıdaki bağlantıdan indirebilirsiniz:

    https://www.raspberrypi.com/software/operating-systems/

    Artık her şey hazırdır. Bundan sonra şu bağlantıları yapmalısınız:

    1) SD kartınızı Raspberry Pi'ınıza yerleştiriniz.
    2) Monitörünüzü Raspberry Pi'ınızın micro HDMI soketine takınız.
    3) Klavye ve farenizi Raspberry Pi'ınızın USB soketlerine takınız.
    4) USB Type-C soketi ile Raspberry Pi'ınıza güç veriniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												5. Ders 19/03/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Gömülü sistemimize Linux'u kurduktan sonra ona başka bir makineden erişmek isteyebiliriz. Bunun çeşitli yolları varsa da 
    en çok kullanılan yöntemler şunlardır:

    1) SSH protokolü ile erişim
    2) VNC protokolü ile erişim
    3) Microsoft RDP protokolü (Remote Desktop Protocol) ile erişim

    VNC ve RDP ile gömülü aygıtımızdaki Linux'a erişebilmemiz için orada bir pencere yönetici programın (yani masaüstü sisteminin)
    kurulu olması gerekir. Raspberry Pi güçlü bir donanıma sahip olduğu için ve kişisel bir bilgisayar gibi kullanılabildiği için
    bu aygıtlara yüklediğimiz Linux sistemlerinde pencere yöneticisi zaten bulunuyor olabilir. Ancak server sistemlerinde ve pek çok 
    gömülü Linux sisteminde bir pencere yöneticisi bulunmamaktadır. Bu durumda erişim genellikle SSH protokolü ile sağlanmaktadır. 
    Eskiden SSH protokolünden önce Telnet isimli benzer bir protokol kullanılıyordu. Ancak Telnet protokolünün güvenilirliği zayıf 
    olduğu için zaman içerisinde SSH protokolü geliştirildi. Bugün konsol tabanlı bir ortamda bir Linux sistemine uzaktan bağlanmak 
    için genellikle SSH protokolü kullanılmaktadır.

    Her türlü TCP/IP uygulamalarında haberleşmenin yapılabilmesi için bir "server" program ile bir de "client" programın bulunuyor 
    olması gerekir. Bize erişimi sağlayan uzak makinedeki program "server" programdır. Bizim erişmek için kullandığımız program 
    ise "client" programdır. SSH server ve client programlar zaten işletim sistemlerinin pek çoğunun içinde default bir biçimde 
    bulunmaktadır. Biz Raspberry Pi'ımıza Raspberry OS işletim sistemini kurduğumuzda zaten SSH client ve server programlar yüklü 
    durumdadır. Ancak eğer gömülü sisteminizde SSH server program bulunmuyorsa onu şöyle kurabilirsiniz:

    $ sudo apt-get install openssh-server

    Bu işlem SSH server programının kurulup çalışır hale getirilmesini sağlamaktadır. Client program da benzer biçime kurulabilir:

    $ sudo apt-get install openssh-client

    ssh client program ile bağlantı aşağıdaki gibi sağlanabilir:

    $ ssh user_name@host_name

    Bizim bağlantı sağlayabilmek için uzak makinede bir kullanıcının ismini ve parolasını biliyor olmamız gerekir. SSH client programı 
    Windows ve macOS sistemlerinde de benzer komut satırı argümanlarıyla hazır bir biçimde bulunmaktadır. Dolayısıyla Windows ve 
    macOS sistemlerinden de gömülü aygıtınıza benzer biçimde bağlanabilirsiniz. SSH programı ile bağlantı yaparken kullanıcı ismini 
    "-l" seçeneği ile de belirtebilirsiniz. Örneğin:

    $ ssh -l user_name host_name

    VNC ile bağlantı da yine bir VNC server programıyla bir de VNC client programının karşılıklı makinelerde yüklü olması gerekmektedir. 
    Bizim bağlanmak istediğimiz makinede server programının çalışıyor olması, bağlantıyı sağlamak istediğimiz tarafta da client programın 
    yüklü olması gerekir. Raspberry Pi'daki eski Raspbian işletim sisteminde VNC server hazır bir biçimde bulunmuyordu. Ancak belli 
    süre sonra artık Raspberry Pi OS içerisinde zaten VNC server programı hazır bir biçimde bulunmaktadır. Ancak VNC server hazır bir 
    biçimde bulunuyor olsa da onun çalışır hale getirilmesi gerekmektedir. Bu işlem pratik olarak ana menüden "Preferences/Raspberry Pi 
    Configurations/Interfaces" sekmesinden yapılabilir. Yukarıda da belirttiğimiz gibi VNC server için Linux sistemimizde bir pencere 
    yöneticisinin çalışıyor olması gerekir. Yani içerisine grafik arayüz yüklenmemiş olan bir Linux sistemine VNC ile bağlanmanın da 
    bir anlamı yoktur.

    VNC server ve client program olarak çeşitli programlar kullanılabilmektedir. Linux'ta en yaygın kullanılan VNC server program
    "tightvncserver" isimli programdır. Bunun kurulumu şöyle yapılabilir:

    $ sudo apt-get install tightvncserver

    Ancak server program kurulduktan sonra bazı ayarlamaların yapılması gerekmektedir. Bu konu ileride başka bir bölümde ele 
    alınacaktır.

    Biz pencere yönetici sisteminin bulunduğu bir Linux sistemine Microsoft'un "Remote Desktop Protocol(RDP)"ünü kullanarak da 
    bağlanabiliriz. Tabii bunun için de bağlanacağımız makinede RDP server programının çalışıyor durumda olması gerekmektedir. 
    Bu protokol Microsoft'a ait olduğu için Linux sistemleri tarafından aktif bir biçimde kullanılmamaktadır. RDP server programı
    aşağıdaki gibi kurulabilir:

    $ sudo apt-get install xrdp

    RDP protokülü için client program olarak genellikle Windows'taki "Uzak Masaüstü Bağlantısı" kullanılmaktadır. Ancak bu 
    protokol için başka client programlar da bulunmaktadır.

    VNC ve RDP protokolleri hem Linux sistemlerinde hem de Windows ve macOS sistemlerinde kullanılabilmektedir. Windows dünyasında
    RDP programları VNC programlarına göre daha hızlı bir biçimde çalışmaktadır. Ancak Linux'ta VNC programları RDP programlarına 
    göre daha hızlıdır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    BeagleBoard'lar en yaygın kullanılan SBC'ler arasındadır. Biz de kursumuz Beaglebone Black (BBB) kullanacağımızı söylemiştik.
    BBB'nin dokümantasyonuna aşağıdaki bağlantıdan erişilebilir:

    https://docs.beagleboard.org/latest/https://docs.beagleboard.org/latest/

    BBB kendi içerisinde ismine "eMMC (Embedded Multi-Media Card)" denilen on-board flash belleğe sahiptir. Zaten ürün satın 
    alındığında bu flash belleğin içerisinde bir Debian Linux dağıtımı yüklü durumdadır. Bu nedenle biz board'umuzu güç kaynağına 
    taktığımızda zaten default olarak bu on-board flash içerisindeki Linux boot edilmektedir. BBB'yi kullanıma hazır hale getirmek 
    için şunlar yapılmalıdır:

    1) BBB'ye güç kaynağını bağlamak için iki soket kullanılabilmektedir. Birincisi eski tip yuvarlak sokettir (DC barrel jack). 
    İkincisi ise mini USB soketidir. Kullanıcılar genellikle güç kaynağını mini USB soketine bağlamaktadır. (Tabii bu mini USB 
    girişi doğrudan masaüstü bilgisayarımızın USB girişine bağlanabilir. Bu durumda gücü buradan alacaktır.)

    2) BBB üzerinde bir tane standart USB soket vardır. Genellikle bu sokete combo klavye fare bağlanmaktadır. Ancak birden fazla
    bağlantı için USB hub kullanılabilir.

    3) BBB'nin klasik modellerinde internet için "wireless" bağlantı yoktur. Dolayısıyla internet bağlantısı sağlamak için ethernet
    soketi kullanılmaktadır. Ancak on-board flash üzerine yüklenmiş olan Debian içerisinde "Internet over USB" için gerekli aygıt
    sürücüler (device drivers) bulunmaktadır. Bu sayede biz örneğin mini USB kablosu ile BBB'yi Windows ya da Linux makinemize 
    bağlayıp BBB'nin oradaki interneti kullanmasını sağlayabiliriz.

    4) BBB'de de Raspberry Pi'da olduğu gibi micro HDMI soketi vardır. Bu sokete doğrudan monitörümüzü bağlayabiliriz.

    5) BBB'de iki önemli düğmecik bulunmaktadır. Bunlardan biri SD kartın yanındaki (USB soket tarafındaki) düğmeciktir. Bu düğmeciğe 
    "boot düğmeciciği (Boot button)" denilmektedir. Diğer düğmecik ise ethernet soketinin hemen yanında bulunmaktadır. Buna da 
    "reset düğmeciği (reset button)" denilmektedir. Boot düğmeciği SD karttan boot sürecini başlatmak için reset düğmeciği ise
    sistemi reset etmek için kullanılmaktadır.

    Tipik olarak BBB'yi ilk kez kullanırken mini USB soketini masaüstü bilgisayarımızın standart USB soketine takarız. Böylece
    masaüstü bilgisayarımız otomatik olarak BBB'nin on-board flash belleğindeki bir disk bölümünü bir sürücü biçiminde görür. 
    Bu sürücü içerisinde host sistem için gerekli olan aygıt sürücüler bulunmaktadır. Eğer host makine olarak Windows'ta çalışıyorsak 
    aygıt sürücüleri yüklerken "UEFI BIOS'tan imzasız aygıt sürücüleri için" izin vermemiz gerekir. Bunun için aşağıdaki bağlantıdaki 
    yönergeleri izleyebilirsiniz:

    https://www.terasic.com.tw/wiki/Disable_Driver_Signature_Enforcement_in_Windows10_x64

    Biz bu biçimde USB bağlantısı yaptığımızda artık IP protokol ailesini USB üzerinden kullanabilir duruma geliriz. Dolayısıyla
    SSH ile BBB'ye bağlanabiliriz. BBB'de yüklü olan Debian dağıtımının default kullanıcı ismi "debian", default parolası ise "temppwd"
    biçimindedir. Tabii hazır yüklü olan Linux dağıtımının klavye ayarları İngilizce'dir. Türkçe klavye ile yazarken buna dikkat 
    ediniz. SSH bağlantısı için BBB'deki IPv4 adresi "192.168.7.2" biçimindedir. Yani bağlantı aşağıdaki gibi yapılabilir:

    $ ssh debian@192.168.7.2

    parola olarak da "temppwd" girilmelidir. On-board flash üzerine yüklenmiş olan Debian dağıtımında bir pencere yönetici program
    bulunmamaktadır. Zaten BBB'nin on-board flash belleği 4 GB'dir.

    Biz BBB'nin mini USB kablosunu host makinemize bağladığımızda artık host makinemizden BBB'ye SSH yoluyla erişebiliriz. Ancak
    BBB'deki Linux sisteminin masaüstü host makinemizdeki interneti kullanabilmesi için Windows ve Linux sistemlerinde bazı 
    ayarların da yapılması gerekmektedir. Tabii BBB'nin interneti kullanabilmesini sağlamanın en normal ve hızlı yolu doğrudan 
    ADSL Router'ımızdan gelen Ethernet RJ45 jakını BBB'ye takmaktır. Biz "Internet over USB" yerine bu yöntemi kullanmanızı 
    öneriririz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												6. Ders 21/03/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    BBB'ni on-board flash belleğine işletim sisteminin yeni bir sürümünü yerleştirebiliriz. Aslında Beagleboard için hazır imajlar
    zaten bulundurulmaktadır. Aşağıdaki bağlantıdan size uygun olan hazır imajları indirebilirsiniz:

    https://www.beagleboard.org/distros

    On-board flash belleğe işletim sistemini yüklemek için sırasıyla şu adımlardan geçilmelidir:

    1) Yukarıda belirttiğimiz sayfadan BBB için uygun sürüm indirilir. Bu sayfadaki hazır imajların bir bölümünde "Flasher" 
    ibaresi vardır. Bu "flasher" ibareli imajlardan biri indirilmelidir. Örneğin sınıftaki denemede aşağıdaki imaj indirilmiştir:

    AM335x 11.7 2023-09-02 4GB eMMC IoT Flasher

    Buradaki "IoT" sözcüğü indirilecek Debian dağıtımının IoT amaçla oluşturulmuş minimalist bir dağıtım olduğunu belirtmektedir. 
    Örneğin alternatif bir imaj da şu olabilir:

    AM335x 11.7 2023-09-02 4GB eMMC Xfce Flasher

    Burada "IoT" ibaresi yerine "Xfce" ibaresi bulunmaktadır. Xfce küçük bir pencere yöneticisidir. Ancak maalesef bu pencere 
    yöneticisi bile BBB'nin pek çok versiyonunda sistem kısıtları nedeniyle çok yavaş çalışma eğilimindedir.

    2) İndirilen imaj zip'li olduğu için açılmalıdır. Açılan imajın uzantısının ".img" olması gerekir.

    3) İmaj SD karta Rufus ya da Etcher benzeri bir programla yazılmalıdır.

    4) SD karta yazma işlemi bittikten sonra SD kart BBB'nin SD kart yuvasına takılır. Sonra "Boot düğmeciği" denilen küçük 
    düğmeciğe basılarak board'a güç verilir. Güç verildikten sonra 7, 8 saniye boot düğmeceğine basılmaya devam edilmelidir. 
    Sonra el boot düğmeciğinden çekilir. BBB'nin dört LED'i önce tamamen yanar. Sonra sırasıyla yanıp sönmeye başlar. Bu durum 
    yazmanın başladığı anlamına gelmektedir. Yazma takriben 5 dakika civarında sürmektedir. Yazma bittikten sonra LED'ler 
    tamamen söner. (Boot düğmeciği Micro SD kartın yanındaki (USB portun bulunduğu taraftaki) düğmeciktir.

    5) SD kart çıkartılarak sistem yeniden boot edilir. Artık on-board flash üzerine çektiğimiz işletim sistemi ile boot işlemini
    yapmış olduk. Ancak bizim indirdiğimiz imaj İngilizce (US) olarak ayarlanmıştır. Dolayısıyla default klavye ayarları da 
    İngilizce klavye biçimindedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Debian türevi sistemlerde klavye ayarlarını değiştirmenin birkaç yolu vardır. Öncelikle locale ayarlarının Türkiye ve Türkçe 
    biçiminde yapılmasını tavsiye ederiz. Çünkü BBB için hazır bulundurulan Debian dağıtımında default locale ayarları Amerika 
    ve İngilizce biçimindedir. Bunu sağlamanın bir yolu aşağıdaki komutu kullanmaktadır:

    $ sudo dpkg-reconfigure locales

    Karşımıza bir menü gelecektir. Bu menüden locale'i "tr_TR.UTF-8" biçiminde ayarlayabilirsiniz. Bu ayarlamadan sonra artık 
    /etc/default/locale dosyası aşağıdaki gibi olacaktır:

    # File generated by update-locale
    LANG=tr_TR.UTF-8

    Ancak locale'in ayarlanması klavye düzenini değiştirmemektedir. Locale'in ayarlanması birtakım mesajların Türkçe çıkmasını, 
    terminal aygıt sürücüsünün girdi ve çıktılarının encoding'ini belirlemektedir. Klavye düzeni manuel olarak "/etc/default/keyboard"
    dosyası üzerinde güncelleme yapılarak ayarlanabilir. Bu dosyanın BBB'deki default içeriği şöyledir:

    # KEYBOARD CONFIGURATION FILE
    # Consult the keyboard(5) manual page.

    XKBMODEL="pc105"
    XKBLAYOUT="us"
    XKBVARIANT=""
    XKBOPTIONS=""
    BACKSPACE="guess"

    Bizim Türkçe klavye için buradaki XKBLAYOUT satırını aşağıdaki gibi değiştirmemiz gerekir:

    XKBLAYOUT="tr"

    Ancak bu dosyada değişiklik yapılması klavye düzeninin değişeceği anlamına gelmemektedir. Bu ve birkaç dosyaya bakarak klavye 
    düzenini ayarlayan bazı programlar vardır. Bunların çalıştırılması gerekir. Bunun için "setupcon" programı kullanılabilir:

    $ sudo setupcon

    Artık klavyemiz Türkçe olarak ayarlanmıştır. Ancak iki problem daha vardır. Birincisi BBB'deki Debian dağıtımındaki default 
    console fontu Türkçe'yi desteklememektedir. Yani klavyedeki tuşların yerleri doğru olarak ele alınmaktadır ama Türkçe 
    karakterler doğru görüntülenememektedir. İkinci sorun ise BBB'yi reboot ettiğimizde yaptığımız ayarların otomatik devreye 
    girmemesidir.

    Console ekranının fontunu değiştirmek için "/etc/default/console-setup" dosyasının edit edilmesi gerekmektedir. Bu dosyasının 
    BBB'deki default durumu şöyledir:

    # CONFIGURATION FILE FOR SETUPCON
    # Consult the console-setup(5) manual page.

    ACTIVE_CONSOLES="/dev/tty[1-6]"
    CHARMAP="ISO_8859-15"
    CODESET="guess"
    FONTFACE="Fixed"
    FONTSIZE="8x16"
    VIDEOMODE=
    # The following is an example how to use a braille font
    # FONT='lat9w-08.psf.gz brl-8x8.psf'

    Bizim burada CHARMAP satırını aşağıdaki gibi UTF-8 olarak güncellememiz gerekir:

    CHARMAP="UTF-8"

    Şimdi artık sistemi reboot ettiğimizde login ekranındaki klavye düzeni İngilizce olsa da login olup "setupcon" programını 
    çalıştırdığımızda her şey Türkçe'ye göre ayarlanmış olacaktır.

    Biz klavyeyi ve console fontlarını ayarlarken bazı dosyaları güncelledik. Aslında bu dosyaları manuel olarak edit etmek yerine 
    bunları güncelleyen küçük programlardan da faydalanılabilir. Örneğin aslında "sudo dpkg-reconfigure locales" komutu 
    "/etc/default/locale" dosyası üzerinde güncelleme yapmaktadır. Benzer biçimde "sudo dpkg-reconfigure console-data" komutu 
    da aslında "/etc/default/console-setup" dosyasını güncellemektedir. Bazen klavye ayarlarını çalışırken o anda başka bir dille 
    de değiştirmek isteyebiliriz. Bunun için "loadkeys" isimli program kullanılmaktadır. Bu program klavye düzenek dosyasını 
    argüman olarak alıp klavyeyi ona göre ayarlamaktadır.

    Yukarıda da belirttiğimiz gibi biz Türkçe ayarlarını yapmış olsak da bu ayarları etkili hale getirmek için "setupcon" 
    programını çalıştırmamız gerekir. Bu nedenle BBB'mizi reboot ettiğimizde login ekranında yine klavye İngilizce'de kalacaktır. 
    Bunu kalıcı ayarlamanın bir yolu "sudo update-initramfs -u" işlemidir. Diğer yolu ise sistem boot edildiğinde otomatik olarak 
    bu "setupcon" programının çalıştırılmasını sağlamaktır. Bu konular ileride ele alınacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Yukarıdaki ayarlama işlemlerinden de görüldüğü gibi aslında birtakım ayarlar "/etc" dizinin altındaki çeşitli dosyalarda 
    saklanmaktadır. Çeşitli programlar da ayarları bu dosyalara bakarak set etmektedir. Microsoft eskiden Linux'takilere benzer
    ismine "ini dosyaları" denilen ayar dosyalarını kullanıyordu. Daha sonra "registry" denilen tüm ayarların saklandığı mini 
    bir hiyerarşik veritabanı sistemine geçti. Ancak UNIX/Linux sistemlerinde böyle bir merkezi ayar sistemi kullanılmamaktadır. 
    Her ayar "/etc" dizininin altında belli formattaki dosyaların içerisinde saklanmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Sizin de gördüğünüz gibi Raspberry Pi donanımı BBB'ye göre oldukça güçlüdür. Raspberry Pi'ın SD kartına yüklediğimiz 
    işletim sistemleri oldukça dolu bir biçimdedir. Çünkü bu sistemler tam bir bilgisayar gibi kullanılsın istenmiştir. Halbuki
    BBB'nin kaynakları zayıf olduğu için hazır imajlar genellikle dolu bir biçimde değildir. Örneğin UNIX/Linux sistemlerinde 
    yardım almak için kullanılan "man" programı BBB'nin default imajında bulunmamaktadır. "man" programını ve onun kullandığı 
    önemli veri dosyalarını aşağıdaki gibi yükleyebiliriz:

    $ sudo apt install man-db manpages-posix
    $ sudo apt install manpages-dev manpages-posix-dev
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    BBB'yi on-board flash (eMMC) üzerine yüklü olan Linux sistemiyle açmak zorunda değiliz. SD kartımıza Linux kurup SD kart ile 
    de boot edebiliriz. SD karttan boot işlemi için yine "boot düğmeciğine basılı olarak board'a güç verilir. Led'ler yandığında 
    basılı olan boot düğmeciğinden el bırakılır. Böylece boot işlemi SD karttan hareketle başlatılacaktır. (Ayrıca internal eMMC'de 
    bir boot loader yoksa yine boot işlemi otomatik olarak SD karttan başlatılmaktadır.) SD karta yazacağınız Linux sistemine 
    dikkat ediniz. Buraya "flasher" olmayan bir imajı yerleştirmelisiniz. SD kartınıza yükleyeceğiniz hazır Debian imajını aşağıdaki 
    bağlantıdan indirebilirsiniz:

    https://www.beagleboard.org/distros

    Örneğin buradan SD kartınız için aşağıdaki imajı indirebilirsiniz:

    AM335x 11.7 2023-09-02 4GB microSD IoT

    Beagleboard Black kartınızın boot süreci kursumuzun ayrı bir bölümünde ayrıntılı bir biçimde ele alınacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												7. Ders 26/03/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Kursumuzun bu bölümünde gömülü Linux sistemlerinde C/C++ ile yazılım geliştirmek için kullanılan toolchain'ler üzerinde
    duracağız. Kursumuzda "toolchain" sözcüğünü bazen bu biçimde İngilizce olarak bazen de "araç zinciri" biçiminde Türkçe 
    olarak kullanacağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aşağı seviyeli (C/C++, sembolik makine dilleri) biçimde yazılım geliştirmek için kullanılan araçlardan oluşan topluluğa 
    "araç zinciri (toolchain)" denilmektedir. Bir araç zincirinin tipik bileşenleri şunlardır:

    - C ve C++ Derleyicileri (C and C++ Compilers)
    - Sembolik Makine Dili Derleyicileri (Assemblers)
    - Bağlayıcılar (Linkers)
    - Binary Araçlar (Binary Utilities). Bu araçlar aşağı seviyeli işlemler için gerekebilen programlardan oluşmaktadır.
    - Debugger'lar. Bunlar hataların tespit edilmesi ve çözümlenmesi amacıyla kullanılmaktadır.
    - C ve C++'tan kullanılabilecek temel kütüphaneler. (Örneğin standart C kütüphanesi, POSIX kütüphanesi gibi.)
    - Emülatörler ve Simülatörler (Emulators amd Simulators). Her türlü araç zincirinde bu bileşenler bulunmayabilir.
    - Build Otomasyon Araçları (Build Automation Tools). Örneğin make ve cmake gibi araçlar.
    - Geliştirme İçin Gerekli Olan Diğer Dosyaların Bulunduğu "sysroot" Dizini. Programların derlenip bağlanabilmesi için
    bazı öğelerin bazı dizinler içerisinde bulunması gerekmektedir.

    Her araç zincirinin bu öğelerin hepsini içermesi gerekmez. Bazı araç zincirleri de daha fazla öğe de içerebilir. Burada bir 
    noktaya dikkatinizi çekmek istiyoruz. Gömülü Linux sistemlerinde "araç zinciri (toolchain)" demekle "aşağı seviyeli araçlar"
    kastedilmektedir. Yani örneğin araç zincirleri içerisine Java, .NET, Python gibi platformlarda yazılım geliştirmek için 
    gerekli olan araçlar dahil değildir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Kursumuzda kimi zaman çapraz derleme (cross compile) işlemleri yapacağız. Bu durumda host makine ile hedef makine arasında 
    dosya transferi yapmamız gerekecek. İki makine arasında dosya transferi yapmak için genellikle IP protokol ailesinin sunduğu 
    olanaklar kullanılmaktadır. Bunun için en çok kullanılan utility program "scp" isimli programdır. Bu program "Secure Copy 
    Protocol" denilen bir protokol yoluyla arka planda SSH kullanarak dosya transferini yapmaktadır. scp programının tipik 
    kullanımı şöyledir:

    $ scp dosya_yol_ifadesi kullanıcı_ismi@uzak_makine

    Burada uzak_makine ip adresi ya da host ismi biçiminde belirtilebilir. Örneğin:

    $ scp app debian@192.168.7.2:

    Burada app dosyası uzak makinenin debian kullanıcısının home dizinine kopyalanmaktadır. (host isminden sonra ':' 
    karakterinin bulundurulması zorunludur.) Örneğin:

    $ scp app debian@192.168.7.2:/Test

    Burada app dosyası uzak makinedeki debian kullanıcısının home dizini içerisindeki "Test" dizinine kopyalanacaktır. Tabii scp 
    ile hedef makineden host makineye ters yönde de kopyalama yapabiliriz. Örneğin:

    $ scp debian@192.168.7.2:app app

    Burada hedef makinedeki app dosyası app ismiyle host makineye kopyalanmaktadır. scp ile bir dizin bütünsel olarak da transfer 
    edilebilir. Bunun için "-r" seçeneğinin kullanılması gerekmektedir. Örneğin:

    $ scp -r Src debian@192.168.7.2:

    Burada yerel makinedeki Src dizininin tamamı uzak makineye kopyalanmaktadır.

    scp programının ayrıntıları için ilgili man sayfalarına başvurabilirsiniz.

    Uzak makineye dosya transfer etmek için diğer pratik bir yöntem de "sshfs" denilen dosya sistemini kullanmaktır. Bu dosya 
    sistemi uzak makinedeki bir dizini yerel makinede bir dizin gibi göstermektedir. Böylece biz o dizine dosya kopyaladığımızda 
    sshfs dosya sistemi onu otomatik olarak hedef makineye transfer etmektedir. Tabii sshfs Linux sistemlerini kurduğumuzda sistemin 
    bir parçası biçiminde yüklü durumda değildir. Onun aşağıdaki gibi indirip kurabiliriz:

    $ sudo apt-get install sshfs

    Kurulumu yaptıktan sonra yerel makinede mount edilecek dizini yaratmamız gerekir. Örneğin:

    $ mkdir BBB

    Artık mount işlemini şöyle yapabiliriz:

    $ sshfs BBB debian@192.168.7.2:

    Artık BBB dizinimiz uzak makinedeki kullanıcının home dizini gibi olmuştur. Yani biz bu BBB dizinine dosya kopyaladığımızda 
    aslında onu uzak makineye kopyalamış oluruz. Benzer biçimde uzak makinede home dizinine bir dosya kopyalandığında biz bu 
    dosyayı BBB dizininde otomatik olarak görürüz.

    Mount ettiğimiz dizinin uzak bağlantı yaptığımız makineden kopartılması için "umount" işleminin uygulanması gerekir.
    umount komutunda dizin ismi argüman olarak verilmektedir. Örneğin:

    $ umount BBB

    Yerel makine ile uzak makine arasında dosya transfer etmenin diğer bir yolu da FTP (File Tranfer Protocol) protokülünü 
    kullanmaktır. Ancak bunun için uzak makinede bir FTP sunucusunun yüklü olması gerekir. Düşük kapasiteli gömülü aygıtlarda 
    geliştirici bu server'ı uzak makineye yüklemek istemeyebiir. FTP server ve client programların Linux sistemlerine nasıl 
    kurulacağını ilgili dokümanlardan öğrenebilirsiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Araç zincirlerini iki bölüme ayırabiliriz:

    1) Doğal Araç Zincirleri (Native Toolchains)
    2) Çapraz Araç Zincirleri (Cross Toolchains)

    Doğal araç zincirleri genellikle dağıtımların içerisinde zaten hazır bir biçimde bulunmaktadır. Örneğin Raspberry Pi için 
    Raspberry Pi OS'yi yüklediğimizde, Beaglebone Black için Debian dağıtımını yüklediğimizde zaten onun içerisinde doğal araç 
    zincirleri bulunmaktadır. Doğal araç zincirleri doğrudan ilgili sistem üzerinde yazılım geliştirilirken kullanılmaktadır. 
    Örneğin biz Raspberry Pi için yazılımımızı doğrudan Raspberry Pi üzerinde geliştirebiliriz. Bu durumda orada yüklü olan doğal 
    araç zincirini kullanabiliriz. Raspberry Pi donanımları (özellikle 4 ve 5) çok güçlü olduğu için doğal araç zincirleri ile 
    geliştirme yapmak artık iyi bir seçenek durumundadır. Ancak Beaglebone Black gibi aygıtların sistem kaynakları daha kısıtlı 
    olduğu için doğrudan bunların üzerinde geliştirme yapmak zor hatta bazen olanaksız hale gelebilmektedir.

    Çapraz araç zincirleri (cross toolchains) geliştirmenin güçlü bir makine üzerinde yapılmasını sağlayan, hedef aygıt için kod 
    üreten araç zincirleridir. Buradaki çapraz (cross) sözcüğü üretilen kodun geliştirmenin yapıldığı makineye değil, başka bir 
    hedef (target) makineye ilişkin olduğunu belirtmektedir. Eğer hedef makine etkin bir geliştirme yapmaya olanak sağlamıyorsa 
    bu durumda çapraz araç zincirleri kullanılabilir. Örneğin Beaglebone Black için tipik olarak çapraz araç zincirleri kullanılmaktadır.

    Pekiyi doğal araç zincirleri mi yoksa çapraz araç zincirleri mi tercih edilmelidir? İşte eğer Raspberry Pi'da olduğu gibi 
    hedef donanım güçlüyse doğal araç zincirlerinin kullanılmasını tavsiye ederiz. Çünkü doğal ortamda geliştirme yapılırken denemeler
    o anda geliştirme yapılan makinede çok daha hızlı yapılabilmektedir. Ancak hedef makine yeteri kadar güçlü değilse güçlü bir
    host makinede çapraz araç zincirleriyle geliştirmenin yapılmasını öneririz. Araç zinciri denildiğinde zaten default olarak
    çapraz araç zincirleri kastedilmektedir.

    Araç zincirlerini başka bakımlardan da sınıflandırabiliriz. Örneğin araç zincirini "tedarik eden (vendor)" kuruma göre, 
    kullanılan derleyici sistemlerine göre de sınıflandırılabiliriz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Araç zincirlerinin isimlendirilmesi genellikle "hedef (target) sisteme" göre yapılmaktadır. İsimlendirmede '-' karakterleriyle
    ayrılmış üç alan ya da dört alan kullanılabilmektedir. Üçlü (triple) isimlendirmede ismin alanları şunlardır:

    CPU-Tedarikçi-İşletimSistemi

    Dörtlü isimlendirmede ayrıca bir de ABI alanı bulundurulmaktadır. Dörtlü isimlendirmenin de genel biçimi şöyledir:

    CPU-Tedarikçi-İşletimSistemi-ABI

    Buradaki bileşenlerin hepsi hedef makineye ilişkin bileşenlerdir. Ancak araç zincirlerindeki isimlendirme biçimi herkes 
    tarafından uyulan, resmi bir standardı olan kural niteliğindeki biçimler değildir. Gevşek kurallardır. Üçlü ya da dörtlü 
    isimlendirmeye uymayan ya da kısmen uyan araç zincirleri de bulunmaktadır.

    Şimdi bazı örnekler vermek istiyoruz.

    i686-apple-darwin10-gcc-4.2.1

    Bu araç zinciri Intel'in 32 bit işlemcilerine ilişkin (x86) kod üretilmektedir. Tedarikçi (vendor) Apple şirketidir. Yani araç 
    zinciri Apple firması tarafından hazırlanmıştır. Hedef işletim sistemi darwin10'dur. Yani oluşturulacak kod bu işletim sistemi 
    tarafından çalıştırılacaktır. (macOS işletim sisteminin kernel'ına "Darwin" denilmektedir. Dolayısıyla buradaki Darwin aslında 
    macOS anlamındadır.) Kullanılan ABI versiyonu gcc-4.2.1 tarafından kullanılan default ABI'yi belirtmektedir.

    arm-none-linux-gnueabi

    Burada ARM kodu üretilmektedir. Tedarikçinin olmaması bunun manuel üretildiği anlamına gelebilmektedir. Burada yine kodun 
    Linux işletim sistemi için üretileceği belirtilmektedir. ABI için kullanılan "gnueabi" tipik olarak GNU araç zincirini ve 
    gömülü sistemler için kullanılan ABI'yi belirtmektedir. (Buradaki eabi "extended abi" anlamına gelmektedir.).

    arm-linux-gcc

    Burada ARM üzerinde çalışan Linux sistemleri için kod üretilecektir. gcc derleyicisinin o sistemdeki default ABI'si 
    kullanılacaktır.

    i686-unknown-linux-gnu

    Burada tipik olarak 32 bit Intel işlemcileri üzerinde çalışan Linux sistemleri için kod üretilecektir. ABI bu sistemlerde 
    kullanılan default ABI'dir. Buradaki "gnu" GNU araç zincirini belirtmektedir.

    x86_64-w64-mingw32

    Buradaki araç zinciri 64 bit Intel işlemcilerini kullanan 64 bit Windows sistemleri için kod üretmektedir. Araç zinciri 
    MinGW dağıtımını referans almaktadır. Dolayısıyla oradaki ABI'yi kullanmaktadır.

    arm-none-eabi

    Burada ARM kodu üretilmektedir. Ancak herhangi bir işletim sistemi hedef alınmamıştır. İşletim sisteminin belirtilmediği 
    durum genellikle "bare metal" araç zinciri anlamına gelmektedir.

    Örneğin Windows'ta sanal makineye kurduğumuz Intel işlemcisini kullanan Mint dağıtımındaki gcc derleyicisinin izini sürelim:

    $ whereis gcc
    gcc: /usr/bin/gcc /usr/lib/gcc /usr/share/gcc /usr/share/man/man1/gcc.1.gz
    $ ls -l /usr/bin/gcc
    lrwxrwxrwx 1 root root 6 Mar 19 21:29 /usr/bin/gcc -> gcc-11
    $ ls -l /usr/bin/gcc-11
    lrwxrwxrwx 1 root root 23 Mar 19 21:29 /usr/bin/gcc-11 -> x86_64-linux-gnu-gcc-11

    Buradaki araç zinciri isimlendirmesinden şu anlaşılmaktadır: Buradaki gcc derleyici 64 bit Intel işlemcilerine ilişkin kod 
    üretmektedir. Söz konusu kod Linux sisteminde çalıştırılmak için üretilmektedir. GNU'nun araçları ve ABI'si kullanılmıştır. 
    Şimdi de BBB'deki Debian dağıtımı için aynı izi sürelim:

    $ whereis gcc
    gcc: /usr/bin/gcc /usr/lib/gcc /usr/share/gcc
    $ ls -l /usr/bin/gcc
    lrwxrwxrwx 1 root root 6 Oca 11 2021 /usr/bin/gcc -> gcc-10
    $ ls -l /usr/bin/gcc-10
    lrwxrwxrwx 1 root root 26 Oca 10 2021 /usr/bin/gcc-10 -> arm-linux-gnueabihf-gcc-10

    Buradaki araç zincirinden de şunu anlıyoruz: Bu araç zinciri 32 bit ARM kodu üretmektedir. Yine üretilen kodun Liux sistemlerinde 
    çalıştırılması gerektiği belirtilmektedir. GNU'nu araçları ve GNU'nun "eabihf" ABI'si kullanılmıştır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi araç zincirleri sistemimizde hazır bir biçimde bulunmuyorsa bunları nasıl elde edebiliriz? İşte bunun tipik olarak 
    üç yolu vardır:

    1) Çeşitli kurumlar ve topluluklar tarafından oluşturulmuş ve hazır hale getirilmiş araç zincirlerini kullanmak: Bunlara 
    "pre-built toolchain" de denilmektedir.

    2) Araç zinciri oluşturan yazılımları ve projeleri kullanmak: Örneğin "crosstool-NG" gibi "buildroot" gibi "yocto" gibi 
    projelerle araç zincirleri daha etkin ve optimize edilmiş bir biçimde oluşturulabilmektedir.

    3) Araç zincirlerini manuel biçimde oluşturmak: Manuel oluşturma çok zorlu bir süreçtir. Çünkü bu yöntemde araç zincirindeki 
    öğelerin kaynak kodlardan hareketle derlenmesi gerekmektedir. Bu işlemleri manuel yapmak için iyi bir deneyime sahip olmak 
    gerekir.

    Biz kursumuzda önce ARM platformu için hazır araç zincirlerini tanıtacağız. Sonra "crosstool-NG" yazılımı ile araç 
    zinciri oluşturmayı göreceğiz. Buildroot ve Yocto projeleri araç zinciri oluşturmaktan daha fazla işlevselliğe sahiptir.
    Biz kursumuzda bunları ileride ayrı bir bölümde ele alacağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    ARM platformu için önceden hazırlanmış ve kullanıma hazır hale getirilmiş hazır doğal ve çapraz araç zincirleri bulunmaktadır. 
    Bu amaçla kullanılan tipik araç zincirleri şunlardır:

    1) ARM Firması Tarafından Oluşturulmuş Olan Araç Zincirleri: ARM firmasının kendisi ARM hedefi için doğrudan kullanılabilecek 
    doğal ve çapraz araç zincirlerini hazırlamıştır. Bu araç zincirleri GNU projesini kullanmaktadır. Bu nedenle bu tür araç 
    zincirlerine "GNU araç zincirleri (GNU toolchains)" de denilmektedir. ARM'ın GNU araç zincirlerine aşağıdaki bağlantıdan 
    erişilebilir:

    https://developer.arm.com/downloads/-/gnu-a

    Örneğin elinizdeki host makinede 64 bit Intel işlemcilerinde çalışan Linux sistemi varsa Beaglebone Black için aşağıdaki çapraz 
    araç zincirini indirip kurabilirsiniz:

    gcc-arm-10.3-2021.07-x86_64-arm-none-linux-gnueabihf.tar.xz

    Raspberry Pi'nızda 64 bit Raspberry Pi OS varsa 64 bit Intel işlemcilerinde çalışan Linux sistemi için aşağıdaki çapraz araç 
    zincirini kullanabilirsiniz:

    gcc-arm-10.3-2021.07-x86_64-aarch64-none-linux-gnu.tar.xz

    Burada yapılacak şey bu dosyaları indirip aşağıdaki örnekte olduğu gibi açmaktır:

    $ tar -xf gcc-arm-10.3-2021.07-x86_64-arm-none-linux-gnueabihf.tar.xz

    Tabii açımı dosya yöneticileri ile de yapabilirsiniz.

    ARM firmasının yukarıda belirttiğimiz sitedeki hazır araç zincirleri ARM tarafından "discontinued" yapılmıştır. Yani ARM 
    yeni araç zinciri sistemine geçmiştir. ARM'ın en yeni araç zincirleri aşağıdaki bağlantıdan indirilebilir:

    https://developer.arm.com/downloads/-/arm-gnu-toolchain-downloads

    Ancak buradaki araç zincirleri maalesef bizim kullandığımız BeagleBone Black ile uyumsuzdur. (Buradaki araç zincirlerinde
    glibc kütüphanesinin daha ileri bir versiyonu kullanılmıştır. Dolayısıyla bu kütüphane dinamik kütüphane olarak kullanılacaksa 
    sorun oluşacaktır. Ancak statik kütüphane biçiminde kullanılacaksa sorun oluşmayacaktır.) Biz burada test amacıyla BeagleBone 
    Black aygıtımızla uyumlu olan ilk verdiğimiz bağlantıdaki araç zincirlerini kullanacağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												8. Ders 28/03/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Yukarıdaki araç zincirini yerel host makineye indirdiğimizde aşağıdaki bir dizin yapısıyla karşılaşırız:

    bin
    lib
    libexec
    arm-none-linux-gnueabihf
    include
    lib64
    share

    Genel olarak araç zincirlerinin çoğundaki dizin yapısı bu biçimdedir. Burada bizim için en önemli dizin "bin" dizinidir. 
    Çünkü bütün çapraz araçlar bu dizin içerisinde bulunmaktadır. Bu dizini görüntülediğimizde içeriği şöyle listelenmektedir:

    arm-none-linux-gnueabihf-addr2line
    arm-none-linux-gnueabihf-ar
    arm-none-linux-gnueabihf-as
    arm-none-linux-gnueabihf-c++
    arm-none-linux-gnueabihf-c++filt
    arm-none-linux-gnueabihf-cpp
    arm-none-linux-gnueabihf-dwp
    arm-none-linux-gnueabihf-elfedit
    arm-none-linux-gnueabihf-g++
    arm-none-linux-gnueabihf-gcc
    arm-none-linux-gnueabihf-gcc-10.3.1
    arm-none-linux-gnueabihf-gcc-ar
    arm-none-linux-gnueabihf-gcc-nm
    arm-none-linux-gnueabihf-gcc-ranlib
    arm-none-linux-gnueabihf-gcov
    arm-none-linux-gnueabihf-gcov-dump
    arm-none-linux-gnueabihf-gcov-tool
    arm-none-linux-gnueabihf-gdb
    arm-none-linux-gnueabihf-gdb-add-index
    arm-none-linux-gnueabihf-gfortran
    arm-none-linux-gnueabihf-gprof
    arm-none-linux-gnueabihf-ld
    arm-none-linux-gnueabihf-ld.bfd
    arm-none-linux-gnueabihf-ld.gold
    arm-none-linux-gnueabihf-lto-dump
    arm-none-linux-gnueabihf-nm
    arm-none-linux-gnueabihf-objcopy
    arm-none-linux-gnueabihf-objdump
    arm-none-linux-gnueabihf-ranlib
    arm-none-linux-gnueabihf-readelf
    arm-none-linux-gnueabihf-size
    arm-none-linux-gnueabihf-strings
    arm-none-linux-gnueabihf-strip

    Burada gcc derleyicimiz "arm-none-linux-gnueabihf-gcc" ismiyle bulunmaktadır. Ancak derleyicimizi kullanmak için oldukça 
    fazla tuşa basmamız gerekir. Bunu engellemek için PATH çevre değişkenine bu "bin" dizini eklenebilir. Ya da aşağıdaki gibi 
    bir sembolik bağlantı dosyası oluşturulabilir:

    $ ln -s gcc-arm-10.3-2021.07-x86_64-arm-none-linux-gnueabihf/bin/arm-none-linux-gnueabihf-gcc gcc-arm

    Burada artık biz ./gcc-arm biçiminde programı çalıştırdığımızda çapraz derleyicimizi çalıştırmış oluruz. Aynı işlemi C++
    derleyicisi için de yapabilirsiniz. C++ derleyicisi de "arm-none-linux-gnueabihf-g++" ismiyle bulunmaktadır. O halde 
    örneğin "sample.c" programını sembolik link oluşturduktan sonra aşağıdaki gibi derleyebiliriz:

    $ ./gcc-arm -o sample sample.c

    2) Linaro Kurumu Tarafından Oluşturulmuş Araç Zincirleri: Yaygın kullanılan hazır araç zincirlerinden biri de "Linaro" 
    tarafından oluşturulmuş araç zincirleridir. Linaro kar amacı gütmeyen bir organizasyondur. Linaro araç zincirlerini 
    aşağıdaki bağlantıdan indirebilirsiniz:

    https://releases.linaro.org/components/toolchain/binaries

    Ya da aşağıdaki bağlantıyı kullanabilirsiniz:

    https://snapshots.linaro.org/

    BBB için Linaro araç zincirinin "bin" dizini içerisindeki çapraz araçların listesi şöyledir:

    arm-linux-gnueabihf-addr2line
    arm-linux-gnueabihf-ar
    arm-linux-gnueabihf-as
    arm-linux-gnueabihf-c++
    arm-linux-gnueabihf-c++filt
    arm-linux-gnueabihf-cpp
    arm-linux-gnueabihf-dwp
    arm-linux-gnueabihf-elfedit
    arm-linux-gnueabihf-g++
    arm-linux-gnueabihf-gcc
    arm-linux-gnueabihf-gcc-14.0.0
    arm-linux-gnueabihf-gcc-ar
    arm-linux-gnueabihf-gcc-nm
    arm-linux-gnueabihf-gcc-ranlib
    arm-linux-gnueabihf-gcov
    arm-linux-gnueabihf-gcov-dump
    arm-linux-gnueabihf-gcov-tool
    arm-linux-gnueabihf-gdb
    arm-linux-gnueabihf-gdb-add-index
    arm-linux-gnueabihf-gfortran
    arm-linux-gnueabihf-gprof
    arm-linux-gnueabihf-ld
    arm-linux-gnueabihf-ld.bfd
    arm-linux-gnueabihf-ld.gold
    arm-linux-gnueabihf-lto-dump
    arm-linux-gnueabihf-nm
    arm-linux-gnueabihf-objcopy
    arm-linux-gnueabihf-objdump
    arm-linux-gnueabihf-ranlib
    arm-linux-gnueabihf-readelf
    arm-linux-gnueabihf-size
    arm-linux-gnueabihf-strings
    arm-linux-gnueabihf-strip

    Bu araç zincirindeki gcc derleyicisi için de aşağıdaki gibi sembolik bağlantı dosyası oluşturabiliriz:

    $ ln -s gcc-linaro-14.0.0-2023.06-x86_64_arm-linux-gnueabihf/bin/arm-linux-gnueabihf-gcc gcc-linaro

    Derlemeyi de şöyle yapabiliriz:

    $ ./gcc-linaro -o sample sample.c

    3) Bootlin Kurumu Tarafından Oluşturulmuş Araç Zincirini İndirip Kurmak: Bootlin gömülü Linux sistemleri alanında faaliyet 
    gösteren bir kurumdur. Bootlin tarafından oluşturulmuş olan çapraz araç zincirleri sık kullanılmaktadır. İlgili araç zinciri
    aşağıdaki sayfadan indirilebilir:

    https://toolchains.bootlin.com/

    Bootlin araç zincirlerinin hepsi Intel işlemcilerinin kullanıldığı Linux sistemleri için hazırlanmıştır.

    4) Windows İçin "gnutoolchains.com" Sitesindeki Araç Zincirini İndirip Kurmak: Bu site yalnızca Windows için çok çeşitli 
    GNU araç zincirlerini barındırmaktadır. Dolayısıyla eğer host sistem olarak Windows'u kullanıyorsak bu site işimizi 
    kolaylaştırabilir. Siteye aşağıdaki bağlantıdan erişebilirsiniz:

    https://gnutoolchains.com/

    Örneğin BBB için bu siteden "Beaglebone" seçilerek "beaglebone-gcc8.3.0.exe" dosyası indirilip kurulabilir. Bu site Windows'ta 
    doğrudan install edilebilen çalıştırılabilir programlar barındırmaktadır. Kurulum yapılırken bize araçların bulunduğu "bin"
    dizininin PATH çevre değişkenine eklenip eklenmeyeceği de sorulmaktadır. Eğer bu eklemeyi yaparsanız komut satırından 
    daha rahat çalışabilirsiniz.

    5) Bazı dağıtımların sunduğu araç zincirleri de bulunmaktadır. Örneğin Debian dağıtımı için ARM çapraz araç zinciri şöyle 
    kurulabilir:

    $ sudo apt-get install crossbuild-essential-armhf

    Bu araç zincirinin de glibc kütüphanesi bakımından BBB ile uyumsuz olduğuna dikkatinizi çekmek istiyoruz. Eğer ARM işlemcisinin
    bulunduğu Debian türevi bir Linux sisteminde çalışıyorsanız Intel kodu üretmek için de aşağıdaki gibi araç zincirini 
    kurabilirsiniz:

    $ sudo apt-get install crossbuild-essential-amd64
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												9. Ders 02/04/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Gömülü Linux sistemleri için host makine olarak Windows kullanılmasının çok uygun olmadığını belirtmiştik. Windows'ta geleneksel
    çalışma modeli GUI çalışma modelidir. Windows'ta komut satırından komutlar yoluyla çalışma yaygın bir kullanım biçimi değildir. 
    Halbuki daha önceden de söylediğimiz gibi UNIX/Linux sistemlerinin geleneksel çalışma biçimi "console" çalışmasıdır. Pekiyi 
    macOS sistemlerini host makine olarak kullanmak uygun olur mu?

    Aslında Apple firması GUI çalışma modelini ilk kullanan firmalardandır. Microsoft'un DOS işletim sistemi zamanlarında 
    Apple firmasının Macintosh sistemleri grafik arayüz kullanıyordu. Sonra 90'lı yılların sonlarına doğru Mac OS X (10) 
    ile birlikte Apple işletim sistemlerinin çekirdeğini değiştirerek UNIX türevi bir çekirdek kullanmaya başladı. Bugünkü 
    macOS sistemleri UNIX türevi bir sistem gibi değerlendirilebilir. Ancak durum böyle olsa da macOS sistemlerinde ağırlıklı 
    çalışma yine grafik arayüz yoluyla yapılmaktadır. Maalesef macOS sistemleri için hazır Linux araç zincirleri bulunmamaktadır. 
    Örneğin ARM, Linaro ve Bootlin kurumlarının macOS host olarak hazır araç zincirleri bulunmamaktadır. Bunların araç zinciri 
    üreten programlar tarafından derlenerek oluşturulması gerekmektedir. Dolayısıyla macOS sistemlerini host sistem olarak 
    kullanmak Windows sistemlerini host sistem olarak kullanmaktan biraz daha zordur. Biz macOS sistemlerini kullanan 
    katılımcılarımıza sanal makinelerine Linux kurmalarını öneriyoruz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Eclipse ilk kez bir Java IDE'si olarak tasarlanmıştır. Daha sonra plugin'ler yoluyla genel bir IDE haline getirilmiştir. 
    Eclips IDE'sinin C/C++ plugin'ine CDT denilmektedir. Elimizde Java için zaten kurmuş olduğumuz bir Eclipse varsa biz bu CDT
    plugin'ini IDE'ye ekleyerek C/C++ çalışması da yapabiliriz. Ancak kolaylık olsun diye Eclipse'in çeşitli diller için plugin'leri
    yüklenmiş halleri kendi sitesinde bulundurulmaktadır. Biz burada Eclipse IDE'si ile çapraz araç zincirlerinin nasıl kullanılacağını 
    göreceğiz.

    Eclipse IDE'si ile çapraz araç zincirini kullanmak için sırasıyla şunlar yapılmalıdır:

    1) Eclipse IDE for C++ Developers (Eclipse - CDT) indirilerek kurulur. İndirmeyi aşağıdaki bağlantıdan yapabilirsiniz:

    https://www.eclipse.org/downloads/packages/

    2) "File/New/C/C++" seçeneğinden "C++ Project" ya da "C Project" seçilir. ("C/C++ Project" seçeneğini seçmeyiniz.)

    3) Karşımıza çıkan diyalog penceresinde projeye bir isim verilir. Sağ taraftaki "Toolchains" panelinden de "Cross GCC" 
    seçilir.

    4) Daha sonra "Project/Properties" menüsünden "Tool Setting" seçilir. Çıkan diyalog penceresinden "Cross Settings" seçilir. 
    Yan taraftaki "Prefix" edit alanına alet zincirinin ön ekleri girilir. Öneklerin sonunda "-" karakterinin de bulundurulması 
    gerekmektedir. Örneğin "arm-linux-gnueabihf-" gibi. "Path edit" alanına ise çapraz alet zincirindeki programların bulunduğu
    "bin" dizininin yol ifadesi girilmelidir. (Örneğin "C:\SysGCC\beaglebone\bin" gibi.)

    5) Daha sonra Proje üzerine gelinerek bağlam menüsünden "Build Project" seçilip build işlemi yapılır.

    Eclipse üzerinden uzak bağlantı kurmak için de şunları yapılabilir:

    1) "Help/Install New Software" seçilir. Buradan aşağıdaki iki plugin kurulur:

    - Remote System Explorer User Actions
    - Remote System Explorer End-User Runtime
    - Remote Command Shell Console

    2) "Window/Show View/Remote Systems" seçilir. "Linux" seçilerek yeni bir bağlantı oluşturulur. Bağlantıya bir isim verilerek "Next" 
    düğmesine basılır. "Configuration" penceresinden "SSH files" seçilir. "Next" düğmesine basılır. Bu kez "Configuration" sekmesinden 
    "processes.shell.linux" seçilir ve "Next" seçilir. Oradan da "ssh.shells" seçilir ve "Finish" düğmesine basılır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												10. Ders 04/04/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Microsoft'un ünlü IDE'sine "Visual Studio" denilmektedir. Visual Studio IDE'si Windows için tasarlanmış ve gerçekleştirilmiştir. 
    Linux sistemlerinde bulunmamaktadır. Microsoft bu IDE'nin macOS versiyonunu çıkartmışsa da artık o projeyi devam ettirmemektedir. 
    Diğer sistemler için IDE ile editör arasında olan "Visual Studio Code" denilen aracı önermektedir. Visual Studio IDE'si 
    paralı bir üründür. Ancak Microsoft bu IDE'nin temel bir versiyonunu "Visual Studio Community" ismi altında bedava bir biçimde
    de vermektedir. IDE aşağıda bağlantıdan indirilebilir:

    https://visualstudio.microsoft.com/tr/downloads/

    Visual Studio uzun süredir ARM tabanlı mobil aygıtlar için kod üreten çapraz derleyicileri bünyesinde barındırmaktadır.

    Windows'ta Visual Studio IDE'sinde ARM tabanlı Linux sistemleri için proje (ve çözüm) şöyle yaratılmaktadır:

    1) Yeni bir proje oluşturulurken Platform olarak "Linux" ve "Empty Console Application" ya da "Empty Project" seçilir.

    2) Üretilecek kod türü ARM seçilir. Bu seçim IDE'nin ana ekranında yukarıdaki combobox'tan yapılabilmektedir.

    3) Daha sonra uzak makineye bağlantı yapılır. Bağlantı sırasında bizden uzak makinenin IP adresi (ya da ismi), oradaki 
    kullanıcının ismi ve parolası istenecektir. Bağlantı "Tools/Options/Multi Platform/Connection Manager" menüsünden yapılabilmektedir.

    4) Projeye kaynak kod eklenip "build" işlemi yapıldığında hedef makine için kod üretilir. Derleme menüsünden "Çözümü Dağıt"
    seçeneği seçildiğinde otomatik olarak tüm proje uzak makineye aktarılmaktadır. Debug işlemleri için de aslında programcının 
    özel bir hazırlık yapmasına gerek kalmamaktadır. Debug işlemi yerel makinede olduğu gibi yapılmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Microsoft değişik sistemlerde platform bağımsız geliştirme yapabilmek için "Visual Studio Code" isimli IDE ile Editör arası
    bir araç da gelişmiştir. Son yıllarda bu araç çok kullanılır olmuştur. Visual Studio Code yüksek seviyeli bir çalışma biçimine 
    sahip değildir. Çalışma düşük seviyede çeşitli ayar dosyaların edit edilmesiyle yapılmaktadır. Ancak editör tasarım olarak 
    genişletilebilir bir biçimde oluşturulmuştur. Yüksek seviyeli çalışma çeşitli plugin'lerle sağlanabilmektedir. Microsoft 
    bu plugin'lere "uzantı (extension)" demektedir. C/C++ programcısı olarak en azından Microsoft'un "C/C++ Extension Pack" 
    isimli eklentisini yüklemenizi öneririz. Ayrıca tek tuşa basarak programı derleyip çalıştırmak için "Code Runner" isimli 
    eklentiden de faydalanabilirsiniz. Örneğin bu eklenti sayesinde "Ctrl+Alt+N" tuşlarına basılarak editördeki program doğrudan 
    derlenip çalıştırılabilmektedir.

    Biz kursumuzdaki kodlama örneklerinde ağırlıklı olarak Visual Studio Code editörünü kullanacağız. Ancak bu aracı bir IDE 
    gibi değil, bir text editör gibi kullanacağız. İşlemleri genellikle manuel bir biçimde komut satırından yapacağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Visual Studio Code ile çapraz derleme işlemi maalesef kolay değildir. Bunun için henüz hazır eklentiler bulunmamaktadır. 
    Programcı tek tuşa basarak Visual Studio'da olduğu gibi işlemlerini otomatize edebilir. Ancak bunu yapmak için Visual Studio 
    Code'un çalışma biçimi hakkında ayrıntılı bilgi sahibi olması gerekir.

    Visual Studio Code aracında tek tuşa basarak çapraz derleme yapmak için sırasıyla şu adımlar izlenebilir:

    1) Önce bir dizin yaratılır. Dizin projeyi temsil edecektir. Sonra dizin içerisinde ".vscode" isimli bir dizin oluşturulur. 
    Bu dizinin içerisinde de "tasks.json" dosyası yaratılır.

    2) tasks.json dosyası için bir şablon şöyle olabilir:

    {
        "version": "2.0.0",
        "tasks": [
            {
                "label": "Build for ARM",
                "type": "process",
                "command": "/home/Study/gcc-arm-10.3-2021.07-aarch64-arm-none-linux-gnueabihf/bin/arm-none-linux-gnueabihf-gcc",
                "args": [
                    "-g",
                    "${workspaceFolder}/sample.c",
                    "-o",
                    "${workspaceFolder}/sample.o",
                    "--static"
                ],
                "group": {
                    "kind": "build",
                    "isDefault": true
                },
                "problemMatcher": [
                    "$gcc"
                ],
                "detail": "Compiler task."
            }
        ]
    }

    Burada "type" programın nasıl çalıştırılacağını belirtmektedir. Eğer buraya "shell" girilirse çalıştırma kabuğa yaptırılır.
    Eğer burada "process" girilirse doğrudan çalıştırma uygulanmaktadır. "command" çalıştırılacak programı belirtmektedir. 
    Tabii bu program ya doğrudan derleyici olur ya da "make" gibi, bir shell script gibi bir program olabilir. "args" ise "command" 
    ile belirtilen programın komut satırı argümanlarını belirtmektedir.

    Bu dosya oluşturulduktan sonra derlenecek dosya editörde aktif hale getirilir. Shift+Ctrl+P tuşlarına basılarak "Run Build Task" 
    seçilir.

    Tabii aslında yukarıdaki "tasks.json" dosyasında birden fazla "label" olabilir. Burada doğrudan derleyici çalıştırmak yerine 
    "make" gibi "cmake" gibi build otomasyon araçlarını da çalıştırabiliriz. Örneğin "tasks.json" dosyasını şöyle de oluşturabiliriz:

    {
    "version": "2.0.0",
    "tasks": [
        {
            "label": "Build for ARM",
            "type": "shell",
            "command": "make",
            "args": [
                "-f",
                "${workspaceFolder}/Makefile"
            ],
            "group": {
                "kind": "build",
                "isDefault": true
            },
            "problemMatcher": [
                "$gcc"
            ],
            "detail": "Compiler task."
        }
    ]
    }

    Burada biz "Shift+Ctlr+P" yapıp "Run Build Task" seçeneğini seçtiğimizde "make" programı çalıştırılacak ve make işlemi 
    yapılacaktır. Make dosyalarının nasıl oluşturulacağını ayrı bir bölümde ele alacağız. Ancak en basit bir make dosyası 
    şöyle oluşturulabilir:

    SDK_PATH=/home/kaan/Study/EmbeddedLinux/gcc-arm-10.3-2021.07-x86_64-arm-none-linux-gnueabihf/bin

    project: sample.o
        $(SDK_PATH)/arm-none-linux-gnueabihf-gcc -o project sample.o
    sample.o: sample.c
        $(SDK_PATH)/arm-none-linux-gnueabihf-gcc -c sample.c

    Bu make kodunu yaratmış olduğunuz proje dizinine "Makefile" ismiyle kaydedebilirsiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Visual Studio Code editöründe uzak bağlantı ile çalışmak için de sırasıyla şunlar yapılmalıdır:

    1) Aşağıdaki bağlantıdan CLI paketini uzak makineye indirip sıkıştırılmış dosyayı açınız:

    https://code.visualstudio.com/Download

    Bu dosyada "code" isimli bir program bulunmaktadır. Bu programı Linux sistemlerinde "/usr/bin" dizinine kopyalayabilirsiniz. 
    Bu işlem Linux sistemlerinde aşağıdaki gibi yapılabilir:

    $ tar xf <indirilen CLI dosyası>
    $ sudo cp code /user/bin

    2) Hedef makinede code programı aşağıdaki gibi çalıştırılır:

    $ code tunnel

    Bu program server'ın çalıştırılmasını sağlayacaktır. Bu çalıştırmayı ilk kez yaptığınızda github için bir onaylama istenmektedir.
    Bundan sonra size bir URL verilir. Bu URL yerel makinenizin tarayıcısında yazılırsa VSCode editörü grafik arayüzle açılacaktır.
    Tabii siz aslında uzak makinede VSCode editörü ile çalışıyor durumda olacaksanız.

    3) Bu işlemden sonra uzak makinedeki server program bir URL verir. Bu URL yerel makinede girilirse karşımıza tarayıcıda 
    Visual Studio Code editörü çıkacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz yukarıda çeşitli kurumlar tarafından hazır hale getirilmiş (prebuilt) araç zincirlerini kullandık. Ancak hazır araç 
    zincirlerini kullanmanın kimi zaman bazı dezavantajları söz konusu olabilmektedir. Örneğin:

    - Hazır araç zincirleri gömülü sistemimizdeki Linux ile uyumlu olmayabilir. Çünkü bir programın çapraz derlenerek hedef 
    makinede çalışabilmesi için çapraz derleme ortamıyla derlenmiş kodun çalışacağı ortamın tam bir uyum içerisinde olması 
    gerekmektedir. Örneğin ARM'ın hazır yeni araç zincirleri bizim kullandığımız BBB ile kütüphane bakımından uyumsuzdur.

    - Hazır araç zincirleri pek çok sistemde çalışabilsin diye hazırlanmaktadır. Bu da belli bir sistem için performansı 
    düşürebilmektedir. Oysa araç zincirleri tam olarak hedef sistem için en uygun kodların üretilebileceği biçimde o sisteme
    özgü oluşturulabilmektedir.

    - Hazır araç zincirleri standart C ve POSIX fonksiyonları için belli bir kütüphaneyi kullanmaktadır. Genellikle de bu 
    kütüphane GNU glibc kütüphanesidir. C++ için de benzer biçimde stdc++ kütüphanesi kullanılmaktadır. Araç zincirlerini 
    manuel biçimde oluştururken bu kütüphaneleri de hedef sistem için daha uygun olacak biçimde belirleyebiliriz.

    - Hazır araç zincirleri bazı klasik ABI'leri kullanmaktadır. Bazı aygıtlar için bazı nedenlerden dolayı farklı ABI'lerin 
    kullanılması gerekebilmektedir.

    Biz daha önce araç zincirlerinin manuel bir biçimde oluşturulmasının zorluklarından bahsetmiştik. İşte araç zincirlerinin
    içinde çok çeşitli programlar vardır. Bunların tek tek konfigüre edilip derlenmesi hem zahmetlidir hem de özel bilgiler 
    gerektirmektedir. İşte bu nedenden dolayı araç zincirlerini otomatik olarak üreten yazılımlar oluşturulmuştur. Biz kursumuzda 
    "buildroot" ve "yocto" projelerini ayrı bölümlerde ele alacağız. Bu projelerle araç zincirleri de oluşturulabilmektedir.
    Araç zincirlerinin oluşturulmasında son zamanlarda "crosstool-NG" isimli yazılım yaygın biçimde kullanılmaya başlanmıştır. Biz de 
    bu bölümde bu crosstool-NG yazılımının kullanılması üzerinde duracağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    crosstool-NG araç zinciri oluşturan bir yazılımdır. Zaman içerisinde çeşitli böcekler giderilmiş olsa da hala birtakım böcekler 
    bulunmaktadır. Ancak yazılım iş görür bir durumdadır.

    crosstool-NG aracını kullanmak için önce onun kaynak kodlarını indirip host makinede derlemek gerekir. Maalesef projenin 
    derlenmiş "binary" biçimi kendi sitesinde bulunmamaktadır. crosstool-NG hangi sistemde derlenirse host sistem o olmaktadır. 
    Biz bu araçta hedef (target) sistemin özelliklerini belirleyip host sistemde çalışacak çapraz derleme araçlarını oluştururuz.

    crosstool-NG aracının tipik host sistemi Linux olmalıdır. Windows'ta derleme yapmak oldukça zordur. macOS sistemlerinde 
    bu aracın kullanılması Windows sistemlerinden daha kolaydır. Ancak macOS için bazı programların "brew (home brew)" ile 
    indirilmesi gerekmektedir. Biz kursumuzda host sistem olarak Linux kullanacağız.

    crosstool-NG'nin tipik kullanımı şöyledir:

    1) Öncelikle crosstool-NG'nin derlenmesi ve araç zincirinin oluşturulması sırasında gerekli olan başka paketler kurulmalıdır.
    Gerekli bütün paketler aşağıda listelenmiştir. Bunu copy-paste yaparak bunların kurulumlarını sağlayabilirsiniz:

    $ sudo apt-get install autoconf automake bison bzip2 cmake flex g++ gawk gcc gettext git gperf help2man libncurses5-dev \
    libstdc++6 libtool libtool-bin make patch python3-dev rsync texinfo unzip wget xz-utils

    2) Projenin kaynak kodları kendi sitesinden indirilip proje derlenmelidir. Projenin resmi sitesi şöyledir:

    https://crosstool-ng.github.io/

    İndirme işlemi doğrudan git'ten yapılabilir. Örneğin:

    $ git clone https://github.com/crosstool-ng/crosstool-ng

    Eğer siteden indirme yapılmışsa indirilen dosya sıkıştırılmış bir dosyadır. Bu dosyanın açılması gerekir. Dosya açılınca bir 
    dizin oluşacaktır.

    3) Kabuktan dizine geçilir ve ilk iş olarak "bootstrap" isimli program aşağıdaki gibi çalıştırılır:

    $ ./bootstrap

    4) Daha sonra "autoconf" projelerinin çoğunda olduğu gibi bir "configure" işlemi yapılmalıdır. Bunun için "configure" denilen 
    program çalıştırılır. Bu program çalıştırılırken kurulumun hangi dizine yapılacağı da "--prefix" komut satırı argümanı
    ile belirtilebilir. Bu argümana "mutlak yol ifadesinin" verilmesi gerekmektedir. Örneğin

    $ ./configure --prefix=/home/kaan/crosstool-NG

    5) Artık projenin derlenmesi "make" komutuyla gerçekleştirilebilir:

    $ make

    6) Artık derleme yapılmıştır. Son aşama olarak derlenmiş programın install edilmesi kalmıştır. Bu işlem de "make install" 
    komutuyla yapılmaktadır:

    $ make install

    Bu komutla crosstool-NG configure işleminde --prefix ile belirtilen dizine kurulacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												11. Ders 16/04/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    crosstool-NG'de çapraz araç zincirleri için üç makine söz konusudur:

    1) Build Makinesi (Build Machine): Çapraz derleme araçlarının oluşturulduğu makinedir. Örneğin biz Intel tabanlı masaüstü 
    bilgisayarımızda alet zinciri oluşturmak amacıyla build işlemi yapıyorsak build makinesi bu makinedir.

    2) Host Makinesi (Host Machine): Oluşturulmuş olan araç zincirinin kullanıldığı makinedir. Örneğin biz Intel tabanlı masaüstü
    bilgisayarımızda ARM için çapraz derleme yapıyorsak bu durumda host makinesi bu çapraz derlemeyi yaptığımız makinedir.

    3) Hedef Makine (Target Machine): Derlenmiş olan kodun çalıştırılacağı makineyi belirtmektedir. Örneğin biz Intel işlemcilerinin
    kullanıldığı host makinede ARM için çapraz derleme yapmışsak burada hedef makine ARM işlemcisinin bulunduğu makinedir.

    Genellikle "build makinesi" ile "host makinesi" aynı makine olmaktadır. Yani biz genellikle araç zincirini build ettiğimiz 
    makinede aynı zamanda çapraz derleme işlemlerini de yaparız.

    crosstool-NG'nin dokümantasyonunda build makinesi, host makinesi ve hedef makine kombinasyonları için dört terim kullanılmaktadır:

    1) Eğer "build makinesi == host makinesi == hedef makine" ise bu tür araç zincirlerine "doğal araç zincirleri (native toolchains) 
    denilmektedir.

    2) Eğer "build makinesi == host makinesi != hedef makine" ise bu tür araç zincirlerine "çapraz araç zincirleri (cross toolchains)" 
    denilmektedir. crosstool-NG için en çok kullanılan araç zincirleri bunlardır.

    3) Eğer "build makinesi != host makinesi == hedef makine" ise bu tür araç zincirlerine "çapraz-doğal araç zincirleri 
    (cross-native toolchains)" denilmektedir.

    4) Eğer "build makinesi != host makinesi != hedef makine" ise böyle araç zincirlerine "kanadalı araç zincirleri (canadian 
    toolchains)" denilmektedir.

    Kanadalı araç zincirine dikkat ediniz. Örneğin biz ARM tabanlı bir Linux makinede araç zinciri oluşturmak isteyelim. 
    Ancak araç zincirimiz Intel tabanlı bir bilgisayarda çalışacak olsun. Ancak bu Intel tabanlı bilgisayarda bu araç zincirini 
    çalıştırdığımızda üretilecek kod MIPS tabanlı bir bilgisayara yönelik olsun. Burada crosstool-NG terminolojisine göre bir 
    Kanadalı araç zinciri söz konusudur.

    Ancak crosstool-NG her zaman build işleminin yapıldığı makinede çalışacak araç zinciri kodu üretmektedir. Yani üretilen 
    araç zincirinde "build makinesi == host makine" olmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    crosstool-NG'de işlemler "bin" klasörünün altında "ct-ng" isimli programla yapılmaktadır. Biz burada sizin crosstool-NG'nin 
    ana klasöründe olduğunuzu varsayacağız.

    Maalesef crosstool-NG aracında halen bazı böcekler bulunmaktadır. Örneğin eğer Linux sisteminizdeki "sistem dili" Türkçe ise
    crosstool-NG derlenirken bu sistem dilini referans aldığı için ürettiği script'lerde Türkçe karakterleri kullanmaktadır.
    Bu da bu script'lerin çalıştırılmasında sorunlara yol açmaktadır. Bu böceğin "arkasından dolaşmak (workaround)" için sistem 
    dili Türkçe yerine İngilizce yapılabilir. (Mint dağıtımında bu işlem ana menüden "Tercihler/Diller" seçeneği kullanılarak 
    yapılabilir. Burada yalnızca arayüz dilini değiştirebilirsiniz.) Tabii bu değişiklik yapıldıktan sonra crosstool-NG'yi yeniden 
    derlenmelidir. (Aslında muhtemelen derleme sırasında kodlar "LANG" ve "LANGUAGE" gibi bazı çevre değişkenlerine bakmaktadır. 
    Sistem ayarlarını değiştirmeden yalnızca birkaç çevre değişkeni geçici olarak da değiştirilebilir. Ancak sistem dilinin 
    değiştirilmesi daha sorunsuz bir çözüm oluşturacaktır.) crosstool-NG derlendikten sonra sistem dilini eski haline getirebilirsiniz. 
    Sistem dilini değiştirdikten sonra makinenizi reboot etmelisiniz.

    crosstool-NG'de araç zinciri derleme işlemi sırasıyla şu adımlardan geçilerek sağlanmaktadır:

    1) Önce araç zinciri "ct-ng" programı ile konfigüre edilir. Araç zincirinin konfigürasyonu için "menuconfig" argümanı 
    kullanılmaktadır:

    $ bin/ct-ng menuconfig

    Karşımıza bir konfigürasyon menüsü gelecektir. Bu menüde ilgili öğeler seçilip konfigürasyon save edilir. Save işlemi sonrasında
    default durumda ".config" isimli bir dosya oluşacaktır. (UNIX/Linux sistemlerinde başında "." olan dosya ve klasörlerin ls 
    komutunda default olarak görüntülenmediğine dikkat ediniz.)

    Konfigürasyon işleminde pek çok menü seçeneği bulunmaktadır. Bu seçeneklerin hepsi için belirlemeler yapmak yerine isteğinize en 
    yakın olan hazır bir konfigürasyonu yükleyip değişiklikleri onun üzerinde yapabilirsiniz. Hazır konfigürasyonların listesi 
    aşağıdaki gibi görüntülenebilir:

    $ bin/ct-ng list-samples
    Status  Sample name
    [G...]   aarch64-ol7u9-linux-gnu
    [G...]   aarch64-ol8u6-linux-gnu
    [G...]   aarch64-ol8u7-linux-gnu
    [G...]   aarch64-rpi3-linux-gnu
    [G...]   aarch64-rpi4-linux-gnu
    [G...]   aarch64-unknown-linux-gnu
    [G..X]   aarch64-unknown-linux-musl
    [G...]   aarch64-unknown-linux-uclibc
    [G...]   alphaev56-unknown-linux-gnu
    [G...]   alphaev67-unknown-linux-gnu
    [G...]   arc-arc700-linux-uclibc
    ...

    Hazır bir konfigürasyonu yüklemek için buradaki isimlerden uygun olanı seçilir ve aşağıdaki gibi yükleme yapılır:

    $ bin/ct-ng <hazır şablonun ismi>

    Örneğin:

    $ bin/ct-ng arm-cortex_a8-linux-gnueabi

    Bir konfigürasyonun belirlemeleri konfigürasyon isminin başına "show-" getirilerek görüntülenebilmektedir. Örneğin:

    $ bin/ct-ng show-arm-cortex_a8-linux-gnueabi
    [G...]   arm-cortex_a8-linux-gnueabi
        Languages       : C,C++
        OS              : linux-6.6.1
        Binutils        : binutils-2.42
        Compiler        : gcc-13.2.0
        C library       : glibc-2.39
        Debug tools     : duma-2_5_21 gdb-14.2 ltrace-0.7.3 strace-6.6
        Companion libs  : expat-2.5.0 gettext-0.21 gmp-6.2.1 isl-0.26 libelf-0.8.13 libiconv-1.16 mpc-1.3.1 mpfr-4.2.1
                          ncurses-6.4 zlib-1.3 zstd-1.5.5
        Companion tools :

    BBB için araç zinciri oluşturmak isteniyorsa buna en yakın konfigürasyon "arm-cortex_a8-linux-gnueabi" isimli konfigürasyondur.
    Bu konfigürasyonu aşağıdaki gibi yükleyebilirsiniz:

    $ bin/ct-ng arm-cortex_a8-linux-gnueabi

    Sonra menuconfig yaparak konfigürasyon menüsüne girebilirsiniz:

    $ bin/ct-ng menuconfig

    Burada şu seçenekleri değiştirmeniz gerekir:

    - "Paths and misc options" menüsünden "Render the toolchain read-only" unchecked yapılır.
    - "Target/Floating Point" menüsünden "hardware (FPU)" seçilir.
    - "Target/Use specific FPU" menüsünde "neon" girilir.
    - "C-Library" menüsünden "Versions of glibc" alt menüsüne gelinip glibc kütüphanesinin versiyon numarası 2.34 yapılır.
    (BBB'deki Debian sürümü glibc 2.34'i kullanmaktadır.)

    2) Araç zinciri menuconfig ile konfigüre edildikten sonra artık "build" işlemi aşağıdaki gibi yapılabilir:

    $ bin/ct-ng build

    3) crosstool-NG ürettiği araç zincirini default olarak "home" dizininin altında "x-tools" isimli bir dizine yerleştirmektedir. 
    Örneğin yukarıda ürettiğimiz araç zinciri bu dizinde şöyle gözükmektedir:

    $ ls -l x-tools
    total 4
    drwxrwxr-x 8 kaan kaan 4096 Nis 16 23:14 arm-cortex_a8-linux-gnueabihf

    Buradaki dizin hazır araç zincirlerinde olduğu bir yapıya sahiptir. Derleyiciler ve diğer binary araçlar "bin" dizininin içerisinde
    bulunmaktadır. Örneğin:

    -rwxr-xr-x 1 kaan kaan  1123904 Nis 16 23:14 arm-cortex_a8-linux-gnueabihf-addr2line
    -rwxr-xr-x 2 kaan kaan  1156456 Nis 16 23:14 arm-cortex_a8-linux-gnueabihf-ar
    -rwxr-xr-x 2 kaan kaan  2193584 Nis 16 23:14 arm-cortex_a8-linux-gnueabihf-as
    -rwxr-xr-x 2 kaan kaan  1850512 Nis 16 23:14 arm-cortex_a8-linux-gnueabihf-c++
    lrwxrwxrwx 1 kaan kaan       33 Nis 16 22:41 arm-cortex_a8-linux-gnueabihf-cc -> arm-cortex_a8-linux-gnueabihf-gcc
    -rwxr-xr-x 1 kaan kaan  1123392 Nis 16 23:14 arm-cortex_a8-linux-gnueabihf-c++filt
    -rwxr-xr-x 1 kaan kaan  1850512 Nis 16 23:14 arm-cortex_a8-linux-gnueabihf-cpp
    -rwxr-xr-x 1 kaan kaan     5812 Nis 16 21:19 arm-cortex_a8-linux-gnueabihf-ct-ng.config
    -rwxr-xr-x 1 kaan kaan  2742848 Nis 16 23:14 arm-cortex_a8-linux-gnueabihf-dwp
    -rwxr-xr-x 1 kaan kaan    43704 Nis 16 23:14 arm-cortex_a8-linux-gnueabihf-elfedit
    -rwxr-xr-x 2 kaan kaan  1850512 Nis 16 23:14 arm-cortex_a8-linux-gnueabihf-g++
    -rwxr-xr-x 2 kaan kaan  1846416 Nis 16 23:14 arm-cortex_a8-linux-gnueabihf-gcc
    -rwxr-xr-x 2 kaan kaan  1846416 Nis 16 23:14 arm-cortex_a8-linux-gnueabihf-gcc-13.2.0
    ...

    crosstool-NG'de daha önce yapılan ve ".config" dosyasına save edilen konfigürasyon dosyası "oldconfig" argümanıyla 
    geri yüklenebilir. Örneğin:

    $ bin/ct-ng oldconfig

    Artık bundan sonra "menuconfig" yaparsak eski konfigürasyon dosyasını yüklemiş oluruz.

    Daha önce yapılan build işleminden kalan birtakım dosyaların kaldırılması için ise "distclean" argümanıyla yapılabilmektedir. 
    Örneğin:

    # bin/ct-ng distclean

    distclean işlemi oluşturulan araç zincirlerini silmemektedir. Araç zincirlerinin oluşturulması için yaratılmış olan dosyaları 
    silmektedir.

    ct-ng programının diğer komut satırı argümanları için aşağıdaki bağlantıdan faydalanabilirsiniz:

    https://man.archlinux.org/man/extra/crosstool-ng/ct-ng.1.en
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Araç zincirlerinin nasıl oluşturulduğunu ve kullanıldığını gördükten sonra şimdi dikkatimizi araç zincirleri içerisindeki 
    araçlara yönelteceğiz. Araç zincirleri içerisindeki en önemli araçlar şüphesiz "C Derleyicileri", "C++ Derleyicileri" ve 
    "Bağlayıcı (linker)" programlardır.

    Bilindiği gibi derleyiciler aslında "amaç dosya (object file)" denilen bir dosya üretmektedir. Bu amaç dosyalara "bağlayıcı
    (linker)" denilen programlara sokularak çalıştırılabilir (executable) dosya oluşturulmaktadır. Sistem programcısının bu 
    kavramlar hakkında temel bilgilere sahip olması gerekmektedir. Amaç dosyaların UNIX/Linux sistemlerindeki uzantıları ".o" 
    biçimindedir. Çalıştırılabilen dosyalar için UNIX/Linux sistemlerinde özel bir uzantı kullanılmamaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Derleyicilerin ürettiği amaç dosyaların (object files) ve bağlayıcıların ürettiği çalıştırılabilir dosyaların (executable files)
    önceden belirlenmiş belli bir formatı vardır. Microsoft DOS zamanlarında amaç dosya formatı olarak "OMF (Object Module Format)" 
    denilen bir formatı, çalıştırılabilir dosya formatı olarak da "MZ (Mark Zbikowski) " denilen bir formatı kullanıyordu. Sonra 
    16 bit Windows sistemleriyle amaç dosya formatı olarak OMF formatını kullanmaya devam etti, ancak çalıştırılabilir dosya formatı 
    olarak "NE (New Executable)" isimli bir formatı kullanmaya başladı. Sonra nihayet 32 bit ve 64 bit Windows sistemlerinde amaç 
    dosya formatı olarak COFF (Common Object File Format)", çalıştırılabilir dosya formatı olarak "PE (Portable Executable)" denilen 
    formatı kullanmaya başladı. Bugün Microsoft COFF ve PE formatlarını kullanmaktadır. COFF formatı ile PE formatı hemen hemen aynı 
    formatlardır. COFF formatı, PE formatının amaç dosya için özelleştirilmiş biçimi gibidir.

    Apple firması macOS sistemlerinde amaç dosya ve çalıştırılabilir dosya formatı olarak "Mach-O" formatı denilen bir dosya formatını
    kullanmaktadır.

    UNIX/Linux sistemlerinde uzunca bir süredir en yaygın kullanılan amaç dosya formatı ve çalıştırılabilir dosya formatı "ELF
    (Executable and Linkable Format)" isimli formattır. ELF formatı hem bir amaç dosya formatı hem de çalıştırılabilir dosya
    formatıdır. ELF formatının 32 bit ve 64 bit biçimleri vardır. Linux geçmişe doğru uyum için eski geleneksel "a.out" denilen 
    çalıştırılabilir dosya formatını da desteklemektedir. Fakat Linux sistemlerindeki default amaç dosya ve çalıştırılabilir 
    dosya formatı ELF formatıdır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    UNIX/Linux sistemlerinde ELF dosyasını belleğe yükleyip çalışmaya hazır hale getirme işlemi "exec fonksiyonları" tarafından
    yapılmaktadır. (Linux sistemlerinde yalnızca execve fonksiyonu sistem fonksiyonu olarak bulundurulmuştur. Diğer exec 
    fonksiyonları execve fonksiyonunu çağırmaktadır.) Kavramsal olarak işletim sistemlerinde çalıştırılabilir dosyayı belleğe 
    yükleyerek çalıştırma durumuna getiren alt sistemlere "yükleyici (loader)" denilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Sistem programcısı olarak bir dosyanın içeriğini byte-byte hex sistemde görmek isteyebiliriz. Windows sistemlerinde bunu 
    yapan pek çok GUI uygulaması vardır. "HxD" denilen program oldukça yeteneklidir ve ücretsiz olarak kullanılabilmektedir. 
    Linux ve macOS sistemlerinde "hex editör" olarak çok güzel GUI programlarla karşılaşmak zordur. "GHex" isimli GUI hex editör 
    oldukça basittir ve GNOME sistemlerinde kullanılmaktadır. "ghex" programı aşağıdaki gibi install edilebilir:

    $ sudo apt-get install ghex

    Yine GUI hex editörlerinden biri de "bless" isimli editördür. Şöyle kurulabilir:

    $ sudo apt-get install bless

    Linux ve macOS sistemlerinde yetenekli IDE'ler aynı zamanda bir hex editör işlevini de görebilmektedir. Örneğin Visual Studio
    Code editörünün "Hex Editor" isimli bir eklentisi (Microsoft tarafından yazılmıştır) dosya içeriklerini hex olarak gösterebilmektedir.

    Ancak tabii Linux sistemleri ağırlıklı biçimde komut satırından işletildiği için sistem programcısının bir dosyanın içeriğini 
    komut satırından hex sistemde görüntülemesi gerekebilmektedir. Linux için konsol ekranında çalışan bazı hex gösterim yapan
    programlar şunlardır:

    - "od" programı. Tipik kullanımı şöyledir:

    od -t x1 <yol ifadesi>

    od default olarak dağıtımlarda bulunmaktadır.

    - "hexer" isimli program eski DOS sistemine benzer bir biçimde görüntüleme yapmaktadır. Şöyle kurulabilir:

    $ sudo ept-get install hexer

    - "hexcurse" isimli program. Hexcurse şöyle kurulabilir:

    $ sudo apt-get install hexcurse
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												12. Ders 18/04/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    ELF dosyasının genel yapısı şöyledir:

    +----------------------------------------------------------------+
    |                    ELF Başlığı (ELF Header)                    |
    +----------------------------------------------------------------+
    |  Program Başlık Tablosu (Program Header Table) (İsteğe Bağlı)  |
    +----------------------------------------------------------------+
    |                     Bölümler (Sections)                        |
    +----------------------------------------------------------------+
    |           Bölüm Başlık Tablosu (Section Header Table)          |
    +----------------------------------------------------------------+

    ELF dosyasının hemen başında bir başlık kısmı (ELF Header) bulunmaktadır. Bu başlık kısmında dosya hakkında en önemli bilgiler
    tutulmaktadır.

    32 bit ELF dokümanlarında ELF formatının yapısal içeriğinde kullanılan tür isimleri ve anlamları şöyledir:

    Name            Size        Alignment       Purpose
    Elf32_Addr      4           4               Unsigned program address
    Elf32_Half      2           2               Unsigned medium integer
    Elf32_Off       4           4               Unsigned file offset
    Elf32_Sword     4           4               Signed large integer
    Elf32_Word      4           4               Unsigned large integer
    unsigned char   1           1               Unsigned small integer

    64 bit ELF dokümanlarında ELF formatının yapısal içeriğinde kullanılan tür isimleri ve anlamları da şöyledir:

    Name                Size        Alignment       Purpose
    Elf64_Addr      8           8               Unsigned program address
    Elf64_Off       8           8               Unsigned file offset
    Elf64_Half      2           2               Unsigned medium integer
    Elf64_Word      4           4               Unsigned integer
    Elf64_Sword     4           4               Signed integer
    Elf64_Xword     8           8               Unsigned long integer
    Elf64_Sxword    8           8               Signed long integer
    unsigned char   1           1               Unsigned small integer
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    ELF Başlığı'nda dosyadaki meta-data alanları hakkında önemli bilgiler yer almaktadır. ELF Başlığı'nın ilk 16 byte'ı "kimlik 
    bilgileri (identification)" denilen dosyanın en kritik bilgilerini tutan kısmıdır. ELF dosyasının ilk dört byte'ında bir 
    "sihirli sayı (magic number)" bulundurulmuştur. Bu ilk 4 byte'ın ilk byte'ı 0x7F sonraki üç byte'ı da 'E', 'L', 'F' karakterlerinin 
    ASCII kodlarından oluşmaktadır. Yani ELF dosyasının ilk 4 byte'ı hex olarak şöyledir:

    7F 45 4C 46

    Kimlik bilgilerinin 4'üncü offset'teki byte'ı ELF dosyasının 32 bit mi 64 bit mi olduğunu belirtmektedir. Eğer ELF dosyası 
    32 bit ise (yani 32 bitlik bir işletim sistemi için oluşturulmuşsa) burada 1 değeri, 64 bit ise (yani 64 bit bir işletim 
    sistemi için oluşturulmuşsa) burada 2 değeri olmalıdır.

    Kimlik bilgilerinin 5'inci offset'teki byte'ı ELF dosyasının "little endian" olarak mı yoksa "big endian" olarak mı 
    oluşturulduğunu belirtmektedir. Buradaki değer 1 ise dosya "little endian", 2 ise dosya "big endian" biçiminde oluşturulmuştur. 
    Intel işlemcilerinin yalnızca "little endian" kullandığını, ARM işlemcilerinin hem "little endian" hem de "big endian" 
    olarak kullanılabildiğini ancak default kullanımın "little endian" olduğunu anımsayınız. O halde burada tipik olarak 1 
    değeri bulunacaktır.

    Kimlik bilgilerinin 6'ıncı offset'indeki byte'ı ELF dosyasının majör versiyon numarasını belirtmektedir. Şu anda ELF dosyasının 
    majör olarak 1'li versiyonları kullanıldığı için burada 1 değeri bulunacaktır.

    Kimlik bilgilerinin 7'nci offset'teki byte'ı kullanılan ABI türünü belirtmektedir. Buradaki 0 değeri klasik "System 5 ABI"
    anlamına gelmektedir. Burada genellikle 0 değeri bulunmaktadır.

    Kimlik bilgilerinin 8'inci offset'teki byte'ı ABI versiyon numarasını belirtmektedir. Genel olarak burada 0 değeri bulunur.

    Kimlik bilgilerinin 9'uncu offset'inden itibaren artık 16 byte'tan geri kalan byte'lar 0'larla doldurulmuştur. Bu 0 byte'larına
    "padding" denilmektedir.

    Aşağıda 64 bit Intel makinesinde oluşturulmuş bir ELF formatının ilk 16 byte'ı görülmektedir:

    7f 45 4c 46 02 01 01 00  00 00 00 00 00 00 00 00  .ELF............

    Aşağıda da 32 bit ARM işlemcileri için oluşturulmuş bir ELF formatının ilk 16 byte'ı görülmektedir:

    7f 45 4c 46 01 01 01 00  00 00 00 00 00 00 00 00  .ELF............

    ELF Başlığı'nda kimlik bilgilerinden (ilk 16 byte) sonra yine dosya hakkında önemli bilgiler yer almaktadır. ELF Başlığı'nın 
    16'ıncı offset'indeki 2 byte'lık işaretsiz tamsayı dosyanın türünü belirtmektedir. Tipik tür değerleri şunlardır:

    0 ---> Geçersiz
    1 ---> Amaç Dosya (Relocatable Object File)
    2 ---> Çalıştırılabilir Dosya (Executable File)
    3 ---> Dinamik Kütüphane Dosyası (Shared Object)
    4 ---> Çekirdek Dosyası (Core File)

    ELF Başlığı'nın 18'inci offset'indeki 2 byte'lık işaretsiz tamsayı dosyanın çalıştırılacağı hedef işlemcinin türünü belirtmektedir. 
    Buradaki 2 byte'lık çeşitli işaretsiz tamsayı değerler çeşitli işlemci türlerini belirtmektedir. Örneğin 0x28 "32 Bit ARM 
    İşlemcilerini", 0x3E "AMD'nin 64 bit Intel Tabanlı İşlemcilerini" belirtmektedir. Bunların tam listesini internetteki 
    dokümanlardan elde edebilirsiniz. (Örneğin Wikipedia'da "Executable and Linkable Format" sayfasında ayrıntılı bir liste 
    verilmiştir.)

    https://en.wikipedia.org/wiki/Executable_and_Linkable_Format

    ELF Başlığı'nın 20'nci offset'teki 4 byte'lık işaretsiz tamsayı yine ELF dosyasının versiyon numarasını belirtmektedir. Burada 
    tipik olarak 1 değeri bulunacaktır.

    ELF Başlığı'nın 24'üncü offset'inde "çalıştırılabilir dosyalar için" programın çalışmaya başlayacağı sanal adresi (virtual address) 
    belirtilmektedir. Çalıştırılabilir bir dosyanın çalıştırılmaya başlanacağı adrese aşağı seviyeli terminoloji de "entry point" 
    denilmektedir. Tabii adres bilgileri 32 bit ELF dosyalarında 4 byte, 64 bit ELF dosyalarında 8 byte uzunluktadır.

    ELF Başlığı'nın sonraki elemanlarının offset'leri artık 32 bit ve 64 bit ELF dosyalarına göre değişmektedir. 32 bit ELF 
    dosyalarında adres bilgileri ve dosya offset bilgileri 4 byte uzunluğunda, 64 bit ELF dosyalarında ise 8 byte uzunluğundadır.

    ELF Başlığı'nda bulunan diğer bilgiler şunlardır:

    - ELF Başlığı'nın (ELF Header) byte uzunluğu.

    - Program Başlık Tablosu'nun (Program Header Table) dosyada hangi offset'ten başladığı bilgisi. Program Başlık Tablosu
    tipik olarak ELF Başlığı'ndan hemen sonra gelmektedir.

    - Program Başlık Tablosu'ndaki Program Başlıkları'nın sayısı

    - Bölüm Başlık Tablosu'nun (Section Header Table) dosyada hangi offset'ten başladığı bilgisi. Bölüm Başlık Tablosu genellikle 
    ELF formatının sonunda bulunmaktadır.

    - Bölüm Başlık Tablosu'ndaki Bölüm Başlıkları'nın sayısı ve bir Bölüm Başlığı'nın byte uzunluğu.

    - Bölüm Başlık İsimleri'nin bulunduğu String Tablosu'nun Bölüm Başlık Tablosu'ndaki indeksi.

    32 bit ELF formatında ELF Başlığı'nın yapısal içeriği şöyledir:

    #define EI_NIDENT		16

    typedef struct {
        unsigned char e_ident[EI_NIDENT];   /* ELF identification */
        Elf32_Half e_type;                  /* Object file type */
        Elf32_Half e_machine;               /* Machine type */
        Elf32_Word e_version;               /* Object file version */
        Elf32_Addr e_entry;                 /* Entry point address */
        Elf32_Off e_phoff;                  /* Program header offset */
        Elf32_Off e_shoff;                  /* Section header offset */
        Elf32_Word e_flags;                 /* Processor-specific flags */
        Elf32_Half e_ehsize;                /* ELF header size */
        Elf32_Half e_phentsize;             /* Size of program header entry */
        Elf32_Half e_phnum;                 /* Number of program header entries */
        Elf32_Half e_shentsize;             /* Size of section header entry */
        Elf32_Half e_shnum;                 /* Number of section header entries */
        Elf32_Half e_shstrndx;              /* Section name string table index */
    } Elf32_Ehdr;

    64 bit ELF formatında ise ELF Başlığı'nın yapısal içeriği şöyledir:

    typedef struct {
        unsigned char e_ident[16];          /* ELF identification */
        Elf64_Half e_type;                  /* Object file type */
        Elf64_Half e_machine;               /* Machine type */
        Elf64_Word e_version;               /* Object file version */
        Elf64_Addr e_entry;                 /* Entry point address */
        Elf64_Off e_phoff;                  /* Program header offset */
        Elf64_Off e_shoff;                  /* Section header offset */
        Elf64_Word e_flags;                 /* Processor-specific flags */
        Elf64_Half e_ehsize;                /* ELF header size */
        Elf64_Half e_phentsize;             /* Size of program header entry */
        Elf64_Half e_phnum;                 /* Number of program header entries */
        Elf64_Half e_shentsize;             /* Size of section header entry */
        Elf64_Half e_shnum;                 /* Number of section header entries */
        Elf64_Half e_shstrndx;              /* Section name string table index */
    } Elf64_Ehdr;
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												13. Ders 25/04/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    ELF formatını parse edip insanların anlayabileceği biçimde görüntüleyen çeşitli utility programlar bulunmaktadır. Bunların 
    en yaygın kullanılan ikisi "readelf" ve "objdump" programlarıdır. Bu programların ayrıntılı dokümantasyonu "man" sayfalarında 
    bulunmaktadır. "objdump" programı daha genel, "readelf" programı daha özel programlardır. Ancak "objdump" programı işlevsel 
    olarak "readelf" programını tam olmasa da kapsar niteliktedir. "readelf" programının kullanımı daha kolaydır.

    "readelf" programında "-h" ya da "--file-header" seçeneği ELF Başlığı'nı görüntülemek için kullanılmaktadır. Örneğin:

    $ readelf -h sample
    ELF Başlığı:
    Sihir:   7f 45 4c 46 02 01 01 00 00 00 00 00 00 00 00 00
    Sınıf:                              ELF64
    Veri:                               2's complement, little endian
    Version:                            1 (current)
    OS/ABI:                             UNIX - System V
    ABI Sürümü:                         0
    Tip:                                DİN (Paylaşımlı nesne dosyası)
    Makine:                             Advanced Micro Devices X86-64
    Sürüm:                              0x1
    Girdi noktası adresi:               0x1060
    Yazılım başlıkları başlangıcı:      64 (bayt dosya içinde)
    Bölüm başlıkları başlangıcı:        14712 (bayt dosya içinde)
    Seçenekler:                         0x0
    Size of this header:                64 (bytes)
    Size of program headers:            56 (bytes)
    Number of program headers:          13
    Size of section headers:            64 (bytes)
    Number of section headers:          31
    Section header string table index:  30

    "objdump" programı ile ELF formatının başlıkları "-x" ya da "--all-headers" seçeneği ile görüntülenebilir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    ELF Formatı içerisinde pek çok "isim" belirten öğe bulunmaktadır. İsimler değişken uzunlukta olabileceği için hem isim 
    tekrarlarında kolaylık sağlamak hem de isimlerin sabit uzunlukta ifade edilmesini sağlamak amacıyla "string tabloları" 
    bulundurulmuştur. String tabloları sonu '\0' ile biten yazılardan oluşmaktadır. ELF formatı içerisinde ne zaman bir isim
    belirtilecek olsa isim yerine o ismin bulunduğu string tablosundaki offset belirtilmektedir. ELF formatında string tabloları 
    da aslında "bölümler (sections)" biçimindedir. ELF dosyasında tek bir string tablosu bulunmak zorunda değildir. Genellikle 
    derleyiciler normal sembolleri ".strtab" isimli bölümde, "bölüm başlıklarının isimlerini" ".shstrtab" isimli bölümde, dinamik
    kütüphanelerdeki sembollerin isimlerini de ".dynstr" isimli bölümde string tabloları biçiminde tutmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Daha önceden de belirttiğimiz gibi ELF formatı "bölümlerden (sections)" oluşmaktadır. Her bölümde belli bir konuya ilişkin
    bilgiler bulunmaktadır. ELF formatının derleyiciler tarafından kullanılan standart bazı bölümleri vardır. Ancak çeşitli 
    derleyiciler ve hatta sistem programcıları standart olmayan bölümler de oluşturabilmektedir. Bölümlerin birer ismi vardır.
    Bölüm isimleri genellikle "." karakteri ile başlatılır. ELF dosyası içerisindeki bütün bölümlerin dosyanın neresinden 
    başladığı, hangi uzunlukta olduğu ve o bölümde hangi tarzda bilgiler bulunduğu "Bölüm Başlık Tablosu (Section Header Table)"
    denilen bir tabloda belirtilmiştir. Bölüm Başlık Tablosu'nun dosya içerisindeki yeri ve Bölüm Başlıkları'nın Sayısı ELF 
    Başlığı'nda bulunmaktadır. Bu durumda ELF dosyasının bölüm bilgilerini elde etmek için önce ELF Başlığı okunmalı oradan Bölüm 
    Başlık Tablosu'nun yeri elde edilmelidir. Bölüm Başlık Tablosu, "Bölüm Başlığı (Section Header)" denilen alanlardan oluşmaktadır. 
    Başka bir deyişle Bölüm Başlık Tablosu, "Bölüm Başlığı Dizileri"nden oluşmaktadır. Bir Bölüm Başlığı'nda aşağıdaki bilgiler 
    bulunmaktadır:

    - Bölümün isminin bölüm isimlerinin bulunduğu string tablosundaki offset numarası

    - Bölümün türü. Her bölüm belli bir konuya ilişkin bilgi tutmaktadır. İşte bölümün hangi konuya ilişkin bilgiyi tuttuğuna
    bölümün türü denilmektedir. Bölüm türleri aslında birer sayıyla belirtiliyorsa da okunabilirliği artırmak için sembolik
    isimlerle de belirtilmektedir. Örneğin SHT_STRTAB türü ilgili bölümün içerisinde "string tablosu olduğunu", SHT_RELA ilgili
    bölümün içerisinde "relocation" bilgilerinin bulunduğunu belirtmektedir.

    - Bölümün bayrakları. Bölüm hakkında diğer bazı önemli bilgiler bölüm bayrakları biçiminde belirtilmektedir. Örneğin bir 
    bölümün yükleyici tarafından dosyasının içerisinde belleğe yüklenip yüklenmeyeceği, bölümün read-only olup olmadığı gibi 
    bayraklar ilgili bölüm hakkında önemli bilgiler vermektedir.

    - Bölüm eğer yükleyici tarafından belleğe yüklenecekse sanal belleğin neresine yükleneceğine ilişkin adres bilgisi. Tabii 
    bölüm belleğe yüklenmeyecekse bu adres bilgisi kullanılmaz. Burada 0 değeri bulunur.

    - Bölümün dosyanın hangi offset'inden başladığı bilgisi.

    - Bölümün kaç byte uzunlukta olduğu bilgisi.

    - Bölümün hangi string tablosunu ya da sembol tablosunu kullandığı bilgisi.

    - Diğer bazı bilgiler.

    32 bit ELF formatında Bölüm Başlığı'nın yapısal içeriği şöyledir:

    typedef struct {
        Elf32_Word sh_name;         /* Section name */
        Elf32_Word sh_type;         /* Section type */
        Elf32_Word sh_flags;        /* Section attributes */
        Elf32_Addr sh_addr;         /* Virtual address in memory */
        Elf32_Off sh_offset;        /* Offset in file */
        Elf32_Word sh_size;         /* Size of section */
        Elf32_Word sh_link;         /* Link to other section */
        Elf32_Word sh_info;         /* Miscellaneous information */
        Elf32_Word sh_addralign;    /* Address alignment boundary */
        Elf32_Word sh_entsize;      /* Size of entries, if section has table */
    } Elf32_Shdr;

    64 bit ELF formatında ise Bölüm Başlığı'nın yapısal içeriği şöyledir:

    typedef struct
    {
        Elf64_Word sh_name;         /* Section name */
        Elf64_Word sh_type;         /* Section type */
        Elf64_Xword sh_flags;       /* Section attributes */
        Elf64_Addr sh_addr;         /* Virtual address in memory */
        Elf64_Off sh_offset;        /* Offset in file */
        Elf64_Xword sh_size;        /* Size of section */
        Elf64_Word sh_link;         /* Link to other section */
        Elf64_Word sh_info;         /* Miscellaneous information */
        Elf64_Xword sh_addralign;   /* Address alignment boundary */
        Elf64_Xword sh_entsize;     /* Size of entries, if section has table */
    } Elf64_Shdr;

    Bölüm Başlık Tablosu'ndaki Bölüm Başlıkları "readelf" programında "-S" veya "--section-headers" veya "--sections" seçenekleri 
    kullanılmaktadır. Örneğin:

    $ readelf -S sample
    There are 31 section headers, starting at offset 0x3978:

    Bölüm Başlıkları:
    [Nr] İsim              Tip              Adres             Basamak
        Boy               EntBoy           Seç    Bağ   Bilgi Hiza
    [ 0]                   NULL             0000000000000000  00000000
        0000000000000000  0000000000000000           0     0     0
    [ 1] .interp           PROGBITS         0000000000000318  00000318
        000000000000001c  0000000000000000   A       0     0     1
    [ 2] .note.gnu.propert NOTE             0000000000000338  00000338
        0000000000000020  0000000000000000   A       0     0     8
    [ 3] .note.gnu.build-i NOTE             0000000000000358  00000358
        0000000000000024  0000000000000000   A       0     0     4
    .................................................................
    [29] .strtab           STRTAB           0000000000000000  00003658
        0000000000000204  0000000000000000           0     0     1
    [30] .shstrtab         STRTAB           0000000000000000  0000385c
        000000000000011a  0000000000000000           0     0     1
    Key to Flags:
    W (write), A (alloc), X (execute), M (merge), S (strings), I (info),
    L (link order), O (extra OS processing required), G (group), T (TLS),
    C (compressed), x (unknown), o (OS specific), E (exclude),
    l (large), p (processor specific)

    Bölüm Başlık Tablosu'ndaki Bölüm Başlıkları "objdump" programı ile "-h" veya "--section-headers" veya "--headers" seçenekleriyle 
    görüntülenebilmektedir. Örneğin:

    $ objdump -h sample

    sample:     elf64-x86-64 dosya biçemi

    Bölümler:
    Idx Name          Size      VMA               LMA               File off  Algn
    0 .interp       0000001c  0000000000000318  0000000000000318  00000318  2**0
                    CONTENTS, ALLOC, LOAD, READONLY, DATA
    1 .note.gnu.property 00000020  0000000000000338  0000000000000338  00000338  2**3
                    CONTENTS, ALLOC, LOAD, READONLY, DATA
    2 .note.gnu.build-id 00000024  0000000000000358  0000000000000358  00000358  2**2
                    CONTENTS, ALLOC, LOAD, READONLY, DATA
    .................................................................................
                    CONTENTS, ALLOC, LOAD, DATA
    25 .bss          00000008  0000000000004010  0000000000004010  00003010  2**0
                    ALLOC
    26 .comment      0000002b  0000000000000000  0000000000000000  00003010  2**0
                    CONTENTS, READONLY
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    ELF formatının en önemli kısımlarından biri "sembol tablosu (symbol table)" denilen kısmıdır. Sembol (symbol) derleyici ve 
    bağlayıcı dünyasında "değişken (identifier)" anlamına gelen bir terimdir. Yani programlamada "değişken (variable/identifier)" 
    kavramı derleyici ve bağlayıcı dünyasında "sembol (symbol)" biçiminde ifade edilmektedir. Semboller fonksiyon isimleri biçiminde, 
    global değişken isimleri biçiminde olabileceği gibi başka varlıklar (entities) biçiminde de karşımıza çıkabilmektedir. Semboller 
    yalnızca isimlerden oluşmazlar sembollere ilişkin başka özellikler de vardır. İşte sembol tablolarında sembollerin isimleri 
    ve onlara ilişkin özellikler tutulmaktadır.

    Sembol tabloları bölümlerin içerisinde bulunur. ELF dosyasında tek bir sembol tablosu bulunmak zorunda değildir. Tipik olarak 
    derleyici ve bağlayıcılar iki ayrı sembol tablosu bulundurmaktadır. Program içerisindeki semboller SHT_SYMTAB bölüm türüyle, 
    dinamik kütüphanelerden kullanılan semboller SHT_DYNSYM bölüm türüyle belirtilmektedir. Sembol tablolarının bulunduğu tipik 
    bölümler şunlardır:

    .symtab         ---> Program içerisindeki sembollerin bulunduğu sembol tablosu
    .dynsym         ---> Dinamik kütüphanelerden kullanılan sembolleri bulunduğu sembol tablosu
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												14. Ders 30/04/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Sembol tabloları sembollerden oluşmaktadır. Yani sembollerden oluşan bir dizi biçimindedir. Sembollerin bilgileri eşit 
    uzunluklu kayıtlar biçimindedir. 32 bit ELF formatındaki sembol tablosunun sembollerinin yapısal içeriği şöyledir:

    typedef struct {
        Elf32_Word st_name;         /* Symbol name */
        Elf32_Addr st_value;        /* Symbol value */
        Elf32_Word st_size;         /* Size of object (e.g., common) */
        unsigned char st_info;      /* Type and Binding attributes */
        unsigned char st_other;     /* Reserved */
        Elf32_Half st_shndx;        /* Section table index */
    } Elf32_Sym;

    64 bit ELF formatındaki sembol tablosunun sembollerinin yapısal içeriği ise şöyledir:

    typedef struct {
        Elf64_Word st_name;         /* Symbol name */
        unsigned char st_info;      /* Type and Binding attributes */
        unsigned char st_other;     /* Reserved */
        Elf64_Half st_shndx;        /* Section table index */
        Elf64_Addr st_value;        /* Symbol value */
        Elf64_Xword st_size;        /* Size of object (e.g., common) */
    } Elf64_Sym;

    Sembol tabloları özellikle "amaç dosyalarda (object files)" kritik önemdedir. Aşağıdaki gibi bir C programı bulunuyor olsun:

    /* sample.c */

    #include <stdio.h>

    char g_a[1000000];
    int g_b = 20;
    int g_c = 30;
    static int g_d = 40;

    void bar(void);

    void foo(void)
    {
        printf("foo\n");
    }

    int main(void)
    {
        foo();
        bar();

        return 0;
    }

    Bu programı "-c" seçeneği ile link etmeden yalnızca derleyelim:

    $ gcc -c sample.c

    readelf programı bize sembol tablosunu her satırda bir sembol bilgisi olacak biçimde de görüntüleyebilmektedir. readelf programı
    ile yalnızca sembol tablosu görüntülenmek isteniyorsa "-s" ya da "--syms" ya da "--symbols" seçenekleri kullanılabilir. Örneğin:

    $ readelf -s sample.o

    Aynı işlem "objdump" programı ile "--syms" seçeneği kullanılarak da yapılabilir:

    $ objdump --syms sample.o

    Biz yukarıdaki amaç dosyanın bütün bilgilerini "readelf -a" seçeneği ile bir dosyaya yönlendirelim:

    $ readelf -a sample.o > sample.o.txt

    readelf programı sembol tablosundaki her sembol bilgisini bir satır olacak biçimde görüntülemektedir. Yukarıdaki C programının 
    derlenmesi sonucunda elde edilen amaç dosyanın ".symtab" isimli sembol tablosu readelf tarafından aşağıdaki gibi görüntülenmiştir:

    Symbol table '.symtab' contains 12 entries:
      Num:    Value          Size Type    Bind   Vis      Ndx Name
        0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND
        1: 0000000000000000     0 FILE    LOCAL  DEFAULT  ABS sample.c
        2: 0000000000000000     0 SECTION LOCAL  DEFAULT    1 .text
        3: 0000000000000008     4 OBJECT  LOCAL  DEFAULT    3 g_d
        4: 0000000000000000     0 SECTION LOCAL  DEFAULT    5 .rodata
        5: 0000000000000000 0xf4240 OBJECT  GLOBAL DEFAULT    4 g_a
        6: 0000000000000000     4 OBJECT  GLOBAL DEFAULT    3 g_b
        7: 0000000000000004     4 OBJECT  GLOBAL DEFAULT    3 g_c
        8: 0000000000000000    26 FUNC    GLOBAL DEFAULT    1 foo
        9: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND puts
        10: 000000000000001a    25 FUNC    GLOBAL DEFAULT    1 main
        11: 0000000000000000     0 NOTYPE  GLOBAL DEFAULT  UND bar

    Amaç dosyanın Bölüm Başlık Tablosu da şöyledir:

    Section Headers:
        [Nr] Name              Type             Address           Offset
            Size              EntSize          Flags  Link  Info  Align
        [ 0]                   NULL             0000000000000000  00000000
            0000000000000000  0000000000000000           0     0     0
        [ 1] .text             PROGBITS         0000000000000000  00000040
            0000000000000033  0000000000000000  AX       0     0     1
        [ 2] .rela.text        RELA             0000000000000000  00000278
            0000000000000060  0000000000000018   I      11     1     8
        [ 3] .data             PROGBITS         0000000000000000  00000074
            000000000000000c  0000000000000000  WA       0     0     4
        [ 4] .bss              NOBITS           0000000000000000  00000080
            00000000000f4240  0000000000000000  WA       0     0     32
        [ 5] .rodata           PROGBITS         0000000000000000  00000080
            0000000000000004  0000000000000000   A       0     0     1
        [ 6] .comment          PROGBITS         0000000000000000  00000084
            000000000000002c  0000000000000001  MS       0     0     1
        [ 7] .note.GNU-stack   PROGBITS         0000000000000000  000000b0
            0000000000000000  0000000000000000           0     0     1
        [ 8] .note.gnu.pr[...] NOTE             0000000000000000  000000b0
            0000000000000020  0000000000000000   A       0     0     8
        [ 9] .eh_frame         PROGBITS         0000000000000000  000000d0
            0000000000000058  0000000000000000   A       0     0     8
        [10] .rela.eh_frame    RELA             0000000000000000  000002d8
            0000000000000030  0000000000000018   I      11     9     8
        [11] .symtab           SYMTAB           0000000000000000  00000128
            0000000000000120  0000000000000018          12     5     8
        [12] .strtab           STRTAB           0000000000000000  00000248
            000000000000002c  0000000000000000           0     0     1
        [13] .shstrtab         STRTAB           0000000000000000  00000308
            0000000000000074  0000000000000000           0     0     1
        Key to Flags:
        W (write), A (alloc), X (execute), M (merge), S (strings), I (info),
        L (link order), O (extra OS processing required), G (group), T (TLS),
        C (compressed), x (unknown), o (OS specific), E (exclude),
        D (mbind), l (large), p (processor specific)

    Sembol tablosundaki bir sembolde şu bilgiler bulunmaktadır:

    - Sembolün İsmi: Bu isim ".strtab" isimli string tablosunda bir index belirtmektedir.

    - Sembolün Türü ve Bağlama Bilgisi: Sembolün türü onun bir "data" sembolü mü yoksa bir "fonksiyon" sembolü mü olduğunu 
    belirten bilgidir. Diğer sembol türleri ELF dokümanlarında belirtilmiştir. Sembolün bağlama bilgisi o sembolün diğer 
    modüller tarafından görünebilirliğine ilişkindir. Örneğin bir sembolün "global" olması demek başka bir modülden kullanılabilir
    olması demektir. Sembolün "local" olması demek sadece o modülde tanınabilmesi demektir. C'deki global değişkenler "global" 
    bağlama biçimine, static global değişkenler ise "local" bağlama biçimine sahiptir. Diğer bağlama biçimleri ELF dokümanlarında
    belirtilmiştir.

    - Sembolün Hangi Bölüm İçerisinde Olduğu Bilgisi: Eğer sembol ilgili modülde bir yer kaplıyorsa o sembol bir bölümün içerisindedir. 
    İşte sembol tablosunda sembolün hangi bölüm içerisinde tanımlandığı (yer kapladığı) ilgili bölümün indeksiyle belirtilmektedir. 
    Fonksiyonlar ".txt" isimli bölümde, ilkdeğer verilmiş global nesneler ".data" isimli bölümde, ilkdeğer verilmemiş global 
    değişkenler ise ".bss" isimli bölümde bulunurlar. Eğer bir sembol o modülde tanımlanmamışsa ona ilişkin bölüm bilgisi de 
    yoktur. Bu tür semboller sembol tablosunda "Undefined" olarak belirtilirler. Örneğin biz C'de başka bir modülde tanımlanmış 
    olan bir fonksiyonu prototipini belirterek çağırmış olalım. Bu fonksiyon bizim dosyamızda yer kaplamamaktadır. Sembol tablosunda 
    bu fonksiyonun ismi bulunur ancak bölüm olarak "Undefined" biçimde belirtilir. (readelf bunu "UND" olarak göstermektedir.)

    Sembolün Değeri: C'de global bir değişkene ilkdeğer verdiğimizi düşünelim. Bu ilkdeğerin de derleyici tarafından amaç 
    dosyaya bağlayıcı tarafından da çalıştırılabilen dosyaya yazılması gerekir. Böylece ilgili bölüm belleğe yüklenirken bu 
    global değişken ilkdeğeri ile birlikte belleğe yüklenecektir. İşte eğer bir modül içerisinde bir nesne tanımlanmışsa o nesne 
    bir bölümün belli bir yerindedir. Sembolün değeri ilgili nesnenin kendi bölümünün kaçıncı offset'inden başladığını belirtmektedir. 
    Global nesnelere verilen ilkdeğerler ilgili bölümün burada belirtilen offset'inde saklanmaktadır.

    Sembolün Uzunluğu: Burada ilgili nesnenin bölüm içerisinde kaç byte yer kapladığı bilgisi bulundurulmaktadır. Eğer ilgili 
    sembol o modülde tanımlanmış olan bir fonksiyon ise sembolün uzunluğu fonksiyonun kapladığı yerin byte uzunluğu olarak 
    sembol tablosuna yazılmaktadır.

    Tabii sembolün değeri ve uzunluğu ancak sembol o modülde tanımlanmış ise anlamlıdır. Örneğin prototipi belirtilmiş olan bir 
    fonksiyonu çağıralım (örneğimizdeki bar fonksiyonu). Ancak bu fonksiyon kendi modülümüzde tanımlanmış olmasın. Bu durumda
    bar sembolü için değer ve uzunluk anlamlı değildir. Burada 0 değerleri bulunur.

    Yukarıda örnek olarak verdiğimiz C programındaki g_c sembolünün sembol tablosundaki görünümüne dikkat ediniz.

    7: 0000000000000004     4 OBJECT  GLOBAL DEFAULT    3 g_c

    Buradan şu anlam çıkmaktadır: Sembol bir "data" sembolüdür. Amaç dosyanın 3 numaralı indeksteki bölümünde (".data" bölümü) yer
    kaplamaktadır. Sembol bu bölümün 4'üncü offset'inden itibaren 4 byte uzunluktadır. Sembol global bir değişkendir ve başka bir 
    modülden extern yapılırsa kullanılabilir. g_c sembolünün C programında aşağıdaki gibi bir tanımlamayla yaratılmış olduğuna 
    dikkat ediniz:

    int g_c = 30;

    İşte ".data" bölümünün 4 numaralı offset'inden başlayan 4 byte'lık "little endian" sayı 30 olacaktır. Şimdi de g_d static 
    global değişkeninin sembol tablosundaki görünümüne bakalım:

    3: 0000000000000008     4 OBJECT  LOCAL  DEFAULT    3 g_d

    Buradan şu sonuç çıkmaktadır: Burada bir "data" sembolü söz konusudur. Yine sembol amaç dosyanın ".data" bölümünde ve ".data" 
    bölümünün 8'inci offset'inden itibaren 4 byte yer kaplamaktadır. Ancak bu sembol "local" bir semboldür. Yani yalnızca
    bu modülden kullanılabilir. Başka bir modülden extern bildirimi yapılsa bile linker bu sembolün kullanılmasını engelleyecektir. 
    Bu sembolün aşağıdaki bir tanımlamayla oluşturulduğuna dikkat ediniz:

    static int g_d = 40;

    Şimdi de g_a sembolü için sembol tablosundaki bilgilere bakalım:

    5: 0000000000000000 0xf4240 OBJECT  GLOBAL DEFAULT    4 g_a

    Buradan g_a'nın bir "data" sembolü olduğunu, onun 4 numaralı bölümde bulunduğunu (".bss bölümü"), dışarıdan kullanılabileceğini
    ve 1000000 byte (0xf4240) yer kapladığını anlamaktayız. Bu sembol derleyici tarafından aşağıdaki tanımlama sonucunda 
    oluşturulmuştur:

    char g_a[100000];

    C'de ilkdeğer verilmemiş global değişkenlerin içerisinde 0 olduğunu biliyoruz. Pekiyi bu sembol için amaç dosyanın ".bss" 
    bölümünde yer fiziksel olarak ayrılmış mıdır? Buradaki 1000000 byte'ın hepsi 0 olduğuna göre bunun amaç dosyada ve çalıştırılabilen 
    dosyada yer ayrılması gereksizdir. ".bss" bölümünün Bölüm Başlık Tablosu'ndaki bilgilerine dikkat ediniz:

    [ 4] .bss              NOBITS           0000000000000000  00000080
        00000000000f4240  0000000000000000  WA       0     0     32

    Burada bu bölümün 1000000 byte yer kapladığı belirtilmiştir. Ancak bölüm türü olarak SHT_NOBITS kullanılmıştır. Bu bölüm 
    türü bu bölümün amaç dosyada (ya da çalıştırılabilir dosyada) yer kaplamayacağı anlamına gelmektedir. O halde biz g_a 
    sembolünden şunu anlamalıyız: Bu sembol 1000000 byte'lık bir alan belirtiyorsa da içi 0 olduğu için gereksiz bir biçimde 
    amaç dosyada bunun için yer ayrılmamıştır. O halde C'de ilkdeğer verilmemiş global nesnelerin sıfırlanması amaç dosya ya da 
    çalıştırılabilir dosya içerisinde derleyici ya da bağlayıcı tarafından değil, onu belleğe yükleyen yükleyici tarafından 
    yapılmaktadır.

    Pekiyi aşağıdaki gibi bir tanımlama yapılsaydı derleyici bu sembolü amaç dosyanın ".bss" bölümüne mi ".data" bölümüne mi
    yerleştirirdi?

    char g_a[100000] = {1};

    Burada C kurallarına göre bu dizinin ilk elemanı 1 diğer tüm elemanları 0 olmalıdır. Eğer derleyici bu sembolü ".bss" 
    bölümüne yerleştirirse bu bölüm yükleyici tarafından sıfırlanacağı için 1 değeri kaybolacaktır. Eğer derleyici bu sembolü 
    ".data" bölümüne yerleştirse amaç dosyada 999999 tane 0 olan byte bulunacaktır. Aslında burada ne olacağını dosyayı derleyip 
    amaç dosyanın uzunluğuna bakarak hemen anlayabilirsiniz. UNIX/Linux sistemlerinde derleyiciler tipik olarak böylesi bir 
    durumda ellerinden bir şey gelmediği için sembolü ".data" bölümüne yerleştirip amaç dosyayı mecburen büyütmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												15. Ders 02/05/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Derleyicilerin "amaç dosya (object file)" oluşturduğunu bu amaç dosyaların linker tarafından birleştirilerek çalıştırılabilir
    bir dosya haline getirildiğini anımsayınız. Pekiyi derleyici üreteceği makine kodlarındaki nesne ve fonksiyon adreslerini nasıl 
    belirlemektedir? Çünkü derleme aşamasında henüz amaç dosyalar birleştirilmemiş ve program belleğe yüklenmemiştir. Örneğin 
    aşağıdaki gibi "a.c" ve "b.c" programları bulunuyor olsun:

    // a.c

    #include <stdio.h>

    void foo(void);
    int g_a;

    int main(void)
    {
        g_a = 10;
        foo();

        return 0;
    }

    // b.c

    extern int g_a;

    void foo(void)
    {
        printf("%d\n", g_a);
    }

    Derleyicimizin 32 bit Intel kodu üreteceğini varsayalım. Şimdi "a.c" dosyasındaki foo çağrımına dikkat ediniz:

    foo();

    Derleyici bu çağrı için Intel işlemcilerinde CALL makine komutu üretecektir. CALL makine komutunun operand'ı call edilecek
    fonksiyonun bellekteki başlangıç adresini almaktadır. Yani CALL makine komutu aşağıdaki gibi bir komuttur:

    CALL <adres>

    Ancak derleyici derleme sırasında foo fonksiyonunun adresini bilmemektedir. Çünkü foo fonksiyonu "b.c" dosyasında tanımlanmıştır. 
    Bu durumda derleyici CALL makine komutunun operand'ına hangi adresi yazacaktır? İşte henüz bilinmeyen bellek adreslerinin sonraki 
    aşamada başka bir program tarafından düzeltilmesine "relocation işlemi", henüz bilinmeyen adreslere de (foo için üretilen CALL 
    makine komutunda olduğu gibi) "relocatable adresler" denilmektedir. Derleyiciler bu tür durumlarda henüz bilmedikleri adresleri 
    boş bırakırlar (tipik olarak o adresler yerine 0 yerleştirirler).

    Pekiyi derleyiciler tarafından oluşturulan bu relocatable adresleri kim ve nasıl düzeltmektedir? İşte bugünkü modern ve gelişmiş 
    işlemcilerin kullanıldığı sistemlerde ileride de açıklanacağı gibi program belli bir adresten itibaren sanal belleğe yüklenecekmiş 
    gibi kod üretilmektedir. Yani link aşamasından geçmiş olan bir program eğer öngörülen adresten itibaren yüklenirse (bu konuda 
    ayrıntılar vardır) sorunsuz çalışabilmektedir. (Tabii şimdi programın belli bir adresten itibaren yükleneceğinin garantisinin nasıl 
    verilebildiğini merak edebilirsiniz. Bu durum bazı konular ele alındıktan sonra anlaşılacaktır.) Ancak şimdilik biz çalıştırılabilen 
    programların belli bir adresten itibaren yüklenecek biçimde oluşturulduğunu varsayalım. Derleyici programın hangi adresten itibaren 
    belleğe yükleneceğini bilse bile yukarıdaki CALL komutunun adres operand'ını derleme aşamasında oluşturamaz. Çünkü linker başka 
    modüllerdeki kod ve verileri de çalıştırılabilen dosyaya yazmaktadır. Bu yüzden derleyici yukarıdaki foo çağrısında CALL makine 
    komutundaki adresi boş bırakmaktadır.

    Pekiyi bu CALL makine komutundaki adresi kim doğru biçimde tespit edebilir? İşte linker farklı amaç dosyaların bölümlerini 
    çalıştırılabilir dosyada bir araya getirmektedir. Linker eğer programın nereye yükleneceğini biliyorsa buradaki adresi düzeltebilir. 
    Çünkü linker link işlemi sırasında zaten bu foo fonksiyonunu diğer amaç dosyalarda arayacak, foo fonksiyonunun o amaç dosyanın 
    hangi bölümünde ve o bölümün kaçıncı offset'inde olduğunu tespit edebilecektir. Çalıştırılabilir dosyanın nereye yükleneceği de belli 
    olduğuna göre linker artık foo fonksiyonunun program çalışırkenki gerçek bellek adresini hesaplayabilecektir. Yani eğer linker 
    programın sanal belleğe hangi adresten itibaren yükleneceğini biliyorsa CALL komutundaki adresi doğru bir biçimde düzeltebilecektir.
    Burada ELF formatında "Program Başlık Tablosu (Program Header Table)" denilen tablo ile ilgili bazı ayrıntılar vardır. Ancak biz 
    burada kabaca linker'ın foo çağrısı için oluşturulan CALL makine komutundaki adresi nasıl düzelttiğini aşama aşama anlatalım:

    1) ELF formatında amaç dosyada nerelerin düzeltileceğini belirten "relocation tablosu" denilen bir tablo bulunmaktadır. Linker 
    "a.o" dosyasının "relocation tablosunu" incelediğinde orada "foo" isimli bir fonksiyonun yerinin tespit edilmesi gerektiğini 
    ve bu tespit yapıldıktan sonra da "a.o" içerisinde nerenin değiştirilmesi gerektiğini anlamaktadır. (Başka bir deyişle linker 
    "a.o" dosyasındaki relocation tablosundan "hangi sembolün nihai adresinin nereye yazılması gerektiğini" anlamaktadır.) Yani adeta 
    "a.o" dosyasının relocation tablosu foo çağrımı için linker'a şunları söylemektedir: "Git diğer modüllerde "foo" isimli fonksiyonu 
    bul, birleştirme sonucunda onun nihai adresini tespit et ve kodun şu kısmını düzelt".

    2) Linker "a.o" dosyasının relocation tablosunda belirtilen "foo" fonksiyonunu diğer modüllerin sembol tablolarında arar. Bizim 
    örneğimizde bu sembol "b.o" dosyasının sembol tablosunda bulunacaktır. (Sembol tablosunda ilgili sembolün hangi bölümün (section) 
    kaçıncı offset'inde olduğu belirtiliyordu.) Linker "a.o" ve "b.o" dosyalarının bölümlerini çalıştırılabilir dosyada birleştirdiğinde 
    artık foo fonksiyonunun hangi adreste olduğunu da tespit edebilmektedir. Linker'lar eğer aranan sembol birden fazla amaç dosyada 
    bulunursa bu durumda error oluşturmaktadır. Tabii aranan sembol hiçbir amaç dosyada bulunamazsa yine error oluşturmaktadır.

    Yukarıdaki örnekte "a.c" dosyası içerisinde main fonksiyonunda g_a global değişkeni aşağıdaki gibi kullanılmıştır:

    g_a = 10;

    Bu ifadenin kodunun derleyici tarafından üretilebilmesi için yine g_a global değişkeninin adresinin biliniyor olması gerekmektedir. 
    Örneğin Intel işlemcilerinde bu işlem aşağıdaki gibi bir makine koduyla yapılabilmektedir:

    mov [<g_a'nın adresi>], 10

    Pekiyi derleyici g_a global değişkeninin adresini derleme sırasında bilmekte midir? Burada her ne kadar g_a aynı modülde tanımlanmış 
    olsa da derleyici yine bu nesnenin bellek adresini derleme zamanında tespit edemeyecektir. Çünkü linker'ın diğer modüllerle birleştirme 
    yapması sonucunda bu global nesnenin adresi değişmiş olacaktır. O halde buradaki g_a nesnesinin adresi de "relocatable" bir adrestir. 
    Bu adres de derleyici tarafından boş bırakılır ve relocation tablosunda belirtilir. Linker bu adresin de nihai değerini tespit edip 
    kodda ilgili yeri düzeltir.

    Pekiyi yerel nesnelerin adresleri de relocatable adresler midir? Hayır yerel nesnelerin yerleri o fonksiyonda stack göstericisine 
    (stack pointer) göreli uzaklıkla tespit edilebilmektedir. Yani yerel nesnelerin adresleri derleme sırasında derleyici tarafından 
    göreli bir biçimde tespit edilebilmektedir.

    Pekiyi çalıştırılabilir bir dosya bellekte eğer yüklenmesi gereken yere yüklenemezse, başka yere yüklenirse ne olur? Linker
    nihai adresleri çalıştırılabilir dosyanın belli bir adresten itibaren yükleneceği fikriyle oluşturmaktadır. Eğer dosya bellekte 
    başka bir yere yüklenirse program düzgün çalışmayacaktır.

    Relocation işlemi aslında yalnızca linker tarafından değil yükleyici tarafından da yapılabilmektedir. İşte bazı sistemlerde 
    çalıştırılabilir programlar için de relocation tabloları oluşturulabilmektedir. Böylece yükleyici programı başka bir adresten 
    itibaren yüklerse bu relocation tablosundan hareketle dosya içerisindeki adresleri de düzeltebilmektedir. Yani amaç dosya 
    içerisindeki relocation tablosu "linker" için, çalıştırılabilir dosyadaki relocation tablosu "yükleyici" için düzeltme bilgilerini
    bulundurmaktadır. Yukarıda da belirttiğimiz gibi genellikle çalıştırılabilir dosyaların sanal belleğin neresine yükleneceği 
    bilinmektedir. Ancak dinamik kütüphanelerin belleğin neresine yükleneceği önceden belirlenememektedir. Linker için relocation 
    tablosunun derleyici tarafından, yükleyici için relocation tablosunun ise linker tarafından oluşturulduğuna dikkat ediniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirtildiği gibi yerel nesnelerin (yani fonksiyonlar içerisinde tanımlanmış nesnelerin) relocation işlemi ile 
    bir ilgisi yoktur. Yerel nesnelerin yerleri ismine "Stack Pointer (SP)" denilen bir yazmaca göreli bir biçimde tespit 
    edilmektedir. "Stack" oldukça zekice düşünülmüş çok pratik bir kullanıma sahip bir kavramdır. Aşağıdaki gibi bir C fonksiyonu 
    olsun:

    void foo(void)
    {
        int a = 10;
        int b = 20;
        int c;

        c = a + b;
        ...
    }

    Derleyici fonksiyonun başında makine komutuyla SP yazmacını fonksiyonun yerel değişkenlerinin toplam uzunluğu kadar yukarı çeker 
    (yani azaltır):

    Yeni SP'nin gösterdiği yer  ----->
    ...
    Eski SP'nin gösterdiği yer  ----->

    Sonra yerel nesneleri SP'nin bulunduğu yere göreli bir biçimde konumlandırır:

    Yeni SP'nin gösterdiği yer  ----->
                                            a
                                            b
                                            c
    Eski SP'nin gösterdiği yer  ----->

    Artık makine kodlarını SP'nin bulunduğu yere göreli bir biçimde oluşturmaktadır. Örneğin 32 bit Intel işlemcileri için aşağıda
    sembolik bir kod örneği verilmiştir:

    SUB     ESP, 12                 ; SP yazmacı fonksiyonun yerel değişkenlerinin toplam uzunluğu kadar yukarı çekilir (yani azaltılır)
    MOV     [ESP + 0], 10           ; a = 10
    MOV     [ESP + 4], 20           ; b = 20
    MOV     EAX, [ESP + 0]          ; a değeri EAX yazmacına yükledi
    ADD     EAX, [ESP + 4]          ; a ile b'yi topladı, sonuç EAX yazmacında
    MOV     [ESP + 8], EAX          ; toplam c'ye atanıyor
    ...
    ADD     ESP, 12                 ; ESP'yi eski değerine çekiyor

    Burada dikkat edilecek bir nokta yerel nesnelerin adreslerinin yalnızca o fonksiyon tarafından bilinebileceğidir. Bu nedenle
    yerel nesneler yalnızca o fonksiyon içerisinde kullanılabilmektedir. Global değişkenlerin adresleri bir yazmaca göreli değil, 
    mutlak olarak belirlendiği için onlar her fonksiyondan kullanılabilmektedir.

    Ayrıca buradan yerel nesnelerin içerisinde neden çöp değer olduğu da anlaşılmaktadır. SP yazmacı sürekli yukarı aşağı gittiği için 
    stack'teki değerler de çöp değerler haline gelmektedir. Yerel nesneler SP yazmacının yukarı çekilmesiyle bir hamlede yaratılmaktadır. 
    Oradaki değerler de daha önceki rastgele stack değerlerinden oluşmaktadır. Derleyicinin yerel nesneleri sıfırlaması da uygun 
    değildir. Çünkü bu sıfırlama işlemi ancak makine komutlarıyla yapılabilir. Bu da programı yavaşlatacaktır. Oysa global nesnelerin 
    sıfırlanması program çalışırken değil yüklenirken yalnızca bir kez yapılmaktadır.

    Yerel nesnelerin çok hızlı yaratılıp (tek bir makine komutuyla), çok hızlı yok edildiğine (tek bir makine komutuyla) de dikkat
    ediniz. C'de yerel değişkenlere "otomatik değişkenler" de denilmektedir.

    Pekiyi iç içe çok fazla fonksiyon çağrılırsa ne olur? İşte bu durumda her fonksiyon SP yazmacını bir miktar yukarı çekeceğine 
    göre ve stack için belli bir alan ayrıldığına göre stack yukarıdan taşabilmektedir. Bu yukarıdan taşmaya İngilizce "stack 
    overflow" da denilmektedir. Bu tür durumlarda muhtemelen program çökecektir. Windows sistemlerinde thread'lerin default stack 
    büyüklüğü 1 MB, Linux sistemlerinde ise 8 MB kadardır. Bu stack miktarları küçük değildir. Ancak programcı büyük dizileri 
    yerel dizi olarak yaratırken dikkat etmelidir. Büyük dizilerin yerel olarak yaratılması stack'i taşırabilir. Bunların static 
    yerel ya da global tanımlanması uygundur. Stack alanı ".data" ve ".bss" alanlarına göre çok küçük bir alandır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    ELF formatının relocation tablosu SHT_REL ya da SHT_RELA bölüm türüyle belirtilen bölümler içerisinde bulunmaktadır. Tipik 
    olarak derleyiciler relocation işlemi hangi bölüm ile ilgiliyse relocation bilgilerini ".rel<isim>" ya da ".rela<isim>" 
    ismindeki bölümlere yerleştirmektedir. Örneğin yukarıdaki "a.c" dosyası derlendiğinde relocation tablosu da ".rela.text" 
    isimli bölümde bulunacaktır. 32 bit ELF formatında relocation bölümlerinin içerisindeki her relocation bilgisi aşağıdaki 
    yapılar ile temsil edilmektedir:

    typedef struct {
        Elf32_Addr r_offset;            /* Address of reference */
        Elf32_Word r_info;              /* Symbol index and type of relocation */
    } Elf32_Rel;

    typedef struct {
        Elf32_Addr r_offset;            /* Address of reference */
        Elf32_Word r_info;              /* Symbol index and type of relocation */
        Elf32_Sword r_addend;           /* Constant part of expression */
    } Elf32_Rela;

    64 bit ELF formatında da bu yapılar şöyledir:

    typedef struct {
        Elf64_Addr r_offset;            /* Address of reference */
        Elf64_Xword r_info;             /* Symbol index and type of relocation */
    } Elf64_Rel;

    typedef struct {
        Elf64_Addr r_offset;            /* Address of reference */
        Elf64_Xword r_info;             /* Symbol index and type of relocation */
        Elf64_Sxword r_addend;          /* Constant part of expression */
    } Elf64_Rela;

    SHT_REL bölüm türüyle belirtilen bölümün yapısı ile SHT_RELA bölüm türüyle belirtilen bölümün yapısının birbirinden farklı
    olduğuna dikkat ediniz. Bu yapılardaki r_offset elemanı linker'ın ya da yükleyicinin düzelteceği yeri belirtmektedir. 
    Burada relocation uygulanacak yer hangi bölümdeyse o bölümün başından itibaren bir offset bilgisi ya da sanal bellek adresi
    tutulmaktadır. Böylece linker ya da yükleyici dosyanın neresini düzelteceğini anlamaktadır. Yapıların r_info elemanları 
    kendi içerisinde iki parçaya ayrılmaktadır. Bu elemanın yüksek anlamlı 4 byte'ı düzeltilecek yere ilişkin sembolün sembol 
    tablosundaki indeksini (byte offset'ini değil sembolün indeksini), düşük anlamlı 4 byte ise düzeltme türünü (relocation type) 
    belirtmektedir. Düzeltme türü platforma göre farklılıklar gösterebilmektedir. Yapılardaki r_addend elemanı ayrıntı içermektedir. 
    Burada ele almayacağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												16. Ders 07/05/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    ELF formatının diğer önemli bir bölümü de "Program Başlık Tablosu (Program Header Table)" denilen bölümüdür. Program Başlık 
    Tablosu eşit uzunlukta Program Başlıkları'ndan (Program Header Table Entry) oluşmaktadır. Program Başlık Tablosu'nun ELF 
    dosyasında nereden başladığı ve hangi uzunlukta olduğu ELF Başlığı'nda belirtilmektedir. Program Başlık Tablosu amaç dosyalarda 
    değil, "çalıştırılabilen dosyalarda ve dinamik kütüphane dosyalarında" bulunmaktadır. İşletim sistemi çalıştırılabilen dosyayı
    ya da dinamik kütüphane dosyasını bölüm bölüm değil, segment segment yüklemektedir. Bir segment aynı özelliğe sahip peşi sıra
    giden bölümlerden oluşmaktadır. Program Başlık Tablosu'ndaki her Program Başlığı bir segment hakkında bilgi vermektedir. 
    Şimdi aklınıza bölümler varken neden segment'lere gereksinim duyulmuştur sorusu gelebilir? Bölümler daha çok linker için, 
    segment'ler ise yükleyici için düşünülmüştür. Dosyada benzer özelliklere sahip bölümler segment ismiyle bir araya getirilmektedir. 
    Böylece işletim sistemi (exec fonksiyonları) bu segment'leri yüklemektedir.

    Program Başlık Tablosu'ndaki Program Başlıkları'nın 32 bit ELF formatındaki yapısal biçimi şöyledir:

    typedef struct {
        Elf32_Word p_type;          /* Type of segment */
        Elf32_Off p_offset;         /* Offset in file */
        Elf32_Addr p_vaddr;         /* Virtual address in memory */
        Elf32_Addr p_paddr;         /* Reserved */
        Elf32_Word p_filesz;        /* Size of segment in file */
        Elf32_Word p_memsz;         /* Size of segment in memory */
        Elf32_Word p_flags;         /* Segment attributes */
        Elf32_Word p_align;         /* Alignment of segment */
    } Elf32_Phdr;

    Program Başlık Tablosu'ndaki Program Başlıkları'nın 64 bit ELF formatındaki yapısal biçimi şöyledir:

    typedef struct {
        Elf64_Word p_type;          /* Type of segment */
        Elf64_Word p_flags;         /* Segment attributes */
        Elf64_Off p_offset;         /* Offset in file */
        Elf64_Addr p_vaddr;         /* Virtual address in memory */
        Elf64_Addr p_paddr;         /* Reserved */
        Elf64_Xword p_filesz;       /* Size of segment in file */
        Elf64_Xword p_memsz;        /* Size of segment in memory */
        Elf64_Xword p_align;        /* Alignment of segment */
    } Elf64_Phdr;

    Program Başlığı'nda şu bilgiler yer almaktadır:

    - Başlığın Türü: Burada PT_LOAD ilgili segment'in belleğe yüklenmesi gerektiği anlamına gelmektedir. Her ne kadar yukarıda 
    Program Başlık Tablosu'nun bellek yüklenecek segment'leri belirttiğini söylemiş olsak da belleğe yüklenmeyen ancak ilgili 
    dosyanın yüklenmesinde kullanılacak bazı bilgiler de Program Başlık Tablosu'nda birer segment olarak bulunmaktadır. 
    Yüklenecek olan segment'lerin türü PT_LOAD biçiminde belirtilmektedir.

    - Segment'in Koruma Bayrakları: İleride ele alınacağı gibi Sayfalama (paging) mekanizmasına sahip olan işlemcilerde RAM 
    sayfalardan (pages) oluşmaktadır. Sayfalara koruma bayrakları iliştirilebilmektedir. Örneğin bir sayfanın koruma bayrağı 
    "Read Only" ise işlemci bu sayfaya yazma yapamaz. Eğer işlemci böyle bir sayfaya yazma yapmaya çalışırsa içsel bir kesme 
    oluşur (page fault) ve program çöker. Bir sayfada bir kodun çalıştırılabilmesi için sayfa koruma bayraklarının "Executable"
    olması gerekir. Aksi takdirde o sayfadaki bir fonksiyonu CALL makine komutlarıyla çağıramayız. Pek çok işlemcide sayfanın 
    "Write" özelliğine sahip olması aynı zamanda "Read" özelliğine de sahip olması anlamına gelmektedir. Ancak linker programları
    bunları ayrı ayrı belirtmektedir.

    - Segment'in ELF Dosyasındaki Başlangıç Offset'i ve Uzunluğu: Yükleyicinin segment'i belleğe yükleyebilmesi için dosyanın 
    neresinden başladığını ve hangi uzunlukta olduğunu bilmesi gerekir.

    - Segment'in Bellekteki Uzunluğu: İlkdeğer verilmemiş global değişkenler ELF dosyalarının içerisinde yer kaplamamaktadır. 
    Ancak bunlar için de bellekte yer ayrılmalıdır. O halde bir segment belleğe yüklenirken bellekte ne kadar yer tahsis edileceği
    de bilinmelidir. Tabii linker ilkdeğer verilmemiş global değişkenlerin bulunduğu bölümleri (tipik olarak .bss) segment'in 
    sonuna almaktadır. Böylece yükleyici dosyada belirtilen uzunluktaki kısmı bellekte tahsis ettiği alanın başından itibaren 
    yükleyebilir.

    Segment'in Sanal Belleğe Yüklenme Adresi: Linker programın belli bir adresten itibaren yükleneceği varsayımıyla kodu düzeltmektedir.
    İşte her segment'in sanal belleğin neresinden itibaren yükleneceği Program Başlığı'nda belirtilmektedir. Ancak segment yükleyici 
    tarafından bu adrese yüklenmeyebilir. Bu durumda yükleyici "relocation" işlemi uygulayacaktır. Yani linker modüllerdeki kodu
    belli bir adresten itibaren yüklenecekmiş gibi oluşturmaktadır. Ancak yükleyici eğer onu başka bir yere yükleyecekse "relocation"
    işlemi uygulamak zorundadır.

    Çalışmakta olan programın sanal bellek alanına map edilen segment'ler proc dosya sisteminden /proc/<proses_id>/maps 
    dosyasının içerisinden görülebilir.

    readelf programında ELF dosyasının Program Başlık Tablosu "-l" seçeneği ile objdump programı ile de "-p" ya da "--program-headers" 
    seçeneği ile görüntülenebilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi biz basit bir yükleyici program yazmak istesek bunu nasıl yazabiliriz? Aslında yükleyiciler burada henüz ele almadığımız
    bazı ayrıntılı işlemleri de yapmaktadır. Ancak kabaca bunu gerçekleştirebilmek için ELF dosya formatını parse edip Program 
    Başlık Tablosu'ndaki PT_LOAD ile belirtilen segment'leri belirtilen sanal bellek adresine mmap fonksiyonu ile yüklenmesi gerekir.
    Tabii yükleme işlemi bittikten sonra programın ELF dosyasının başlık kısmında belirtilen "entry point"den başlatılması gerekir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    ELF formatının diğer önemli bir bölümü de ".dynamic" isimli bölümüdür. Bu bölüm ".dynsym" bölümüyle birlikte kullanılmaktadır. 
    Bu bölümün işlevini anlayabilmek için dinamik kütüphanelerin nasıl yüklendiğinin bilinmesi gerekir. Biz önce statik ve 
    dinamik kütüphaneleri ele alıp ondan sonra ELF formatının bu bölümlerini açıklayacağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Kütüphane "hazır kodların bulunduğu topluluklar" için kullanılan bir terimdir. Ancak aşağı seviyeli dünyada kütüphane 
    kavramı daha farklı bir biçimde kullanılmaktadır. Aşağı seviyeli dünyada "içerisinde derlenmiş bir biçimde fonksiyonların 
    bulunduğu dosyalara kütüphane (library)" denilmektedir. Aslında kütüphaneler yalnızca fonksiyon değil, global nesneler 
    de içerebilmektedir.

    Kütüphaneler "statik" ve "dinamik" olmak üzere ikiye ayrılmaktadır. Statik kütüphane dosyalarının uzantıları UNIX/Linux 
    sistemlerinde ".a (archive)" biçiminde, Windows sistemlerinde ".lib (library)" biçimindedir. Dinamik kütüphane dosyalarının 
    uzantıları ise UNIX/Linux sistemlerinde ".so (shared object), Windows sistemlerinde ".dll (dynamic link library)" biçimindedir. 
    UNIX/Linux dünyasında kütüphane dosyaları geleneksel olarak başında "lib" öneki olacak biçimde isimlendirilmektedir. (Örneğin 
    "x" isimli bir statik kütüphane dosyası UNIX/Linux sistemlerinde genellikle "libx.a" biçiminde, "x" isimli bir dinamik kütüphane 
    dosyası ise UNIX/Linux sistemlerinde genellikle "libx.so" biçiminde isimlendirilmektedir.)
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Statik kütüphaneler aslında "object modülleri (yani .o dosyalarını)" tutan birer kap gibidir. Yani statik kütüphaneler object
    modüllerden oluşmaktadır. Statik kütüphanelere link aşamasında linker tarafından bakılır. Bir program statik kütüphane dosyasından 
    bir çağırma yaptıysa (ya da o kütüphaneden bir global değişkeni kullandıysa) linker o statik kütüphane içerisinde ilgili 
    fonksiyonun bulunduğu object modülü link aşamasında statik kütüphane dosyasından çekerek çalıştırılabilir dosyaya yazar. 
    (Yani statik kütüphaneden bir tek fonksiyon çağırsak bile aslında o fonksiyonun bulunduğu object modülün tamamı çalıştırılabilen 
    dosyaya yazılmaktadır.) Statik kütüphaneleri kullanan programlar artık o statik kütüphaneler olmadan çalıştırılabilirler.

    Statik kütüphane kullanımının şu dezavantajları vardır:

    1) Kütüphaneyi kullanan farklı programlar aynı fonksiyonun (onun bulunduğu object modülün) bir kopyasını çalıştırılabilir dosya 
    içerisinde bulundururlar. Yani örneğin printf fonksiyonu statik kütüphanede ise her printf kullanan C programı aslında printf 
    fonksiyonunun bir kopyasını da barındırıyor durumda olur. Bu da programların diskte fazla yer kaplamasına yol açacaktır.

    2) Aynı statik kütüphaneyi kullanan programlar belleğe yüklenirken işletim sistemi aynı kütüphane kodlarınını yeniden fiziksel 
    belleğe yükleyecektir. İşletim sistemi bu kodların ortak olarak kullanıldığını anlayamamaktadır.

    3) Statik kütüphanede bir değişiklik yapıldığında onu kullanan programların yeniden link edilmesi gerekir.

    Statik kütüphane kullanımının şu avantajları vardır:

    1) Kolay konuşlandırılabilirler. Statik kütüphane kullanan bir programın yüklenmesi için başka dosyalara gereksinim 
    duyulmamaktadır.

    2) Statik kütüphanelerin kullanımları kolaydır, statik kütüphane kullanan programlar için daha kolay build ya da make işlemi 
    yapılabilmektedir.

    3) Statik kütüphane kullanan programların yüklenmesi dinamik kütüphane kullanan programların yüklenmesinden çoğu kez daha hızlı
    yapılmaktadır. Ancak bu durum çeşitli koşullara göre tam ters bir hale de gelebilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    UNIX/Linux sistemlerinde statik kütüphane dosyaları üzerinde işlemler "ar" isimli utility program yoluyla yapılmaktadır. 
    ar programına önce bir seçenek, sonra statik kütüphane dosyasının ismi, sonra da bir ya da birden fazla object modül ismi komut
    satırı argümanı olarak verilir. Örneğin:

    $ ar r libmyutil.a x.o y.o

    Burada r seçeneği belirtmektedir. ar eski bir komut olduğu için burada seçenekler '-' ile başlatılarak verilmemektedir. Komuttaki
    "libmyutil.a" işlemden etkilenecek statik kütüphane dosyasını "x.o" ve "y.o" argümanları ise object modülleri belirtmektedir. 
    Tipik ar seçenekleri ve yaptıkları işler şunlardır:

    r (replace) seçeneği (yanında "-" olmadığına dikkat ediniz) ilgili object modüllerin kütüphaneye yerleştirilmesini sağlar. 
    Eğer kütüphane dosyası yoksa komut aynı zamanda onu yaratmaktadır. Örneğin:

    $ ar r libmyutil.a x.o y.o

    Burada "libmyutil.a" statik kütüphane dosyasına "x.o" ve "y.o" object modülleri yerleştirilmiştir. Eğer "libmyutil.a" dosyası
    yoksa aynı zamanda bu dosya yaratılacaktır.

    t seçeneği kütüphane içerisindeki object modüllerin listesini almakta kullanılır. Örneğin:

    $ ar t libsample.a

    d (delete) seçeneği kütüphaneden bir object modülü silmekte kullanılır. Örneğin:

    $ ar d libmyutil.a x.o

    x (extract) seçeneği kütüphane içerisindeki object modülü bir dosya biçiminde diske save etmekte kullanılır. Ancak bu object 
    modül kütüphane dosyasından silinmeyecektir. Örneğin:

    $ ar x libmyutil.a x.o

    m (modify) seçeneği de bir object modülün yeni versiyonunu eski versiyonla değiştirmekte kullanılır.

    O halde "x.c" ve "y.c" dosyalarının içerisindeki fonksiyonları statik kütüphane dosyasına eklemek için sırasıyla şunlar
    yapılmalıdır:

    $ gcc -c x.c
    $ gcc -c y.c
    $ ar r libmyutil.a x.o y.o
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Statik kütüphane kullanan programları derlerken statik kütüphane dosyaları komut satırında belirtilebilir. Bu durumda gcc 
    ve clang derleyicileri o dosyayı bağlama (link) işleminde kullanmaktadır. Örneğin:

    $ gcc -o app app.c libmyutil.a

    Burada "libmyutil.a" dosyasına C derleyicisi bakmamaktadır. gcc aslında bu dosyayı bağlayıcıya (linker) iletmektedir. Biz bu 
    işlemi iki adımda da yapabilirdik:

    $ gcc -c app.c
    $ gcc -o app app.o libmyutil.a

    Her ne kadar GNU'nun bağlayıcı programı aslında "ld" isimli programsa da genellikle programcılar bu ld bağlayıcısını doğrudan 
    değil yukarıdaki gibi gcc yoluyla kullanırlar. Çünkü ld bağlayıcısını kullanılırken "libc" kütüphanesinin start-up amaç dosyaların
    (start-up object modules) programcı tarafından ld bağlayıcısına verilmesi gerekmektedir. Bu da oldukça sıkıcı bir işlemdir. 
    Halbuki biz ld bağlayıcısını gcc yoluyla çalıştırdığımızda libc kütüphanesi ve bu start-up amaç dosyalar ld bağlayıcısına gcc 
    tarafından verilmektedir.

    gcc eskiden C derleyicisi anlamına geliyordu (GNU C Compiler). Ancak zamanla derleyicileri çalıştıran bir önyüz (front-end) 
    program haline getirildi ve ismi de "GNU Compiler Collection" biçiminde değiştirildi. Yani aslında uzunca bir süredir gcc 
    programı ile yalnızca C programlarını değil, diğer programlama dillerinde yazılmış olan programları da derleyebilmekteyiz.

    Komut satırında kütüphane dosyalarının komut satırı argümanlarının sonunda belirtilmesi uygundur. Çünkü gcc programı kütüphane 
    dosyalarını yalnızca onların solunda belirtilen dosyaların bağlanmasında kullanmaktadır. Örneğin:

    $ gcc -o app app1.o libmyutil.a app2.o

    Böylesi bir kullanımda "libmyutil.a" kütüphanesinin solunda yalnızca "app1.o" dosyası vardır. Dolayısıyla bağlayıcı yalnızca 
    bu modül için bu kütüphaneye bakacaktır, "app2.o" için bu kütüphaneye bakılmayacaktır.

    Şüphesiz statik kütüphane kullanmak yerine aslında amaç dosyaları da doğrudan bağlama işlemine sokabiliriz. Örneğin:

    $ gcc -o sample sample.c x.o y.o

    Ancak çok sayıda object modül söz konusu olduğunda bu işlemin zorlaşacağına dikkat ediniz. Yani amaç dosyalar (object modules) 
    dosyalara benzetilirse statik kütüphane dosyaları dizinler gibi düşünülebilir.

    Derleme işlemi sırasında kütüphane dosyası -l<isim> biçiminde de belirtilebilir. Bu durumda arama sırasında "lib" öneki 
    ve ".a" uzantısı aramaya dahil edilmektedir. Yani örneğin:

    $ gcc -o sample sample.c -lmyutil

    İşleminde aslında "libmyutil.a" (ya da "libmyutil.so") dosyaları aranmaktadır. Arama işlemi sırasıyla bazı dizinlerde yapılmaktadır. 
    Örneğin "/lib" dizini, "/usr/lib dizini", "/usr/local/lib" dizini gibi dizinlere bakılmaktadır. Ancak "bulunulan dizine (current 
    working directory)" bakılmamaktadır. -l seçeneği ile belli bir dizine de bakılması isteniyorsa "-L" seçeneği ile ilgili dizin 
    belirtilebilir. Örneğin:

    $ gcc -o sample sample.c -lmyutil -L.

    Buradaki '.' çalışma dizinini temsil etmektedir. Artık "libmyutil.a" kütüphanesi için bulunulan dizine de (current working 
    directory) bakılacaktır. Birden fazla dizin için -L seçeneğinin yinelenmesi gerekmektedir. Örneğin:

    $ gcc -o sample sample.c -lmyutil -L. -L/home/csd

    Geleneksel olarak "-l" ve "-L" seçeneklerinden sonra boşluk bırakılmamaktadır. Ancak boşluk bırakılmasında bir sakınca yoktur.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bir statik kütüphane başka bir statik kütüphaneye bağımlı olabilir. Örneğin biz "liby.a" kütüphanesindeki kodda "libx.a" 
    kütüphanesindeki fonksiyonları kullanmış olabiliriz. Bu durumda "liby.a" kütüphanesini kullanan program "libx.a" kütüphanesini
    de komut satırında belirtmek zorundadır. Örneğin:

    $ gcc -o sample sample.c libx.a liby.a
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												17. Ders 09/05/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Dinamik kütüphane dosyalarının UNIX/Linux sistemlerinde uzantıları ".so" (shared object'ten kısaltma), Windows sistemlerinde 
    ise ".dll" (Dynamic Link Library) biçimindedir.

    Bir dinamik kütüphaneden bir fonksiyon çağrıldığında linker statik kütüphanede olduğu gibi gidip fonksiyonun kodunu (fonksiyonun 
    bulunduğu amaç dosyayı) çalıştırılabilen dosyaya yazmaz. Bunun yerine çalıştırılabilen dosyaya çağrılan fonksiyonun hangi 
    dinamik kütüphanede olduğu bilgisini yazar. Çalıştırılabilen dosyayı yükleyen işletim sistemi o dosyanın çalışması için 
    gerekli olan dinamik kütüphaneleri çalıştırılabilen dosyayla birlikte bütünsel olarak prosesin sanal bellek alanına yüklemektedir. 
    Böylece birtakım ayarlamalar yapıldıktan sonra artık çağrılan fonksiyon için gerçekten o anda sanal belleğe yüklü olan dinamik 
    kütüphane kodlarına gidilmektedir. Örneğin biz "app" programımızda "libmyutil.so" dinamik kütüphanesinden foo isimli fonksiyonu 
    çağırmış olalım. Bu foo fonksiyonunun kodları dinamik kütüphaneden alınıp "app" dosyasına yazılmayacaktır. Bu "app" dosyası 
    çalıştırıldığında işletim sistemi bu "app" dosyası ile birlikte "libmyutil.so" dosyasını da sanal belleğe yükleyecektir. Programın 
    akışı foo çağrısına geldiğinde akış "libmyutil.so" dosyası içerisindeki foo fonksiyonunun kodlarına aktarılacaktır. Dinamik kütüphane 
    dosyalarının bir kısmının değil hepsinin prosesin adres alanına yüklendiğine dikkat ediniz. (Tabii işletim sisteminin sanal bellek 
    mekanizması aslında yalnızca bazı sayfaları fiziksel belleğe yükleyebilecektir.)

    Dinamik kütüphane kullanımının avantajları şunlardır:

    1) Çalıştırılabilen dosyalar fonksiyon kodlarını içermezler. Dolayısıyla önemli bir disk alanı kazanılmış olur. Oysa statik 
    kütüphanelerde statik kütüphanelerden çağrılan fonksiyonlar çalıştırılabilen dosyalara yazılmaktadır.

    2) Dinamik kütüphaneler birden fazla proses tarafından fiziksel belleğe tekrar tekrar yüklenmeden kullanılabilmektedir.
    Yani işletim sistemi arka planda aslında aynı dinamik kütüphaneyi kullanan programlarda bu kütüphaneyi tekrar tekrar fiziksel 
    belleğe yüklememektedir. Bu da statik kütüphanelere göre önemli bir bellek kullanım avantaj oluşturmaktadır. Bu durumda eğer 
    dinamik kütüphanenin ilgili kısmı daha önce fiziksel belleğe yüklenmişse bu durum dinamik kütüphane kullanan programın daha hızlı 
    yüklemesine de yol açabilmektedir. Prog1 ve Prog2 biçiminde iki programın çalıştığını düşünelim. Bunlar aynı dinamik 
    kütüphaneyi kullanıyor olsun. İşletim sistemi bu dinamik kütüphaneyi bu proseslerin sanal bellek alanlarının farklı yerlerine 
    yükleyebilir. Ancak aslında işletim sistemi sayfa tablolarını kullanarak mümkün olduğunca bu iki dinamik kütüphaneyi aynı 
    fiziksel sayfaya eşlemeye çalışacaktır. Tabii bu durumda proseslerden biri dinamik kütüphane içerisindeki bir statik 
    nesneyi değiştirdiğinde artık "copy on write" mekanizması devreye girecek ve dinamik kütüphanenin o sayfasının yeni bir kopyası 
    oluşturulacaktır. Aslında bu durum fork fonksiyonu ile yeni bir prosesin yaratılması durumuna çok benzemektedir. Burada anlatılan 
    unsurların ayrıntıları "sayfalama ve sanal bellek" kullanımın açıklandığı paragraflarda ele alınacaktır.

    3) Dinamik kütüphaneleri kullanan programlar bu dinamik kütüphanelerdeki değişikliklerden etkilenmezler. Yani biz dinamik 
    kütüphanenin yeni bir versiyonunu oluşturduğumuzda bunu kullanan programları yeniden derlemek ya da bağlamak zorunda kalmayız. 
    Örneğin bir dinamik kütüphaneden foo fonksiyonunu çağırmış olalım. Bu foo fonksiyonunun kodları bizim çalıştırılabilir dosyamızın
    içerisinde değil de dinamik kütüphanede olduğuna göre dinamik kütüphanedeki foo fonksiyonu değiştirildiğinde bizim programımız 
    artık değişmiş olan foo fonksiyonunu çağıracaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Dinamik kütüphanelerin gerçekleştiriminde ve kullanımında önemli bir sorun vardır. Dinamik kütüphanelerin tam olarak sanal 
    belleğin neresine yükleneceği baştan belli değildir. Halbuki çalıştırılabilen dosyanın sanal belleğin neresine yükleneceği 
    baştan bilinebilmektedir. Yani çalıştırılabilen dosyanın tüm kodları aslında derleyici ve bağlayıcı tarafından zaten "onun 
    sanal bellekte yükleneceği yere göre" oluşturulmaktadır. Fakat dinamik kütüphanelerin birden fazlası prosesin sanal adres 
    alanına yüklenebildiğinden bunlar için yükleme adresinin önceden tespit edilmesi mümkün değildir. İşte bu sorunu giderebilmek 
    için işletim sistemlerinde değişik teknikler kullanılmaktadır. Windows sistemlerinde "import-export tablosu ve "load time 
    relocation" yöntemleri tercih edilmiştir. Bu sistemlerde dinamik kütüphane belli bir adrese yüklendiğinde işletim sistemi 
    o dinamik kütüphanenin "relocation" tablosuna bakarak gerekli makine komutlarını düzeltmektedir. Dinamik kütüphane fonksiyonlarının
    çağrımı için de "import tablosu" ve "export tablosu" denilen tablolar kullanılmaktadır. UNIX/Linux dünyasında dinamik kütüphanelerin 
    herhangi bir yere yüklenebilmesi ve minimal düzeyde relocation uygulanabilmesi için "Konumdan Bağımsız Kod (Position Independent 
    Code)" denilen teknik kullanılmaktadır. Konumdan bağımsız kod "nereye yüklenirse yüklenilsin çalışabilen kod" anlamına gelmektedir. 
    Konumdan bağımsız kod oluşturabilmek derleyicinin yapabileceği bir işlemdir. Konumdan bağımsız kod oluşturabilmek için gcc 
    ve clang derleyicilerinde derleme sırasında "-fPIC" seçeneğinin bulundurulması gerekmektedir. Biz kursumuzda konumdan bağımsız 
    kodun ayrıntıları üzerinde durmayacağız.

    Pekiyi Windows sistemlerinin kullandığı "relocation" tekniği ile UNIX/Linux sistemlerinde kullanılan "konumdan bağımsız
    kod tekniği" arasında performans bakımından ne farklılıklar vardır? İşte bu tekniklerin kendi aralarında bazı avantaj 
    ve dezavantajları bulunmaktadır. Windows'taki teknikte "relocation" işlemi bir zaman kaybı oluşturabilmektedir. Ancak 
    bir "relocation" işlemi yapıldığında kodlar daha hızlı çalışma eğilimindedir. Konumdan bağımsız kod tekniğinde ise
    "relocation" işlemine minimal düzeyde gereksinim duyulmaktadır. Ancak dinamik kütüphanelerdeki fonksiyonlar çağrılırken 
    göreli biçimde daha fazla zaman kaybedilmektedir. Aynı zamanda bu teknikte kodlar biraz daha fazla yer kaplamaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi neden dinamik kütüphane dosyaları linker tarafından tıpkı çalıştırılabilir dosyalarda olduğu gibi sanal bellekte belli 
    bir yere yüklenince sorunsuz çalışacak biçimde oluşturulmuyor? Çalıştırılabilir dosyalar sanal bellek boşken yüklendiğinden 
    onların belli bir yere yüklenmesinde bir sorun oluşmamaktadır. Ancak bir program çok fazla dinamik kütüphane kullanabileceğine 
    göre bu dinamik kütüphanelerin baştan yerinin belirlenmesi olanaksızdır.

    Pekiyi dinamik kütüphaneler içerisindeki global değişkenlerin ve fonksiyonların yükleme yerinden bağımsız bir biçimde dinamik 
    kütüphane içerisinden kullanılması nasıl sağlanabilir? Dinamik kütüphane içerisinde aşağıdaki gibi bir kod parçası bulunuyor 
    olsun:

    int g_a;
    ...

    g_a = 10;

    Burada derleyicinin yukarıdaki ifadeye ilişkin makine kodlarını üretebilmesi için g_a değişkeninin tüm bellekteki adresini 
    (yani tepeden itibaren adresini) bilmesi gerekir. Bir nesnenin belleğin tepesinden itibarenki adresine "mutlak adres (absolute
    address) de denilmektedir. Örneğin Intel işlemcilerinde yukarıdaki ifade aşağıdaki gibi makine komutlarına dönüştürülmektedir:

    MOV EAX, 10
    MOV [g_a'nın mutlak adresi], EAX

    İşte sorun buradaki g_a değişkeninin mutlak adresinin program yüklenene kadar bilinmemesidir. Bu sorunu çözmenin de iki yolu 
    vardır:

    1) Derleyici ve linker g_a'nın mutlak adresinin bulunduğu yeri boş bırakır. Yükleyicinin bu yeri yükleme adresine göre 
    doldurmasını ister. İşte bu işlem yükleyicinin yaptığı "relocation" işlemidir. Bu tür relocation işlemlerine "load time 
    relocation" da denilmektedir. Windows sistemleri bu yöntemi kullanmaktadır.

    2) Derleyici makine komutunu o anda komutun yürütüldüğü yerin adresini barındıran ve ismine "Instruction Pointer" denilen 
    yazmaca dayalı olarak oluşturabilir. Çünkü linker komutun bulunduğu yerden g_a'ya kadar kaç byte'lık bir açıklık olduğunu 
    bilmektedir. İşte buna "konumdan bağımsız kod (position independent code)" denilmektedir.

    Yukarıda da belirttiğimiz gibi birinci teknik (Windows sistemlerinin kullandığı teknik) relocation yapıldıktan sonra kodun
    hızlı çalışmasını sağlamaktadır. Ancak bu teknikte relocation zamanı yüklemeyi uzatabilmektedir. İkinci teknikte ise relocation
    minimal düzeyde tutulmaktadır. Ancak bu global değişkenlere erişim birkaç makine komutu ile daha yavaş yapılmaktadır. 
    UNIX/Linux sistemleri genel olarak bu tekniği kullanmaktadır. Ayrıca birinci teknikte kod üzerinde relocation uygulandığı 
    için mecburen "copy on write" mekanizması devreye sokulmaktadır. Bu da fiziksel belleğin kullanım verimini düşürebilmektedir.

    Bu noktada ek olarak işlemcilerde bazı makine komutlarının (MOV, LOAD, STORE gibi) mutlak adres kullandığını ancak CALL ve 
    JMP gibi bazı makine komutlarının hem mutlak hem de göreli adres kullanabildiğini belirtelim. Aslında işlemcileri tasarlayanlar 
    relocation işlemi gerekmesin diye CALL ve JMP komutlarının göreli (relative) versiyonlarını da oluşturmuşlardır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    UNIX/Linux sistemlerinde bir dinamik kütüphaneler şöyle oluşturulmaktadır:

    1) Önce dinamik kütüphaneye yerleştirilecek amaç dosyaların (object files) -fPIC seçeneği ile "Konumdan Bağımsız Kod (Position 
    Independent Code)" tekniği kullanılarak derlenmesi gerekir. (-fPIC seçeneğinde -f'ten sonra boşluk bırakılmamalıdır.)

    2) Bağlama işleminde "çalıştırılabilir (executable)" değil de "dinamik kütüphane" dosyasının oluşturulması için -shared seçeneğinin 
    kullanılması gerekir. "-shared" seçeneği kullanılmazsa bağlayıcı dinamik kütüphane değil, normal çalıştırılabilir dosya oluşturmaya
    çalışmaktadır. (Zaten bu durumda main fonksiyonu olmadığı için linker hata mesajı verecektir.) Örneğin:

    $ gcc -fPIC a.c b.c c.c
    $ gcc -shared -o libmyutil.so a.o b.o c.o

    Dinamik kütüphanelere daha sonra dosya eklenip çıkartılamaz. Onların her defasında yeniden bütünsel biçimde oluşturulmaları 
    gerekmektedir. Yukarıdaki işlem aslında tek hamlede de aşağıdaki gibi yapılabilmektedir:

    $ gcc -shared -o libmyutil.so -fPIC a.c b.c c.c
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi biz -fPIC seçeneğini kullanmadan yani "konumdan bağımsız kod" üretmeden dinamik kütüphane oluşturmaya çalışırsak
    ne olur? Mevcut GNU linker programları "-shared" seçeneği kullanıldığında global değişkenler için relocation işlemi söz konusu
    ise bir mesaj vererek link işlemini yapmamaktadır. Yani bu durumda mevcut GNU linker programları kodun "-fPIC" seçeneği ile
    derlenmesini zorunlu tutmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												18. Ders 14/05/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz yukarıda dinamik kütüphanelerin nasıl oluşturulduğunu gördük. Pekiyi dinamik kütüphaneler nasıl kullanılmaktadır?

    Dinamik kütüphane kullanan bir program bağlanırken kullanılan dinamik kütüphanenin komut satırında belirtilmesi gerekir. 
    Örneğin:

    $ gcc -o app app.c libmyutil.so

    Tabii bu işlem yine -l seçeneği ile de yapılabilirdi:

    $ gcc -o app app.c -lmyutil -L.

    Bu biçimde çalıştırılabilir dosya oluşturulduğunda linker bu çalıştırılabilir dosyanın çalıştırılabilmesi için hangi 
    dinamik kütüphanelerin yüklenmesi gerektiğini ELF formatının ".dynamic" isimli bölümüne yazmaktadır. Böylece yükleyici 
    bu programı yüklerken onun kullandığı dinamik kütüphaneleri de yükleyecektir. Ancak linker bu ".dynamic" bölümüne çalıştırılabilir
    dosyanın kullandığı dinamik kütüphanelerin yol ifadesini (yani tam olarak nerede olduğunu) yazmaz. Yalnızca isimlerini 
    yazmaktadır. İşte yükleyici (dinamik linkler) bu nedenle dinamik kütüphaneleri önceden belirlenen bazı yerlerde aramaktadır. 
    Bu yere çalıştırılabilir dosyanın yüklendiği dizin (current working directory) dahil değildir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    İster statik kütüphane isterse dinamik kütüphane yazacak olalım yazdığımız kütüphaneler için bir başlık dosyası oluşturmak 
    iyi bir tekniktir. Örneğin içerisinde çeşitli fonksiyonların bulunduğu "libmyutil.so" dinamik kütüphanesini "libmyutil.c" 
    dosyasından hareketle oluşturmak isteyelim. İşte "libmyutil.c" dosyasındaki fonksiyonların prototipleri, gerekli olan sembolik 
    sabitler, makrolar, inline fonksiyonlar, yapı bildirimleri gibi "nesne yaratmayan bildirimler" bir başlık dosyasına yerleştirilmelidir. 
    Böylece bu kütüphaneyi kullanacak kişiler bu dosyayı include ederek gerekli bildirimlerin kodlarını oluşturmuş olurlar. Başlık 
    dosyaları oluşturulurken iki önemli noktaya dikkat edilmelidir:

    1) Başlık dosyalarına yalnızca "nesne yaratmayan bildirimler (declarations)" yerleştirilmelidir.

    2) Başlık dosyalarının başına "include koruması (include guard)" yerleştirilmelidir. Include koruması aşağıdaki gibi yapılabilir:

    #ifndef SOME_NAME
    #define SOME_NAME

    <dosyanın içeriği>

    #endif

    Buradaki SOME_NAME dosya isminden hareketle uydurulmuş olan herhangi bir isim olabilir. Örneğin:

    #ifndef MYUTIL_H_
    #define MYUTIL_H_

    <dosyanın içeriği>

    #endif

    Örneğin "myutil.so" dinamik kütüphanesinde foo ve bar isimli iki fonksiyon bulunuyor olsun. Bunun için "myutil.h" isimli
    başlık dosyası aşağıdaki gibi oluşturulabilir:

    #ifndef MYUTIL_H_
    #define MYUTIL_H_

    void foo(void);
    void bar(void);

    #endif
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Standart C fonksiyonlarının ve POSIX fonksiyonlarının bulunduğu "libc" kütüphanesi gcc ve clang programlarıyla derleme yapıldığında 
    otomatik olarak bağlama aşamasında devreye sokulmaktadır. Yani biz standart fonksiyonları ve POSIX fonksiyonları için bağlama 
    aşamasında kütüphane belirtmek zorunda değiliz. Default durumda gcc ve clang programları standart C fonksiyonlarını ve POSIX 
    fonksiyonlarını dinamik kütüphaneden alarak kullanır. Ancak programcı isterse "-static" seçeneği ile statik bağlama işlemi 
    de yapabilir. Bu durumda bu fonksiyonlar statik kütüphanelerden alınarak çalıştırılabilen dosyalara yazılacaktır. Örneğin:

    $ gcc -o app -static app.c

    "-static" seçeneği ile bağlama işlemi yapıldığında artık üretilen çalıştırılabilir dosyanın dinamik kütüphanelerle hiçbir ilgisi 
    kalmamaktadır. Zaten "-static" seçeneği belirtildiğinde artık dinamik kütüphaneler bağlama aşamasına programcı tarafından da 
    dahil edilememektedir. Tabii bu biçimde statik bağlama işlemi yapıldığında çalıştırılabilen dosyanın boyutu çok büyüyecektir.

    Eğer "libc" kütüphanesinin default olarak bağlama aşamasında devreye sokulması istenmiyorsa "-nodefaultlibs" seçeneğinin kullanılması 
    gerekir. Örneğin:

    $ gcc -nodefaultlibs -o app app.c

    Burada glibc kütüphanesi devreye sokulmadığı için bağlama aşamasında hata oluşacaktır. Tabii bu durumda da kütüphane açıkça 
    belirtilebilir:

    $ gcc -nodefaultlibs -o app app.c -lc

    Bir kütüphanenin statik ve dinamik biçimi aynı anda bulunuyorsa ve biz bu kütüphaneyi "-l" seçeneği ile belirtiyorsak bu 
    durumda default olarak kütüphanenin dinamik versiyonu devreye sokulmaktadır. Eğer bu durumda kütüphanelerin statik versiyonlarının 
    devreye sokulması isteniyorsa "-static" seçeneğinin kullanılması ya da komut satırında açıkça statik kütüphaneye referans 
    edilmesi gerekir. Örneğin:

    $ gcc -o app app.c -lmyutil -L.

    Burada eğer hem "libmyutil.so" hem de "libmyutil.a" dosyaları varsa "libmyutil.so" dosyası kullanılacaktır. Yani dinamik bağlama 
    yapılacaktır. Tabii biz açıkça statik kütüphanenin ya da dinamik kütüphanenin kullanılmasını sağlayabiliriz:

    $ gcc -o app app.c libmyutil.a

    Aynı etkiyi şöyle de sağlayabilirdik:

    $ gcc -static -o app app.c -lmyutil -L.

    Burada "libc" kütüphanesinin dinamik biçimi devreye sokulacaktır. Ancak "libmyutil" kütüphanesi statik biçimde bağlanmıştır.
    Eğer "-static" seçeneği kullanılırsa bu durumda tüm kütüphanelerin statik versiyonları devreye sokulmaktadır. Tabii bu durumda 
    biz açıkça dinamik kütüphanelerin bağlama işlemine sokulmasını isteyemeyiz. Örneğin:

    $ gcc -static -o app app.c libmyutil.so

    Bu işlem başarısız olacaktır. Çünkü "-static" seçeneği zaten "tüm kütüphanelerin statik olarak bağlanacağı" anlamına 
    gelmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Dinamik kütüphane kullanan programlarda bağlayıcı tarafından ELF formatında iki önemli bölüm oluşturulmaktadır. Bu bölümler 
    ".dynamic" ve ".dynsym" isimli bölümlerdir. ".dynamic" bölümü çalıştırılabilir dosyanın kullandığı dinamik kütüphaneler hakkında 
    bilgiler içermektedir. ".dynsym" bölümü ise dinamik kütüphanelerden kullanılan sembollerin tutulduğu sembol tablosudur. Programın 
    normal sembollerinin ".symtab" isimli bölümdeki sembol tablosunda tutulduğunu anımsayınız.

    32 bit ELF formatının ".dynamic" bölümünün yapısal içeriği şöyledir:

    typedef struct {
        Elf32_Sword d_tag;
        union {
            Elf32_Word d_val;
            Elf32_Addr d_ptr;
        } d_un;
    } Elf32_Dyn;

    64 bit ELF formatının ".dynamic" bölümünün yapısal içeriği ise şöyledir:

    typedef struct {
        Elf64_Sxword d_tag;
        union {
            Elf64_Xword d_val;
            Elf64_Addr d_ptr;
        } d_un;
    } Elf64_Dyn;

    ELF formatının ".dynamic" bölümü yukarıdaki yapılardan oluşan bir dizi gibidir. Bu bölümün içeriğini aşağıdaki gibi temsil
    edebiliriz:

    d_tag d_un
    d_tag d_un
    d_tag d_un
    d_tag d_un
    d_tag d_un
    ...

    Burada d_un ya d_val olabilir ya da d_ptr olabilir, ancak ikisi birden olamaz. d_val bir değer, d_ptr ise bir sanal adres 
    belirtmektedir.

    Yapıların d_tag elemanı ilgili girişin türünü belirtmektedir. Yapının d_un elemanının d_val ya da d_ptr elemanını mı içereceği
    bu d_tag elemanına bağlıdır. Önemli bazı d_tag değerleri şunlardır:

    DT_NEEDED: Bu tag'ı d_val elemanı izlemektedir. Bu tag'daki d_val elemanı modülün yüklenmesi için gerekli olan dinamik kütüphanenin
    isminin (yol ifadesinin değil) string tablosundaki (".strtab") indeks numarası belirtilmektedir.

    DT_SONAME: Bu tag'ı d_val elemanı izlemektedir. Bu tag dinamik kütüphanelerde bulunmaktadır. Burada dinamik kütüphanenin "so 
    isminin" bulunduğu string tablosundaki (".strtab" bölümündeki) indeks belirtilmektedir.

    Buradaki pek çok tag önemli bilgiler içermektedir. Bu tag'lar hakkında bilgileri ELF formatına başvurarak edinebilirsiniz.
    İzleyen paragraflarda bazı bilgiler için bu tag'lara referans edeceğiz.

    Aşağıda readelf programı ile ".dynamic" bölümünün görüntülenme biçimi gösterilmektedir:

    Dynamic section at offset 0xd78 contains 28 entries:
    Tag        Type                         Name/Value
    0x0000000000000001 (NEEDED)             Shared library: [libmyutil.so]
    0x0000000000000001 (NEEDED)             Shared library: [libc.so.6]
    0x000000000000000c (INIT)               0x610
    0x000000000000000d (FINI)               0x85c
    0x0000000000000019 (INIT_ARRAY)         0x10d68
    0x000000000000001b (INIT_ARRAYSZ)       8 (bytes)
    0x000000000000001a (FINI_ARRAY)         0x10d70
    0x000000000000001c (FINI_ARRAYSZ)       8 (bytes)
    0x000000006ffffef5 (GNU_HASH)           0x298
    0x0000000000000005 (STRTAB)             0x3c0
    0x0000000000000006 (SYMTAB)             0x2b8
    0x000000000000000a (STRSZ)              151 (bytes)
    0x000000000000000b (SYMENT)             24 (bytes)
    0x0000000000000015 (DEBUG)              0x0
    0x0000000000000003 (PLTGOT)             0x10f78
    ...

    O halde çalıştırılabilir dosyanın ya da dinamik kütüphane dosyasının hangi dinamik kütüphaneleri kullandığını komut satırından
    aşağıdaki gibi elde edebiliriz:

    $ readelf -d app | grep "NEEDED"
    0x0000000000000001 (NEEDED)             Shared library: [libmyutil.so]
    0x0000000000000001 (NEEDED)             Shared library: [libc.so.6]

    Tabii biz bu biçimde yalnızca çalıştırılabilen dosyanın doğrudan kullandığı dinamik kütüphaneleri görüntülemiş oluruz. 
    Oysa dinamik kütüphaneler de başka dinamik kütüphaneleri kullanıyor olabilir. Bu tür durumlarda özyinelemeli (recursive) 
    biçimde yükleme yapılmaktadır. Bir çalıştırılabilir dosyanın yüklenebilmesi için özyinelemeli biçimde bütün gereken
    dinamik kütüphaneler "ldd" komutuyla elde edilebilmektedir. Örneğin:

    $ ldd app
    linux-vdso.so.1 (0x0000ffffaf206000)
    libmyutil.so => not found
    libc.so.6 => /lib/aarch64-linux-gnu/libc.so.6 (0x0000ffffaf03f000)
    /lib/ld-linux-aarch64.so.1 (0x0000ffffaf1d6000)
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Dinamik kütüphanelerden kullanılan semboller genellikle ELF formatının ".dynsym" isimli sembol tablosunda bulunmaktadır. 
    Aslında dinamik kütüphanedeki sembollerin hangi sembol tablosunda bulunacağı da ".dynamic" bölümündeki DT_SYMTAB tag'ında
    belirtilmektedir. ".dynsym" bölümü daha önce incelediğimiz sembol tablosu formatına sahiptir. Aşağıda örnek bir ".dynsym"
    sembol tablosunun readelf programı ile elde edilen görüntüsü verilmiştir:

    Symbol table '.dynsym' contains 11 entries:
      Num:    Value          Size Type    Bind   Vis      Ndx Name
        0: 0000000000000000     0 NOTYPE  LOCAL  DEFAULT  UND
        1: 0000000000000610     0 SECTION LOCAL  DEFAULT   11
        2: 0000000000011000     0 SECTION LOCAL  DEFAULT   22
        3: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND _ITM_deregisterTMCloneTab
        4: 0000000000000000     0 FUNC    WEAK   DEFAULT  UND __cxa_finalize@GLIBC_2.17 (2)
        5: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND bar
        6: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND __libc_start_main@GLIBC_2.17 (2)
        7: 0000000000000000     0 NOTYPE  WEAK   DEFAULT  UND __gmon_start__
        8: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND abort@GLIBC_2.17 (2)
        9: 0000000000000000     0 FUNC    GLOBAL DEFAULT  UND foo
        10: 0000000000000000    0 NOTYPE  WEAK   DEFAULT  UND _ITM_registerTMCloneTable
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux sistemlerinde dinamik kütüphane kullanan programların yüklenmesi süreci biraz ilginçtir. Anımsanacağı gibi aslında
    her türlü program exec fonksiyonları tarafından yüklenip çalıştırılmaktadır. Bu exec fonksiyonlarının taban olanı "execve"
    isimli fonksiyondur. (Yani diğer exec fonksiyonları bunu çağırmaktadır.) execve fonksiyonu da bir sistem fonksiyonu olarak 
    yazılmıştır.

    Dinamik kütüphane kullanan programların kullandığı dinamik kütüphaneler ismine "dinamik linker (dynamic linker)" denilen
    özel bir program tarafından yüklenmektedir. exec fonksiyonları aslında sıra dinamik kütüphanelerin yüklenmesine geldiğinde 
    dinamik linker denilen bu programı çalıştırmaktadır. Dinamik linker "ld.so" ismiyle temsil edilmektedir. Programın kullandığı 
    dinamik kütüphanelerin başka bir program tarafından yüklenmesi esneklik sağlamaktadır. Bu sayede sistem programcısı isterse 
    (genellikle istemez) bu dinamik linker programını değiştirerek yükleme sürecinde özel işlemler yapabilir. Dinamik linker 
    tamamen user modda çalışmaktadır.

    Programın dinamik kütüphanelerinin yüklenmesinde kullanılacak olan dinamik linker'ın yol ifadesi ELF formatında Program Başlık 
    Tablosu'nda INTERP türüyle belirtilmektedir. INTERP türüne ilişkin Program Başlığı'nda dinamik bağlayıcının yol ifadesinin 
    bulunduğu dosya offset'i belirtilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												19. Ders 21/05/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi bizim programımız örneğin "libmyutil.so" isimli bir dinamik kütüphaneden çağrı yapıyor olsun. Bu "libmyutil.so" 
    dosyasının program çalıştırılırken nerede bulundurulması gerekir? İşte program çalıştırılırken ilgili dinamik kütüphane 
    dosyasının özel bazı dizinlerde bulunuyor olması gerekmektedir. Dinamik kütüphanelerin dinamik bağlayıcı tarafından yüklendiğini
    ve dinamik bağlayıcının da "ld.so" ismiyle temsil edildiğini anımsayınız. "ld.so" ismiyle temsil edilen dinamik bağlayıcı hakkında
    "man ld.so" komutuyla bilgi alabilirsiniz.

    "ld.so" için hazırlanan "man" sayfasında dinamik kütüphaneleri dinamik bağlayıcının nasıl ve nerelerde aradığı maddeler halinde 
    açıklanmıştır. Bu maddeleri tek tek ele almak istiyoruz:

    1) Dinamik bağlayıcı önce çalıştırılabilen dosyanın ".dynamic" bölümündeki DT_RPATH tag'ına bakar. Bu tag'ın değeri tek bir dizin 
    ya da ':' karakterleriyle ayrılmış olan birden fazla dizin belirten bir yazı olabilir. Bu durumda dinamik bağlayıcı bu dizinlere 
    sırasıyla bakmaktadır. Ancak birinci aşamada bu tag'a bakılmasının bir tasarım kusuru olduğu anlaşılmıştır. Bu nedenle ".dynamic" 
    bölümüne DT_RPATH tag'ının yerleştirilmesi "deprecated" yapılmıştır.

    2) Dinamik bağlayıcı yüklenmekte olan program dosyasına ilişkin prosesin LD_LIBRARY_PATH çevre değişkenine bakar. Eğer böyle 
    bir çevre değişkeni varsa dinamik kütüphaneleri bu çevre değişkeninde belirtilen dizinlerde sırasıyla arar. Bu çevre değişkeni 
    ':' karakterleriyle ayrılmış yol ifadelerinden oluşmaktadır. Biz programı genellikle kabuk üzerinden çalıştırdığımıza göre 
    kabukta bu çevre değişkenini aşağıdaki örnekte olduğu gibi set edebiliriz:

    $ export LD_LIBRARY_PATH=/home/kaan:/home/kaan/Study/EmbeddedLinux:.

    Burada artık dinamik kütüphaneler sırasıyla "/home/kaan" dizininde, "/home/kaan/Study/EmbeddedLinux" dizininde ve prosesin 
    çalışma dizininde (current working directory) aranacaktır. Çevre değişkeninin sonundaki "." karakterinin exec uygulayan prosesin 
    o andaki çalışma dizinini temsil ettiğine dikkat ediniz. Tabii biz kabuk programının değil, çalıştırılacak programın çevre 
    değişken listesine ekleme yaparak da programı aşağıdaki gibi çalıştırabiliriz:

    $ LD_LIBRARY_PATH=:. ./app

    3) Dinamik bağlayıcı çalıştırılabilen dosyanın ".dynamic" bölümündeki DT_RUNPATH tag'ına bakar. Birinci aşamada biz DT_RPATH
    tag'ının "deprecated" yapıldığını belirtmiştik. İşte bu tag yerine artık DT_RUNPATH tag'ı kullanılmalıdır. Bu tag'ın değeri 
    de yine ':' karakterleriyle ayrılmış olan dizin listesinden oluşmaktadır. Dinamik bağlayıcı bu dizinlerde sırasıyla arama 
    yapmaktadır. DT_RPATH ile DT_RUNPATH arasındaki tek fark DT_RUNPATH tag'ına LD_LIBRARY_PATH çevre değişkeninden daha sonra 
    bakılmasıdır.

    4) Dinamik bağlayıcı daha sonra "/etc/ld.so.cache" isimli cache dosyasına bakar. Bu cache dosyası her bir dinamik kütüphanenin
    hangi dizinlerde olduğunu belirtmektedir. Bu konu izleyen paragraflarda ele alınacaktır.

    5) Nihayet dinamik bağlayıcı dinamik kütüphaneleri sırasıyla "/lib", /usr/lib" dizinlerinde de aramaktadır. 64 bit Linux 
    sistemlerinin bir bölümünde 64 bit dinamik kütüphaneler için "/lib64" ve "/usr/lib64" dizinlerine de bakılabilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Yukarıdaki üçüncü maddede aranacak yol ifadesini çalıştırılabilir dosyanın DT_RUNPATH tag'ına yerleştirmek için ld bağlayıcısında
    "-rpath <yol ifadeleri>" bağlayıcı seçeneği kullanılmalıdır. Buradaki yol ifadelerinin mutlak olması zorunlu değilse de şiddetle
    tavsiye edilmektedir. gcc ve clang derleyicilerinde "-rpath" seçeneğini bağlayıcıya geçirebilmek için "-Wl" seçeneği kullanılabilir. 
    "-Wl" seçeneği bitişik yazılan virgüllü alanlardan oluşmalıdır. gcc ve clang bu komut satırı argümanını "ld" bağlayıcısına virgüller 
    yerine boşluklar (SPACE) koyarak geçirmektedir. Örneğin:

    $ gcc -o app app.c -Wl,-rpath,/home/kaan/Study/EmbeddedLinux libmyutil.so

    Burada ELF formatının DT_RUNPATH tag'ına yerleştirme yapılmaktadır. Çalıştırılabilir dosyaya iliştirilen DT_RUNPATH bilgisi 
    "readelf" programı ile aşağıdaki gibi görüntülenebilir:

    $ readelf -d app | grep "RUNPATH"
    0x000000000000001d (RUNPATH)            Library runpath: [/home/csd/Study/EmbeddedLinux]

    Biz bu tag'a birden fazla dizin de yerleştirebiliriz. Bu durumda yine dizinleri ':' ile ayırmamız gerekir. Örneğin:

    $ gcc -o app app.c -Wl,-rpath,/home/csd/Study/EmbeddedLinux:/home/kaan libmyutil.so

    Birden fazla kez "-rpath" seçeneği kullanıldığında bu seçenekler tek bir DT_RUNPATH tag'ına aralarına ':' karakteri getirilerek 
    yerleştirilmektedir. Yani aşağıdaki işlem yukarıdaki ile eşdeğerdir:

    $ gcc -o app app.c -Wl,-rpath,/home/csd/Study/EmbeddedLinux,-rpath,/home/kaan libmyutil.so

    "-rpath" bağlayıcı seçeneğinde default durumda DT_RUNPATH tag'ına yerleştirme yapıldığına dikkat ediniz. Eğer DT_RPATH tag'ına 
    yerleştirme yapılmak isteniyorsa bağlayıcı seçeneklerine ayrıca "--disable-new-dtags" seçeneğinin de girilmesi gerekmektedir. 
    Örneğin:

    gcc -o app app.c -Wl,-rpath,/home/csd/Study/EmbeddedLinux,--disable-new-dtags libmyutil.so

    DT_RUNPATH tag'ını da aşağıdaki gibi görüntüleyebiliriz:

    $ readelf -d app | grep "RUNPATH"
    0x000000000000001d (RUNPATH)            Library runpath: [/home/kaan/Study/EmbeddedLinux]

    Çalıştırılabilir dosyaya DT_RUNPATH tag'ının mutlak ya da göreli yol ifadesi biçiminde girilmesi bazı kullanım sorunlarına yol 
    açabilmektedir. Çünkü bu durumda dinamik kütüphaneler uygulamanın kurulduğu dizine göreli biçimde konuşlandırılacağı zaman 
    uygulamanın kurulum yeri değiştirildiğinde sorunlar oluşabilmektedir. Örneğin biz çalıştırılabilir dosyanın DT_RUNPATH tag'ına 
    "home/kaan/test" isimli yol ifadesini yazmış olalım. Programımızı ve dinamik kütüphanemizi bu dizine yerleştirirsek bir sorun 
    oluşmayacaktır. Ancak başka bir dizine yerleştirirsek dinamik kütüphanemiz bulunamayacaktır. İşte bunu engellemek için "-rpath" 
    seçeneğinde '$ORIGIN' argümanı kullanılmaktadır. Buradaki '$ORIGIN' argümanı "o anda çalıştırılabilen dosyanın bulunduğu dizini" 
    temsil etmektedir. Örneğin:

    $ gcc -o app app.c -Wl,-rpath,'$ORIGIN'/. libmyutil.so

    Burada artık çalıştırılabilen dosya nereye yerleştirilirse yerleştirilsin ve nereden çalıştırılırsa çalıştırılsın dinamik 
    kütüphaneler çalıştırılabilen dosyanın yerleştirildiği dizinde aranacaktır.

    Yukarıda da belirttiğimiz gibi aslında arama sırası bakımından DT_RPATH tag'ının en yukarıda olması (LD_LIBRARY_PATH'in 
    yukarısında olması) yanlış bir tasarımdır. Geriye doğru uyumu koruyarak bu yanlış tasarım DT_RUNPATH tag'ı ile telafi 
    edilmiştir. DT_RUNPATH tag'ına LD_LIBRARY_PATH çevre değişkeninden sonra başvurulmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Dinamik kütüphanelerin aranması sırasında "/lib" ve "/usr/lib" dizinlerine bakılmadan önce özel bir dosyaya da bakılmaktadır. 
    Bu dosya "/etc/ld.so.cache" isimli dosyadır. "/etc/ld.so.cache" dosyası aslında binary bir dosyadır. Bu dosya hızlı aramanın 
    yapılabilmesi için "sözlük (dictionary)" tarzı yani algoritmik aramaya izin verecek biçimde bir içeriğe sahiptir. Bu dosya
    ilgili dinamik kütüphane dosyalarının hangi dizinler içerisinde olduğunu gösteren bir yapıdadır. (Yani bu dosya ".so" dosyalarının 
    hangi dizinlerde olduğunu belirten binary bir dosyadır.) Başka bir deyişle bu dosyanın içerisinde "falanca .so dosyası filanca 
    dizinde" biçiminde bilgiler vardır. İlgili ".so" dosyasının yerinin bu dosyada aranması dizinlerde aranmasından çok daha hızlı 
    yapılabilmektedir. Ayrıca dinamik kütüphaneler değişik dizinlerde bulunabilmektedir. Bunların LD_LIBRARY_PATH çevre değişkeninde
    belirtilen dizinlerde tek tek aranması bir yavaşlık oluşturabilmektedir.

    Pekiyi bu "/etc/ld.so.cache" dosyasının içerisinde hangi ".so" dosyaları vardır? Aslında bu dosyanın içerisinde "/lib" ve 
    "/usr/lib" dizinindeki ".so" dosyalarının hepsi bulunmaktadır. Ama programcı isterse kendi dosyalarını da bu cache dosyasının 
    içerisine yerleştirebilir. Burada dikkat edilmesi gereken nokta bu cache dosyasına "/lib" ve "/usr/lib" dizinlerinden 
    daha önce bakıldığı ve bu dizinlerin içeriğinin de zaten bu cache dosyasının içerisinde olduğudur. O halde aslında "/lib" ve 
    "/usr/lib" dizinlerinde arama çok nadir olarak yapılmaktadır. Ayrıca bu cache dosyasına LD_LIBRARY_PATH çevre değişkeninden 
    daha sonra bakıldığına dikkat ediniz. O halde programcının kendi ".so" dosyalarını da -eğer uzun süreliğine konuşlandıracaksa- 
    bu cache dosyasının içerisine yerleştirmesi tavsiye edilmektedir.

    Pekiyi "/etc/ld.so.cache" dosyasına biz nasıl bir dosya ekleriz? Aslında programcı bunu dolaylı olarak yapmaktadır. Şöyle ki: 
    "/sbin/ldconfig" isimli bir program vardır. Bu program "/etc/ld.so.conf" isimli bir text dosyasına bakar. Bu dosya dizinlerden 
    oluşmaktadır. Bu "ldconfig" programı bu dizinlerin içerisindeki "so" dosyalarını "/etc/ld.so.cache" dosyasına eklemektedir. 
    Şimdilerde "/etc/ld.so.conf" dosyasının içeriği şöyledir:

    include /etc/ld.so.conf.d/*.conf

    Bu satır "/etc/ld.so.conf.d" dizinindeki tüm ".conf" uzantılı dosyaların bu işleme dahil edileceğini belirtmektedir.

    Biz "ldconfig" programını çalıştırdığımızda bu program "/lib", "/usr/lib" ve "/etc/ld.so.conf" (dolayısıyla "/etc/ld.so.conf.d" 
    dizinindeki ".conf" dosyalarına) bakarak "/etc/ld.so.cache" dosyasını yeniden oluşturmaktadır. O halde bizim bu cache'e ekleme 
    yapmak için tek yapacağımız şey "/etc/ld.so.conf.d" dizinindeki bir ".conf" dosyasına yeni bir satır olarak bir dizinin yol ifadesini
    girmektir. (".conf" dosyaları her satırda bir dizinin yol ifadesinden oluşmaktadır.) Tabii programcı isterse bu dizine yeni bir 
    ".conf" dosyası da ekleyebilir. İşte programcı bu işlemi yaptıktan sonra "/sbin/ldconfig" programını çalıştırınca artık onun 
    eklediği dizinin içerisindeki ".so" dosyaları da "/etc/ld.so.cache" dosyasının içerisine eklenmiş olacaktır. Daha açık bir 
    anlatımla programcı bu cache dosyasına ekleme işini adım adım şöyle yapar:

    1) Önce ".so" dosyasını bir dizine yerleştirir.
    2) Bu dizinin ismini "/etc/ld.so.conf.d" dizinindeki bir dosyanın sonuna ekler. Ya da bu dizinde yeni ".conf" dosyası oluşturarak
    dizini bu dosyanın içerisine yazar.
    3) "/sbin/ldconfig" programını çalıştırır.

    "ldconfig" programının "sudo" ile çalıştırılması gerektiğine dikkat ediniz. Zaten "/sbin" dizinindeki tüm programlar "super user"
    için bulundurulmuştur.

    Programcı "/etc/ld.so.conf.d" dizinindeki herhangi bir dosyaya değil de "-f" seçeneği sayesinde kendi belirlediği bir dosyaya 
    da ilgili dizinleri yazabilmektedir. Başka bir deyişle "-f" seçeneği "şu config dosyasına da bak" anlamına gelmektedir. "ldconfig"
    her çalıştırıldığında sıfırdan yeniden cache dosyasını oluşturmaktadır.

    Programcı "/lib" ya da "/usr/lib" dizinine bir ".so" dosyası eklediğinde "ldconfig" programını çalıştırması -zorunlu olmasa da- 
    iyi bir tekniktir. Çünkü o dosya da cache dosyasına yazılacak ve daha hızlı bulunacaktır.

    ldconfig programında "-p" seçeneği ile cache dosyası içerisindeki tüm dosyalar görüntülenebilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												20. Ders 23/05/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Dinamik kütüphane dosyalarının "so" isimleri denilen bir isimleri de bulunabilmektedir. Dinamik kütüphane dosyalarının "so" 
    isimleri bağlayıcı tarafından kullanılan isimleridir. Dinamik kütüphane dosyası oluşturulurken "so" isimleri verilmeyebilir. 
    Yani bir dinamik kütüphane dosyasının "so" ismi olmak zorunda değildir. Dinamik kütüphane dosyalarına "so" isimlerini vermek 
    için "-soname <isim>" bağlayıcı seçeneği kullanılmaktadır. Kütüphanelere verilen "so" isimleri ELF formatının ".dynamic" bölümündeki 
    DT_SONAME isimli bir tag'ına yerleştirilmektedir. "-soname" komut satırı argümanı bağlayıcıya ilişkin olduğu için "-Wl" seçeneği 
    ile kullanılmalıdır. Örneğin biz "libmyutil.so" isimli bir dinamik kütüphaneyi "so" ismi vererek oluşturmak isteyelim. Bu işlemi 
    şöyle yapabiliriz:

    $ gcc -o libmyutil.so -fPIC -shared -Wl,-soname,libmyutil.so.1 libmyutil.c

    Burada "libmyutil.so" kütüphane dosyasına "libmyutil.so.1" "so" ismi verilmiştir. Kütüphane dosyalarına iliştirilen "so" 
    isimleri "readelf" programı ile aşağıdaki gibi görüntülenebilir:

    $ readelf -d libmyutil.so | grep "SONAME"
    0x000000000000000e (SONAME)             Kitaplık so_adı: [libmyutil.so.1]

    Aynı işlem "objdump" programıyla da şöyle yapılabilir:

    $ objdump -x libmyutil.so | grep "SONAME"
    SONAME           libmyutil.so.1

    Tabii yukarıda da belirttiğimiz gibi biz dinamik kütüphanelere "so" ismi vermek zorunda değiliz.

    "so" ismi içeren bir kütüphaneyi kullanan bir program bağlanırken bağlayıcı çalıştırılabilen dosyaya "so" ismini içeren 
    kütüphanenin ismini değil "so" ismini yazmaktadır. Yukarıdaki örneğimizde "libmyutil.so" kütüphanesi "so" ismi olarak 
    "libmyutil.so.1" ismini içermektedir. Şimdi "libmyutil.so" dosyasını kullanan "app.c" programını derleyip bağlayalım:

    $ gcc -o app app.c libmyutil.so

    Burada link işleminde "libmyutil.so" dosya ismi kullanılmıştır. Ancak oluşturulan "app" dosyasının içerisine bağlayıcı bu 
    ismi değil, "so" ismi olan "libmyutil.so.1" ismini yazacaktır. Örneğin:

    $ readelf -d app | grep "NEEDED"
    0x0000000000000001 (NEEDED)             Paylaşımlı kitaplık: [libmyutil.so.1]
    0x0000000000000001 (NEEDED)             Paylaşımlı kitaplık: [libc.so.6]

    O halde biz buradaki "app" dosyasını çalıştırmak istediğimizde yükleyici (yani dinamik bağlayıcı) artık "libmyutil.so" dosyasını 
    değil, "libmyutil.so.1" dosyasını yüklemeye çalışacaktır. Örneğin:

    $ export LD_LIBRARY_PATH=.
    $ ./app
    ./app: error while loading shared libraries: libmyutil.so.1 cannot open shared object file: No such file or directory

    Tabii yukarıda belirttiğimiz gibi eğer kütüphaneyi oluştururken ona "so" ismi vermeseydik bu durumda bağlayıcı "app" dosyasına
    "libmyutil.so" dosyasını yazacaktı ve dinamik bağlayıcı da bu dosyayı yükleyecekti.

    Pekiyi yukarıdaki örnekte "app" programı artık "libmyutil.so.1" dosyasını kullanıyor gibi olduğuna göre ve böyle de bir dosya 
    da olmadığına göre bu işlemlerin ne anlamı vardır? İşte biz bu örnekte "so" ismine ilişkin dosyayı bir sembolik bağlantı dosyası 
    haline getirirsek ve bu sembolik link dosyası da "libmyutil.so" dosyasını gösterir hale getirirsek sorunu ortadan kaldırabiliriz. 
    Örneğin:

    $ ln -s libmyutil.so libmyutil.so.1
    $ ls -l libmyutil.so libmyutil.so.1
    -rwxrwxr-x 1 kaan kaan 15600 May 21 22:35 libmyutil.so
    lrwxrwxrwx 1 kaan kaan    12 May 23 20:09 libmyutil.so.1 -> libmyutil.so

    Şimdi artık "app" dosyasını çalıştırmak istediğimizde dinamik bağlayıcı "libmyutil.so.1" dosyasını yüklemek isteyecektir. Ancak 
    "libmyutil.so.1" dosyası da zaten "libmyutil.so" dosyasını belirttiği için yine "libmyutil.so" dosyası yüklenecektir. Yani 
    artık "app" dosyasını çalıştırabiliriz:

    $ LD_LIBRARY_PATH=. ./app
    foo
    bar

    Tabii burada tüm bunları neden yapmış olduğumuza bir anlam verememiş olabilirsiniz. İşte bunun anlamını izleyen paragraflarda 
    dinamik kütüphanelerin versiyonlanması konusunda açıklayacağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    UNIX/Linux sistemlerinde dinamik kütüphane dosyalarına isteğe bağlı olarak birer versiyon numarası verilebilmektedir. Bu 
    versiyon numarası dosya isminin bir parçası durumundadır. Linux sistemlerinde izlenen tipik numaralandırma (convention) 
    şöyledir:

    <dosya_ismi>.so.<majör_numara>.<minör_yüksek_numara>.<minör_alçak_numara>

    Örneğin:

    libmyutil.so.2.4.6

    Minör numaranın iki basamaklı olduğuna dikkat ediniz. Ancak minör numara da tek basamak biçiminde verilebilmektedir.

    Majör numaralar büyük değişiklikleri, minör numaralar ise küçük değişiklikleri anlatmaktadır. Majör numara değişirse yeni 
    dinamik kütüphane eskisiyle uyumlu olmaz. Burada "uyumlu olmama" geçmişe ve geleceğe doğru uyumsuzluğu belirtmektedir. 
    Yani kütüphanenin düşük bir majör numarasını kullanan program yüksek bir majör numarasını kullanmamalı, yüksek bir majör
    numarasını kullanan program da düşük bir majör numarasını kullanmamalıdır. Çünkü muhtemelen bu yeni majör versiyonda 
    fonksiyonların isimlerinde, parametrik yapılarında değişiklikler söz konusu olmuş olabilir ya da bazı fonksiyonlar silinmiş 
    olabilir. Fakat majör numarası aynı ancak minör numaraları farklı olan kütüphaneler birbirleriyle uyumludur. Alçak minör numarayı 
    kullanan program yüksek minör numarayı kullanırsa sorun oluşmayacaktır. Bu durumda tabii yüksek minör numaralı kütüphanede hiçbir 
    fonksiyonun ismi, parametrik yapısı değişmemiş ve hiçbir fonksiyon silinmemiş olmalıdır. Örneğin yüksek minör numaralarda 
    fonksiyonların daha hızlı çalışması için optimizasyonlar yapılmış olabilir. Ya da örneğin yüksek minör numaralarda yeni birtakım 
    fonksiyonlar da eklenmiş olabilir. Çünkü yeni birtakım fonksiyonlar eklendiğinde eski fonksiyonlar varlığını devam ettirmektedir. 
    Tabii yine de bu durum dinamik kütüphanenin eski versiyonunu kullanan programların düzgün çalışacağı anlamına gelmemektedir. 
    Çünkü programcılar kodlarına yeni birtakım şeyler eklerken istemeden eski kodların çalışmasını da bozabilmektedir. (Bu tür 
    problemler Windows sistemlerinde eskiden ciddi sıkıntılara yol açmaktaydı. Bu probleme Windows sistemlerinde "DLL cehennemi 
    (DLL Hell)" deniyordu.) Şöyle bir özet yapabiliriz:

    - Kütüphanenin düşük majör numarasını kullanan programlar onların yüksek majör numarasını kullanmamalıdır. Yüksek majör 
    numarasını kullanan programlar da onların düşük majör numaralarını kullanmamalıdır.

    - Kütüphanenin aynı majör fakat düşük minör numarasını kullanan programlar aynı majör yüksek minör numaralarını da kullanabilir. 
    Ancak aynı majör yüksek minör numarasını kullanan programlar aynı majör düşük minör numarasını kullanmamalıdır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux sistemlerinde versiyonlama bakımından bir dinamik kütüphanenin üç ismi bulunmaktadır:

    1) Gerçek ismi (real name)
    2) so ismi (so name)
    3) Bağlayıcı ismi (linker name)

    Kütüphanenin majör ve çift minör versiyonlu ismine gerçek ismi denilmektedir. Örneğin:

    libmyutil.so.2.4.6

    "so" ismi ise yalnızca majör numara içeren ismidir. Örneğin yukarıdaki gerçek ismin "so" ismi şöyledir:

    libmyutil.so.2

    Bağlayıcı ismi ise hiç versiyon numarası içermeyen ismidir. Örneğin yukarıdaki kütüphanelerin linker ismi ise şöyledir:

    libmyutil.so

    İşte tipik olarak bağlayıcı ismi en yüksek majör numaralı so ismine, so ismi de en yüksek numaralı gerçek isme sembolik bağlantı
    yapılmaktadır:

    bağlayıcı ismi ---> en yüksek majör numaralı so ismi ---> en yüksek minör numaralı isim

    Örneğin:

    $ gcc -fPIC -o libmyutil.so.1.0.0 -shared -Wl,-soname,libmyutil.so.1 libmyutil.c      (gerçek isimli kütüphane dosyası oluşturuldu)
    $ ln -s libmyutil.so.1.0.0 libmyutil.so.1                                             (so ismi oluşturuldu)
    $ ln -s libmyutil.so.1 libmyutil.so                                                   (bağlayıcı ismi oluşturuldu)

    Burada oluşturulan üç dosyayı "ls -l" komutu ile görüntüleyelim:

    lrwxrwxrwx 1 kaan study    14 Şub 25 15:45 libmyutil.so -> libmyutil.so.1
    lrwxrwxrwx 1 kaan study    18 Şub 25 15:45 libmyutil.so.1 -> libmyutil.so.1.0.0
    -rwxr-xr-x 1 kaan study 15736 Şub 25 15:45 libmyutil.so.1.0.0
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Dinamik kütüphanelerin verisyonlanmasının ve yukarıdaki işlemlerin yapılmasının nedenlerini şöyle özetleyebiliriz:

    1) Bu sayede aynı kütüphanenin değişik versiyonları değişik isimlerle aynı dizinde birlikte bulunabilmektedir.
    2) Çalıştırılabilen bir dosya kütüphanenin bir majör ve minör versiyonunu kullanırken yeniden bağlama işlemi yapılmadan 
    sembolik bağlantı oluşturularak onun yüksek minör numaraya ilişkin kütüphaneyi kullanması sağlanabilmektedir.
    3) Yeni programlar yazılırken en normal durum kütüphanelerin son versiyonlarının kullanılmasıdır. Böylece bağlama aşamasında
    yanlış bir isim ile bağlama yapılabilmektedir.

    Şimdi bu işlemlerden amacı açıklayan bir örnek yapalım:

    1) Yeni yazdığımız kütüphanenin majör ve minör numaraları "1.0.0" olsun. Kütüphaneyi şöyle oluşturmuş olalım.

    $ gcc -fPIC -o libmyutil.so.1.0.0 -shared -Wl,-soname,libmyutil.so.1 libmyutil.c

    Burada biz gerçek ismi "libmyutil.so.1.0.0" olan so ismi "libmyutil.so.1" olan bir dinamik kütüphane oluşturmuş olduk.

    2) Kütüphanenin so ismini en yüksek minör numaraya sembolik link yapalım:

    $ ln -s libmyutil.so.1.0.0 libmyutil.so.1

    Artık elimizde iki dosya vardır:

    $ ls -l libmyutil.so.1.0.0 libmyutil.so.1
    lrwxrwxrwx 1 kaan kaan    18 May 23 21:40 libmyutil.so.1 -> libmyutil.so.1.0.0
    -rwxrwxr-x 1 kaan kaan 15600 May 23 21:36 libmyutil.so.1.0.0

    3) Şimdi de kütüphanenin bağlayıcı ismini en yüksek majör numaralı isme sembolik bağlantı yapalım:

    $ ln -s libmyutil.so.1 libmyutil.so

    Artık elimizde üç dosya vardır:

    $ ls -l libmyutil.so libmyutil.so.1 libmyutil.so.1.0.0
    lrwxrwxrwx 1 kaan kaan    14 May 23 21:42 libmyutil.so -> libmyutil.so.1
    lrwxrwxrwx 1 kaan kaan    18 May 23 21:40 libmyutil.so.1 -> libmyutil.so.1.0.0
    -rwxrwxr-x 1 kaan kaan 15600 May 23 21:36 libmyutil.so.1.0.0

    4) Bu kütüphaneyi kullanan bir "app.c" isimli programı şöyle derleyebiliriz:

    $ gcc -o app app.c libmyutil.so

    Burada aslında bağlama işleminde sembolik link izleneceği için "libmyutil.so.1.0.0" dosyası kullanılmıştır. Bu dosyanın 
    içerisindeki so ismi "libmyutil.so.1" olduğuna göre artık app programı "libmyutil.so.1" dinamik kütüphanesini kullanıyor 
    gibidir:

    $ readelf -d app | grep "NEEDED"
    0x0000000000000001 (NEEDED)             Shared library: [libmyutil.so.1]
    0x0000000000000001 (NEEDED)             Shared library: [libc.so.6]

    5) Artık app programını çalıştırdığımızda bir sorun çıkmayacaktır. Çünkü "libmyutil.so.1" dosyası "libmyutil.so.1.0.0" 
    dosyasına sembolik bağlantı yapılmıştır:

    $ LD_LIBRARY_PATH=. ./app
    foo
    bar

    6) Şimdi "libmyutil.so.1.0.0" kütüphanesinin eskisi ile uyumlu yeni bir versiyonunun oluşturulması istensin. Bu versiyonda 
    foo ve bar iyileştirilmiş olsun ve kütüphaneye birkaç yeni fonksiyon eklenmiş olsun. Bunun versiyon numarasının da 
    "libmyutil.so.1.0.5" olduğunu varsayalım. Şimdi bu yeni kütüphaneyi oluşturalım:

    $ gcc -fPIC -o libmyutil.so.1.0.5 -shared -Wl,-soname,libmyutil.so.1 libmyutil.c

    Artık "libmyutil.so.1.0.5" isimli yeni bir kütüphane versiyonu da oluşturulmuş oldu.

    Bu durumda biz "app" programını çalıştırırsak bu program kütüphanenin "libmyutil.so.1.0.0" versiyonunu kullanacaktır.

    7) Şimdi "app" programına dokunmadan bu "app" programının aynı majör versiyonun yüksek minör versiyonu olan kütüphaneyi 
    kullanmasını sağlayalım:

    $ rm libmyutil.so.1 
    $ ln -s libmyutil.so.1.0.5 libmyutil.so.1
    $ LD_LIBRARY_PATH=. ./app
    daha optimize foo
    daha optimize bar

    Artık "app" programı yeni minör versiyonu kullanmaktadır. Ancak eski minör versiyonlu kütüphane de dizinde bulunmaktadır.

    8) Şimdi de kütüphanemizin "libmyutil.so.2.0.0" biçiminde yeni bir majör versiyonunun oluşturulduğunu varsayalım. 1 numaralı 
    majör versiyonla 2 numaralı majör versiyon birbirleriyle uyumlu değildir. Biz bu "libmyutil.so.2.0.0" yeni versiyonu derlerken 
    ona "so ismi" olarak artık "libmyutil.so.2" ismini vermeliyiz. Tabii bu durumda biz yine "libmyutil.so.2" sembolik bağlantı 
    dosyasının "libmyutil.so.2.0.0" dosyasını göstermesini sağlamalıyız. Artık kütüphanenin 2'nci versiyonunu kullanan programlar
    için yüklenecek kütüphane "libmyutil.so.2" kütüphanesi olacaktır. Bu kütüphanede 2'nci versiyonunun gerçek kütüphane ismine 
    sembolik bağlantı yapılmış durumdadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Dinamik kütüphanelerin bağlayıcı isimleri o kütüphaneyi kullanan programlar bağlama işlemine sokulurken bağlama aşamasında 
    kullanılan isimlerdir. Bu sayede bağlama işlemini yapan programcıların daha az tuşa basarak genel bir isim kullanması sağlanmıştır. 
    Bu durumda örneğin biz libmyutil.so isimli kütüphaneyi kullanan programı şöyle derleyip bağlayabiliriz:

    $ gcc -o app app.c libmyutil.so

    Ya da şöyle yapabiliriz:

    $ gcc -o app app.c -lmyutil -L.

    Burada aslında "libmyutil.so" dosyası "so" ismine, "so" ismi de "gerçek isme" link yapılmış durumdadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												21. Ders 28/05/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    "so ismine" ilişkin sembolik link çıkartma ve "/etc/ld.so.cache" dosyasının güncellenmesi işlemi "ldconfig" programı tarafından 
    otomatik olarak da yapılabilmektedir. Yani aslında örneğin biz kütüphanenin gerçek isimli dosyasını "/lib" ya da "/usr/lib" 
    içerisine yerleştirip "ldconfig" programını çalıştırdığımızda bu program zaten "so ismine" ilişkin sembolik linki de oluşturmaktadır. 
    Örneğin biz "libmyutil.so.1.0.0" dosyasını "/usr/lib" dizinine kopyalayalım ve "ldconfig" programını çalıştıralım. "ldconfig" 
    programı "libmyutil.so.1" sembolik link dosyasını oluşturup bu sembolik link dosyasının "libmyutil.so.1.0.0" dosyasına referans 
    etmesini sağlayacaktır. Tabii cache'e de "libmyutil.so.1" dosyasını yerleştirecektir. Örneğin:

    $ ldconfig -p | grep "libmyutil"
    libmyutil.so.1 (libc6,x86-64) => /lib/libmyutil.so.1
    $ ls -l /usr/lib | grep "libmyutil"
    lrwxrwxrwx  1 root root       18 Mar  1 21:02 libmyutil.so.1 -> libmyutil.so.1.0.0
    -rwxr-xr-x  1 root root    15736 Mar  1 21:01 libmyutil.so.1.0.

    Özetle Dinamik kütüphane kullanırken şu konvansiyona uymak iyi bir tekniktir:

    - Kütüphane ismini "lib" ile başlatarak vermek
    - Kütüphane ismine majör ve minör numara vermek
    - Gerçek isimli kütüphane dosyasını oluştururken "so ismi" olarak "-Wl,-soname" seçeneği ile kütüphanenin "so ismini" yazmak
    - Kütüphane için "bağlayıcı ismi" ve "so ismini" sembolik link biçiminde oluşturmak
    - Kütüphane paylaşılacaksa onu "/lib" ya da tercihen "/usr/lib" dizinine yerleştirmek ve "ldconfig" programı çalıştırarak 
    /etc/ld.so.cache dosyasının güncellenmesini sağlamak
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bazen bir dinamik kütüphane içerisindeki sembollerin o dinamik kütüphaneyi kullanan kodlar tarafından kullanılması istenmeyebilir. 
    Örneğin dinamik kütüphanede "bar" isimli bir fonksiyon vardır. Bu fonksiyon bu dinamik kütüphanenin kendi içerisinden başka 
    fonksiyonlar tarafından kullanılıyor olabilir. Ancak bu fonksiyonun dinamik kütüphanenin dışından kullanılması istenmeyebilir.
    (Bunun çeşitli nedenleri olabilir. Örneğin kapsülleme sağlamak için, dışarıdaki sembol çakışmalarını ortadan kaldırmak için vs.) 
    İşte bunu sağlamak için dışarıdan kullanılmasını istemediğiniz kütüphane fonksiyonlarını static olarak tanımlamalısınız. Böylece
    bu fonksiyonlar dışarıdan kullanılmak istendiğinde bağlama aşamasında error oluşacaktır. Aynı işlem gcc ve clang derleyicilerine 
    özgü "__attribute__((...))" eklentisiyle de yapılabilmektedir. "__attribute__((...))" eklentisi pek çok seçeneğe sahip platform 
    spesifik bazı işlemlere yol açmaktadır. Bu eklentinin seçeneklerini gcc dokümanlarından elde edebilirsiniz. Bizim bu amaçla 
    kullanacağımız "__attribute__((...))" seçeneği "visibility" isimli seçenektir.

    Aşağıdaki örnekte bar fonksiyonu foo fonksiyonu tarafından kullanılmaktadır. Ancak kütüphanenin dışından bu fonksiyonun 
    kullanılması istenmemiştir. Eğer fonksiyon isminin soluna "__attribute__((visibility("hidden")))" yazılırsa bu durumda 
    bu fonksiyon dinamik kütüphanenin dışından herhangi bir biçimde kullanılamaz. Örneğin:

    void __attribute__((visibility("hidden"))) bar(void)
    {
        // ...
    }

    Burada fonksiyon özelliğinin (yani __attribute__ sentaksının) fonksiyon isminin hemen soluna getirildiğine ve çift parantez 
    kullanıldığına dikkat ediniz. Burada kullanılan özellik "visibility" isimli özelliktir ve bu özelliğin değeri "hidden" 
    biçiminde verilmiştir.

    Aşağıdaki örnekte "libmyutil.so.1.0.0" kütüphanesindeki foo fonksiyonu dışarıdan çağrılabildiği halde bar fonksiyonu 
    dışarıdan çağrılamayacaktır. Tabii kütüphane içerisindeki foo fonksiyonu bar fonksiyonunu çağırabilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Dinamik kütüphanelerde son olarak "sembol versiyonlaması (symbol versioning)" konusu üzerinde duracağız. Sembol versiyonlaması 
    nispeten yeni bir özelliktir. Bu özelliği uygulayabilmek için ELF formatına üç ayrı bölüm (section) eklenmiştir. Biz bu problemle
    daha önce karşılaşmıştık. Host makinede çapraz derleme yapıp çalıştırılabilen dosyayı BBB'ye taşıdığımızda sembol versiyonlamasına
    ilişkin bir hata ortaya çıkmıştı.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Sembol versiyonlamasının ana amacı bir fonksiyonun değişik versiyonlarının aynı dinamik kütüphane içerisinde bulundurulmasıdır.
    Böylece eski programlar fonksiyonun eski versiyonunu kullanırken yeni programlar fonksiyonun yeni versiyonunu kullanabilecektir.
    Aslında bu işlemlerin için biz dinamik kütüphanelerin versiyonlanması yoluyla yapıldığını yukarıda görmüştük. Örneğin foo
    fonksiyonunun eskisiyle uyumlu olmayan yeni bir versiyonu oluşturulacaksa majör numarala artırılıp yeni bir dinamik kütüphane
    yaratılabiliyodu. İşte sembol versiyonlaması dinamik kütüphane versiyonlamasına bir alternatif oluşturmaktadır. Belki ileride
    sembol versiyonlaması dinamik kütüphane versiyonlamasının yerine geçebilecektir. Çok sayıda fonksiyondan oluşan bir dinamik
    kütüphane oluşturduğumuzu varsayalım. Ancak bu kütüphanedeki foo fonksiyonunun geçmişle uyumu olmayan yeni bir versiyonunu
    yazmak istediğimizi düşünelim. Tek bir fonksiyon için yeni bir kütüphane oluşturup majör numarayı artırmak yerine sembol 
    versiyonlamasını kullanabiliriz.

    Sembol versiyonlaması aynı isimli bir fonksiyonun değişik versiyonlarının aynı dinamik kütüphane içerisinde bulundurulmasının
    sağlanmasına yönelik mekanizmayı belirtmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Sembol versiyonlamasının nasıl yapıldığını adım adım bir örnekle açıklayalım:

    1) Oluşturduğumuz kütüphanede foo, bar ve tar isimli üç fonksiyon bulunuyor olsun. Biz bu fonksiyonlara MYUTIL-1.0 versiyon
    numarasını atamak isteyelim. Bunun için bir bağlayıcı script'i oluşturup onun içerisindeki fonksiyonlara bu script ile
    version yazısı atamak gerekmektedir. Örneğin:

    /* myutil.h */

    #ifndef MYUTIL_H_
    #define MYUTIL_H_

    void foo(void);
    void bar(void);
    void tar(void);

    #endif

    /* libmyutil.c */

    #include <stdio.h>
    #include "myutil.h"

    void foo(void)
    {
        printf("foo: VERSION-1.0\n");
    }

    void bar(void)
    {
        printf("bar: VERSION-1.0\n");
    }

    void tar(void)
    {
        printf("tar: VERSION-1.0\n");
    }

    /* libmyutil.map */

    MYUTIL_VERSION_1.0 {
        global: foo; bar;
        local: *;
    };

    Bu scriptteki cümlecik foo ve bar fonksiyonuna VERSION_1.0 versiyon yazısının atanacağını belirtmektedir. Bağlayıcı script'lerinin
    ayrıntıları için aşağıdaki dokümana başvurabilirsiniz:

    https://ftp.gnu.org/old-gnu/Manuals/ld-2.9.1/html_chapter/ld_toc.html#TOC6

    Bağlayıcı script'indeki "local: *" satırı "geri kalan bütün fonksiyonlar dışarıdan kullanılmasın" anlamına gelmektedir. 
    Eğer scriptimizi böyle bırakırsak "tar fonksiyonunu dışarıdan kullanamayız. Tabii aynı işlem anımsanacağı gibi "static"
    belirleyicisi ile ya da __attribute__ belirleyicisi ile de yapılabiliyordu. Biz tar fonksiyonun da dışarıdan kullanılmasını
    sağlamak için bu local satırını kaldıralım:

    /* libmyutil.map */

    MYUTIL_VERSION_1.0 {
        global: foo; bar;
    };

    Kütüphaneyi aşağıdaki gibi derleyelim:

    $ gcc -fPIC -shared -Wl,--version-script,libmyutil.map -o libmyutil.so libmyutil.c

    2) Şimdi bu versiyonu kullana app1.c programını yazalım:

    #include <stdio.h>
    #include "myutil.h"

    int main(void)
    {
        foo();
        bar();
        tar();

        return 0;
    }

    Programı şöyle derleyebiliriz:

    $ gcc -o app1 app1.c libmyutil.so

    Programı aşağıdaki gibi çalıştırabiliriz:

    $ LD_LIBRARY_PATH=. ./app1
    foo: VERSION-1.0
    bar: VERSION-1.0
    tar: VERSION-1.0

    3) ELF formatındaki sembol versiyonlamasına ilişkin bölümler readelf programında "-V" seçeneği ile objdump programında da 
    "-T" seçeneği ile görüntülenebilir. Örneğin:

    $ readelf -V libmyutil.so

    Version symbols section '.gnu.version' contains 12 entries:
    Addr: 0x00000000000003e4  Offset: 0x0003e4  Link: 3 (.dynsym)
    000:   0 (*local*)       0 (*local*)       0 (*local*)       0 (*local*)
    004:   3 (GLIBC_2.17)    0 (*local*)       3 (GLIBC_2.17)    0 (*local*)
    008:   2 (MYUTIL_VERSION_1.0)        2 (MYUTIL_VERSION_1.0)        1 (*global*)      2 (MYUTIL_VERSION_1.0)

    Version definition section '.gnu.version_d' contains 2 entries:
    Addr: 0x0000000000000400  Offset: 0x000400  Link: 4 (.dynstr)
    000000: Rev: 1  Flags: BASE  Index: 1  Cnt: 1  Name: libmyutil.so
    0x001c: Rev: 1  Flags: none  Index: 2  Cnt: 1  Name: MYUTIL_VERSION_1.0

    Version needs section '.gnu.version_r' contains 1 entry:
    Addr: 0x0000000000000438  Offset: 0x000438  Link: 4 (.dynstr)
    000000: Version: 1  File: libc.so.6  Cnt: 1
    0x0010:   Name: GLIBC_2.17  Flags: none  Version: 3

    $ readelf -V app1

    Version symbols section '.gnu.version' contains 12 entries:
    Addr: 0x0000000000000486  Offset: 0x000486  Link: 5 (.dynsym)
    000:   0 (*local*)       0 (*local*)       0 (*local*)       0 (*local*)
    004:   2 (GLIBC_2.17)    3 (MYUTIL_VERSION_1.0)        2 (GLIBC_2.17)    3 (MYUTIL_VERSION_1.0)
    008:   0 (*local*)       2 (GLIBC_2.17)    0 (*local*)       0 (*local*)

    Version needs section '.gnu.version_r' contains 2 entries:
    Addr: 0x00000000000004a0  Offset: 0x0004a0  Link: 6 (.dynstr)
    000000: Version: 1  File: libmyutil.so  Cnt: 1
    0x0010:   Name: MYUTIL_VERSION_1.0  Flags: none  Version: 3
    0x0020: Version: 1  File: libc.so.6  Cnt: 1
    0x0030:   Name: GLIBC_2.17  Flags: none  Version: 2

    Görüldüğü gibi sembol versiyonlamasına ilişkin farklı amaçlarla oluşturulmuş üç farklı bölüm bulunmaktadır.

    4) Şimdi de fonksiyonunun eskisiyle uyumlu olmayan yeni bir versiyonunu kütüphaneye ekleyecek olalım. Bunun üç şey yapmamız
    gerekir:

        - Birincisi "libmyutil.c" dosyasında foo fonksiyonun yeni bir versiyonun başka bir isim altına oluşturulması gerekir.
        - İkincisi gcc'ye clang derleyicilerine özgü olan __asm__ direktifi ile foo fonksiyonun eski versiyonunun ismi ile 
        yeni versiyonun isminin belirlenmesi gerekir. Bu belirleme şöyle yapılmaktadır:

        __asm__(".symver foo,foo@MYUTIL_VERSION_1.0");
        __asm__(".symver foo_v2,foo@MYUTIL_VERSION_2.0");

        Buradaki birinci __asm__ direktifi foo fonksiyonunun eski "MYUTIL_VERSION_1.0" sahip olduğunu belirtmektedir. İkinci 
        __asm__ direktifi ise "artık dışarıdan foo ismiyle kullanılacak olan fonksiyonun" foo_v2 anlamına geleceğini belirtmektedir. 
        Bu direktiflerdeki @ sembolü isim ile versiyon numarasını ayırmaktadır. @@ sembolü ise "default versiyon" anlamına gelmektedir.
        Yani artık dışarıdan yapılacak foo çağrısının kütüphanedeki foo_v2 fonksiyonuna referans edeceği belirtilmektedir. 
        Böylece yeni programlar foo fonksiyonunu çağırdığında bu yeni foo_v2 fonksiyonunu çağırırken eski programlar foo fonksiyonunu
        çağıracaktır.
        - Üçüncüsü bağlayıcı scriptinde foo ile foo_v2 fonksiyonlarının farklı versiyonlara ilişkin olduğu belirtilmelidir. 
        Bu belirtme aşağıdaki gibi yapılmaktadır:

        MYUTIL_VERSION_1.0 {
            global: foo; bar;
        };

        MYUTIL_VERSION_2.0 {
            global: foo_v2;
        } MYUTIL_VERSION_1.0;

    Artık kütüphaneyi yeniden aşağıdaki gibi yazabiliriz:

    /* libmyutil.c */

    #include <stdio.h>
    #include "myutil.h"

    __asm__(".symver foo,foo@MYUTIL_VERSION_1.0");
    __asm__(".symver foo_v2,foo@MYUTIL_VERSION_2.0");

    void foo(void)
    {
        printf("foo: VERSION-1.0\n");
    }

    void bar(void)
    {
        printf("bar: VERSION-1.0\n");
    }

    void tar(void)
    {
        printf("tar: VERSION-1.0\n");
    }

    void foo_v2(void)
    {
        printf("foo: VERSION-2.0\n");
    }

    Derleme işlemini şöyle yapabiliriz:

    $ gcc -fPIC -shared -Wl,--version-script,libmyutil.map -o libmyutil.so libmyutil.c

    Şimdi de kütüphanenin yeni versiyonunu kullanan "app2.c" programını yazalım:

    /* app2.c */

    #include <stdio.h>
    #include "myutil.h"

    int main(void)
    {
        foo();
        bar();
        tar();

        return 0;
    }

    Artık app1 programı foo fonksiyonun eski versiyonunu kullanırken app2 programı yeni versiyonunu kullanmaktadır. Ancak ortada
    tek bir kütüphane dosyası vardır.

    $ LD_LIBRARY_PATH=. ./app1
    foo: VERSION-1.0
    bar: VERSION-1.0
    tar: VERSION-1.0

    $ LD_LIBRARY_PATH=. ./app2
    foo: VERSION-2.0
    bar: VERSION-1.0
    tar: VERSION-1.0

    Pekiyi foo fonksiyonun üçüncü bir versiyonunu nasıl oluşturabiliriz? Tabii yukarıda yaptığımız işlemlerin benzerlerini yaparak:

    /* libmyutil.c */

    #include <stdio.h>
    #include "myutil.h"

    __asm__(".symver foo,foo@MYUTIL_VERSION_1.0");
    __asm__(".symver foo_v2,foo@MYUTIL_VERSION_2.0");
    __asm__(".symver foo_v3,foo@@MYUTIL_VERSION_3.0");

    void foo(void)
    {
        printf("foo: VERSION-1.0\n");
    }

    void bar(void)
    {
        printf("bar: VERSION-1.0\n");
    }

    void tar(void)
    {
        printf("tar: VERSION-1.0\n");
    }

    void foo_v2(void)
    {
        printf("foo: VERSION-2.0\n");
    }

    void foo_v3(void)
    {
        printf("foo: VERSION-3.0\n");
    }

    Bağlayıcı script'i de şöyle olmalıdır:

    /* libmyutil.map */

    MYUTIL_VERSION_1.0 {
        global: foo; bar;
    };

    MYUTIL_VERSION_2.0 {
        global: foo_v2;
    } MYUTIL_VERSION_1.0;

    MYUTIL_VERSION_3.0 {
        global: foo_v3;
    } MYUTIL_VERSION_2.0;

    Derlemeyi yine şöyle yapabiliriz:

    $ gcc -fPIC -shared -Wl,--version-script,libmyutil.map -o libmyutil.so libmyutil.c

    Şimdi de foo fonksiyonunun üçüncü versiyonunu kullanan app3 programını yazıp derleyelim:

    /* app3.c */

    #include <stdio.h>
    #include "myutil.h"

    int main(void)
    {
        foo();
        bar();
        tar();

        return 0;
    }

    Artık üç ayrı program foo fonksiyonunun üç ayrı versiyonunu kullanmaktadır. Ancak toplamda tek bir kütüphane dosyası vardır:

    $ LD_LIBRARY_PATH=. ./app1
    foo: VERSION-1.0
    bar: VERSION-1.0
    tar: VERSION-1.0

    $ LD_LIBRARY_PATH=. ./app2
    foo: VERSION-2.0
    bar: VERSION-1.0
    tar: VERSION-1.0

    $ LD_LIBRARY_PATH=. ./app3
    foo: VERSION-3.0
    bar: VERSION-1.0
    tar: VERSION-1.0
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												22. Ders 30/05/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çok prosesli (multiprocessing) işletim sistemlerinin çalıştığı donanımlarda kullanılan mikroişlemcilerin "koruma mekanizması 
    (protection mechanism)" denilen bir özelliği vardır. Çok prosesleri sistemlerde bütün programlar o anda RAM'de bir biçimde 
    bulunmaktadır. Tabii işletim sisteminin kendisi de RAM'de bulunur. Bir programın göstericiler yoluyla kendi bellek alanının 
    dışına çıkarak başka bir prosesin bellek alanına erişmesi mutlaka engellenmesi gereken bir durumdur. Çünkü eğer bu durum 
    engellenmezse bir program başka bir programın bellek alanını bozabilir. Bu bozulma da o programın hatalı çalışmasına ya da 
    çökmesine yol açabilir. Program başka bir programın bellek alanını bozmasa bile oradaki programlar üzerinde casusluk 
    faaliyetleri yürütebilir. Buna ek olarak bazı makine komutları tamamen sistemin çökmesine de yol açabilmektedir. Bu makine 
    komutlarını kullanan programlar tüm sistemi çökertebileceği için bu durumun da önüne geçilmesi gerekir. İşte işlemcilerin
    koruma mekanizması bu tür ihlallerin birinci elden işlemci tarafından tespit edilip engellenmesini sağlamaktadır.

    İşlemcilerin koruma mekanizmasının iki yönü vardır:

    1) Bellek Koruması
    2) Komut Koruması

    Bellek koruması bir prosesin kendi bellek alanının dışına erişimlerinin tespit edilmesine yönelik mekanizmadır. Komut koruması 
    ise sistemi çökertme potansiyeline sahip makine komutlarının kullanımının engellenmesine yönelik mekanizmadır.

    Tabii her türlü mikroişlemci böyle bir mekanizmaya sahip değildir. Ancak güçlü işlemcilerde bu mekanizma bulunmaktadır. 
    Örneğin Intel'in 80386 ve sonrası işlemcileri ARM'nin Cortex A ve Cortex R serisi işlemcileri, Alpha işlemcileri, PowerPC 
    işlemcileri, Itanium işlemcileri bu mekanizmalarsa sahiptir. Mikrodenetleyicilerde genel olarak küçük işlemciler bulunduğu için 
    bunlar koruma mekanizmasına sahip değillerdir. Windows gibi Linux gibi macOS gibi işletim sistemleri bu mekanizmaya sahip 
    olmayan işlemcilerin bulunduğu donanımlarda kullanılamazlar.

    Bir prosesin bellek korumasını ve komut korumasını ihlal etmesi birinci elden mikroişlemci tarafından tespit edilmektedir. 
    Mikroişlemci ihlali tespit eder ve işletim sistemine bildirir. İşletim sistemi de hemen her zaman programı sonlandırır.

    Öte yandan çekirdek içerisindeki kodların ve aygıt sürücülerin kodlarının bu koruma engeline takılmaması gerekmektedir. Çekirdek 
    belleğin her yerine erişebilmelidir. Çünkü programları bile belleğe yükleyen çekirdektir. Aynı zamanda çekirdek sistemi çökertme 
    potansiyelinde olan pek çok makine komutunu uygun bir biçimde kullanmaktadır. Benzer biçimde aygıt sürücüler de mecburen 
    bu tür makine komutlarını kullanmak zorundadırlar. İşte çekirdek kodlarının ve aygıt sürücü kodlarının bir biçimde bu koruma 
    mekanizmasından muaf olması gerekmektedir.

    İşlemcileri tasarlayanlar genellikle prosesler için iki çalışma modu tanımlamışlardır: "Kernel Mode" ve "User Mode".
    Eğer bir kod "kernel mode'da" çalışıyorsa işlemci koruma mekanizmasını o kod için işletmez. Böylece o kod her şeyi yapabilir. 
    Ancak eğer bir kod "user mode'da" çalışıyorsa işlemci o kod için koruma mekanizmasını işletmektedir. Normal programların hepsi 
    user mode'da çalışmaktadır. Ancak kernel kodları ve aygıt sürücüler (kernel modülleri) kernel mode'da çalışırlar.

    Bir programın "sudo" ile çalıştırılmasının (yani programın proses id'sinin 0 olmasının) bu konuyla hiçbir ilgisi yoktur. 
    Proses id'nin 0 olması yalnızca dosya erişimleri için avantaj sağlayabilmektedir. Yoksa biz bir programı "sudo" ile çalıştırsak 
    bile o program yine "user mode'da" çalıştırılmaktadır.

    Pekiyi biz kendi programımızı kernel mode'da çalıştıramaz mıyız? Bu sorunun yanıtı genel olarak "hayır" biçimindedir. Bunun tek 
    yolu "aygıt sürücü" ya da "kernel modül" denilen biçimde kod yazmaktır. Zaten aygıt sürücülerin en önemli özelliği onların 
    kernel mode'da çalışmasıdır. Tabii aygıt sürücüler ancak sistem yöneticisi tarafından bir parola eşliğinde (yani sudo ile) 
    yüklenebilmektedir.

    İşletim sistemlerinde sistemle ilgili önemli işler yapan bazı fonksiyonların "user mode'tan" çağrılmasına izin verilmiştir. 
    Bu fonksiyonlara "sistem fonksiyonları (system calls)" denilmektedir. Bazı POSIX fonksiyonları işletim sisteminin sistem 
    fonksiyonlarını çağırarak işlemlerini yapmaktadır. Tabii işletim sistemlerinin sistem fonksiyonları sistemden sisteme 
    değişebilmektedir. Oysa POSIX fonksiyonları her UNIX türevi sistemde aynı biçimde kullanılabilecek taşınabilir fonksiyonlardır.

    Sistem fonksiyonları kernel'ın içerisindeki fonksiyonlardır. Dolayısıyla bu fonksiyonlar özel makine komutlarını kullanırlar ve 
    bellekte her yere erişebilirler. Aksi takdirde bu fonksiyonların yazılabilmesi mümkün değildir. Pekiyi bizim programlarımız
    user mode'da çalıştığına göre biz bir sistem fonksiyonunu çağırdığımızda ne olacaktır? İşte user mode bir proses bir sistem 
    fonksiyonunu çağırdığında prosesin modu otomatik olarak kernel moda geçirilmektedir. Böylece sistem fonksiyonu yine kernel 
    mode'da çalışmış olmaktadır. Sistem fonksiyonunun çalışması bittiğinde proses yine otomatik olarak user mode'a dönmektedir. 
    Örneğin Intel işlemcilerinde bu geçişi sağlayan mekanizmaya "kapı (gate)" denilmektedir. Tabii kapı yerleştirmek kernel mode'da 
    yapılabilecek bir işlemdir. Dolayısıyla user mod bir proses yalnızca zaten belirlenmiş olan kodları çalıştırmak üzere kernel moda 
    geçebilmektedir.

    Sistem fonksiyonlarını çağırmanın zamansal bir maliyeti vardır. Çünkü prosesin user mode'dan kernel moda geçmesi ve birtakım 
    gerekli kontrollerin kernel mode'da yapılması zaman kaybına yol açmaktadır. Örneğin:

    read(fd, (char *)0x123456, 10)

    Linux'ta read POSIX fonksiyonu doğrudan sys_read isimli sistem fonksiyonunu çağırmaktadır. Eğer bu sistem fonksiyonu ikinci 
    parametreyle verilen adresi hiç kontrol etmezse koruma mekanizmasından da muaf olduğu için tuzağa düşecektir. İşte bu tür 
    sistem fonksiyonları kesinlikle adreslerin o prosesin alanı içerisinde olup olmadığını test ederler. Bunun gibi pek çok 
    yapılması gereken irili ufaklı kontroller vardır.

    O halde aslında bir proses yaşamının önemli bir kısmını user mode'da geçirirken bir kısmını da kernel mode'da geçirebilmektedir. 
    Örneğin "time" isimli kabuk komutuyla biz prosesin ne kadar zamanı kernel mode'da ne kadar zamanı user mode'da geçirdiğini görebiliriz:

    $ time ./sample

    real	0m0,189s
    user	0m0,185s
    sys	0m0,005s

    Burada "sys" kernel modu, "user" user modu ve "real" da toplam zamanı vermektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Modern kapasiteli mikroişlemcilerde "sayfalama (paging)" denilen önemli bir mekanizma vardır. Örneğin Intel işlemcileri 
    bu sayfalama mekanizmasına 80386 modelleriyle birlikte sahip olmuştur. ARM Cortex A serisi ve Cortex M serisi işlemcilerin 
    de bu mekanizmaları vardır. Itanium, PowerPC gibi işlemciler"de de sayfalama mekanizması bulunmaktadır. Genellikle koruma 
    mekanizmasına sahip işlemciler sayfalama mekanizmasına da sahip olurlar. Ancak koruma mekanizmasına sahip olduğu halde 
    sayfalama mekanizmasına sahip olmayan işlemciler de vardır. Sayfalama mekanizması güçlü işlemcilerde bulunan bir mekanizmadır. 
    Genel olarak mikrodenetleyicilerde bu mekanizma yoktur. Örneğin ARM'ın Cortex M serisi mikrodenetleyicilerinde sayfalama 
    mekanizması bulunmamaktadır. Ayrıca işlemcilerdeki bu sayfalama mekanizması aktif ve pasif duruma getirilebilmektedir. 
    Yani işlemci sayfalama mekanizmasına sahip olduğu halde sistem programcısı bu mekanizmayı açmayabilir ve kullanmayabilir. 
    İşlemciler reset edildiğinde sayfalama mekanizması pasif durumdadır. İşletim sistemleri bazı ön hazırlıkları yaptıktan sonra
    bu mekanizmayı açmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Sayfalama mekanizmasında fiziksel RAM aynı zamanda "sayfa (page)" denilen ardışıl bloklara ayrılır. Sayfa uzunluğu sistemden
    sisteme hatta aynı işlemcide işlemcinin modundan moduna değişebilir. Ancak en tipik kullanılan sayfa uzunluğu 4096 (4K) 
    byte'tır. Gerçekten de bugün Linux, Windows ve macOS sistemleri 4K'lık sayfalar kullanmaktadır. Sayfalama mekanizması etkin 
    hale getirildiğinde işlemci RAM'deki her sayfaya bir sayfa numarası karşılık getirir. Örneğin ilk 4096 byte 0'ıncı sayfaya, 
    sonraki 4096 byte 1'inci sayfaya ilişkindir. Sayfalar bu biçimde ilk sayfa 0'dan başlatılarak ardışıl biçimde numaralandırılmaktadır. 
    Yani her byte aslında bir sayfa içerisinde bulunur.

    Bir program içerisinde kullanılan yani derleyicinin ürettiği adresler aslında gerçek fiziksel adresler değildir. Bu adreslere 
    "sanal adresler (virtual addresses)" denilmektedir. Derleyiciler kodları sanki geniş bir RAM'de program tek başına çalışacakmış 
    gibi üretmektedir. Örneğin 32 bit işlemcilerin kullanıldığı bir Linux sisteminde derleyici sanki program 4 GB'lik RAM'de tek başına 
    4 MB'den itibaren yüklenecekmiş gibi kod üretmektedir. Yani örneğin 32 bit Linux sistemlerinde (Windows ve macOS'te de böyle) 
    sanki derleyiciler program 4 GB bellekte 4 MB'den itibaren tek başlarına yüklenecekmiş gibi bir kod üretmektedir. Her program 
    derlendiğinde aynı biçimde kod üretilmektedir. Çünkü derleyicinin ürettiği bu adresler sanal adreslerdir. Pekiyi her program 
    aynı biçimde sanki RAM'in 4 MB'sinden başlanarak ardışıl bir biçimde yüklenecekmiş gibi bir koda sahipse bu programlar nasıl 
    çalışmaktadır?

    İşte sayfalama mekanizmasına sahip olan CPU'lar aslında "sayfa tablosu (page table)" denilen bir taloya bakarak çalışırlar. 
    Sayfa tablosu sanal sayfa numaralarını fiziksel sayfa numaralarına eşleyen bir tablodur. Sayfa tablosunun görünümü aşağıdaki 
    gibidir:

    Sanal Sayfa No              Fiziksel Sayfa No
    ...                         ...
    4562                        17456
    4563                        18987
    4564                        12976
    ...                         ...

    Şimdi Intel işlemcisinin aşağıdaki gibi bir makine kodunu çalıştırdığını düşünelim:

    MOV EAX, [05C34782]

    Burada makine komutu bellekte 05C34782 numaralı adresten başlayan 4 byte erişmek istemektedir. İşlemci önce bu adres değerinin 
    kaçıncı sanal sayfaya karşılık geldiğini hesaplar. Bu hesap işlemci tarafından oldukça kolay bir biçimde yapılır. Sayı 12 kere 
    sağa ötelenirse başka bir deyişle sayının sağındaki 3 hex digit atılırsa bu sanal adresin kaçıncı sanal sayfaya karşılık geldiği 
    bulunabilir:

    05C34782 >> 12 = 05C34 (sanal sayfa no, decimal 23604)

    Artık işlemci sayfa tablosunda 0x5C34 yani decimal 23604 numaralı girişe bakar. Sayfa tablosunun ilgili kısmı şöyle olsun:

    Sanal Sayfa No  (decimal/hex)   Fiziksel Sayfa No (decimal/hex)
    ...                         ...
    23603 (5C33)                      47324 (B8DC)
    23604 (5C34)                      52689 (CDD1)
    23605 (5C35)                      29671 (73E7)
    ...                         ...

    Burada 23604 (5C34) numaralı sanal sayfa 52689 (CDD1) fiziksel sayfasına yönlendirilmiştir. Pekiyi işlemci hangi fiziksel adrese 
    erişecektir? İşte bizim sanal adresimiz 05C34782 idi. Bu adres iki kısma ayrıştırılabilir:

    05C24   Sanal sayfa no (hex)
    782     Sayfa offset'i (hex)

    Bu durumda işlemci aslında fiziksel RAM'de 52689 (CDD1)'uncu fiziksel sayfanın 1922 (782) byte'ına erişecektir. O zaman gerçek
    bellekteki erişim adresi 52689 (CDD1) * 4096 (1000) + 1922 (782) olacaktır.

    Burada özetle anlatılmak istenen şey şudur: İşlemci her bellek erişiminde erişilecek sanal adresi iki kısma ayırır: "Sanal Sayfa 
    No" ve "Sayfa Offset'i". Sonra sayfa tablosuna giderek sanal sayfa numarasına karşı gelen fiziksel sayfa numarasını elde eder. 
    O fiziksel sayfanın sayfa offet'i ile belirtilen byte'ına erişir. Örneğin şöyle bir fonksiyon çağırmış olalım:

    foo();

    Derleyicimiz de şöyle bir kod üretmiş olsun:

    CALL 06F14678  (hex)

    Burada 06F14678 foo fonksiyonunun sanal bellek adresidir. Derleyici bu adresi üretmiştir. Ancak program çalışırken işlemci bu adresi 
    ikiye ayırır (hex olarak konuşacağız):

    06F146      Sanal Sayfa No (hex)
    678         Sayfa Offseti (hex)

    Sonra sayfa tablosuna gider ve 06F146 sayfasının hangi fiziksel sayfaya yönlendirildiğini tespit eder. Bu fiziksel sayfanın 
    hex olarak 7C45 olduğuna düşünelim. O zaman işlemcinin erişeceği fiziksel adres 7C45000 + 678 hex adresi olacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Buraya kadar şunları anladık:

    - Derleyici 32 bit bir sistemde sanki program 4 GB'lik bir RAM'de tek başına 4 MB'ye yüklenerek çalıştırılacakmış gibi bir kod
    üretmektedir.

    - İşlemci kodu çalıştırırken her bellek erişiminde sayfa tablosuna bakıp aslında o sanal adresleri fiziksel adreslere dönüştürmektedir.

    Pekiyi sayfa tablosunu kim oluşturmaktadır? Sayfa tablosu işletim sistemi tarafından proses belleğe yüklenirken (exec fonksiyonları 
    tarafından) oluşturulmaktadır. İşletim sisteminin yükleyicisi (loader) programı 4K'lık parçalara ayırarak sanal sayfa numaraları 
    ardışıl ancak fiziksel sayfa numaraları ardışıl olmayacak biçimde fiziksel RAM'e yüklemektedir. Yani işletim sistemi fiziksel 
    RAM'deki boş sayfalara bakar. Programın 4K'lık kısımlarını bu fiziksel RAM'deki boş sayfalara yükler ve sayfa tablosunu buradan 
    hareketle oluşturur.

    Aslında sayfa tablosu bir tane değildir. İşletim sistemi her proses için ayrı bir sayfa tablosu oluşturmaktadır. CPU'lar sayfa 
    tablolarını belli bir yazmacın gösterdiği yerde ararlar (Örneğin Intel işlemcilerinde sayfa tablosu CR3 yazmacının gösterdiği 
    yerdedir.) İşletim sistemi thread'ler arası geçiş (context switch) yapıldığında çalışmasına ara verilen thread ile yeni 
    geçilen thread'in aynı prosesin thread'leri olup olmadığına bakar. Eğer yeni geçilen thread ile çalışmasına ara verilen thread aynı 
    prosese ilişkinse sayfa tablosu değiştirilmez. Çünkü aynı prosesin thread'leri aynı sanal bellek alanını kullanmaktadır. Ancak 
    yeni geçilen thread kesilen thread'le farklı proseslere ilişkinse işletim sistemi CPU'nun gördüğü sayfa tablosunu da değiştirmektedir. 
    Böylece aslında bir prosesin thread'i çalışırken CPU o prosesin sayfa tablosunu gösterir durumda olur.

    Her prosesin sayfa tablosu birbirinden farklı olduğu için iki farklı prosesteki sanal adresler aynı olsa bile bu adreslerin 
    fiziksel karşılıkları farklı olacaktır. Örneğin aynı programı iki kez çalıştıralım. Bu durumda bu iki proses için işletim 
    sistemi iki farklı sayfa tablosu kullanıp aynı sanal adresleri farklı fiziksel sayfalara yönlendirecektir. Böylece aslında 
    aynı sanal adreslere sahip olan programlar farklı fiziksel adreslere sahip olacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Konu ile ilgili sorular ve kısa cevapları şöyledir:

    Soru: Bir programı debugger ile inceliyorum. Orada bir nesnenin adresini görüyorum. Bu adres nasıl bir adresitir?
    Yanıt: Bu adres sanal bir adrestir. İşlemci bu adrese erişmek istediğinde aslında sayfa tablosu yoluyla fiziksel olan başka 
    bir adrese erişecektir.

    Soru: İki farklı programda sanal 5FC120 adresi kullanılıyorsa bunlar fiziksel RAM'de aynı yeri mi gösteriyordur?
    Yanıt: Hayır, çünkü işletim sistemi her proses için farklı bir sayfa tablosu oluşturmaktadır. Bir thread çalışırken işlemci 
    o thread'e ilişkin prosesin sayfa tablosunu kullanıyor durumdadır. Dolayısıyla bu iki farklı proseste işletim sistemi sayfa 
    tablolarının ilgili sayfalarını aslında farklı fiziksel sayfalara yönlendirmiş durumdadır.

    Soru: 32 bit bir derleyicinin ürettiği kodun aslında sanki 4 GB belleğe tek başına 4 MB'den itibaren yüklenecekmiş gibi üretildiği 
    söylendi. Sanal bellek alanındaki bu 4 MB boşluğun anlamı nedir?
    Yanıt: Bunun çok özel bir anlamı yoktur. Bir kere NULL adres için en az bir sayfa gerekmektedir. Pek çok işletim sistemi
    güvenlik amacıyla ve bazı başka nedenlerden dolayı sanal bellek alanının belli bir bölümünü boş bırakmaktadır. Windows'ta da
    bu alan 4 MB'dir. Ancak programın minimal yüklenme adresi 64K'ya kadar düşürülebilmektedir.

    Soru: CPU sayfa tablosunun yerini nereden bilmektedir?
    Yanıt: CPU'lar sayfa tablosunu özel bir yazmacın gösterdiği yerde arayacak biçimde tasarlanmıştır. Dolayısıyla context switch 
    sırasında aslında işletim sistemi yazmacın değerini değiştirmektedir. Yani işletim sistemi aslında tüm proseslerin sayfa 
    tablolarını fiziksel RAM'da oluşturur. Context switch sırasında yalnızca sayfa tablosunun yerini belirten ilgili yazmacın 
    değerini değiştirir.

    Soru: Sayfalama mekanizması CPU'nun çalışmasını yavaşlatmaz mı?
    Yanıt: Teorik olarak sayfalama mekanizması CPU'nun çalışmasını yavaşlatabilir. Ancak bugünkü CPU'ların çalışma hızları zaten 
    bu sayfalama mekanizmasının aktif olduğu durumla belirlenmektedir. Dolayısıyla donanımsal olarak sayfalama mekanizması iyi 
    bir biçimde oluşturulduğu için buradaki hız kaybı önemsenecek ölçüde değildir. Ayrıca işlemciler sayfa tablosuna erişimi 
    azaltmak için zaten onun bazı bölümlerini kendi içlerindeki bir cache sisteminde tutabilmektedir. Ayrıca sayfa girişlerine 
    hızlı erişim için işlemciler TLB (Translation Lookaside Buffer) denilen bir cache mekanizması da oluşturmaktadır.

    Soru: Sayfalama mekanizmasına ne gerek vardır?
    Yanı: Bu durum izleyen paragraflarda ele alınacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    İşletim sistemi her proses için ayrı bir sayfa tablosu oluşturduğuna göre ve bu sayfa tablosunda aynı sanal sayfa numaralarını 
    zaten farklı fiziksel sayfalara yönlendirdiğine göre aslında hiçbir proses diğerinin alanına erişemez. Yani proseslerin 
    birbirlerinin alanlarına erişmesi zaten sayfalama mekanizmasıyla engellenmiş olmaktadır. Bu duruma "sayfalama mekanizması 
    ile proseslerin fiziksel bellek alanlarının izole edilmesi" denilmektedir. Örneğin aşağıdaki gibi iki prosesin sayfa tablosu 
    söz konusu olsun:

    Proses-1

    Sanal Sayfa No  (decimal/hex)   Fiziksel Sayfa No (decimal/hex)
    ...                                   ...
    23603 (5C33)                      47324 (B8DC)
    23604 (5C34)                      52689 (CDD1)
    23605 (5C35)                      29671 (73E7)
    ...                               ...

    Proses-2

    Sanal Sayfa No  (decimal/hex)   Fiziksel Sayfa No (decimal/hex)
    ...                               ...
    23603 (5C33)                      84523 (14A2b)
    23604 (5C34)                      62981 (F605)
    23605 (5C35)                      42398 (A59E)
    ...                               ...

    İki prosesin sayfa tablosunda Fiziksel Sayfa Numaraları birbirinden ayrıldığında zaten bu iki proses asla birbirlerinin 
    alanlarına erişemeyecektir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------

    Pekiyi 32 bit bir mimaride işletim sisteminin sayfa tablosu yukarıdaki şekillere göre ne kadar yer kaplar? 32 bit mimaride
    fiziksel RAM en fazla 4 GB olabilir. Proseslerin sanal bellek alanları da 4 GB'dir. O halde toplam sayfa sayısı 
    4 GB/4 K = 2^32/2^12 = 2^20 = 1 MB olur. Her sayfa tablosu girişi Intel mimarisinde 4 byte'tır. Dolayısıyla yukarıdaki 
    şekillere göre bir prosesin sayfa tablosu 4 MB yer kaplar. Bu alan sayfa tablosu için çok büyüktür. Bu nedenle işlemcileri 
    tasarlayanlar sayfa tablolarının kapladığı alanı küçültmek için sanal adresleri iki parçaya değil, üç ya da dört parçaya 
    ayırma yoluna gitmişlerdir. Gerçekten de örneğin Intel'in 32 bit mimarisinde bir sanal adres üç parçaya ayrılmaktadır. Bu 
    ayrıntı kursumuzun konusu dışındadır ve Derneğimizde "80X86 ve ARM Sembolik Makine Dilleri" kursunda ele alınmaktadır. 
    Biz bu kursumuzda çeşitli gösterimlerde sanal adresleri ikiye ayıracağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz yukarıda 32 bit sistemlere göre örnekler verdik. Pekiyi 64 bit sistemlerde durum nasıldır? 64 bit sistemlerde fiziksel 
    RAM'in teorik büyüklüğü 2^64 = 16 exabyte olmaktadır. Dolayısıyla prosesin sanal bellek alanı da bu kadar olacaktır. Burada 
    eğer sanal adres iki parçaya ayrılırsa sayfa tablolarının aşırı büyük yer kaplaması kaçınılmazdır. Bu nedenle 64 bit sistemlerde 
    genellikle işlemcileri tasarlayanlar sanal adresleri dört parçaya ayırmaktadır. Bu konu yine kursumuzun kapsamı dışındadır. 
    Ancak 64 bit sistemlerde değişen bir şey yoktur. Program yine çok geniş bir sanal belleğe sanki tek başına yüklenecekmiş 
    gibi derlenir. Yine işletim sistemi proses için sayfa tablosu oluşturarak sanal sayfa numaralarını gerçek fiziksel sayfa 
    numaralarına yönlendirir. Tabii pek çok işletim sistemi 16 exabyte sanal bellek alanı çok büyük olduğu için bunu kısıtlama 
    yoluna gitmektedir. Örneğin Linux yalnızca 256 TB alanı kullanmaktadır. Windows ise yalnızca 16 TB alan kullanır. Bu alanlar 
    bile bugün için çok büyüktür.

    Sayfa tablolarının gerçek organizasyonu için kurs dokümanlarında /doc/ebooks klasöründe Intel'in AMD'nin ve ARM işlemcilerinin 
    orijinal dokümanları bulundurulmuştur.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi sayfalama (paging) mekanizmasının ne faydası vardır? İşte sayfalama mekanizmasının iki önemli işlevi vardır:

    1) Sayfalama mekanizması programların fiziksel RAM'e ardışıl yüklenmesinin zorunluluğunu ortadan kaldırır. Böylece 
    "bölünme (fragmentation)" denilen olgunun olumsuz etkisini azaltır.

    2) Sayfalama mekanizması "sanal bellek (virtual memory)" denilen olgunun gerçekleştirimi için gerekmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bölünme (fragmentation) bellek yönetimi konusunda önemli bir problemdir. Bir nesnenin belleğe yüklenmesi ardışıl bir biçimde 
    yapılırsa zamanla yükleme boşaltma işlemlerinin sonucunda bellekte çok sayıda küçük alan oluşmaktadır. Bu küçük alanlar ardışıl 
    olmadığı için genellikle bir işe yaramamaktadır. Küçük alanların toplamı oldukça büyük miktarlara varabilmekte ve toplam 
    belleğin önemli miktarını kaplayabilmektedir. Bu olguya "bölünme (fragmentation)" denilmektedir. Bölünmenin engellenmesi 
    için ardışıl yükleme zorunluluğunun ortadan kaldırılması gerekir. Bu durumda bellek bloklara ayrılır. Yüklenecek nesne bloklara 
    bölünerek ardışıl olmayacak biçimde boş bloklara atanır. Ancak nesnenin hangi parçasının hangi bloklarda olduğu da bir biçimde 
    kaydedilir. Bu teknik hem RAM yönetiminde hem de disk yönetiminde benzer biçimde kullanılmaktadır. Ancak bloklama yöntemiyle 
    bölünme ortadan kaldırılmaya çalışıldığında bu sefer başka bir problem ortaya çıkmaktadır. Nesnelerin son bloklarında 
    kullanılmayan alanlar kalabilmektedir. Bu da bir çeşit bölünmedir. Bu bölünme durumuna "içsel bölünme (internal fragmentation)" 
    denilmektedir. İçsel bölünmede yapılabilecek bir şey yoktur. Ancak içsel bölünmenin etkisi diğerine göre daha az olmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												23. Ders 04/06/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Sanal bellek (virtual memory) bir programın tamamının değil belli kısmının belleğe yüklenerek disk ile RAM arasında yer 
    değiştirmeli bir biçimde çalıştırılmasına yönelik bir mekanizmadır. Bu mekanizma sayesinde örneğin 100 MB'lık bir programın 
    başlangıçta yalnızca 64K'lık kısmı RAM'e yüklenebilir. Sonra program çalışmaya başlar. Çalışma sırasında programın bellekte 
    olmayan bir kısmına erişildiğinde işletim sistemi programın bellekte olmayan kısmını o anda diskten belleğe yükler ve çalışma 
    kesintisiz devam ettirilir.

    Sanal bellek kullanımında yine fiziksel RAM sayfalara ayrılır. Her sayfaya bir numara verilir. İşletim sistemi RAM'in hangi 
    sayfasının hangi programın neresini tuttuğunu bir biçimde oluşturduğu veri yapılarıyla bilir duruma gelir. Bir programın RAM'de 
    olmayan bir sayfasının diskten RAM'e yüklenmesine "swap in" denilmektedir. Ancak zamanla RAM'deki tüm fiziksel sayfalar dolu 
    duruma gelebilir. Bu durumda işletim sistemi bir programın bir parçasını RAM'e çekebilmek için RAM'deki bir sayfayı da RAM'dan 
    atmak durumunda kalır. Bu işleme ise "swap out" denilmektedir. Tabii işletim sistemi hangi programın RAM'deki hangi sayfasının 
    boşaltılacağı konusunda iyi bir karar vermek durumundadır. İşletim sistemine göre "gelecekte kullanılma olasılığı en düşük olan 
    sayfanın" RAM'den atılması en iyi stratejidir.

    Bu durumda bir program çalışırken aslında sürekli bir biçimde disk ile RAM arasında yer değiştirmeler yapılmaktadır. Bu yer 
    değiştirmelere genel olarak işletim sistemi dünyasında "swap" işlemi denilmektedir. Şüphesiz swap işlemi yavaş bir işlemdir 
    ve toplam performans üzerinde en önemli zayıflatıcı etkilerden birini oluşturmaktadır. Swap işlemlerinin olumsuz etkisini 
    azaltmak için ilk akla gelen şey fiziksel RAM'i büyütmektir. Ancak fiziksel RAM'in büyütülmesi maliyet oluşturmaktadır. 
    Bugünkü SSD'ler hard disklere göre oldukça iyi performans göstermektedir. Dolayısıyla bilgisayarımızda hard disk yerine SSD 
    varsa swap işlemleri daha hızlı yürütülecektir. Şüphesiz en önemli unsur aslında sayfaların yer değiştirilmesi konusunda 
    uygulanan algoritmalardır. Bunlara "page replacement" algoritmaları denilmektedir. Tabii bugünkü işletim sistemleri 
    bilinen en iyi algoritmaları zaten kullanmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi işletim sistemi programın RAM'de olmayan bir sayfasını yüklemek istediğinde RAM'den sayfa boşaltacağı zaman ya 
    boşaltılacak sayfa üzerinde daha önce yazma işlemleri (update) yapıldıysa ne olacaktır? İçeriği değiştirilmiş olan sayfanın 
    RAM'den atılırken mecburen diskte saklanması gerekir. İşte işletim sistemleri bu işlemler için diskte ismine "swap file" ya 
    da "page file" denilen dosyalar tutmaktadır. Değiştirilmiş olan sayfaları bu dosyalara yazmaktadır. Linux işletim sistemi 
    swap alanı olarak genellikle ayrı bir disk bölümünü kullanmaktadır. Ancak herhangi bir dosya da swap dosyası olarak 
    kullanılabilmektedir. Kullanılacak swap disk alanının ya da dosyalarının toplamı bazen önemli olabilir. Çünkü sistemin toplam 
    sanal bellek kapasitesi bu swap dosyalarıyla da ilgilidir. Linux sistemlerinde o andaki toplam swap alanları "/proc/swaps" 
    dosyasından elde edilebilir. Buradaki değer Kilo Byte cinsindendir. Ya da "swapon -s" komutuyla aynı bilgi elde edilebilir.

    Pekiyi sistemin kullandığı swap alanı dolarsa ne olur? İşte bu durumda sistemin sanal bellek limiti dolmuş kabul edilir. 
    Yapılacak şey sisteme yeni swap alanları eklemektir. Bunun Linux'ta nasıl yapılacağını ilgili kaynaklardan öğrenebilirsiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi işletim sistemi programı belleğe yüklerken baştan kaç sayfayı yüklemektedir? İşte buna "minimum working set" 
    denilmektedir. İşletim sistemleri genel olarak bir program için en az yüklenecebilecek sayfa sayısını belirlemiş durumdadır. 
    Böylece yüklenmiş her programın en azından "minimum working set" kadar sayfası RAM'de bulunmak zorundadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi sanal bellek mekanizması nasıl gerçekleştirilmektedir? İşte işlemciler sanal bellek mekanizmasını oluşturabilmek için özel 
    bir biçimde tasarlanmıştır. İşlemci ne zaman sanal adresi fiziksel adrese dönüştürmek için sayfa tablosuna başvursa, eğer sayfa tablosunda
    o sanal adrese bir fiziksel sayfa karşılık getirilmemişse ismine "page fault" denilen bir içsel kesme (interrupt) oluşturmaktadır. Örneğin:

    Sanal Sayfa No  (decimal/hex)   Fiziksel Sayfa No (decimal/hex)
    ...                         ...
    23603                       84523
    23604                       -
    23605                       42398
    23606                       -
    23607                       73245
    ...                         ...

    Burada Fiziksel Sayfa Numarasındaki "-" sembolleri o sanal sayfaya bir fiziksel sayfanın karşı getirilmediğini belirtmektedir. 
    Dolayısıyla örneğin işlemci 23604 numaralı, 23606 numaralı sanal sayfalar için dönüştürme yapmak istediğinde "page fault" oluşturacaktır. 
    İşte "page fault"" denilen kesme oluştuğunda işletim sisteminin kesme kodu devreye girer. Buna "page fault handler" denilmektedir. Bütün 
    swap mekanizması bu işletim sisteminin kesme kodu tarafından yapılmaktadır. İşletim sisteminin bu kesme kodu (page fault handler) önce
    hangi prosesin hangi sayfaya erişmek istediğini tespit eder. Sonra onun diskteki karşılığını bulur ve yer değiştirme işlemini yapar. 
    Tabii bu kesme kodu yer değiştirme işlemini yaptıktan sonra artık sayfa tablosunu da güncellemektedir. İşletim sisteminin kesme kodu bittiğinde
    kesmeye yol açan makine komutu yeniden çalıştırılarak akış devam ettirilmektedir. Bu komut yeniden çalıştırıldığında artık sayfa tablosu 
    düzeltildiği için page fault oluşmayacaktır. Bu durumda bir program çalıştırılmak istendiğinde işletim sistemi aslında programın az sayıda 
    sayfasını RAM'e yükleyip sayfa tablosunun o sayfalar dışındaki fiziksel sayfa numaralarını "-" haline getirir. Böylece yukarıda açıklanan mekanizma
    eşliğinde kesiksiz çalışma sağlanacaktır.

    Pekiyi ya erişilmek istenen sanal adres uydurma bir adresse ne olacaktır? İşte işletim sisteminin page fault kesme kodu (handler)
    öncelikle erişilmek istenen adresin o proses için legal bir adres olup olmadığına bakmaktadır. Eğer erişilmek istenen adres 
    legal bir adres değilse artık hiç swap işlemi yapılmadan proses cezalandırılır ve sonlandırılır. Yani her türlü sanal adresin 
    diskte bir karşılığı yoktur. Biz bir göstericiye rastgele bir adres yerleştirip oraya erişmek istesek aslında proses bu page 
    fault kesme kodu tarafından sonlandırılmaktadır.

    O halde sanal bellek mekanizması tipik olarak işlemci ve işletim sistemi tarafından olarak şöyle gerçekleştirilmektedir:

    1) Proses bir sanal adrese erişmeye çalışır.
    2) İşlemci sanal adresi parçalarına ayırır ve sayfa tablosuna başvurur.
    3) Sayfa tablosunda ilgili sayfaya bir fiziksel sayfa karşı getirilmişse sorun oluşmaz çalışma normal olarak devam eder. 
    Ancak sanal sayfaya bir fiziksel adres karşı getirilmemişse (şekilde onu "-" ile gösterdik) bu durumda işlemci "page fault" 
    denilen içsel kesmeyi oluşturur.
    4) Page fault kesmesi için kesme kodunu işletim sistemini yazanlar bulundurmuştur. Bu kod önce erişilmek istenen adresin geçerli 
    bir adres olup olmadığına bakar. Eğer erişilmek istenen adres geçerli bir adres değilse proses sonlandırılır. Eğer geçerli 
    bir adresse page fault kesme kodu "swap mekanizması" ile programın o kısmını RAM'e yükler, sayfa tablosunu günceller ve 
    kesme kodundan çıkar. Artık işlemci fault oluşturan makine komutuyla çalışmasına devam eder. Ancak sayfa tablosu düzeltildiği 
    için bu kez fault oluşmayacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi işletim sisteminin "bellek yönetimi (memory management)" kısmını yazanlar hangi bilgileri tutmak zorundadır? İşte 
    işletim sistemleri tipik olarak bu mekanizma için şu bilgileri kernel alanı içerisinde oluşturmak zorundadır:

    1) Tüm fiziksel RAM'deki tüm sayfaların "free" olup olmadığına ilişkin tablo
    2) Bir fiziksel sayfa free halde değilse onun hangi proses tarafından kullanıldığına ilişkin bilgi
    3) Swap dosyalarının yerleri ve organizasyonu
    4) Hani proseslerin hangi sayfalarının o anda fiziksel RAM'de hangi fiziksel sayfalarda bulunduğu bilgisi
    5) Diğer başka bilgiler

    Bellek yönetimi (memory management) bir işletim sisteminin en önemli ve en zor yazılan alt sistemlerden biridir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi sanal bellek toplamda bize ne sağlamaktadır? Şüphesiz sanal bellek mekanizmasının en önemli faydası RAM yeterli olmasa 
    bile çok sayıda büyük programın aynı anda çalışır durumda tutulabilmesidir. Bizim elimizde 8 GB RAM olsa bile biz onlarca büyük 
    programı çalışır durumda tutabiliriz. Ancak yukarıda da belirtildiği gibi işletim sistemi bir swap alanı bulundurmaktadır. 
    Eğer bu swap alanı dolarsa başka bir limit nedeniyle "out of memory" durumu oluşabilmektedir. Bu nedenle eğer programlar çok 
    fazla bellek kullanıyorsa bu swap alanlarının büyütülmesi de gerekebilir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Sayfalama ve sanal bellek mekanizmasında işletim sistemi de o anda sanal bellek alanı içerisinde bulunmak zorundadır. Pekiyi 
    işletim sisteminin kodları sayfa tablosunda sanal belleğin neresindedir? İşte genellikle işletim sistemi tasarımcıları
    sanal bellek alanını "user space" ve "kernel space" olarak ikiye ayırmaktadır. "user space" genellikle sanal bellek alanının düşük 
    anlamlı kısmında, kernel space ise yüksek anlamlı kısmında bulundurulur. Örneğin 32 bit Linux sistemleri 4 GB'lik sanal bellek alanını 
    şöyle ayırmıştır:

    32 Bit Linux Proses Sanal Bellek Alanı

    3 GB        User Space
    1 GB        Kernel Space

    Bu durumda 32 bit Linux sistemlerinde bir programın kullanabileceği maksimum sanal bellek 3 GB'dir. (Windows ta 2 GB user space için, 
    2 GB kernel space için kullanılmıştır.) 64 bit Linux sistemlerinde ise prosesin sanal bellek alanı şöyle organize edilmiştir:

    64 Bit Linux Proses Sanal Bellek Alanı

    128 TB        User Space
    128 TB        Kernel Space

    Görüldüğü gibi aslında teorik sanal bellek 16 exabyte olduğu halde 64 bit Linux sistemleri yalnızca 256 TB sanal belleğe
    izin vermektedir.

    Proseslerin sayfa tablolarında kernel alanının içeriği hep aynıdır. Yani context switch yapılsa bile kernel kodları hep aynı 
    sanal adreslerde bulunmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz bir program içerisinde yüksek miktarda dinamik tahsisat yaptığımızda ne olur? Linux sistemlerinde malloc fonksiyonu
    brk ya da sbrk denilen sistem fonksiyonunu çağırabilmektedir. Ancak arka planda sanal bellek bakımından şunlar gerçekleşir:

    - İşletim sistemi malloc ile tahsis edilen alanı sayfa tablosunda oluşturur. Oluştururken de tahsis edilen alanın 
    toplam swap alanından küçük olduğunu garanti etmeye çalışır. Çünkü malloc ile tahsis edilen alan eninde sonunda swap dosyası 
    içerisinde bulundurulacaktır.

    - İşletim sistemi swap dosyasının boyutu yeterliyse tahsisatı kabul etmektedir. Ancak sistemden sisteme değişebilecek biçimde
    bu sırada swap dosyasında tahsisat yapılabilir ya da yapılmayabilir. Eğer swap dosyasında o anda tahsisat yapılırsa bu durumda 
    swap alanı ciddi biçimde azalacak ve belki de başka proses artık aynı tahsisatı yapamayacaktır. Ancak işletim sistemi swap 
    dosyasında tahsisatı henüz yapmayabilir. Bu işlemi dinamik alan kullanıldığında yapabilir. Genellikle Linux sistemleri bu 
    yola başvurmaktadır. Literatürde dinamik alan için swap dosyasında baştan yer ayrılmasına "alanın commit edilmesi" denilmektedir.

    Aşağıdaki 3 GB RAM olan 2 GB swap alanına sahip 64 bit Linux sisteminde 5 GB alan dinamik olarak tahsis edilmek istenmiştir. 
    Burada tahsisat başarılı gibi gözükse de tahsis edilen alan kullanılırken swap alanı yetersizliğinden dolayı sinyal oluşacak 
    ve proses sonlandırılacaktır.

    O halde 64 bit Linux sistemlerinde biz teorik olarak her biri 128 TB olan onlarca programı bir arada çalıştırabiliriz. Ancak 
    bunun için swap alanımızın da yeterli büyüklükte diskte oluşturulmuş olması gerekir. Swap alanının yetersizliği durumunda 
    bir sinyal ile proses sonlandırılmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

#include <stdio.h>
#include <stdlib.h>

int main(void)
{
	char *pc;

	pc = (char *)malloc(5000000000);
	if (pc == NULL) {
		fprintf(stderr, "cannot allocate memory!...\n");
		exit(EXIT_FAILURE);
	}

	for (long i = 0; i < 5000000000; ++i)
		pc[i] = 0;

	printf("ok\n");

	getchar();

	free(pc);

	return 0;
}

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux sistemlerinde free komutu (bu sistemlerde komutların çok büyük çoğunluğu aslında birer programdır) çalıştığımız sistemdeki
    fiziksel RAM ve swap alanı hakkında bilgi vermektedir. Örneğin çalıştığımız sanal makinede bu komutu uygulayalım:

    $ free
                total        used        free      shared  buff/cache   available
    Mem:         3969588     3444604      251248       27680      273736      269272
    Swap:        2097148     1077432     1019716

    Buradan toplam 4 GB civarında fiziksel RAM ve 2 GB civarında da diskte swap alanı olduğunu görüyoruz. Komut "-h" seçeneği ile
    kullanılıra daha okunaklı (human readable) bir görüntü elde edilebilir:

    $ free -h
                    total        used        free      shared  buff/cache   available
    Mem:           3,8Gi       3,3Gi       229Mi        23Mi       270Mi       253Mi
    Swap:          2,0Gi       1,0Gi       1,0Gi

    Swap alanlarının büyüklüğü ve swap dosyasının yeri "swapon" komutu ile de görüntülenebilir. Örneğin:

    $ swapon
    NAME      TYPE SIZE USED PRIO
    /swapfile file   2G   1G   -2

    Burada swap dosyasının kök dizindeki "swapfile" isimli bir dosya biçiminde olduğu görülmektedir.

    Aynı bilgiler "/proc/swaps" dosyasının görüntülenmesiyle de elde edilebilir. Örneğin:

    $ cat /proc/swaps
    Filename				Type		Size		Used		Priority
    /swapfile               file		2097148		668568		-2

    Aslında swapon komutu da "/proc/swaps" dosyasına başvurmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux'ta swap alanları bir disk bölümü (partition) biçiminde de bir dosya biçiminde de oluşturulabilmektedir. Genellikle 
    sistemi kurarken kurulum sırasında kurulum programı swap alanı için bir disk bölümünün ayrılıp ayrılmayacağını sormaktadır. 
    Elinizdeki sistemde disk bölümlerine bakarak bir swap disk bölümünün sisteminiz için ayrılıp ayrılmadığını anlayabilirsiniz. 
    Disk bölümlerini görüntülemek için "fdisk -l" komutunu kullanabilirsiniz. Ancak komutun root önceliğinde "sudo" ile çalıştırılması
    gerekir. Örneğin:

    $ sudo fdisk -l

    Disk /dev/sda: 60 GiB, 64424509440 bytes, 125829120 sectors
    Disk model: VMware Virtual S
    Units: sectors of 1 * 512 = 512 bytes
    Sector size (logical/physical): 512 bytes / 512 bytes
    I/O size (minimum/optimal): 512 bytes / 512 bytes
    Disklabel type: gpt
    Disk identifier: 80ABF335-7C9E-4872-B886-A3281ECEFCBE

    Device       Start       End   Sectors  Size Type
    /dev/sda1     2048      4095      2048    1M BIOS boot
    /dev/sda2     4096   1054719   1050624  513M EFI System
    /dev/sda3  1054720 125827071 124772352 59,5G Linux filesystem

    Burada bir swap disk alanının ayrılmadığı görülmektedir.

    Pekiyi Linux sistemlerinde swap alanlarını nasıl artırabiliriz? Bunun için mevcut swap dosyası büyütülebilir. Ancak genellikle
    izlenen yol yeni bir dosya oluşturup onun da swap amaçlı kullanılmasını sağlamaktır. Bu işlemler sırasıyla şöyle yapılabilir:

    1) Önce bir swap dosyasının yaratılması gerekir. Bunun için yeterli disk alanının olduğundan emin olmalısınız. Diskteki 
    boş alanları görüntülemek için "df" komutu kullanılabilir. "df -h" komutu daha anlaşılabilir (human readable)" görüntü vermektedir.
    Örneğin:

    $ df -h
    Filesystem      Size  Used Avail Use% Mounted on
    tmpfs           388M  1,5M  387M   1% /run
    /dev/sda3        59G   31G   26G  55% /
    tmpfs           1,9G   19M  1,9G   1% /dev/shm
    tmpfs           5,0M  4,0K  5,0M   1% /run/lock
    /dev/sda2       512M  6,1M  506M   2% /boot/efi
    tmpfs           388M  124K  388M   1% /run/user/1000

    İçi sıfırlarla dolu bir dosya yaratmak için dd komutu kullanılabilir. Örneğin:

    $ sudo dd if=/dev/zero of=swapfile_ext bs=512 count=2097152

    Burada 512 * 2097152 = 1 GB kadar içi sıfırlarla dolu bir alan oluşturulmuştur. Aynı işlem fallocate komutu ile de yapılabilmektedir:

    $ sudo fallocate -l 1073741824 swapfile_ext

    2) Oluşturulan swap dosyasının başkaları tarafından okunabilmesinin engellenmesi için yalnızca owner'a read/write hakkı 
    verebiliriz. Yarattığımız dosyanın owner'ının "root" olduğuna dikkat ediniz. Bu işlemi şöyle yapabiliriz:

    $ sudo chmod 600 swapfile_ext
    $ ls -l swapfile_ext
    -rw------- 1 root root 1073741824 Haz  4 22:10 swapfile_ext

    3) Oluşturulan bu dosyanın bir swap dosyası olarak kullanılabilmesi için içinin belli biçimde düzenlemesi gerekmektedir. Bu
    işlem de "mkswap" komutuyla yapılmaktadır. Örneğin:

    $ sudo mkswap swapfile_ext
    Setting up swapspace version 1, size = 1024 MiB (1073737728 bytes)
    no l    abel, UUID=5c960a31-8385-4eb0-a0f2-9f044b3d5483

    4) Artık bu hazırlanan dosyanın işletim sistemine swap dosyası olarak tanıtılması gerekir. Bu işlem "swapon" komutu ile 
    yapılmaktadır:

    $ sudo swapon swapfile_ext

    Artık swap dosyamız çekirdek tarafından kullanılmaya başlanmıştır. Örneğin:

    $ free -h
                   total        used        free      shared  buff/cache   available
    Mem:           3,8Gi       904Mi       2,1Gi        32Mi       780Mi       2,6Gi
    Swap:          3,0Gi       652Mi       2,4Gi

    Görüldüğü gibi önceden swap alanı 2 GB iken artık 3 GB'dir. Benzer biçimde:

    $ swapon
    NAME          TYPE  SIZE   USED PRIO
    /swapfile     file    2G 652,9M   -2
    /swapfile_ext file 1024M     0B   -3

    $ cat /proc/swaps
    Filename				Type		Size		Used		Priority
    /swapfile               file		2097148		668568		-2
    /swapfile_ext           file		1048572		0		-3

    5) Yukarıda yaptığımız swapon işlemi kalıcı değildir. Yani bizim sistem her açıldığında swapon yapmamız gerekir. Bunun otomatize
    edilebilmesi için "/etc/fstab" dosyası kullanılabilir. Bunun için bu dosyaya aşağıdaki formata uygun bir satır girmelisiniz:

    /swapfile_ext      none            swap    sw              0       0

    6) Yaratılmış olan swap alanın yok edilmesi için yukarıda yapılan işlemlerin geri alınması gerekir. Yani swap dosyası 
    ve "/etc/fstab" gitişi silinmelidir. Ancak bu işlemleri yapmadan önce swap dosyasının çekirdek tarafından kullanımının 
    sonlandırılması gerekir. Bu da "swapoff" komutuyla yapılmaktadır. Örneğin:

    $ sudo swapoff swapfile_ext

    Tabii eğer sisteminiz zaten bir swap dosyası kullanıyorsa bu swap dosyasını da büyütebilirsiniz. Ancak swap dosyalarının 
    başlık kısımlarında onların büyüklüğü yazdığı için onu büyütme işleminden sonra yeniden mkswap işlemini yapmalısınız. Örneğin
    elimizde zaten "/swapfile" isimli 2 GB'lik bir swap dosyası bulunuyor olsun. Biz de onu 3 GB'ye çıkartmak isteyelim. Önce onu silip 
    aynı isimli 3 GB'lik yeni bir dosya oluşturabiliriz. Ya da aşağıdaki gibi doğrudan ekleme de yapabiliriz:

    $ sudo swapoff /swapfile
    $ sudo dd if=/dev/zero of=/swapfile bs=1G count=1 conv=notrunc oflag=append
    1+0 kayıt girdi
    1+0 kayıt çıktı
    1073741824 bytes (1,1 GB, 1,0 GiB) copied, 0,907437 s, 1,2 GB/s
    $ sudo mkswap /swapfile
    mkswap: /swapfile: uyarı: eski imza swap temizleniyor.
    swapspace sürüm 1 kuruluyor, boyut = 3 GiB (3221217280 bayt)
    bir etiket yok, UUID=e733c9e9-4060-429b-8279-b8b023cd8103
    $ sudo swapon /swapfile
    $ free -h
    total        used        free      shared  buff/cache   available
    Bellek:        3,8Gi       1,4Gi       1,1Gi        34Mi       1,3Gi       2,1Gi
    Takas:         3,0Gi          0B       3,0Gi

    Tabii aslında sistemimiz için herhangi bir swap alanı oluşturmamız zorunlu değildir. Eğer oluşturulmuş bir swap alanı yoksa
    işletim sistemi değişmiş (kirlenmiş) sayfalar için swap-out yapmaz. Tabii eğer sayfa güncellenmemişse ve bu sayfanın diskte 
    çalıştırılabilir dosyada ya da dinamik kütüphane dosyasında bir karşılığı varsa bu durumda işletim sistemi bu sayfalar swap 
    out yapabilir. Fakat swap alanı olmadığı zaman yetersiz RAM'den dolayı bir tıkanma ortaya çıkabilir. Bu durumda da işletim 
    sistemi çalışmakta olan programlara sinyal göndererek onları sonlandırabilir. Özetle swap alanı kullanılmayacaksa RAM'in 
    miktarının artırılması uygun olmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												24. Ders 06/06/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Gömülü sistemlerde disk yerine Flash EPROM'lar (genellikle NAND tipi flash EPROM'lar) kullanılmaktadır. Bu belleklere belli
    miktarda yazma yapılabilmektedir. Belli miktardan fazla yazma yapılması durumunda bellekte bozulma oluşabilmektedir. İşte bu 
    nedenle gömülü Linux sistemlerinde swap işlemlerinde doğrudan bu medyaların kullanımı genellikle tercih edilmez. Bu konuda
    ileride daha geniş açıklamalar yapacağız ve bazı alternatifler üzerinde duracağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Anımsanacağı gibi işletim sistemi sayfa tabloları yoluyla proseslerin bellek alanlarını tam olarak birbirinden izole
    etmektedir. Dolayısıyla bir proses istese de başka bir prosesin bellek alanına erişememektedir. Ancak ismine "paylaşılan 
    bellek alanları (shared memory)" denilen bir teknik ile işletim sistemi farklı proseslerin aynı fiziksel sayfaya erişimini 
    sağlayabilmektedir. Şöyle ki: İşletim sistemi iki prosesin sayfa tablosunda farklı sanal sayfaları aynı fiziksel sayfaya 
    eşlerse bu iki proses farklı sanal adreslerle aslında aynı fiziksel sayfayı görüyor durumda olur. Örneğin:

    Proses-1 Sayfa Tablosu
    ---------------------------------------------------------
    Sanal Sayfa Numarası            Fiziksel Sayfa Numarası
    ...                             ...
    987                             1245
    988                             1356
    999                             1412
    ...                             ...

    Proses-2 Sayfa Tablosu
    ----------------------------------------------------------
    Sanal Sayfa Numarası            Fiziksel Sayfa Numarası
    ...                             ...
    356                             7645
    357                             1356
    358                             489
    ...                             ...

    Görüldüğü gibi birinci prosesin 988'inci sanal sayfa numarası ikinci prosesin 357'nci sanal sayfa numarasıyla aynı fiziksel 
    adrese yönlendirilmiştir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aslında sayfa tablolarında her bir sayfanın da ayrıca bir "özellik bilgisi (attribute)" vardır. Yani sayfa tablolarının formatı
    daha gerçekçi bir biçimde şöyledir:

    Sanal Sayfa No          Fiziksel Sayfa No       Sayfa özelliği
    ...                     ...                     ...

    Sayfa özelliği o fiziksel sayfanın "read only" mi, "read/write" mı "execute" özelliğine sahip mi olduğunu belirtmektedir. 
    Ayrıca bir fiziksel sayfa "user mode" ya da "kernel mode" sayfa olarak belirlenebilmektedir. İşletim sistemi prosesin tüm 
    fiziksel sayfalarını "user mode" olarak ancak kernel'ın tüm sayfalarını "kernel mode" olarak ayarlamaktadır. User mode bir 
    proses yalnızca user mode sayfalara erişebilmektedir. Kernel mode sayfalara erişememektedir. Eğer user mode bir proses kernel 
    mode sayfaya erişmek isterse işlemci bir "içsel kesme (fault)" oluşturmakta ve işletim sistemi devreye girerek prosesi 
    sonlandırmaktadır. Ancak kernel mode bir proses hem kernel mode sayfalara hem de user mode sayfalara erişebilmektedir. 
    Bizim prosesimiz user mode'da çalışmaktadır. User mode prosesler bir user mode sayfaya erişirken işlemci erişim biçimine bakar 
    ve duruma göre yine içsel kesme oluşturur. User mode bir proses user mode ancak read-only bir sayfaya yazma yaparsa içsel 
    kesme (page fault) oluşturulmaktadır. Bu durumda işletim sistemi prosesi cezalandırarak sonlandırma yoluna gitmektedir. Ayrıca 
    pek çok işlemci ailesinde bir kodun bir fiziksel sayfada çalışabilmesi için o kodun "execute" özelliğine sahip bir fiziksel sayfada 
    bulunması gerekmektedir. Bu mekanizma altında örneğin bir proses "execute" olmayan bir fiziksel sayfadaki bir fonksiyonu çağırmak 
    isterse yine işlemci içsel kesme (page fault) oluşturmaktadır. Örneğin C derleyicileri string'leri ELF formatında özel bir 
    bölüme (section) yerleştirirler ve işletim sisteminin yükleyicisi de (UNIX/Linux sistemlerindeki exec fonksiyonları) bu sayfaları 
    sayfa tablosunda oluştururken bu sayfaların özelliklerini "read-only" yaparlar. Böylece biz bir string'i değiştirmek istediğimizde
    koruma mekanizması yüzünden prosesimiz sonlandırılır. Zaten C'de string'lerin güncellenmesi "tanımsız davranış (undefined behavior)" 
    olarak belirtilmektedir. Benzer biçimde derleyiciler genellikle global const nesneleri de yine "read-only" bölümlere 
    (sections) yerleştirmektedir. (Ancak yerel const nesneler stack'te olduğu için read-only yerleştirilememektedir.)
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aynı programın ikinci kez çalıştırıldığını düşünelim. Bu durumda her şeyi aynı olan iki program çalışıyor durumda olacaktır.
    Ancak bu iki proses birbirinden bağımsız olduğuna göre bu iki prosesin farklı sayfa tabloları vardır ve aslında bu iki prosesin
    bellek alanı tamamen izole edilmelidir. İşte işletim sistemleri bu tür durumlarda "copy on write" denilen bir mekanizma uygulamaktadır. 
    Bu mekanizmada işletim sistemi bir program ikinci kez çalıştırıldığında sayfa tablosunda önceki çalıştırma ile aynı fiziksel 
    sayfaları eşler. Ancak bu sayfaları "read-only" biçimde işaretler. Proseslerden biri bu sayfaya yazma yaptığında içsel kesme 
    (page fault) oluşur, işletim sistemi devreye girer tam yazma yapıldığı sırada o sayfanın bir kopyasını oluşturup iki prosesin 
    fiziksel sayfalarını birbirinden ayırır. Böylece iki proses baştan aynı fiziksel sayfaları paylaşırken daha sonra bu fiziksel 
    sayfalar birbirinden ayrıştırılmaktadır. Bu mekanizma sayesinde aslında hiç yazma yapılmayan fiziksel sayfaların boşuna bir 
    kopyası oluşturulmamış olur. Örneğin ikinci çalıştırılan programın makine kodlarının bulunduğu sayfalar aslında hiç güncellenmemektedir. 
    Bu durumda iki kopyanın aynı fiziksel sayfayı görmesinde bir sakınca yoktur. İşletim sistemleri dinamik kütüphanelerde de 
    benzer tekniği kullanmaktadır. Bir dinamik kütüphane iki farklı proses tarafından kullanıldığında mümkün olduğunca bu proseslerin 
    sayfa tabloları aynı fiziksel sayfaları gösterir. Ancak proseslerden biri dinamik kütüphanedeki bir sayfada değişiklik 
    yaparsa o noktada bu sayfanın kopyasından oluşturulmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    İşletim sisteminin nasıl devreye girip çalıştığını merak edebilirsiniz. Aslında işletim sistemini bir fonksiyon yığını olarak
    düşünebiliriz. İşletim sisteminin içerisinde kodlar tipik olarak aşağıdaki durumlarla çalışma fırsatı bulmaktadır:

    1) Boot sonrasında işletim sisteminin kendisini kullanıma hazır hale getirme (initialize) sürecinde ve shutdown işlemi sürecinde.

    2) Sistem fonksiyonları çağrıldığında. Bizim programımız bir sistem fonksiyonunu çağırdığında aslında işletim sisteminin çekirdek
    kodları çalıştırılmaktadır.

    3) Kesme (interrupt) mekanizması yoluyla. Örneğin Ethernet karına bir ethernet paketi geldiğinde bu kart CPU'da kesme oluşturarak
    işletim sisteminin kesme kodunun çalışmasına yol açmaktadır. Ya da örneğin periyodik kesme oluşturan "timer devreleri" yoluyla 
    işletim sisteminin kesme kodları periyodik biçimde devreye girmektedir. Örneğin thread'ler arası geçiş (context switch) bu yolla
    gerçekleştirilmektedir. Ya da örneğin sanal bellek mekanizması (yani swap out, swap in) işlemleri yine kesme mekanizması yoluyla
    sağlanmaktadır.

    4) İşletim sisteminin bir proses gibi çalışan thread'leri de vardır. Bunlara "kernel thread'ler" denilmektedir. Örneğin "page cache"
    mekanizmasında işletim sistemi diske erişimi azaltmak için çok erişilen disk bloklarını RAM'da tutmaktadır. Yazma sırasında da
    eğer bu bloklar RAM'de ise diske değil RAM'e yazmaktadır. Ancak bu bloklar çok bekletilmeden bir kernel thread yoluyla diske 
    flush edilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Kursumuzun bu bölümünde Linux sistemlerinin boot edilmesi süreci ele alınacaktır. İşletim sisteminin otomatik olarak yüklenerek 
    çalışır hale getirilmesi sürecine "boot" işlemi denilmektedir. (Boot terimi İngilizce "askeri bottan" gelmektedir.) Biz bilgisayar
    sistemine güç verdiğimizde bir süre sonra işletim sisteminin otomatik yüklendiğini görmekteyiz. Aslında işletim sisteminin 
    yüklenmesi biraz karmaşık bir süreçle gerçekleşmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Mikroişlemciye güç uygulandığında belli bir adresten itibaren çalışacak biçimde tasarlanmıştır. Buna işlemcilerin "reset vektörü"
    denilmektedir. İşlemcilerin reset vektörleri genellikle fiziksel belleğin başında ya da sonunda bulunmaktadır. Örneğin Intel
    işlemcilerinde reset vektörü belleğin sonunda, ARM işlemcilerinde belleğin başında bulunmaktadır. İşlemci reset edildiğinde belli 
    bir adresten çalışmaya başladığına göre orada çalışmaya hazır bir kodun bulunuyor olması gerekir. Tabii bu kod RAM (DRAM) bellekte
    bulunamaz. Çünkü sisteme güç uygulandığında RAM belleğin de içeriği sıfırlanmaktadır. İşte bilgisayar sistemlerinde işlemcinin 
    reset vektöründe tipik olarak ROM bellekler bulundurulur. Eskiden bu amaçla EPROM bellekler kullanılıyordu. Artık uzunca bir süredir
    EEPROM (flash EPROM) bellekler kullanılmaktadır. Pekiyi reset vektöründeki kod ne yapmaktadır?

    Bugün kullandığımız DRAM bellekler güç kaynağı verilir verilmez kullanıma hazır hale getirilememektedir. Onların da kullanıma 
    hazır hale getirilmesi (initialize edilmesi) gerekmektedir. Benzer biçimde yine bazı donanım aygıtlarının kullanılmadan önce yine 
    kullanıma hazır hale getirilmesi (initialize edilmesi) edilmesi gerekmektedir. İşte reset vektörüne yerleştirilmiş olan kodlar 
    bilgisayar sistemini kullanıma hazır hale getirecek kodları barındırmaktadır. Tabii burada donanımdan donanıma değişen bazı 
    ayrıntılar da söz konusu olabilmektedir. Biz kursumuzda önce konuyu genel olarak ele alıp sonra RaspberryPi gibi BeagleBone Black 
    gibi donanımlardaki boot süreci üzerinde duracağız.

    Reset vektöründeki kodlar çalıştırılınca artık sistem genel olarak çalışmaya hazır bir duruma getirilmiştir. Artık akışın bir 
    biçimde sistem programcısına devredilmesi gerekir. Akışın devredilmesi tipik olarak ikincil bellekteki belli bir disk bloğunun
    RAM'e yüklenmesi ve oradaki kodun çalıştırılması biçiminde yapılmaktadır. Tersten gidersek sistem programcısı programını ikincil 
    belleğin bu bloğuna yerleştirir ve bu süreçler sonucunda bu program çalışır hale gelir. Pekiyi işletim sistemi nasıl yüklenmektedir?
    ROM'daki kodun işletim sistemini yüklemesi genel olarak mümkün değildir. Bunun temel nedenleri şunlardır:

    - İşletim sistemleri çok büyük olabilir. ROM'daki kod bunu yapabilecek yeterlilikte olmayabilir.
    - İşletim sistemlerinin yüklenmesi sistemden sisteme değişebilen ve nispeten karmaşık bir süreçtir. ROM'daki küçük kodun bunu
    yapması genellikle mümkün olamamaktadır.
    - İkincil bellekte birden fazla işletim sistemi bulunuyor olabilir. Bu durumda bunların hangisinin nasıl yükleneceğine karar verilmesi 
    ve karar verilen işletim sisteminin yüklenmesi ROM'daki küçük program tarafından genellikle yapılamaz.

    O halde tek çıkar yol ROM'daki programın diskteki ön bir yükleyiciyi yüklemesi ve işletim sisteminin yüklenmesinin bu program 
    tarafından yapılmasıdır. İşletim sistemlerini yükleyen bu tür programlara "boot loader" denilmektedir. Bugün değişik platformlarda
    kullanılan değişik "boot loader" programlar bulunmaktadır. Örneğin Microsoft kendi Windows sistemleri için kendi "boot loader" 
    programını kullanmaktadır. Buna "Windows Boot Manager" denilmektedir. UNIX/Linux sistemlerinde değişik proje grupları tarafından 
    yazılmış olan değişik "boot loader" programlar kullanılabilmektedir. Örneğin Linux sistemlerinde eskiden "LILO" isimli boot loader 
    yoğun biçimde kullanılıyordu. Daha sonra "GRUB" isimli boot loader yaygın biçimde kullanılmaya başlandı. Son yıllarda SYSLINUX 
    isimli boot loader paketi de belli bir ölçüde kullanım bulmuştur. Gömülü Linux sistemlerinde bugün en çok tercih edilen boot loader 
    programı "Das U-Boot" ya da kısaca "U-Boot (Universal Boot Loader)" denilen boot loader programdır.

    O halde işletim sisteminin yüklenmesi pek çok donanım ve platformda aşağıdaki aşamalardan geçilerek yapılmaktadır:

    Mikroişlemci RESET Ediliyor ---> ROM'daki RESET Vektörde Bulunan Kodlar Çalışıyor ---> ROM'daki Kodlar İkincil Bellekteki Boot
    Loader Programını RAM'e Yüklüyor ---> İşletim Sistemine Jump Ediliyor

    Burada birkaç soru aklınıza gelebilir. Bunlardan biri ROM'daki RESET vektöründe bulunan kodların oraya kimin tarafından
    yerleştirilmiş olduğudur. ROM'daki RESET vektöründe bulunan kodlar çok aşağı seviyeli kodlar olduğu için bunlar genellikle 
    donanımı oluşturan kurumlar tarafından yazılıp oraya yerleştirilmektedir. Örneğin bugün kullandığımız PC sistemlerinde ROM'daki
    bu kodlara BIOS (Basic Input Output System) denilmektedir. BIOS kodları eskiden Microsoft tarafından yazılmıştı. Ancak bugün 
    BIOS üretici firmalar tarafından yazılmaktadır. Bu ROM bellekler bugün EEPROM teknolojisi ile üretildikleri için BIOS güncellemesi 
    de yapılabilmektedir. Örneğin BBB kartlarındaki ROM programı Texas Instruments (TI) firması tarafından yazılmış durumdadır. Özetle 
    ROM'da bulunan bu aşağı seviyeli kodlar ilgili donanımı tasarlayan kurumlardaki sistem programcıları tarafından yazılmıştır.

    Pekiyi ROM'daki program boot loader programını ikincil bellekte nasıl arayıp bulmaktadır? Bunun için birkaç teknik kullanılabilmektedir. 
    Birincisi ROM'daki programın doğrudan ikincil belleğin önceden belirlenmiş bloklarını yüklemesidir. Örneğin klasik PC sistemlerinde 
    ROM'daki (BIOS'taki) program diskin 0'ıncı bloğunu (yani ilk 512 byte'ı içeren bloğu) yüklemektedir. (Ancak daha sonra PC sistemlerinde
    "UEFI BIOS" ismi altında eski klasik BIOS kodları oldukça geliştirilmiştir. Artık bu UEFI BIOS kodları bazı dosya sistemlerini de 
    tanımaktadır.) Örneğin Raspberry Pi'da ROM'daki kodlar FAT dosya sistemini tanıyabilmektedir. FAT dosya sistemi Microsoft'un DOS 
    sistemlerinde kullandığı karmaşık olmayan sade bir dosya sistemidir. İşte ROM'daki kodlar FAT gibi bir dosya sistemini tanıyorsa 
    oranın kök dizininde belli isimdeki dosyayı bulup RAM'e yükleyebilmektedir.

    Sistem reset edildiğinde tüm boot işlemi bir bütününün parçaları gibi düşünülürse burada devreye giren programlara birer aşama
    numarası verilebilir. Örneğin boot işleminin reset vektöründe bulunan kısmına "Birinci Aşama Boot Loader (Stage-1 / First Stage 
    Boot Loader)", bu programın yüklediği programa "ikinci aşama boot loader (stage-2/second stage boot loader)" ve bunun da 
    yüklediği (yani işletim sistemini yükleyen) programa da "üçüncü aşama boot loader (stage-3 / third stage boot loader)" diyebiliriz. 
    Ancak bazı kaynaklar bu ROM'daki kodu boot sürecinin bir parçası olarak ele almamaktadır. Dolayısıyla bu kaynaklar ROM kodunun kendisine 
    onun değil yüklediği programa "birinci aşama boot loader (stage-1 / first stage boot loader), işletim sistemini yükleyen programa 
    ise "ikinci aşama boot loader (stage-2 / second stage boot loader)" demektedir. (Örneğin Wikipedia boot işleminde donanım 
    bileşenlerini hazır hale getiren programı "birinci aşama boot loader", işletim sistemini yükleyen programı ise "ikinci aşama 
    boot loader" olarak isimlendirmiştir. Biz kursumuzda izleyen paragraflarda bu terminolojiyi kullanacağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												25. Ders 11/06/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bugün kullandığımız PC sistemlerinin temel donanımları 70'li yılların sonlarında ve 80'li yılların başlarında IBM tarafından 
    tasarlanmıştır. (Burada PC demekle Intel tabanlı masaüstü bilgisayarları ve notebook bilgisayarları kastediyoruz.) Bu bilgisayarlar 
    1980'in Aralık ayında IBM'in tasarladığı donanım ve Microsoft'un tasarladığı DOS işletim sistemiyle piyasa sürüldü. Zaman 
    ilerledikçe bu PC donanımlarında bazı iyileştirmeler yapıldıysa da temel mimari büyük ölçüde aynı kalmıştır. (2000'lerin başında 
    Apple Intel tabanlı PC mimarisine geçtiyse de kullandığı PC donanımında bazı farklılıklar da oluşturmuştur. Dolayısıyla burada 
    PC demekle Intel ve ARM tabanlı macOS sistemlerini kastetmiyoruz.)

    Bugünkü PC sistemlerini reset ettiğimizde çalışma BIOS denilen EEPROM bellekten başlamaktadır. Buradaki kod DRAM belleği ve
    pek çok donanım birimini programladıktan sonra CMOS setup'ta belirtilen "boot sırasına (boot sequence)" bakarak ilgili medyanın 
    0'ıncı sektörünü belleğe yükleyip akışı oraya devretmektedir. (PC mimarisinde diskten okunabilecek ya da diske yazılabilecek en 
    küçük birime "sektör" denilmektedir.) İkincil belleklerdeki ilk sektöre "MBR (Master Boot Record)" denilmektedir. MBR'de toplam 
    512 byte'lık bir program bulunmaktadır. MBR'nin sonunda 64 byte'lık "Disk Bölümleme Tablosu (Disk Partition Table)" vardır. 
    MBR'deki program duruma göre ya bir boot loader programını yüklemekte ya da default durumda aktif disk bölümünün 0'ıncı 
    sektörünü RAM'e yükleyip akışı oraya devretmektedir. (PC sistemlerinde her disk bölümünün ilk sektörüne (0'ıncı sektörüne) "boot 
    sektör" denilmektedir. Boot sektör ilgili işletim sisteminin yüklenmesinden sorumludur.) Tabii MBR'deki program daha büyük 
    bir boot loader programını da yükleyebilir. Bu durumda hangi işletim sisteminin yükleneceği bir menü yoluyla kullanıcıya da 
    sorulabilmektedir. PC sistemlerindeki boot sürecini aşağıdaki gibi özetleyebiliriz:

    PC'ye güç veriliyor ---> EEPROM'daki BIOS kodları temel hazırlık işlemlerini yapıyor ---> EEPROM'daki BIOS kodları diskin ilk 
    sektörünü (MBR) RAM'e yüklüyor ve akışı ona devrediyor ---> MBR'deki program boot loader'ı RAM'e yüklüyor ---> Boot Loader seçilen 
    disk bölümünün boot sektörünü RAM'e yüklüyor ---> Seçilen disk bölümünün boot sektörü işletim sistemini yüklüyor ---> Akış işletim 
    sistemi kodlarına devrediliyor.

    Bugün Linux yüklü olan Intel X86 tabanlı PC sistemlerinde genellikle boot loader olarak GRUB tercih edilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi Raspberry Pi donanımındaki boot süreci üzerinde duralım. Raspberry Pi donanımlarındaki boot süreci şu aşamalardan geçilerek 
    yürütülmektedir:

    1) Raspberry Pi'ye güç verildiğinde CPU reset vektöründen çalışmaya başlar. Reset vektöründe SoC'un (System on Chip) ROM alanı 
    vardır. Dolayısıyla çalışma SoC'un ROM'una yerleştirilmiş programdan başlamaktadır.

    2) SoC'un ROM'undaki program GPU'yu başlatır. GPU SD karttaki FAT dosya sisteminin kök dizininde "bootcode.bin" dosyasını arar. 
    Buradaki kod FAT dosya sistemini tanımaktadır. Bu dosya bulunursa onu SoC içerisindeki GPU'nın L2 cache belleğine (internal RAM) 
    yükler ve akışı oraya devreder. (Uzantısı ".bin" olan dosyalara "pure binary" ya da "flat binary" dosyalar da denilmektedir. 
    Bu dosyalar hiçbir başlık kısmı içermezler, doğrudan makine kodlarını içerirler.) "bootcode.bin" dosyası sırasıyla şu medyalarda 
    aranmaktadır:

    Birincil SD Kart (Primary SD Card)
    İkinci SD Kart (Secondary SD Card)
    NAND
    SPI
    USB

    Bu aşamada henüz DRAM belleğin kullanıma hazır hale getirilmediğine (initialize edilmediğine) dolayısıyla henüz onun kullanılamayacağına 
    dikkat ediniz.

    3) "bootcode.bin" dosyası GPU tarafından çalıştırılmaktadır. (Bunun nedeni üzerinde durmayacağız.) Bu dosyaya "birinci aşama boot 
    loader (stage-1 / first stage boot loader)" da diyebiliriz. Bu kod DRAM belleği kullanıma hazır hale getirir (initialize eder), 
    daha sonra SD kartın kök dizininden "start.elf" isimli dosyayı DRAM belleğe yükler ve akışı o programa devreder.

    4) "start.elf dosyası" donanım birimlerini kullanıma hazır hale getirir, sonra işletim sisteminin çekirdeğini ve gerekli olan diğer 
    öğeleri DRAM belleğe yükler ve akışı işletim sisteminin çekirdek dosyasının (kernel image) başındaki koda devreder. (Genellikle 
    çekirdek kodları sıkıştırılmış biçimde DRAM'a yüklenmektedir. Çekirdek kodlarının açılması da yine bu sıkıştırılmış çekirdek 
    dosyasının başındaki program tarafından yapılmaktadır.) Buradaki "start.elf" dosyası "ikinci aşama boot loader (stage-2 / second 
    stage boot loader) görevindedir. Sürecin işleyişini şekille şöyle gösterebiliriz:

    CPU reset ediliyor ---> ROM'daki kod çalışıyor (CPU --> GPU) --> ROM'daki kod "bootcode.bin" dosyasını içsel SRAM'e yüklüyor (GPU) 
    ---> "bootcode.bin" dosyası DRAM belleği kullanıma hazır hale getiriyor ve "start.elf" dosyasını DRAM belleğe yüklüyor (GPU) 
    ---> "start.elf" dosyası donanım bileşenlerini ayarlıyor, Linux çekirdeğini ve diğer bileşenleri DRAM belleğe yüklüyor (GPU) ---> 
    Akış çekirdek Dosyasının başına devrediliyor (CPU) ---> Çekirdek kodları kendi kendini açıyor ve çekirdeği kullanıma hazır hale 
    getiriyor (CPU)

    "start.elf" programı çeşitli firmware kodlarını içermektedir. Bu kod FAT dosya sistemindeki kök dizinde bulunan "config.txt" 
    dosyasını okuyarak donanım bileşenlerini yapılandırmaktadır. "config.txt" dosyası pek çok donanım biriminin konfigürasyon ayarlarını 
    barındırmaktadır. "start.elf" dosyası çekirdek dosyasını (kernel image) yüklemek için önce "config.txt" dosyasındaki şu satırı 
    aramaktadır:

    kernel=kernel_dosyasının_ismi

    Bunu bulursa burada belirtilen çekirdek dosyasını yükler. Bulamazsa FAT dosya sisteminin kökünde "kernel.img", "kernel7.img" 
    ve "kernel8.img" gibi önceden belirlenmiş çekirdek dosyalarını arar. Yukarıda da belirttiğimiz gibi aslında çekirdek dosyası 
    diskte sıkıştırılmış bir biçimde bulunmaktadır ve sıkıştırılmış bu dosya boot loader tarafından DRAM'a yüklenmektedir.

    FAT Microsoft tarafından tasarlanmış ve ilk kez DOS sistemlerinde kullanılmış bir dosya sistemidir. FAT dosya sisteminin kendi
    içerisinde FAT12, FAT16 ve FAT32 isminde türleri vardır. Bu türler arasındaki farklılık dosya sisteminin "File Allocation Table"
    denilen veri yapısıyla ilgilidir. Microsoft halen bu dosya sistemini desteklemeye devam etmektedir. Ancak birinci dosya sistemi
    olarak Windows sistemlerinde uzunca bir süredir NTFS (Windows NT File System) dosya sistemi kullanılmaktadır. Yukarıdaki anlatımlardan
    da gördüğünüz gibi FAT dosya sistemi bugün hala gömülü Linux sistemlerinin boot sürecinde kullanılmaktadır.

    Raspberry Pi'ın ikinci aşama boot loader programı yalnızca çekirdek imajını RAM'e yüklememektedir. Çekirdeğin kullanacağı bazı 
    bileşenleri de DRAM'a yüklemektedir. Bu bileşenler tipik olarak şunlardır:

    - Çekirdek Komut Satırı Parametreleri (Kernel Command Line Parameters)
    - Geçici Kök Dosya Sistemi (Temporary Root File System)
    - Aygıt Ağacı (Device Tree)

    Raspberry Pi'da bu bileşenlerin FAT dosya sistemindeki dosya isimleri yukarıda sözünü ettiğimiz "config.txt" dosyası içerisinde 
    belirtilebilmektedir. Ancak bu belirlemeler bu dosya içerisinde yapılmadıysa FAT dosya sistemindeki kök dizinde 
    bulunan default bazı dosyalar kullanılmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												26. Ders 13/06/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirttiğimiz gibi FAT dosya sistemi içerisindeki "config.txt" dosyası ikinci aşama boot loader görevinde olan 
    "start.elf" programı tarafından okunmaktadır. Bu dosyanın konfigürasyon parametrelerine ilişkin bilgilere aşağıdaki bağlantıdan 
    erişebilirsiniz:

    https://www.raspberrypi.com/documentation/computers/config_txt.html

    Bu dosya kabaca "özellik=değer" biçiminde satırlardan oluşmaktadır. İstenirse bu özelliklerin Raspbery Pi'ın belli versiyonlarına
    özgü olması da [model_ismi] başlığıyla sağlanabilmektedir. "config.txt" dosyasında yapılabilecek belirlemeler yukarıdaki 
    bağlantıda açıklanmıştır. Bu belirlemelerin birkaçına şöyle örnek verebiliriz:

    - kernel=dosya_adı satırı çekirdek dosyasının FAT dosya sistemindeki ismini belirtir. Yani biz yeni bir Linux çekirdeğini 
    derlediğimizde eskisini muhafaza edip bu satırı yeni çekirdeğin ismi ile değiştirirsek sistem yeni derlediğimiz Linux çekirdeği 
    ile açılacaktır.

    - arm64_bit=1 satırı işlemcinin 64 bit modda çalıştırılacağı anlamına gelmektedir. Eğer işlemci 32 bit modda çalıştırılacaksa 
    arm64_bit=0 yapılmalıdır. Tabii bu durumda çekirdek dosyasının da 32 bit olması gerekir.

    - initramfs=dosya_ismi satırı geçici kök dosya sistemi için bulundurulan dosyanın isminin belirtilmesine olanak sağlamaktadır. 
    Bu satır belirtilmezse kök dosya sistemine ilişkin dosya default isimle aranmaktadır.

    - ramfsaddr=fiziksel_adres satırı initramfs dosyasının çekirdeğin kullanması için fiziksel belleğin neresine yükleneceğini 
    belirtmektedir. Bu satır yazılmazsa dosya default bir yere yüklenip adresi çekirdeğe geçirilmektedir.

    - cmdline=dosya_ismi satırı çekirdeğin komut satırı parametrelerinin elde edileceği dosya isminin belirlenmesini sağlamaktadır. Bu 
    belirleme yapılmazsa çekirdek parametreleri "cmdline.txt" isimli dosyadan okunmaktadır.

    - total_mem=megabyte_değeri satırı işletim sisteminin sanki burada belirtilen kadar RAM varmış gibi çalışmasını sağlamaktadır. 
    Örneğin düşük RAM ile test işlemlerinde biz bu değeri küçülterek sistemi boot edebiliriz. Böylece Linux sanki kendisine bu kadar 
    RAM bağlıymış gibi çalışacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux çekirdeğinin kodlarına dokunmadan onunla ilgili bazı davranış değişikliklerinin yapılması üç biçimde sağlanabilmektedir:

    1) Çekirdek derlenirken bazı konfigürasyon parametrelerine bakılmaktadır. O halde biz çekirdeği derlemeden önce çekirdek konfigürasyon
    parametreleri üzerinde değişiklik yapıp çekirdeği derlersek bir davranış değişikliği oluşturabiliriz.

    2) Çekirdek derlendikten sonra kendini kullanıma hazır hale getirirken (initialize ederken) ismine "çekirdek komut satırı 
    parametreleri (kernel command line parameters)" denilen parametreler yoluyla davranış değişikliği oluşturulabilmektedir. 
    Çekirdek komut satırı parametreleri "boot loader tarafından" çekirdeğe iletilmektedir.

    3) Nihayet çekirdek çalışırken de çekirdeğin davranışı bazı komutlarla (bu komutlar bazı mekanizmaları ve sistem fonksiyonlarını 
    kullanmaktadır), konfigürasyon dosyalarıyla ve bazı mekanizmalarla da değiştirilebilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux'ta çekirdek komut satırı parametreleri birbirinden boşlukla ayrılmış yazılardan oluşmaktadır. Bazı parametrelerin argümanları
    yoktur, bazılarının vardır. Eğer parametrenin varsa "parametre=değer" biçiminde yoksa yalnızca "parametre" biçiminde belirtilmektedir. 
    Çekirdek komut satırı parametreleri tek bir yazı biçiminde çekirdeğe aktarılmaktadır. Çekirdek bu komut satırı parametrelerini 
    kendini kullanıma hazır hale getirmenin (kendini initialize etmenin) ön aşamalarında parse eder ve bu değerleri çekirdeğin 
    yapılandırılması amacıyla kullanır. Tabii çekirdeğin komut satırı parametreleri boot loader tarafından çekirdeğe iletilmektedir. 
    Örneğin çekirdek komut satırı parametreleri aşağıdaki gibi bir görünümde olabilir:

    console=serial0,115200 console=tty1 root=PARTUUID=382d6f16-02 rootfstype=ext4 fsck.repair=yes rootwait quiet splash 
    plymouth.ignore-serial-consoles cfg80211.ieee80211_regdom=TR

    Linux çekirdeğinin onlarca farklı komut satırı parametresi vardır. Bunların çoğu spesifik konulara ilişkindir ve ancak çekirdeğin 
    yapısını iyi bilen kişiler tarafından anlamlandırılabilir. Tabii bazı parametrelerin anlamları herkes tarafından anlaşılacak kadar 
    açıktır. Çekirdek parametrelerinin dokümantasyonuna aşağıdaki bağlantıdan erişebilirsiniz:

    https://www.kernel.org/doc/html/v4.14/admin-guide/kernel-parameters.html

    İşte Raspberry Pi'da FAT dosya sistemindeki "cmdline.txt" dosyasının içeriği "start.elf" boot loader programı tarafından Linux 
    çekirdeğine komut satırı parametreleri olarak aktarılmaktadır. Örneğin kursumuzundaki Raspberry Pi sistemindeki "cmdline.txt"
    dosyasının default içeriği şöyledir:

    console=serial0,115200 console=tty1 root=PARTUUID=382d6f16-02 rootfstype=ext4 fsck.repair=yes rootwait quiet splash 
    plymouth.ignore-serial-consoles cfg80211.ieee80211_regdom=TR

    Örneğin biz bu satırın sonuna "maxcpus=2" parametresini ekleyip sistemi reboot edersek artık Linux çekirdeği yalnızca iki
    CPU kullanacak biçimde açılacaktır. maxcpus parametresi çekirdeğin kaç CPU kullanacağını belirtmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    RAM'in belli kısmının disk gibi kullanılmasına "ramdisk" denilmektedir. Ramdisk kullanımı çok eskiden beri işletim sistemlerinde 
    bulunmaktadır. Linux'ta da bazı dosya sistemleri diskte değil tamamen RAM'de yani ramdisk üzerinde oluşturulmaktadır. 
    Örneğin "proc dosya sistemi" işletim sistemi ve aygıt sürücüler tarafından dış dünyaya bilgi vermek için kullanılmaktadır. 
    Bu dosya sisteminin disk ile hiçbir ilgisi yoktur. Tamamen RAM'de yaratılmış olan yani ramdisk üzerine kurulu olan bir dosya 
    sistemidir.

    Pekiyi disk yerine RAM'de dosya sistemi oluşturmanın tipik faydaları şunlardır:

    1) Hızlı Erişim: Örneğin "proc" dosya sistemi RAM yerine diskte oluşturulsaydı sistem çok yavaş çalışırdı.

    2) Geçici ve Güvenli Erişim: Bazen bizim bir dosya sistemini oluşturup bir süre kullanıp onu yok etmemiz gerekebilmektedir. Bu
    tür durumlarda disk yerine ramdisk tercih edilebilir. Bazı geçici bilgilerin diskte yer alması onların çalınabilmesini 
    kolaylaştırabilmektedir. Onların ramdisk içerisinde tutulması daha güvenli bir kullanım oluşturabilir.

    3) Test işlemleri: Bazı test işlemlerinin kısıtlı alanlarda yapılması gerekebilir. Bunun için ramdisk'ler tercih edilebilmektedir.

    Linux sistemlerinde "ramdisk" üzerinde kullanılabilecek iki dosya sistemi bulunmaktadır. Bunlardan biri "ramfs" isimli 
    dosya sistemidir. ramfs dosya sistemi aşağıdaki gibi mount edilerek kullanılabilir:

    sudo mount -t ramfs ramfs myramdisk

    Burada "myramdisk" mount edilecek dizini belirtmektedir. ramfs dosya sistemine dosya yerleştirildikçe bu dosya sistemi 
    fiziksel RAM'den alan almakta ve gittikçe genişlemektedir. Bunun için ayrılan fiziksel RAM swap işlemine sokulmamaktadır. 
    Böylece her zaman hızlı bir erişim olanağı vermektedir. Ancak dikkatle kullanılması gerekir.

    Ramdisk üzerinde oluşturulan diğer bir dosya sistemi de "tmpfs" biçiminde isimlendirilen dosya sistemidir. Bu dosya sisteminde 
    yaratılan ramdisk için bir büyüklük koşulu oluşturulabilmektedir. Bu dosya sistemindeki RAM sayfaları aynı zamanda isteğe 
    bağlı bir biçimde swap işlemine de sokulabilmektedir. Bu dosya sistemi de aşağıdaki gibi mount edilerek kullanılabilir:

    sudo mount -t tmpfs -o size=10M tmpfs myramdisk

    Burada 10 MB uzunluğunda bir ramdisk oluşturulmuştur. Tabii sistem reboot edildiğinde tüm mount noktaları otomatik unmount 
    edileceği için bu ramdisk içerikleri de silinmiş olacaktır. Kalıcılık sağlamak için mount işlemi "/etc/fstab" dosyasında 
    yapılabilir.

    ramfs ve tmpfs dosya sistemlerinin mount edilmesinde bir aygıt dosyasının kullanılmadığına dikkat ediniz. Bu dosya sistemleri 
    doğrudan RAM üzerinde kendi organizasyonlarını oluşturmaktadır. Ancak siz "ext2", "ext3" ve "ext4" gibi dosya sistemlerini 
    RAM'de mount ederek kullanmak istiyorsanız bu durumda "/dev/ramN" (burada N bir sayı belirtiyor) blok aygıt sürücülerinden
    faydalanabilirsiniz. Bu aygıt sürücüler "brd" isimli modül tarafından kontrol edilmektedir. Bu modül yüklenirken bunların 
    kullanacağı RAM miktarı (yani ramdisk'in büyüklüğü) ayarlanmaktadır. Sisteminizde bu modül otomatik olarak yüklenmemişse
    yüklemeyi aşağıdaki gibi yapabilirsiniz:

    $ sudo modprobe brd rd_nr=1 rd_size=65536

    Buradaki komut satırı parametreleri kaç aygıt dosyası oluşturulacağını ve bunların büyüklüğünü belirtmektedir. İstediğiniz 
    dosya sisteminin mount edilmesini şöyle sağlayabilirsiniz:

    $ sudo mkfs.ext4 /dev/ram0
    $ sudo mkdir ramdisk
    $ sudo mount /dev/ram0 ramdisk
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												27. Ders 25/06/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Beaglebone Black'teki boot süreci de aslında Raspberry Pi'a benzemektedir. İşlemci reset edildiğinde yine reset vektöründen
    çalışmaya başlar. Orada ROM bellek bulunmaktadır. Bu ROM bellekteki program minimal bazı ön işlemleri yaparak boot aygıtını 
    belirlemeye çalışır. Eğer SD kart yuvasında SD kart varsa ve güç verilirken BOOT düğmesine basılıysa boot işlemi SD karttan 
    değilse içsel emmc bellekten yürütülür. Diğer medyalardan boot etme süreci ileride ayrıca ele alınacaktır.

    Eskiden BBB SD karttan boot edilirken FAT32 disk bölümü mutlaka bulunduruluyordu. Sonra artık yeni hazır imajlarda FAT32 
    disk bölümü bulundurulmamaktadır. Ancak yine boot işleminde FAT32 içeren SD kart da kullanılabilir. Örneğin bizim aşağıdaki
    bağlantıdan indirdiğimiz BBB Linux imajı FAT32 disk bölümü içermemektedir:

    https://www.beagleboard.org/distros

    Burada SD kart şöyle bir organizasyona sahiptir:

    |Disk Bölümleme Tablosu|Boot Loader Programlar|EXT4 Dosya sistemi|

    Yine kart üzerindeki EMMC bellekteki imaj da bu biçimdedir. Ancak yine biz boot işlemini iki disk bölümü ile Raspberry Pi'daki
    gibi de yapabiliriz. Bu durumda SD kart organizasyonu şöyle olacaktır:

    |Disk Bölümleme Tablosu|FAT32 Dosya Sistemi|EXT4 Dosya sistemi|

    Bu organizasyonda boot loader programlar Raspberry Pi'da olduğu gibi FAT32 disk bölümünde bulundurulabilmektedir. Tabii 
    boot loader programların FAT32 disk bölümünde değil de doğrudan SD karttaki bazı bloklarda bulunuyor olması boot sürecini 
    biraz daha hızlandırmaktadır.

    BBB'de de boot sürecinde iki düzeyli boot loader kullanılmaktadır. ROM'daki kod önce minimal birtakım ilk işlemleri yaptıktan 
    sonra ismine "x-loader" ya da "MLO" denilen birinci düzey boot loader'ı board üzerindeki içsel RAM'e yükler. (Bu RAM 128K 
    büyüklüğündedir ve L2 cache olarak da kullanılmaktadır.) X-loader ya da MLO artık gerekli olan donanımsal hazırlık işlemlerini 
    yapar (örneğin DRAM belleğin initialize edilmesi de bu birinci düzey boot loader tarafından yapılmaktadır.) işletim sistemini 
    yükleyecek ikinci düzey boot loader'ı SD karttan ya da EMMC bellekten DRAM belleğe yükler. Nihayet ikinci düzey boot loader 
    da işletim sistemini ve "aygıt ağacı", "geçici root dosya sistemini" yükleyerek akışı işletim sistemine devreder.

    BBB'de boot loader olarak U-Boot kullanılmaktadır. Burada sözünü ettiğimiz MLO programı (yani birinci düzey boot loader programı)
    U-Boot ile oluşturulabilmektedir. X-Loader aslında TI firmasının kendi birinci düzey boot loader'ı için kullandığı bir 
    terimdi. Bugün genellikle x-loader denildiğinde TI firmasının eskiden ürettiği birinci düzey boot loader'lar MLO denildiğinde
    ise U-Boot tarafından üretilen birinci düzey boot loader'lar anlaşılmaktadır. BBB'ye ilişkin herhangi bir dokümanda "x-loader"
    ya da "MLO" terimlerini görürseniz bunların işlev olarak aynı anlama geldiğini düşünebilirsiniz. BBB'de bu terimlerle kastedilen 
    şey birinci düzey boot loader'lardır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Kalıcı bellek görevinde olan hard disklere, SSD belleklere ve micro SD kartlara genel olarak disk denilmektedir. Disk ile 
    DRAM arasında aktarımlar byte byte değil blok blok yapılmaktadır. Terminoloji ortamlara göre değişebilmektedir. Ancak 
    genel olarak disk ile RAM arasında transfer edilecek en küçük byte topluluğuna sektör denilmektedir. Bir sektör genellikle
    512 byte biçimindedir. Bu durumda örneğin diskteki 1 byte'ı değiştirecek bile olsak önce o byte'ın içinde bulunduğu 512 
    byte'lık sektörün RAM'e çekilmesi, değişikliğin RAM'de yapılması ve yine 512 byte'tın sektör biçiminde diske geri yazılması 
    gerekmektedir. Donanımsal düzeyde baktığımızda diskte dosyalar yoktur yalnızca sektörler vardır. Dosya kavramı işletim 
    sistemleri tarafında oluşturulan yüksek seviyeli kavramdır. Yani işletim sistemleri aslında diskteki hangi sektörlerin 
    hangi dosyanın hangi parçası olduğunu bir biçimde tutmaktadır. Böylece sanki programcılara dosyaların ardışıl byte 
    topluluklarından oluştuğu gibi bir algı sunmaktadır. İşte işletim sistemlerinin diskteki sektörleri dosya gibi gösteren 
    ve dosya kavramını oluşturan alt sistemlerine "dosya sistemleri (file systems)" denilmektedir.

    Diskteki sektörlere tıpkı bellekteki byte'larda olduğu gibi bir sıra numarası karşılık düşürülmüştür. Yani her sektörün
    ilk sektör 0 olmak üzere bir numarası vardır. Donanımsal olarak bir sektöre onun sektör numarasıyla erişilmektedir. 
    Bu sektör numarasına LBA (Logical Block Address) de denilmektedir.

    Dosya sistemlerinin işletim sistemleri bakımından iki tarafı vardır: Disk ve bellek. İşletim sistemleri hangi sektörlerin 
    hangi dosyanın parçası olduğunu kalıcı olarak tutmak için diskte bir organizasyon yapmaktadır. Bu dosya sisteminin disk
    tarafıdır. Ayrıca işletim sistemi diskteki dosyalar üzerinde işlemler yapabilmek için çekirdek alanı içerisinde bazı 
    organizasyonlar da yapmaktadır. Bu da dosya sisteminin bellek tarafıdır.

    Bugün için çok sayıda dosya sistemi vardır. Örneğin Microsoft'un işletim sistemleri FAT tabanlı dosya sistemlerini kullanırken 
    UNIX/Linux sistemleri i-node tabanlı dosya sistemlerini kullanmaktadır. MacOS sistemlerindeki dosya sistemleri de i-node
    tabanlı dosya sistemlerine benzemektedir. Tabii bir işletim sistemi başka bir işletim sisteminni dosya sistemlerini de 
    destekleyebilmektedir. Örneğin biz Linux'ta FAT dosyası sistemi üzerinde NTFS dosya sistemi üzerinde işlemler yapabilmekteyiz.
    Ancak UNIX/Linux dünyasının asıl dosya sistemleri i-node tabanlı sistemlerdir. Bugün Linux sistemlerinde i-node tabanlı 
    dosya sistemi olarak Ext-2, Extg-3 ve Ext-4 dosya sistemleri yoğun kullanılmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bir diske birden fazla bağımsız dosya sisteminin (ve belki de işletim sisteminin) yüklenebilmesi için diskin mantıksal 
    bakımdan parçalara ayrılması gerekmektedir. Diskin mantıksal bakımdan parçalara ayrılmasına ise "disk bölümlemesi" 
    denilmektedir. Disk bölümlemesi aslında disk bölümlerinin hangi sektörden başlayıp kaç sektör uzunluğunda olduğunun belirlenmesi
    anlamına gelmektedir. Böylece her dosya sistemi başkasının alanına müdahale etmeden yalnızca o disk bölümünü kullanmaktadır.

    Diskteki disk bölümleri hakkında bilgileri barındıran tabloya "disk bölümleme tablosu (disk partition table)" denilmektedir. 
    Bugün için iki disk bölümleme tablo formatı kullanılmaktadır:

    1) Klasik (legacy) MBR Disk Bölümleme Tablo Formatı
    2) Modern UEFI BIOS Sistemlerinin Kullandığı GPT (Guid Partition Table) Formatı

    UEFI BIOS'lar GPT disk bölümleme tablosu kullanırken eski sistemler ve gömülü sistemler genel olarak klasik MBR disk bölümleme
    tablosunu kullanmaktadır. Gömülü sistemler için oluşturduğumuz SD kartlar'daki disk bölümleme tablosu klasik (legacy) disk 
    bölümleme tablosudur. Ancak bugünkü büyük çaplı UEFI BIOS'lar önce GPT disk bölümleme tablosuna bakmakta eğer onu bulamazsa 
    klasik disk bölümleme tablosunu aramaktadır. Yani geçmişe doğru uyum korunmaya çalışılmıştır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												28. Ders 27/06/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Gömülü Linux programcılarının disk sistemi üzerinde temel bazı bilgilere ve becerilere sahip olması gerekmektedir. UNIX/Linux 
    sistemlerinde diskler blok aygıt sürücüleri tarafından yönetilmektedir. Disklere ilişkin blok aygıt sürücüleri için "/dev" 
    dizini içerisinde aygıt dosyaları bulunmaktadır. Örneğin hard diskler ve SSD diskler için blok aygıt sürücülerinin isimleri 
    genellikle "sda" ve "sdb" biçimindedir. Burada "sda" birinci diski "sdb" ise ikinci diski belirtmektedir. Disk bölümlendirmesi 
    yapılmışsa disk bölümleri için ayrı minör numaralı aygıt dosyaları bulunur. Örneğin kursun yapıldığı sanal makinede disklere 
    ilişkin aygıt sürücüler şöyledir:

    $ lsblk
    NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
    sda      8:0    0   60G  0 disk
    ├─sda1   8:1    0    1M  0 part
    ├─sda2   8:2    0  513M  0 part /boot/efi
    └─sda3   8:3    0 59,5G  0 part /
    sr0     11:0    1 1024M  0 rom

    Burada "/dev/sda" aygıt dosyası diski bir bütün olarak ele almakta "/dev/sda1", "/dev/sda2" ve "/dev/sda3" aygıt dosyaları 
    ise ilgili disk bölümlerini bağımsız birer diskmiş gibi ele almaktadır.

    Disklere ilişkin aygıt sürücü isimleri diskin türüne göre değişebilmektedir. Örneğin "lsblk" komutunu BBB'de uyguladığımızda
    aşağıdaki gibi bir çıktı elde ediyoruz:

    $ lsblk
    NAME         MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
    mmcblk1      179:0    0  3,6G  0 disk
    └─mmcblk1p1  179:1    0  3,6G  0 part /
    mmcblk1boot0 179:256  0    2M  1 disk
    mmcblk1boot1 179:512  0    2M  1 disk

    Burada görüldüğü gibi kart üzerindeki built-in EMMC diskine ilişkin aygıt dosyası "mmcblk1" biçimindedir. BBB'de SD kart yuvasına
    SD kartı taktığımızda ona ilişkin aygıt dosyasının "mmcblk0" isminde olduğunu göreceksiniz. SD kartlardaki disk bölümleri aygıt 
    "mmcblk0p1", "mmcblk0p1" gibi ana ismin yanında "p1" "p2" sonekleriyle isimlendirilmektedir.

    O halde biz aslında bir C programcısı olarak bu aygıt sürücülerini bir dosya gibi açıp onun içerisindeki byte'ları okuyabiliriz. 
    Tabii bunu yapan utility programlar zaten vardır. Dosyayı hex biçimde görüntüleyen "od" gibi "hexdump" gibi utility programların 
    komut satırından kullanımını anlatan pek çok kaynak bulunmaktadır. Aşağıdaki basit C programı bir dosyanın ilk 512 byte'ını 
    HEX sistemde görüntülemektedir. Biz bu programı çalıştırırken dosya olarak yukarıda sözünü ettiğimiz aygıt dosyalarını verirsek 
    ilgili diskten okuma yapmış oluruz. Örneğin programın ismi "sample" olmak üzere:

    ./sample /dev/sda

    çalıştırmayı bu biçimde yapabilirsiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

#include <stdio.h>
#include <stdlib.h>

#define BUFFER_SIZE		512

int main(int argc, char *argv[])
{
	FILE *f;
	unsigned char buf[BUFFER_SIZE];

	if (argc != 2) {
		fprintf(stderr, "wrony number of arguments!...\n");
		exit(EXIT_FAILURE);
	}

	if ((f = fopen(argv[1], "rb")) == NULL) {
		fprintf(stderr, "cannot open file!...\n");
		exit(EXIT_FAILURE);
	}

	if (fread(buf, 1, BUFFER_SIZE, f) != BUFFER_SIZE) {
		fprintf(stderr, "cannot read!...\n");
		exit(EXIT_FAILURE);
	}

	for (int i = 0; i < BUFFER_SIZE; ++i)
		printf("%02X%c", buf[i], i % 16 == 15 ? '\n' : ' ');

	fclose(f);

	return 0;
}

/*-----------------------------------------------------------------------------------------------------------------------------
    "hexdump" isimli utility program ile aynı diskin ilk 512 byte'ı şöyle görüntülenebilir:

    $ sudo hexdump -C -n 512 -v /dev/sda

    "od" utility programı aynı şey şöyle de yapılabilir:

    $sudo od -t x1 -N 512 -v /dev/sda
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Disk işlemlerinde çok kullanılan diğer bir utility program da "dd" isimli programdır. Aslında bu program dosyalar üzerinde 
    blok transferi ile kopyalama işlemi yapan genel amaçlı bir programdır. Bu programın beş önemli komut satırı argümanı vardır:

    if=<yol_ifadesi>: Bu okumanın yapılacağı dosyanın yol ifadesini belirtmek için kullanılır.
    of=<yol_ifadesi>: Yazmanın yapılacağı dosyanın yol ifadesini belirtmek için kullanılır.
    bs: "if" dosyasından "of" dosyasına yapılacak okuma yazma işlemlerinin byte miktarını belirtmektedir. (Default değeri 512'dir.)
    count: bs parametresi ile belirtilen byte aktarımının kaç kere yapılacağını belirtmektedir. Bu argüman belirtilmezse kaynak
    "if" dosyasının tamamı kopyalanana kadar aktarıma devam edilmektedir.
    skip: Bu argüman "if" ile belirtilen dosyanın neresinden başlanarak kopyalamanın yapılacağını belirtmektedir. Buradaki birim bs 
    cinsindendir.
    seek: Bu argüman ise "of" ile belirtilen dosyanın neresinden başlanarak kopyalamanın yapılacağını belirtmektedir. Buradaki birim 
    yine bs cinsindendir.

    Eğer yalnızca "if" ve "of" argümanları belirtilirse ancak count değeri belirtilmezse bu durumda if dosyanının sonuna gelinene
    kadar of dosyasına kopyalama yapılmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    "/dev" dizinin altında bazı ilginç karakter aygıt sürücülerine ilişkin aygıt dosyaları da bulunmaktadır. Bunlardan biri 
    "/dev/zero" aygıt dosyasıdır. Bu aygıt dosyasından okuma yapıldığında her zaman 0 değerleri okunmaktadır. Bu aygıt dosyasının 
    sonu yoktur. Yani okuma yapıldığında hiçbir zaman EOF oluşmamaktadır. Bu dosyaya yapılan yazma işlemleri ise atılmaktadır.

    "/dev" dizini altındaki diğer ilginç bir aygıt dosyası da "/dev/null" isimli aygıt dosyasıdır. Bu aygıt dosyasına yazma 
    yapıldığında ilgili aygıt sürücü yazılanları atmaktadır. "/dev/null" aygıt dosyasından okuma yapılmak istendiğinde ise sanki 
    EOF pozisyonundan okuma yapılıyormuş gibi bir etki oluşmaktadır. "/dev/null" aygıt dosyası özellikle IO yönlendirmesi ile
    birtakım çıktıların atılması gerektiği durumlarda kullanılmaktadır. Örneğin:

    $ find / -name "sample.c" 2> /dev/null

    Burada stderr dosyasına yazılan tüm mesajlar atılmaktadır. Örneğin biz içi sıfırlarla dolu 512 * 100 byte'lık bir dosyayı 
    şöyle oluşturabiliriz:

    $ dd if=/dev/zero of=test.dat bs=512 count=10000
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux sistemlerinde bir dosyayı sanki blok aygıtı gibi gösteren hazır aygıt sürücüler bulunmaktadır. Bunlara "loop" aygıt 
    sürücüleri denilmektedir. Bu aygıt sürücülere ilişkin aygıt dosyaları "/dev" dizini içerisinde "loopN" ismiyle (burada N bir 
    sayı belirtiyor) bulunmaktadır. Örneğin:

    $ ls -l /dev/loop*
    brw-rw---- 1 root disk  7,   0 Haz  4 22:31 /dev/loop0
    brw-rw---- 1 root disk  7,   1 Haz  4 22:31 /dev/loop1
    brw-rw---- 1 root disk  7,   2 Haz  4 22:31 /dev/loop2
    brw-rw---- 1 root disk  7,   3 Haz  4 22:31 /dev/loop3
    brw-rw---- 1 root disk  7,   4 Haz  4 22:31 /dev/loop4
    brw-rw---- 1 root disk  7,   5 Haz  4 22:31 /dev/loop5
    brw-rw---- 1 root disk  7,   6 Haz  4 22:31 /dev/loop6
    brw-rw---- 1 root disk  7,   7 Haz  4 22:31 /dev/loop7
    crw-rw---- 1 root disk 10, 237 Haz  4 22:31 /dev/loop-control

    Bir dosyayı blok aygıt sürücüsü biçiminde kullanabilmek için önce "losetup" programı ile bir hazırlık işleminin yapılması 
    gerekir. Hazırlık işleminde "loop" aygıt sürücüsüne ilişkin aygıt dosyası ve blok aygıt sürücüsü olarak gösterilecek dosya 
    belirtilir. Bu işlemin sudo ile yapılması gerekmektedir. Örneğin:

    $ sudo losetup /dev/loop0 mydisk.dat

    Tabii bizim burada "mydisk.dat" isimli bir dosyaya sahip olmamız gerekir. İçi 0'larla dolu 100 MB'lik böyle bir dosyayı
    dd komutuyla aşağıdaki gibi oluşturabiliriz:

    $ dd if=/dev/zero of=test.dat bs=512 count=10000

    Burada artık "/dev/loop0" aygıt dosyası adeta bir disk gibi kullanılabilir hale gelmiştir. Biz bu "/dev/loop0" dosyasını 
    kullandığımızda bu işlemlerden aslında "mydisk.dat" dosyası etkilenecektir.

    Sıfırdan bir diske ya da bir disk bölümüne bir dosya sistemi yerleştirebilmek için onun formatlanması gerekir. UNIX/Linux
    sistemlerinde formatlama için "mkfs.xxx" isimli programlar bulundurulmuştur. Örneğin aygıtta FAT dosya sistemi oluşturmak 
    için "mkfs.fat" programı, ext4 dosya sistemi oluşturmak için "mkfs.ext4" programı kullanılmaktadır. Örneğin biz yukarıda
    oluşturmuş olduğumuz "/dev/loop" aygıtını ext2 dosya sistemi ile aşağıdaki gibi formatlayabiliriz:

    $ sudo mkfs.ext2 /dev/loop0

    Burada işlemden aslında "mydisk.dat" dosyası etkilenmektedir. Artık formatladığımız aygıta ilişkin dosya sistemini aşağıdaki 
    gibi mount edebiliriz:

    # sudo mount /dev/loop0 mydisk

    Loop aygıtının dosya ile bağlantısını kesmek için "losetup" programı "-d" seçeneği ile çalıştırılır. Tabii önce aygıtın 
    kullanımdan düşürülmesi gerekir:

    $ sudo umount mydisk
    $ sudo losetup -d /dev/loop0

    Eğer loop aygıt sürücüsünün bir dosyayı onun belli bir offset'inden itibaren kullanmasını istiyorsak losetup programında
    "-o (ya da "--offset") seçeneğini kullanmalıyız. Örneğin bir disk imajının içerisindeki Linux dosya sisteminin disk imajının 
    8192'nci sektöründen başladığını varsayalım. "dev/loop0" aygıt sürücüsünün bu imaj dosyasını bu offset'ten itibaren kullanmasını
    şöyle sağlayabiliriz:

    $ sudo losetup -o 4194304 /dev/loop0 am335x-debian-11.7-iot-armhf-2023-09-02-4gb.img

    512 * 8192 = 4194304 olduğuna dikkat ediniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi "loop" aygıt sürücüsü yoluyla BBB'nin siteden indirdiğimiz imajın üzerinde gezinelim. Siteden indirilen imaj bir disk 
    imajı olduğuna göre diskin içerisinde disk bölümleme tablosu ve u-boot boot loader programları bulunmaktadır. O halde bizim 
    bu imaj içerisindeki Linux dosya sisteminin nereden başladığını belirlememiz gerekir. Bu belirlemeyi şöyle yapabiliriz:

    ******************************************************
    $ fdisk -l am335x-debian-11.7-iot-armhf-2023-09-02-4gb.img
    Disk am335x-debian-11.7-iot-armhf-2023-09-02-4gb.img: 3,52 GiB, 3774873600 bytes, 7372800 sectors
    Units: sectors of 1 * 512 = 512 bytes
    Sector size (logical/physical): 512 bytes / 512 bytes
    I/O size (minimum/optimal): 512 bytes / 512 bytes
    Disklabel type: dos
    Disk identifier: 0xee60af7b

    Device                                           Boot Start     End Sectors  Size Id Type
    am335x-debian-11.7-iot-armhf-2023-09-02-4gb.img1 *     8192 7372799 7364608  3,5G 83 Linux
    ******************************************************

    Buradan Linux dosya sisteminin imaj dosyasının 8192'nci sektöründen (yani 8192 * 512 offset'inden) başladığını anlıyoruz.
    O halde loop aygıtını şöyle kullanıma hazırlayabiliriz:

    $ sudo losetup -o 4194304 /dev/loop0 am335x-debian-11.7-iot-armhf-2023-09-02-4gb.img

    Artık mount işlemini aşağıdaki gibi yapabiliriz.

    $ sudo mount /dev/loop0 mydisk

    Şimdi "mydisk" geçtiğimizde aslında bu dizin imaj dosyasının içerisindeki Linux dosya sistemini kullanmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												29. Ders 02/07/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Klasik MBR (legacy) disk bölümlendirmesinde diskin ilk sektörüne (0 numaralı sektörüne) MBR (Master Boot Record) sektörü 
    denilmektedir. MBR sektörünün sonundaki 2 byte MBR'nin bilinçli olarak oluşturulduğunu belirten sihirli bir sayıdan (magic 
    number) oluşmaktadır. Bu sihirli sayı hex olarak 55 AA biçimindedir. Aşağıda "loop0" aygıtı üzerinde oluşturulmuş bir MBR
    sektörü görülmektedir:

    00000000  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000010  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000020  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000030  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000040  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000050  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000060  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000070  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000080  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000090  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    000000a0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    000000b0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    000000c0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    000000d0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    000000e0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    000000f0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000100  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000110  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000120  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000130  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000140  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000150  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000160  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000170  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000180  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    00000190  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    000001a0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    000001b0  00 00 00 00 00 00 00 00  03 74 de d6 00 00 80 01  |.........t......|
    000001c0  01 00 83 20 0d 13 3f 00  00 00 01 b0 04 00 00 20  |... ..?........ |
    000001d0  0e 13 83 3e 18 26 40 b0  04 00 c0 af 04 00 00 00  |...>.&@.........|
    000001e0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    000001f0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 55 aa  |..............U.|

    Sektörün sonunun 55 AA ile bittiğine dikkat ediniz.

    Klasik MBR Disk Bölümlemesinde MBR sektörünün sonundaki 64 byte'a "Disk Bölümleme Tablosu (Disk Partition Table)" denilmektedir. 
    Tabii sektörün sonunda hex olarak 55 AA bulunduğu için disk bölümleme tablosu da bu 55 AA byte'larının hemen gerisindeki 
    64 byte'tadır. O halde MBR sektörünün sonu aşağıdaki gibidir:

    ... <64 byte (Disk Bölümleme Tablosu)> 55 AA

    Yukarıdaki MBR sektörünün son 64 byte'ı ve 55 AA değerleri aşağıda verilmiştir:

                                                         80 01  |.........t......|
    000001c0  01 00 83 20 0d 13 3f 00  00 00 01 b0 04 00 00 20  |... ..?........ |
    000001d0  0e 13 83 3e 18 26 40 b0  04 00 c0 af 04 00 00 00  |...>.&@.........|
    000001e0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00  |................|
    000001f0  00 00 00 00 00 00 00 00  00 00 00 00 00 00 55 aa  |..............U.|

    Başka bir deyişle Disk Bölümleme Tablosu MBR sektörünün 0x1BE (446) offset'inden başlayıp 64 byte sürmektedir. Disk Bölümleme 
    Tablosu'ndaki her disk bölümü 16 byte ile betimlenmektedir. Dolayısıyla klasik Disk Bölümleme Tablosu 4 disk bölümünü barındırmaktadır. 
    Pekiyi bu durumda 4'ten fazla disk bölümü oluşturulamaz mı? İşte "Genişletilmiş Disk Bölümü (Extended Disk Partition)" kavramı 
    ile bu durum mümkün hale getirilmiştir. Yukarıdaki Disk Bölümleme Tablosu'nun 16 byte'lık disk bölümleri aşağıda verilmiştir:

    80 01 01 00 83 20 0d 13  3f 00 00 00 01 b0 04 00
    00 20 0e 13 83 3e 18 26  40 b0 04 00 c0 af 04 00
    00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00
    00 00 00 00 00 00 00 00  00 00 00 00 00 00 00 00

    Disk Bölümleme Tablosu'ndaki 16 byte'lık disk bölümünün içeriği şöyledir:

    Offset (Hex)    uzunluk         Anlamı
    -------------------------------------------------------------------------------------------------
    0               1 BYTE          Disk Bölümünün Aktif Olup Olmadığı Bilgisi
    1               3 BYTE          Disk Bölümünün Eski Sistemdeki (CHS Sistemindeki) Başlangıç Sektörü
    4               1 BYTE          Sistem ID Değeri
    5               3 Byte          Disk Bölümünün Eski Sistemdeki (CHS Sistemindeki) Bitiş Sektörü
    8               4 BYTE (DWORD)  Disk Bölümünün LBA Sistemindeki Başlangıç Sektörü
    C               4 BYTE (DWORD)  Disk Bölümündeki Sektör Sayısı (Disk Bölümünün Uzunluğu)

    - 4 disk bölümünden yalnızca bir tanesi aktif olabilmektedir. Sistem aktif disk bölümünden boot edilmektedir. Aktif disk 
    bölümü için 0x80 değeri aktif olmayan disk bölümü için 0x00 değeri kullanılmaktadır.

    - Eskiden diskteki bir sektörün yeri "hangi yüzde (her yüzü bir kafa okuduğu için, hangi kafada), hangi track'te (track'e 
    silindir (cylinder) de denilmektedir) ve hangi sektör diliminde olduğu bilgisiyle ifade ediliyordu. Bu koordinat sistemine
    CHS (Cylinder-Head-Sector) koordinat sistemi deniyordu. Sonra bu koordinat sisteminden vazgeçildi. Sektörün yeri ilk sektör 
    0 olmak üzere tek bir sayıyla temsil edilmeye başlandı.

    - Her disk bölümünde farklı bir işletim sisteminin kullandığı dosya sistemi bulunuyor olabilir. "Sistem ID Değeri" o disk 
    bölümünde hangi işletim sistemine ilişkin bir dosya sisteminin bulunduğunu belirtmektedir. Böylece Disk Bölümleme Tablosu'nu 
    inceleyen kişiler disk bölümlerinin hangi işletim sistemi için oluşturulduğunu anlayabilmektedir. Tüm Sistem ID Değerleri 
    için bunların listelendiği dokümanlara başvurabilirsiniz. Biz burada birkaç System ID değerini verelim:

    0C: Windows FAT32 Sistemi
    0E: Windows FAT Sistemi
    0F: Genişletilmiş Disk Bölümü
    83: Linux Dosya Sistemlerinden Birisi
    82: Linux İçin Swap Alanı Olarak Kullanılacak Disk Bölümü

    - Bir disk bölümü için en önemli iki bilgi onun diskin hangi sektöründen başlayıp kaç sektör uzunlukta olduğudur. Yani disk 
    bölümünün başlangıç sektör numarası ve toplam sektör sayısıdır. İşletim sistemleri böylece kendileri için belirlenmiş olan 
    disk bölümlerinin dışına erişmezler. Yani disk bölümleri adeta disk içerisindeki disklerin yerlerini belirtmektedir.

    - 90'larla birlikte diskteki sektörlerin adreslenmesi için CHS sistemi yavaş yavaş bırakılmaya başlanmış LBA (Logical Block 
    Address) denilen sisteme geçilmiştir. Bu sistemde diskin ilk sektörü 0 olmak üzere her sektöre artan sırada bir tamsayı karşılık 
    düşürülmüştür. İşte bu koordinat sistemine LBA denilmektedir. Artık MBR Disk Bölümlerinde disk bölümünün başlangıç sektörü 
    LBA sistemine göre belirtilmektedir.

    - LBA sisteminde bir disk bölümünde en fazla 2^32 tane sektör bulunabilir. Bir sektör 2^9 (512) byte olduğuna göre MBR
    Disk Bölümleme Tablosu en fazla 2^41 = 2TB diskleri destekleyebilmektedir. Gömülü sistemlerde henüz bu büyüklükte diskler 
    kullanılmadığı için klasik MBR Disk Bölümleme Tablosu iş görmektedir. Ancak masaüstü sistemlerde artık bu sınır aşılmaktadır. 
    İşte UEFI BIOS'lar tarafından kullanılan "GUID Disk Bölümlemesi (GPT)" bu sınırı çok daha ötelere taşımaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    MBR Disk Bölümleme Tablosu'nun 4 girişe sahip olması en fazla 4 tane disk bölümünün oluşturulabilmesine yol açmaktadır. 
    Ancak bazen 4'ten fazla disk bölümünün oluşturulması istenebilir. İşte bunun için "Genişletilmiş Disk Bölümü (Extended 
    Partition)" denilen bir yöntem oluşturulmuştur. Genişletilmiş bir disk bölümü ana 4 girişten bir tanesi olarak oluşturulur. 
    Genişletilmiş Disk Bölümü aslında diskin bir parçasını sanki ayrı bir diskmiş gibi betimlemektedir. Şöyle ki, Genişletilmiş 
    Disk Bölümünün 0'ıncı sektöründe (yani ilk sektöründe) yine aynı yerde Disk Bölümleme Tablosu vardır. Bu disk Bölümleme Tablosu 
    sanki disk o kadarmış gibi bölümleme yapmaktadır. Genişletilmiş Disk Bölümlerindeki Disk Bölümleme Tabloları en fazla 2 girişe
    sahip olabilir. Bu girişlerden biri o genişletilmiş bölümdeki yeni disk bölümünü diğeri ise yine o Genişletilmiş Disk bölümündeki
    Genişletilmiş Disk Bölümünü betimler.

    Ancak gömülü sistemlerde genellikle 4'ten fazla disk bölümünün kullanılması karşılaşılan bir durum değildir. Bu nedenle biz
    burada Genişletilmiş Disk Bölümlerinin formatı konusundaki ayrıntılar girmeyeceğiz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												30. Ders 04/07/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi biz disk bölümlemesi nasıl yapabiliriz? Aslında mademki disk bölümleme tablosunun tüm formatı zaten biliniyor bu 
    durumda bir disk editörle (hex editörle) manuel olarak disk bölümleri üzerinde işlemler yapabiliriz. Tek yapılacak şey diskin 
    MBR bölümünü okuyup Disk Bölümleme Tablosu'nun yerini bulup onu değiştirmektir.

    Diskteki sektörler üzerinde görüntüleme ve güncelleme işlemlerini yapan programlara "disk editörleri" denilmektedir. UNIX/Linux
    sistemlerinde diskler de aygıt sürücüler sayesinde birer dosya gibi kullanılabildiği için disk editörler yerine GUI hex
    editörler de bu amaçla kullanılabilmektedir. Windows sistemlerinde "freeware (yani parasız kullanılabilen)" HxD isimli
    program oldukça iyi yazılmıştır. Maalesef UNIX/Linux sistemlerinde HxD kalitesinde bir disk editör programı bulunmamaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux sistemlerinde disk bölündermesi için en yaygın kullanılan program "fdisk" isimli programdır. Microsoft'un da Windows
    sistemlerinde kullanılabilen aynı isimli bir programı vardır. fdisk konsol ekranında interaktif olarak kullanılabilen 
    bir programdır. Aslında doğrudan belli bir dosya üzerinde de disk gibi bölümlendirme işlemlerini yapabilmektedir. fdisk
    programının temel kullanımı şöyledir:

    1) Hangi disk üzerinde işlem yapılacaksa o diske ilişkin aygıt dosyası fdisk programına komut satırı argümanı olarak 
    verilmelidir. Tabii disk aygıt dosyaları "root" kullanıcısına ilişkin olduğu için fdisk programı da genellikle "sudo" 
    ile çalıştırılır. Örneğin önce blok aygıt sürücülerimize bakalım:

    ******************************************************
    $ lsblk
    NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
    sda      8:0    0   80G  0 disk
    ├─sda1   8:1    0  512M  0 part /boot/efi
    ├─sda2   8:2    0    1K  0 part
    └─sda5   8:5    0 79,5G  0 part /
    sr0     11:0    1 1024M  0 rom
    ******************************************************

    Burada "sda" diski bir bütün olarak gösteren aygıt sürücüsüdür. Bu aygıt sürücüye ilişkin aygıt dosyası "/dev/sda" biçimindedir. 
    "sda1", "sda2" ve "sda5" disk üzerindeki disk bölümleridir. Bizim bölümlendirme için diski bir bütün olarak ele almamız 
    gerekir. Bu nedenle "sda" diski için fdisk programı şöyle çalıştırılmalıdır:

    $ sudo fdisk /dev/sda

    Tabi biz örneğimizde loop aygıtı kullanacağız. Bu durumda loop aygıtını şöyle kullanıma hazır hale getirebiliriz:

    ******************************************************
    $ dd if=/dev/zero of=disk.img bs=300M count=1
    1+0 kayıt girdi
    1+0 kayıt çıktı
    314572800 bytes (315 MB, 300 MiB) copied, 1,23241 s, 255 MB/s
    ******************************************************

    Buradan diski temsil eden içi sıfırlarla dolu 300MB'lik bir dosya oluşturduk. Şimdi bu dosyayı "/dev/loop0" aygıt dosyası 
    ile bir blok aygıtı gibi gösterelim:

    $ sudo losetup /dev/loop0 disk.img

    Artık "/dev/loop0" aygıt dosyası sanki bir disk gibi kullanılabilecektir. Bu aygıt üzerinde işlem yaptığımızda işlemden 
    "disk.img" dosyası etkilenecektir.

    Artık blok aygıt sürücülerine baktığımızda "loop0" aygıtını göreceğiz:

    ******************************************************
    $ lsblk
    NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
    loop0    7:0    0  300M  0 loop
    sda      8:0    0   80G  0 disk
    ├─sda1   8:1    0  512M  0 part /boot/efi
    ├─sda2   8:2    0    1K  0 part
    └─sda5   8:5    0 79,5G  0 part /
    sr0     11:0    1 1024M  0 rom
    *****************************************************

    Artık fdisk programını bu aygıt üzerinde kullanabiliriz:

    $ sudo fdisk /dev/loop0

    2) Artık interaktif bir biçimde disk bölümlendirme işlemleri yapılabilir. Burada tek harfli çeşitli komutlar girildiğinde
    interaktif bir biçimde işlemler yapılmaktadır. Bu komutlardan önemli olanlarını açıklamak istiyoruz:

    - "n" (new) komutu yeni bir disk bölümü oluşturmak için kullanılmaktadır. Bu komut verildiğinde yaratılacak disk bölümünün 
    "primary" bölüm mü "extended" bölüm mü olduğu sorulmaktadır. Primary disk bölümü ana 4'lük girişteki bölümlerdir. Dolayısıyla
    burada genellikle "p" komutu ile "primary" disk bölümü oluşturulur. Sonra bize 4 girişten hangisinin disk bölümü olarak 
    oluşturulacağı sorulmaktadır. Bu durumda sıradaki numarayı vermek (disk tamamen ilk kez bölümlendiriliyorsa 1) uygun olur. 
    Sonra da bize ilgili disk bölümünün hangi sektörden başlatılacağı ve ne uzunlukta olacağı sorulmaktadır. Aşağıda bir örnek 
    görüyorsunuz:

    **************************************************************************************
    Komut (yardım için m): n
    Disk bölümü tipi
    p   birincil (0 birincil, 0 genişletilmiş, 4 boş)
    e   genişletilmiş (mantıksal disk bölümleri için konteyner)
    Seç (varsayılan p): p
    Disk bölümü numarası (1-4, varsayılan 1): 1
    İlk sektör (2048-614399, varsayılan 2048):
    Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-614399, varsayılan 614399): +50M

    Yeni bir disk bölümü 1, 'Linux' tipinde ve 50 MiB boyutunda oluşturuldu.
    ***************************************************************************************

    - "p" (print) komutu oluşturulmuş olan disk bölümlerini görüntülemektedir. Örneğin:

    **************************************************************************************
    Komut (yardım için m): p
    Disk /dev/loop0: 300 MiB, 314572800 bayt, 614400 sektör
    Birimler: sektör'i 1 * 512 = 512 baytın
    Sektör boyutu (mantıksal/fiziksel): 512 bayt / 512 bayt
    G/Ç boyutu (en düşük/en uygun): 512 bayt / 512 bayt
    Disketikeri tipi: dos
    Disk belirleyicisi: 0x267a62e0

    Aygıt        Açılış Başlangıç    Son Sektör Boyut ld Türü
    /dev/loop0p1             2048 104447 102400   50M 83 Linux
    **************************************************************************************

    - fdisk yaratılan disk bölümlerinin ID'sini default olarak 0x83 (Linux) yapmaktadır. Eğer disk bölümüne FAT dosya sistemi 
    yerleştirilecekse "t" (type) komutu ile bölüm ID'si değiştirilmelidir. Örneğin:

    **************************************************************************************
    Komut (yardım için m): t
    Seçilen disk bölümü 1
    Hex kod (bütün kodlar için L tuşlayın): c
    'Linux' disk bölümünün tipini 'W95 FAT32 (LBA)' olarak değiştirin.

    Komut (yardım için m): p
    Disk /dev/loop0: 300 MiB, 314572800 bayt, 614400 sektör
    Birimler: sektör'i 1 * 512 = 512 baytın
    Sektör boyutu (mantıksal/fiziksel): 512 bayt / 512 bayt
    G/Ç boyutu (en düşük/en uygun): 512 bayt / 512 bayt
    Disketikeri tipi: dos
    Disk belirleyicisi: 0x267a62e0

    Aygıt        Açılış Başlangıç    Son Sektör Boyut ld Türü
    /dev/loop0p1             2048 104447 102400   50M  c W95 FAT32 (LBA)
    **************************************************************************************

    Şu anda biz bir FAT disk bölümü yaratmış olduk. Şimdi ikinci Linux dosya sistemleri için ikinci bölümünü de yaratalım:

    **************************************************************************************
    Komut (yardım için m): n
    Disk bölümü tipi
    p   birincil (1 birincil, 0 genişletilmiş, 3 boş)
    e   genişletilmiş (mantıksal disk bölümleri için konteyner)
    Seç (varsayılan p): p
    Disk bölümü numarası (2-4, varsayılan 2):
    İlk sektör (104448-614399, varsayılan 104448):
    Last sector, +/-sectors or +/-size{K,M,G,T,P} (104448-614399, varsayılan 614399):

    Yeni bir disk bölümü 2, 'Linux' tipinde ve 249 MiB boyutunda oluşturuldu.

    Komut (yardım için m): p
    Disk /dev/loop0: 300 MiB, 314572800 bayt, 614400 sektör
    Birimler: sektör'i 1 * 512 = 512 baytın
    Sektör boyutu (mantıksal/fiziksel): 512 bayt / 512 bayt
    G/Ç boyutu (en düşük/en uygun): 512 bayt / 512 bayt
    Disketikeri tipi: dos
    Disk belirleyicisi: 0x267a62e0

    Aygıt        Açılış Başlangıç    Son Sektör Boyut ld Türü
    /dev/loop0p1             2048 104447 102400   50M  c W95 FAT32 (LBA)
    /dev/loop0p2           104448 614399 509952  249M 83 Linux
    **************************************************************************************

    Artık diskimizde iki disk bölümü vardır.

    - Bir disk bölümünü aktive etmek için "a" komutu (activate) kullanılmaktadır. Örneğin biz FAT32 disk bölümünü aktif disk 
    bölümü haline getirelim:

    **************************************************************************************
    Komut (yardım için m): a
    Disk bölümü numarası (1,2, varsayılan 2): 1

    Disk bölümü 1'de önyüklenebilir bayrağı artık etkin.

    Komut (yardım için m): p
    Disk /dev/loop0: 300 MiB, 314572800 bayt, 614400 sektör
    Birimler: sektör'i 1 * 512 = 512 baytın
    Sektör boyutu (mantıksal/fiziksel): 512 bayt / 512 bayt
    G/Ç boyutu (en düşük/en uygun): 512 bayt / 512 bayt
    Disketikeri tipi: dos
    Disk belirleyicisi: 0x267a62e0

    Aygıt        Açılış Başlangıç    Son Sektör Boyut ld Türü
    /dev/loop0p1 *           2048 104447 102400   50M  c W95 FAT32 (LBA)
    /dev/loop0p2           104448 614399 509952  249M 83 Linux
    **************************************************************************************

    - fdisk önce yazılacakları kendi içerisinde biriktirmekte sonra bunları diske yazmaktadır. Biriktirilenlerin diske yazılması 
    için "w" (write) komutu kullanılmaktadır. Örneğin:

    **************************************************************************************
    Komut (yardım için m): w
    Disk bölümleme tablosu değiştirildi.
    Disk bölüm tablosunu yeniden okumak için ioctl() çağrılıyor.
    Disk bölümü tablosu yeniden okunamadı.: Geçersiz bağımsız değişken

    Çekirdek hala eski tabloyu kullanıyor. Yeni tablo bir sonraki yeniden başlatma işleminden sonra ya da partprobe(8) veya kpartx(8)'i 
    çalıştırdığınızda kullanılacak.
    **************************************************************************************

    - Bir disk bölümünü silmek için "d" komutu kullanılmaktadır. Disk bölümlerini silerken dikkat ediniz.

    3) Disk bölümlerini oluşturduktan sonra çekirdeğin onları o anda görmesi için "partprobe" komutu kullanılmalıdır. Örneğin:

    **************************************************************************************
    $ sudo partprobe /dev/loop0
    [sudo] kaan için parola:
    $ lsblk
    NAME      MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT
    loop0       7:0    0  300M  0 loop
    ├─loop0p1 259:0    0   50M  0 part
    └─loop0p2 259:1    0  249M  0 part
    sda         8:0    0   80G  0 disk
    ├─sda1      8:1    0  512M  0 part /boot/efi
    ├─sda2      8:2    0    1K  0 part
    └─sda5      8:5    0 79,5G  0 part /
    sr0        11:0    1 1024M  0 rom
    **************************************************************************************

    Aslında yukarıda yapılan işlemlerin soucu olarak Disk Bölümleme Tablosu'ndaki iki giriş (32 byte) güncellenmiştir.

    5) fdisk programının başka komutları da vardır. Örneğin disk bölümlendirmesi yapıldıktan sonra bu bölümlendirme bilgileri 
    "O" komutu ile bir dosyaya aktarılabilir. Sonra "I" komutu ile bu dosyadan yükleme yapılabilir. Böylece farklı diskler için
    aynı işlemlerin daha kolay yapılması sağlanabilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Disk bölümlendirmesi GUI araçlarıyla da görsel bir biçimde yapılabilmektedir. Örneğin "gparted" bunun için en çok tercih
    edilen programdır. Ancak "gparted" pek çok dağıtımda default olarak bulunmamaktadır. Onu Debian tabanlı dağıtımlarda aşağıdaki 
    gibi kurabiliriz:

    $ sudo apt-get install gparted

    Programı hiç komut satırı argümanı vermeden çalıştırırsak sabit diskler üzerinde işlemler yapar. Ancak istersek 
    işlem yapmak istediğimiz diski de programı çalıştırırken belirtebiliriz. Örneğin:

    $ sudo gparted /dev/loop

    gparted GUI bir uygulama olduğu için kullanımı oldukça kolaydır. Kullanıcılar ilk kez karşılaştıklarında bile sezgisel 
    biçimde gerekli işlemleri yapabilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Son yıllarda sık kullanılmaya başlanan diğer bir disk bölümleme aracı da "sfdisk" isimli programdır. Bu program eskiden bazı 
    dağıtımlarda default olarak bulundurulmuyordu. Ancak bu program bir süredir "fdisk" paketinin içerisindedir. Dolayısıyla artık 
    pek çok dağıtımda default olarak bulunmaktadır.

    sfdisk programının fdisk programından temel farklılığı disk bölümlerinin "stdin" dosyasından okuma yapılarak basit bir biçimde
    oluşturulabilmesidir. Bu nedenle tek hamlede disk bölümlerini komut satırından oluşturmak isteyenler sfdisk programını tercih
    edebilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Disk bölümlendirmesi yapıldıktan sonra disk bölümlerinin formatlanması gerekmektedir. Burada formatlama demekle disk bölümüne
    yerleştirilecek dosya sistemi için metadata alanların oluşturulması kastedilmektedir. (Formatlama terimi Microsoft tarafından
    sıkça kullanılan eski bir terimdir.)

    Linux sistemlerinde formatlama için (yani ilgili disk bölümünü belli bir dosya sistemine hazırlamak için) "mkfs.xxx" biçiminde
    programlar bulundurulmuştur. Örneğin disk bölümünü Microsoft'un FAT dosya sistemi için formalyacaksak "mkfs.fat" programını, 
    Linux ext2 dosya sistemi için formalyacaksak "mkfs.ext2" programını kullanırız. Tabii bu programların komut satırı argümanları 
    birbirinden farklıdır. Çünkü dosya sisteminin parametrik yapıları diğerinden farklıdır.

    Disk bölümünü FAT32 olarak formatlamak için "mkfs.fat" programında disk bölümüne ilişkin aygıt dosyası belirtilmeli ve FAT32 
    için -F32 seçeneği bulundurulmalıdır. FAT16 için -F16 ve FAT12 için -F12 seçenekleri de bulunmaktadır.

    $ sudo mkfs.fat -F32 /dev/loop0p1
    mkfs.fat 4.1 (2017-01-24)

    Diğer disk bölümünü ext2 dosya sistemi ile aşağıdaki gibi formatlayabiliriz:

    $ sudo mkfs.ext2 /dev/loop0p2
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bir dosya sistemi belli bir dizin altına mount edilebilmektedir. Mount etmek "bir dosya sistemini ana dizin ağacının herhangi
    bir yerine takmak" anlamına gelmektedir. Mount işleminde disk bölümüne ilişkin aygıt dosyası ve mount edilecek dizin belirtilmektedir. 
    Mount işlemi sonrasında mount edilen dosya sisteminin kökü o dizinde olacak biçimde bir durum oluşturulur. Linux sistemlerinde
    kök altındaki "/mnt" dizini "mount dizinleri (mount points)" için oluşturulmuştur. Tabii biz dosya sistemini istediğimiz 
    bir yere mount edebiliriz. Mount işleminde eğer mount dizini doluysa mount işlemi sonrasında artık o dizinin içeriği erişilemez
    hale gelir. Unmount işlemi yapıldığında yeniden o dizin eski yerinde görünecektir. Mount işlemi sırasında Linux çekirdeği dosya 
    sistemini otomatik olarak anlamaya çalışır. Ancak "-t" seçeneği ile biz açıkça dosya sistemini de belirtebiliriz. Örneğin yukarıda
    oluşturmuş olduğumuz iki dosya sistemini aşağıdaki gibi mount edebiliriz:

    $ mkdir fatpart
    $ mkdir linuxpart
    $ sudo mount /dev/loop0p1 fatpart
    $ sudo mount /dev/loop0p2 linuxpart

    Artık "fatpart" ve "linuxpart" dizinleri ilgili disk bölümlerindeki dosya sistemlerinin kökü olarak işlev görecektir.

    Mount edilen disk bölümleri "umount" komutuyla unmount edilebilir. umount komutunda argüman olarak mount dizini verilmelidir. 
    Örneğin:

    $ sudo umount fatpart
    $ sudo umount linuxpart

    umount komutuna mount dizini yerine aygıt dosyası da verilebilmektedir. Bu durumda o aygıtın tüm mount işlemleri unmount
    edilmektedir.

    Bazen sistem yöneticileri mount işleminin boot süreci sırasında otomatik yapılmasını da isteyebilmektedir. Bunun için 
    "/etc/fstab" dosyasında mount edilecek aygıt dosyası ve mount dizini bir satır içerisinde belirtilmektedir. Bu dosya 
    boot işlemi sırasında init prosesi tarafından okunup işletilmektedir. Tabii loop aygıtları üzerinde otomatik mount işlemi
    yapmak istiyorsanız "losetup" işlemini de bu boot işlemi sırasında yapmanız gerekir. Bunun da birkaç yolu vardır. Ancak bu 
    işlemler "systemd" paketinin anlatıldığı bölümde ele alınacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz daha önce kök dosya sistemini henüz oluşturamadığımız için BBB'nin sitesinden indirdiğimiz imajın içerisindeki kök 
    dosya sistemini kullanmıştık. Ancak bu imajın içerisindeki Linux disk bölümü 3.5 GB kadardır. Dosya sisteminin büyüklüğü
    yalnızca onun yer aldığı disk bölümünün büyüklüğü ile ilgili değildir. Dosya sisteminin kendi büyüklüğü o dosya sisteminin 
    kendi metadata alanlarında da belirtilmektedir. Dolayısıyla biz 3.5 GB civarındaki disk bölümünü dd programıyla daha büyük
    bir micro SD karttaki daha büyük bir disk bölümüne kopyaladığımızda o dosya sisteminin uzunluğunu değiştirmiş olmayız. 
    Dosya sisteminin uzunluğunu değiştirebilmek için o dosya sistemine özgü bir biçimde o dosya sisteminin metadata alanlarında
    değişiklik yapmak gerekir. Ext dosya sistemleri için bu işlemi yapan "resize2fs" isimli hazır bir program bulunmaktadır. Bu 
    programın kullanımı oldukça basittir. Tek yapılacak şey programa komut satırı argümanı olarak disk bölümünün aygıt dosyasını 
    vermektedir. Örneğin:

    $ sudo resize2fs /dev/sdc2

    "resize2fs" programı duruma göre dosya sisteminin "fsck" programı ile kontrol edilmesini talep edebilmektedir. Bu işlem şöyle 
    yapılabilir:

    $ sudo e2fsck -f /dev/sdc2

    "resize2fs" programı default olarak dosya sistemini içinde bulunduğu disk bölümü kadar büyütmeye çalışmaktadır. Ancak bu 
    program tam ters amaçla da kullanılabilmektedir. -M seçeneği dosya sistemini olabilecek en kompakt duruma getirmektedir. 
    Örneğin:

    $ sudo resize2fs -M /dev/sdc2

    Tabii aslında dosya sistemini ve disk bölümlerini büyütmek başka utility programlarla da yapılabilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												31. Ders 11/07/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de gömülü Linux sistemlerinde çokça kullanılan U-Boot isimli boot loader'ın kullanımı üzerinde duracağız. Bu boot 
    loader'ı kendi projelerinizde sıfırdan kullanacaksanız öncelikle kaynak kodlarını indirip hedef makine için derlemeniz 
    gerekir. Örneğin biz U-Boot'u BBB'de ya da Raspberry Pi'da kullanmak istiyorsak önce onun kaynak kodlarını sitesinden indirip 
    ARM işlemcileri için ARM araç zincirlerini kullanarak derlememiz gerekir. Bu derleme işleminden birinci düzey ve ikinci düzey 
    boot loader dosyaları elde edilir. Bu dosyalar da hedef sistemde uygun yerlere yerleştirilir. Yapılacak işlemleri şöyle 
    özetleyebiliriz:

    U-Boot Kaynak Kodları İndirilir ---> Kaynak Kodlar Hedef Araç Zinciri Kullanarak Derlenir ---> Oluşturulan Birinci ve İkinci 
    Düzey Boot Loader Dosyaları Hedef Sistemde Uygun Yerlere Yerleştirilir

    U-Boot'un dokümanlarına aşağıdaki bağlantıdan erişebilirsiniz:

    https://docs.u-boot.org/en/latest/
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    U-Boot derlemesi aşağıdaki adımlardan geçilerek gerçekleştirilmektedir:

    1) Öncelikle U-Boot'un kaynak kodları sitesinden indirilir. Bunun için aşağıdaki git komutunu kullanabilirsiniz:

    $ git clone https://source.denx.de/u-boot/u-boot.git

    Bu işlemden sonra U-Boot'un kaynak kodları "u-boot" isimli bir dizin yaratılarak onun içerisine yerleştirilecektir.

    2) Derleme için hedef makineye ilişkin uygun araç zinciri elde edilmelidir. Çünkü oluşturulan dosyaların hedef makinede 
    çalışabilmesi için hedef makineye uygun makine kodlarının oluşturulması gerekir. Örneğin biz BBB için U-Boot'u kullanmak 
    isteyelim. (BBB'de zaten default durumda U-Boot'un kullanıldığını anımsayınız). Bu durumda 32 bit ARM işlemcileri için 
    uygun araç zincirinin yüklenmesi gerekir. Eğer Raspberry Pi için aynı işlemi yapacak olsaydık 64 bitlik ARM araç zincirini 
    hazır bulundurmamız gerekecekti. Anımsanacağı gibi bu araç zincirleri zaten birkaç kaynakta hazır bir biçimde ("pre-built"
    biçimde) bulunmaktadır. Ancak istersiniz daha önce görmüş olduğumuz crosstool-NG ile de araç zincirini sıfırdan da 
    oluşturabilirsiniz. Biz burada ARM'ın kendisinin sunduğu araç zincirlerini indirip kullanalım. Bu araç zincirlerinin aşağıdaki 
    bağlantıdan elde edilebileceğini görmüştük:

    https://developer.arm.com/downloads/-/arm-gnu-toolchain-downloads

    Bu sayfa açıldığında "x86_64 Linux hosted cross toolchains" başlığı altındaki "AArch32 GNU/Linux target with hard float 
    (arm-none-linux-gnueabihf)" alt başlığında belirtilen "arm-gnu-toolchain-13.3.rel1-x86_64-arm-none-eabi.tar.xz" dosyasını
    indirip aşağıdaki gibi açabiliriz:

    $ tar -xf arm-gnu-toolchain-13.3.rel1-x86_64-arm-none-linux-gnueabihf.tar.xz

    3) Projenin make dosyasında derleme işlemi yapılırken derleyicinin dışında bazı araçlar da kullanılmıştır. U-Boot'un kendi
    sitesinde aşağıdaki araçların make dosyası tarafından kullanılabileceği belirtilmiştir. Bu araçların bazıları standart bir 
    Linux dağıtımında zaten yüklenmiş biçimde bulunmaktadır. Ancak siz bunların hepsini aşağıdaki gibi yüklemeye çalışabilirsiniz:

    sudo apt-get install bc bison build-essential coccinelle \
    device-tree-compiler dfu-util efitools flex gdisk graphviz imagemagick \
    liblz4-tool libgnutls28-dev libguestfs-tools libncurses-dev \
    libpython3-dev libsdl2-dev libssl-dev lz4 lzma lzma-alone openssl \
    pkg-config python3 python3-asteval python3-coverage python3-filelock \
    python3-pkg-resources python3-pycryptodome python3-pyelftools \
    python3-pytest python3-pytest-xdist python3-sphinxcontrib.apidoc \
    python3-sphinx-rtd-theme python3-subunit python3-testtools \
    python3-virtualenv swig uuid-dev

    Tabii bu araçlar o anda derlemenin yapılacağı host sistemde çalışacak olan araçlardır.

    4) Build işleminden önce bizim CROSS_COMPILE çevre değişkenini araç zincirimizin önekini belirtecek biçimde oluşturmamız 
    gerekir. Çünkü U-Boot'un make dosyası bu önekin sonuna "gcc", "ld" gibi program isimlerini ekleyerek araçları çalıştırmaktadır. 
    Örneğin bizim ARM sitesinden indirdiğimiz araç zincirlerinin öneki "arm-none-linux-gnueabihf-" biçimindedir. İşte CROSS_COMPILE 
    çevre değişkenini bu öneki belirtecek biçiminde set etmeliyiz:

    $ export CROSS_COMPILE=arm-none-linux-gnueabihf-

    Bu ayarlama yapıldıktan sonra bizim ayrıca araç zincirlerinin bulunduğu dizini de PATH çevre değişkenine eklememiz gerekir. 
    Sınıfta yaptığımız örnekte araç zincirini "/home/kaan/Study/EmbeddedLinux/U-Boot" dizinine açmıştık. Bu durumda araç 
    zincirlerinin içerisindeki programlar da aşağıdaki dizinde bulunacaktır:

    "/home/kaan/Study/EmbeddedLinux/U-Boot/arm-gnu-toolchain-13.3.rel1-x86_64-arm-none-linux-gnueabihf/bin"

    Bu dizini PATH çevre değişkenine şöyle ekleyebiliriz:

    $ PATH=$PATH:/home/kaan/Study/EmbeddedLinux/U-Boot/arm-gnu-toolchain-13.3.rel1-x86_64-arm-none-linux-gnueabihf/bin

    5) Şimdi bizim derleme sırasında kullanılacak olan hedef donanıma ilişkin ayarları belirlememiz gerekir. Kaynak kodlar 
    içerisindeki "configs" dizini altında pek çok kart için hazır config dosyaları bulunmaktadır. Bu config dosyalarından bizim 
    hedefimize en yakın olanını seçip onu temel alarak ayarlamaları yapabilirsiniz. Örneğin BBB için "am335x_evm_defconfig" isimli 
    konfigürasyon dosyası kullanılabilir. Bu konfigürasyon dosyasının seçimi şöyle yapılabilir:

    $ make am335x_evm_defconfig

    Bu komutu uygularken "u-boot" ana dizinin kökünde olmanız gerekir. Bu duruma dikkat ediniz. Bu işlem sonrasında artık söz 
    konusu konfigürasyon dosyası "u-boot" dizinin kökünde ".config" dosyası olarak kopyalanacaktır.

    6) Eğer istenirse seçilen konfigürasyon dosyası temel alınarak bazı boot parametreleri değiştirilebilir. Bu işlem şöyle yapılır:

    $ make menuconfig

    Burada karşımıza bir GUI penceresi çıkacaktır. menuconfig işleminde ".config" dosyası okunarak oradaki seçimler menü elemanlarında 
    belirtilir. Uygulamacı da bunlar üzerinde değişiklikler yapıp ".config" dosyasını yeniden save edebilir.

    7) Build işlemi sırasında seçilen karta ilişkin aygıt ağacı da (device tree) otomatik oluşturulmaktadır. Ancak programcı 
    isterse make işlemi öncesinde aygıt ağacını da belirleyebilir. Bu konu üzerinde daha sonra duracağız.

    8) Nihayet build işlemi aşağıdaki gibi "make" komutu ile başlatılır:

    $ make

    Build işlemi bittiğinde u-boot dizininin kök dizininde bazı önemli dosyalar oluşturulmuş olacaktır. Bunlardan biri "birinci 
    düzey boot loader" görevinde olan MLO dosyasıdır. Oluşturulan diğer bir dosya da "u-boot.img" isimli dosyadır. Bu dosya
    "ikinci düzey boot loader" görevini yapmaktadır. Yani Linux çekirdeği, geçici kök dizin ve aygıt ağacı bu dosyadaki kodlar
    tarafından yüklenmektedir. Kök dizinde ayrıca yine ikinci düzey boot loader görevinde olan "u-boot.bin" isimli diğer bir 
    dosya da oluşturulmaktadır. Bu dosyanın başında birtakım başlık kısımları yoktur. Dolayısıyla bu dosya dosya sistemine 
    yerleştirilmek yerine doğrudan sektörlere yazılmak için kullanılmaktadır. Yine kök dizinde "u-boot.dtb" isimli bir dosya 
    da oluşturulmuştur. Bu dosya ileride ele alacağımız "aygıt ağacı" dosyasıdır.

    9) Eğer sıfırdan yeni bir derleme yapmak isterseniz bunun için clean işlemi yapabilirsiniz:

    $ make clean

    Eğer U-Boot tarafından yaratılmış olan dosyaları da silmek isterseniz clean işlemini şöyle de yapabilirsiniz:

    $ make distclean

    distclean işleminden sonra artık default konfigürasyon dosyası da (".config" dosyasını kastediyoruz) silinmiş olacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi U-Boot hedef aygıt için derlendikten sonra elde edilen dosyaların konuşlandırılması nasıl yapılacaktır? Burada iki
    yöntem izlenebilir. Birincisi micro SD kartımızda bir FAT bölümü oluşturup "MLO" ve "u-boot.img" dosyalarını bu FAT 
    dosya sisteminin kök dizinine kopyalamaktır. Bu gömülü Linux sistemlerinde izlenen klasik yoldur. Anımsayacağınız gibi bu 
    yöntem Raspberry Pi'da aynı biçimde kullanılmaktadır. İkincisi elde edilen dosyaları micro SD kartın ilk sektörlerine
    yazmaktır. ROM'daki kod eğer FAT disk bölümünü bulamazsa boot işlemini bu biçimde yapmaktadır. Anımsanacağı gibi BBB'nin 
    kendi sitesindeki yeni imajlar bu yöntemi kullanmaktadır. Biz burada önce FAT dosya sistemi yöntemini kullanacağız. Ancak 
    konuşlandırmayı yaptıktan sonra boot işlemi otomatik yapılmamaktadır. Bu işlemin nasıl otomatize edileceği izleyen paragraflarda
    ele alınmaktadır.

    Öncelikle micro SD kartımızı kullanıma hazır hale getireceğiz. Kartımızda bir tane FAT disk bölümü bir tane de Linux disk 
    bölümü olmalıdır. İşlemleri sırasıyla şöyle yapabiliriz:

    1) Kartımızı micro SD okuyucuya yerleştiririz. Aygıt dosyasının ismini "lsblk" komutu ile elde edebiliriz. Örneğin:

    $ lsblk
    NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
    loop0    7:0    0  3,5G  0 loop /home/kaan/Study/EmbeddedLinux/mydisk
    sda      8:0    0   60G  0 disk
    ├─sda1   8:1    0    1M  0 part
    ├─sda2   8:2    0  513M  0 part /boot/efi
    └─sda3   8:3    0 59,5G  0 part /
    sdb      8:16   1    0B  0 disk
    sdc      8:32   1 29,7G  0 disk
    sdd      8:48   1    0B  0 disk
    sr0     11:0    1 1024M  0 rom

    Burada "sdc" aygıtı bizim micro SD kartımızı belirtmektedir. Aygıt dosyası "/dev/sdc" biçimindedir. O halde fdisk programı
    ile bu blok aygıt dosyası üzerinde bölümleme yapabiliriz:

    $ sudo fdisk /dev/sdc

    2) Şimdi önce FAT disk bölümünü sonra da Linux disk bölümünü daha önce gördüğümüz komutlarla oluşturacağız:

    ***********************************************************
        Command (m for help): n
    Partition type
    p   primary (0 primary, 0 extended, 4 free)
    e   extended (container for logical partitions)
    Select (default p): p
    Partition number (1-4, default 1): 1
    First sector (2048-62333951, default 2048):
    Last sector, +/-sectors or +/-size{K,M,G,T,P} (2048-62333951, default 62333951): +60M

    Created a new partition 1 of type 'Linux' and of size 60 MiB.

    Command (m for help): t
    Selected partition 1
    Hex code or alias (type L to list all): C
    Changed type of partition 'Linux' to 'W95 FAT32 (LBA)'.

    Command (m for help): p
    Disk /dev/sdc: 29,72 GiB, 31914983424 bytes, 62333952 sectors
    Disk model: MassStorageClass
    Units: sectors of 1 * 512 = 512 bytes
    Sector size (logical/physical): 512 bytes / 512 bytes
    I/O size (minimum/optimal): 512 bytes / 512 bytes
    Disklabel type: dos
    Disk identifier: 0x04c91dbe

    Device     Boot Start    End Sectors Size Id Type
    /dev/sdc1        2048 124927  122880  60M  c W95 FAT32 (LBA)

    Command (m for help): n
    Partition type
    p   primary (1 primary, 0 extended, 3 free)
    e   extended (container for logical partitions)
    Select (default p): p
    Partition number (2-4, default 2):
    First sector (124928-62333951, default 124928):
    Last sector, +/-sectors or +/-size{K,M,G,T,P} (124928-62333951, default 62333951):

    Created a new partition 2 of type 'Linux' and of size 29,7 GiB.

    Command (m for help): p
    Disk /dev/sdc: 29,72 GiB, 31914983424 bytes, 62333952 sectors
    Disk model: MassStorageClass
    Units: sectors of 1 * 512 = 512 bytes
    Sector size (logical/physical): 512 bytes / 512 bytes
    I/O size (minimum/optimal): 512 bytes / 512 bytes
    Disklabel type: dos
    Disk identifier: 0x04c91dbe

    Device     Boot  Start      End  Sectors  Size Id Type
    /dev/sdc1         2048   124927   122880   60M  c W95 FAT32 (LBA)
    /dev/sdc2       124928 62333951 62209024 29,7G 83 Linux

    Command (m for help): a
    Partition number (1,2, default 2): 1

    The bootable flag on partition 1 is enabled now.

    Command (m for help): p
    Disk /dev/sdc: 29,72 GiB, 31914983424 bytes, 62333952 sectors
    Disk model: MassStorageClass
    Units: sectors of 1 * 512 = 512 bytes
    Sector size (logical/physical): 512 bytes / 512 bytes
    I/O size (minimum/optimal): 512 bytes / 512 bytes
    Disklabel type: dos
    Disk identifier: 0x04c91dbe

    Device     Boot  Start      End  Sectors  Size Id Type
    /dev/sdc1  *      2048   124927   122880   60M  c W95 FAT32 (LBA)
    /dev/sdc2       124928 62333951 62209024 29,7G 83 Linux

    Command (m for help): w
    The partition table has been altered.
    Calling ioctl() to re-read partition table.
    Syncing disks.
    ***********************************************************

    Görüldüğü gibi bu işlemin sonucunda bir FAT disk bölümü bir de Linux dosya bölümü oluşturulmuştur.

    3) Şimdi ilgili disk bölümlerini ilgili dosya sistemleriyle formatlayalım:

    $ sudo partprobe
    $ sudo mkfs.fat /dev/sdc1 -F32 -n "BOOTFS"
    $ sudo mkfs.ext2 /dev/sdc2 -L rootfs

    4) U-Boot'ta oluşturduğumuz "MLO" ve "u-boot.img" dosyalarını FAT dosya sisteminin köküne kopyalamamız gerekir. Tabii 
    bunun için önce mount işlemi yapmalıyız:

    $ mkdir bootfs
    $ sudo mount /dev/sdc1 bootfs
    $ sudo cp u-boot/MLO u-boot/u-boot.img bootfs
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												32. Ders 16/07/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    5) Şimdi biz SD kartımızın FAT disk bölümüne MLO ve u-boot.img dosyalarını kopyaladık. Ancak SD kartımızın Linux disk bölümü
    boştur. Biz sistemi reboot etmeye çalışırsak bunu başaramayız. Çünkü u-boot'un yükleyeceği bir çekirdek imajı, aygıt ağacı
    dosyası ve kök dosya sistemi yoktur. Bunları biz manuel bir biçimde Linux disk bölümünün boot dizini içerisine kopyalasak 
    bile yine boot işlemini yapamayız. Çünkü SD kartımızın Linux disk bölümünde boot sonrasına devreye girmesi gereken dizin 
    yapısı ve dosyalar da yoktur. Yani bizim boot işlemini yapabilmemiz için SD kartımızın kök dizininde kurulu bir Linux 
    sisteminin olması gerekir. Biz minimal düzeyde boot işlemi yapılabilmesi için gerekli olan dizinlerin ve dosyaların nasıl 
    oluşturulacağını ayrı bir başlık altında ele alacağız. Ancak burada daha pratik bir yöntem izleyeceğiz. Daha önce 
    https://www.beagleboard.org/distros sitesinden indirdiğimiz imajın Linux disk bölümünü SD kartımızın Linux disk bölüme 
    kopyalarsak bu durumda zaten her şeyiyle hazır olan Linux kurulumunu hemen kullanabiliriz. Bu kopyalama işlemini komut satırından 
    dd komutuyla yapabiliriz. Aslında bunun için BBB disk imajının bir loop aygıtı olarak gösterilmesine gerek yoktur. Ancak biz 
    daha önce öğrendiklerimizi uygulamak için bu yola sapalım. Siteden indirdiğimiz ve açtığımız BBB disk imajının ismi şöyledir:

    am335x-debian-11.7-iot-armhf-2023-09-02-4gb.img

    Bu imaja fdisk ile bakalım:

    ***********************************************************
    $ fdisk am335x-debian-11.7-iot-armhf-2023-09-02-4gb.img

    Welcome to fdisk (util-linux 2.37.2).
    Changes will remain in memory only, until you decide to write them.
    Be careful before using the write command.

    Command (m for help): p
    Disk am335x-debian-11.7-iot-armhf-2023-09-02-4gb.img: 3,52 GiB, 3774873600 bytes, 7372800 sectors
    Units: sectors of 1 * 512 = 512 bytes
    Sector size (logical/physical): 512 bytes / 512 bytes
    I/O size (minimum/optimal): 512 bytes / 512 bytes
    Disklabel type: dos
    Disk identifier: 0xee60af7b

    Device                                           Boot Start     End Sectors  Size Id Type
    am335x-debian-11.7-iot-armhf-2023-09-02-4gb.img1 *     8192 7372799 7364608  3,5G 83 Linux

    Command (m for help):
    ***********************************************************

    Buradan disk bölümünün 8192'nci sektörden (512 * 8192 = 4194304 numaralı offset'ten) başladığı görülmektedir. O halde loop 
    aygıtını bu offset'ten başlayacak biçimde ayarlayalım:

    $ sudo losetup -o 4194304 /dev/loop0 am335x-debian-11.7-iot-armhf-2023-09-02-4gb.img

    SD kartımızı kart okuyucuya takıp lsblk komutunu kullanalım:

    $ lsblk
    NAME   MAJ:MIN RM  SIZE RO TYPE MOUNTPOINTS
    loop0    7:0    0  3,5G  0 loop
    sda      8:0    0   60G  0 disk
    ├─sda1   8:1    0    1M  0 part
    ├─sda2   8:2    0  513M  0 part /boot/efi
    └─sda3   8:3    0 59,5G  0 part /
    sdb      8:16   1    0B  0 disk
    sdc      8:32   1 29,7G  0 disk
    ├─sdc1   8:33   1   60M  0 part /media/kaan/BOOTFS
    └─sdc2   8:34   1 29,7G  0 part /media/kaan/a139ac97-bdce-4e23-9d9f-e7e342030530
    sdd      8:48   1    0B  0 disk
    sr0     11:0    1 1024M  0 rom

    Burada SD kartın Linux disk bölümüne ilişkin aygıtın "/dev/sdc2" olduğu görülmektedir. O halde kopyalamayı şöyle yapabiliriz:

    $ sudo dd if=/dev/loop0 of=/dev/sdc2 status=progress

    Tabii burada işlem biraz zaman alacaktır. dd komutundaki "status=progress" komut satırı argümanı uzun süre alacak bu 
    işlemde işlemin normal biçimde devam ilerlediğini gösteren bir geri bildirim verilmesini sağlamaktadır.

    6) Bu biçimde oluşturduğumuz SD kartımızı BBB'nin SD kart slotuna takıp Boot düğmesine basılı biçimde BBB'ye güç verdiğimizde
    boot işlemi henüz otomatik biçimde gerçekleşmeyecektir. Bu aşamadan sonra bu boot işleminin nasıl yapılacağı izleyen 
    paragraflarda ele alınmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Yukarıdaki işlemlerde bizim henüz incelemediğimiz şu konular vardır:

    1) Sistem boot edilirken Linux disk bölümündeki boot dizininde şu dosyaların bulunuyor olması gerekir:

        - Linux çekirdek imaj dosyası (Linux kernel image)
        - Aygıt ağacı dosyası (device tree file)
        - Geçici kök dosya sistemini bulunduran ramdisk dosyası

    Pekiyi bu dosyalar nasıl elde edilecektir? Biz yukarıda zaten hazır disk imajını kullandığımız için bu dosyaları biz 
    oluşturmadık. Linux çekirdek imaj dosyası Linux çekirdeğinin kaynak kodları derlenerek oluşturulmaktadır. Aygıt ağacı 
    dosyası çeşitli yardımcı programlarla oluşturulabilmektedir. Yine geçici kök dosya sistemine ilişkin ramdisk dosyası 
    da çeşitli yardımcı programlarla oluşturulabilmektedir.

    2) Linux boot edilirken yalnızca yukarıdaki dosyalar değil kalıcı kök dosya sistemine ilişkin dosyaların da SD kartta 
    bulunması gerekir. Yani başka bir deyişle bizim SD kartımızda dolu bir Linux sisteminin konuşlandırılmış olması gerekir. 
    Çünkü boot sürecinde çekirdek kendini ayarladıktan sonra dosya sistemindeki bazı programları çalıştırmaktadır. Örneğin 
    bunlardan en önemlisi "init" paketi denilen ve şimdilerde daha çok "systemd" biçiminde kullanılan pakettir.

    3) Yukarıda belirttiğimiz tüm dosyalar olması gereken yerlerde bulunuyor olsa bile yine de boot işlemi otomatik bir biçimde 
    gerçekleştirilemeyecektir. Boot işleminin otomatik bir biçimde yapılabilmesi için U-Boot'a ilişkin bazı düzenlemelere 
    gereksinim duyulmaktadır.

    Bu konular kursumuzda izleyen konularda tek tek ele alınacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Anımsanacağı gibi artık BeagleBoard sitesinde BBB için indirilen imajda bir FAT dosya sistemi bulunmamaktadır. Pekiyi bu 
    durumda bu imaj ile boot işlemi nasıl yapılmaktadır? İşte BBB reset edildiğinde BBB içerisindeki ROM kodu önce SD karttaki 
    FAT disk bölümünü aramakta eğer onu bulursa MLO programını oradan yüklemektedir. Ancak SD kartta bir FAT bölümünü bulamazsa 
    bu durumda SD kartın 0x20000 offsetindeki disk bloklarını SRAM'e yükleyip oradaki kodu çalıştırmaktadır. Yani eğer biz MLO
    programını FAT disk bölümüne yerleştirmeyeceksek SD kartın 0x20000 offsetine (256'ıncı sektörüne) kopyalamalıyız. MLO programı 
    default durumda "u-boot.img" dosyasını eğer FAT disk bölümü yoksa SD kartın 0x60000 offsetinden (768'inci) sektörden yüklemektedir. 
    Bu durumda bizim "u-boot.img" dosyasını bu offset'ten itibaren SD karta kopyalamamız gerekir. Bu işlemler aşağıdaki gibi 
    yapılabilir:

    $ sudo dd if=MLO of=/dev/sdc bs=512 seek=256
    $ sudo dd if=u-boot.img of=/dev/sdc bs=512 seek=768

    Burada "dev/sdc" aygıt dosyası SD kartı belirtmektedir. Tabii bizim yine kök dosya sisteminin bulunduğu içi dolu bir Linux
    disk bölümümüzün olması gerekir. Tipik olarak bu Linux disk bölümünü SD kartımızın 8192'nci sektöründen oluşturabiliriz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												33. Ders 18/07/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bugünkü masaüstü bilgisayarlarda artık klasik seri port'lar bulundurulmamaktadır. Seri port bağlantısı gereken yerlerde 
    "seri port-USB" dönüştürücüleri kullanılmaktadır. Biz kursumuzun başında üç uçlu böyle bir dönüştürücüyü (CP2102 modülü) 
    malzeme listesine eklemiştik. Kursumuzda kullandığımız CP2102 modülünde seri port için üç uç bulunmaktadır. Modül üzerindeki
    Pinler şöyledir:

    3V  ----- (1)
    TxD ----- (2)
    RxD ----- (3)
    GND ----- (4)
    +5V ----- (5)

    Bu uçlar RxD, TxD ve GND uçlarıdır. Seri port bağlantısında bir tarafın RxD ucu karşı tarafın TxD ucuna, TxD ucu ise karşı 
    tarafın RxD ucuna bağlanır. GND uçları da karşılıklı bağlanmaktadır. Yani bağlantı şöyle yapılmaktadır.

    RxD <------ TxD
    TxD ------> RxD
    GND ------- GND

    Bu durumda biz kullandığımız CP2102 modülünün RxD ucunun BBB'nin TxD ucuna, TxD ucunun ise BBB'nin RxD ucuna bağlanması 
    gerekir. GNC uçları da karşılıklı bağlanmalıdır. BBB'nin yeni modellerinde seri port için GPIO soketlerinin yanında 6 
    tane erkek pin bulunmaktadır. Bu pinlerin bizim için önemli olan üç tanesi şöyledir:

    PIN-1 ---> GND
    PIN-4 ---> RxD
    PIN-5 ---> TxD

    Bu durumda BBB ile CP2102 bağlantısı şöyle yapılmalıdır:

    CP2102           BBB
    RxD (3) <------ TxD (2)
    TxD (2) ------> RxD (3)
    GND (4) ------- GND (4)

    Seri port haberleşmesi aslında oldukça basittir. Gönderici taraf bir byte'ı bitlerine ayrıştırır ve TxD ucundan bu bitleri 
    belli bir periyotta gönderir. Karşı taraf da RxD ucunu aynı periyotta örnekler ve bitleri alır. Bu haberleşmede byte'lar 
    arasındaki süre değişebilir, ancak byte'ların bitleri aynı hızda gönderilip alınmaktadır. Başka bir deyişle bir grup byte
    biçimde gönderilip alınacaksa byte'lar arasındaki süreler değişebilir. Ancak bir byte'ın bitleri belirlenen hızda gönderilip
    alınmaktadır. İki tarafın belirlediği bu hız için genellikle "baud rate" terimi kullanılmaktadır. Bu tarz seri haberleşmelere
    "asenkron seri haberleşmeler (asynchronous serial communication)" denilmektedir. (Eğer byte'ların da aynı hızda gönderilmesi 
    söz konusu ise buna da genellikle "senkron seri haberleşme (synchronous serial communication)" denilmektedir.) Asenkron seri 
    haberleşmede byte'ların bitlere ayrıştırılması ve gönderilip alınması için özel devreler tasarlanmıştır. Bu devrelere genel 
    olarak UART (Universal Asynchronous Transmitter and Receiver) denilmektedir. Eski kişisel bilgisayarlarda UART devresi olarak 
    Intel'in 8250 işlemcisi kullanılıyordu. Sonra NS firmasının 16550 işlemcileri yaygın kullanılmaya başlandı. Bugün artık USB 
    haberleşmesinin yaygınlaşmasıyla UART haberleşmesi çok az kullanılır hale gelmiştir. UART işlemcilerinin çıktıları TTL 
    düzeyindedir (ani kabaca +5V, 0V). Ancak eski PC'lerde uzun kablolar ile haberleşme yapılabilmesi için UART çıkış seviyeleri 
    RS232 denilen standarda (-15V, +15V) yükseltilmektedir.

    Seri port ayarlanırken aşağıdaki parametrelerin belirlenmiş olması gerekir:

    - Data bitlerinin sayısı (5, 6, 7 ya da 8)
    - Stop bit sayısı (1 ya da 2)
    - Parity durumu (none, even ya da odd)
    - Baud rate

    En çok kullanılan ayar takımı "8 data bit, 1 stop bit, no parity ve en yüksek hız olan 115200 baud rate" biçimindedir. 
    Zaten pek çok programda baud rate dışındaki default ayarlar bu biçimdedir. Asenkron seri haberleşmede bilgi gönderilmiyorken 
    hat lojik 1 seviyesinde bekletilir. Bilgi gönderilmeye başlanacakken hat bir periyot lojik 0'a çekilir. Sonra belirlenen 
    kadar data biti belirlenen baud rate ile kodlanır. Data bitleri gönderildikten sonra isteğe bağlı bir parity biti de 
    gönderilebilmektedir. Parity "gönderilen bitlerdeki 1'lerin sayısını çifte ya da teke tamamlamak için gereken" bite 
    denilmektedir. Çift parity (even parity) çifte tamamlama, tek parity ise teke tamamlama anlamına gelmektedir. Bu bitler
    gönderildikten sonra hattın yeniden lojik 1 seviyesine çekilmesi gerekmektedir. Buna da "stop bit" denilmektedir. Normal 
    durumda 1 stop bir kullanılmaktadır. Eskiden haberleşmeyi yavaşlatmak için 2 stop bit de kullanılabiliyordu.

    Asenkron seri haberleşme aslında 3 uçtan daha fazla uçla da yapılabilmektedir. Diğer uçlar genellikle "akış kontrolü 
    (flow control)" için kullanılmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Seri port üzerinde işlem yapmak için kullanılan çeşitli yardımcı programlar vardır. En çok tercih edilenlerden biri 
    PuTTY isimli programdır. Bu program hem Windows sistemleri hem de Linux sistemleri için bulunmaktadır. Siz de Linux sisteminize
    programı aşağıdaki gibi kurabilirsiniz:

    $ sudo apt-get install putty

    Linux'ta seri port-USB dönüştürücüsü için aygıt dosyası genellikle "/dev/ttyUSB0" biçimindedir. Yani biz bu aygıt sürücüyü 
    open fonksiyonuyla açarsak read fonksiyonuyla karşı tarafın gönderdiği byte'ları okuyabiliriz. write fonksiyonuyla da 
    karşı tarafa byte'lar gönderebiliriz. IOCTL işlemleri ile seri port konfigüre edilebilmektedir.

    Linux sistemlerinde seri port haberleşmesi için yaygın biçimde kullanılan diğer bir program da "picocom" isimli programdır. 
    Programı şöyle indirip kurabilirsiniz:

    $ sudo apt-get install picocom

    "picocom" ile seri port bağlantısını aşağıdaki gibi yapabilirsiniz:

    $ picocom -b 115200 /dev/ttyUSB0

    Burada -b seri port'un hızını belirlemek için kullanılmaktadır. Default durumda zaten parity off, data birlerinin sayısı 8 
    ve 1 stop bit söz konusudur.

    Diğer bir alternatif de "minicom" isimli programdır. Bu programı da aşağıdaki gibi indirip kurabilirsiniz:

    $ sudo apt-get install minicom

    Programın örnek kullanımı şöyledir:

    $ minicom -D /dev/ttySUB0 -b 115200

    Diğer bir alternatif de "screen" isimli programdır. Programı şöyle indirip kurabilirsiniz:

    $ sudo apt-get install screen

    Örnek bir kullanım şöyle olabilir:

    $ screen /dev/ttyUSB0 115200
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    BBB cihazımızla bilgisayarımızı CP2102 modülü ile bağladıktan sonra artık U-Boot boot sürecinde olan biteni gözlemleyebiliriz
    ve boot süreci üzerinde etkili olabiliriz. U-Boot boot loader'ı bir komut satırı eşliğinde kullanıcıdan komutlar alabilmektedir. 
    Tabii bunun için önce U-Boot'un komut satırına düşmek gerekir. Bunun için yapılması gereken şeyler şunlardır:

    1) PC tarafındaki seri port'u hızı 115200 baud, 8 bit veri ve 1 stop bit ve No Parity olacak biçimde ayarlamalısınız. Seri 
    porta ilişkin aygıt dosyası yukarıda da belirttiğimiz gibi genellikle "/dev/ttyUSB0" biçimindedir. putty programını sudo 
    ile çalıştırmayı unutmayınız.

    2) Aygıtınızı reset ederken klavyeden bir tuşa basınız. (Eğer bu tuşa zamanında basamazsanız komut satırını kaçırabilirsiniz. 
    Bu nedenle reset işlemi sırasında klavyeden herhangi bir tuşa basarak bekleyebilirsiniz.)

    U-Boot'un komut satırı imleci => biçimindedir. U-Boot komut satırına düşmekteki amacımız manuel biçimde bazı ayaralamaları
    yapıp boot sürecini manuel yürütebilmektir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    U-Boot komut satırında bizim girebileceğimiz çeşitli komutlar vardır. Bu komutların listesi için "U-Boot Reference Manual"
    isimli dokümandan ya da kendi sitesindeki dokümanlardan faydalanabilirsiniz. Bunun için doğrudan U-Boot komut satırındaki 
    "help" komutunu da kullanabilirsiniz. Aşağıda önemli U-Boot kabuk komutları hakkında kısa açıklamalar yapıyoruz:

    - Komut satırına düştükten sonra boot işlemini sanki komut satırına düşmemişsiniz gibi devam ettirmek için "boot" komutu 
    kullanılmaktadır.

    - "bdinfo (board info)" komutu genel olarak kullandığımız kart hakkında donanımsal bilgileri bize vermektedir.

    - U-Boot'ta önemli bir kavram "çevre değişkeni (environment variable)" kavramıdır. Tabii buradaki çevre değişkeni kavramının
    Linux sistemlerindeki çevre değişkeni kavramıyla bir ilgisiyi yoktur. Buradaki çevre değişkeni birtakım ayarlamalarda 
    kullanılan değişkenlerdir. Ancak uygulamacı da çevre değişkeni yaratabilmektedir. Bir çevre değişkeni bir sisim ve ona karşı
    gelen bir yazıdan oluşmaktadır.

    - Bir çevre değişkeninin değeri "printenv" komutuyla elde edilebilir. Örneğin:

    => printenv loadaddr
    loadaddr=0x82000000
    => printenv bootcmd
    bootcmd=run findfdt; run init_console; run envboot; run distro_bootcmd

    - Yeni bir çevre değişkeni oluşturmak için "setenv" komutu kullanılmaktadır. Bu komutta önce çevre değişkeninin ismi boşluk
    ve sonra da değeri girilir. Tırnaklama zorunluluğu yoktur. Örneğin:

    => setenv myenv "this is a test"
    => printenv myenv
    myenv=this is a test

    - Bir çevre değişkeninin değeri tıpkı UNIX/Linux sistemlerinin kabuklarında olduğu gibi ${çevre_değişkeni} biçiminde elde 
    edilebilir. Örneğin:

    => setenv myenv "loading address = ${loadaddr}"
    => printenv myenv
    myenv=loading address = 0x82000000

    - "resetenv" komutu tüm standart çevre değişkenlerini komut satırına ilk düşüldüğü değerlere geri çekmektedir.

    - Bir çevre değişkeni aslında bir script gibi de kullanılabilmektedir. Script içerisinde birden fazla komut varsa komutlar 
    ';' karakteriyle ayrılmalıdır. Bir script'i çalıştırmak için "run" komutu kullanılmaktadır. Örneğin:

    => setenv myscript 'printenv loadaddr;printenv fdtaddr'
    => run myscript
    loadaddr=0x82000000
    fdtaddr=0x88000000

    Burada myscript bir çevre değişkeni biçiminde oluşturulmuştur. "run" komutu uygulandığında o çevre değişkenindeki komutlar
    çalıştırılmaktadır.

    - U-Boot içerisinde bazı built-in çevre değişkenleri de vardır. Örneğin "baudrate" çevre değişkeni cihazın seri port hızını 
    belirtmektedir. Değerini şöyle yazdırabiliriz:

    => printenv baudrate
    baudrate=115200

    Bu built-in çevre değişkenlerinin değerleri değiştirilebilir. Örneğin iyi bir fikir olmasa da biz U-Boot'un kullandığı seri port 
    hızını "setenv" komutu ile değiştirebiliriz:

    => setenv baudrate 9600
    ## Switch baudrate to 9600 bps and press ENTER ...

    - Built-in "bootcmd" çevre değişkeni default boot işlemini devam ettirmektedir. Zaten "boot" komutu da bu script'i 
    çalıştırmaktadır.

    - Aslında çevre değişkenlerine ilişkin printenv, "setenv", "resetenv" gibi komutlar yerine daha genel olan "env" komutunun 
    argümanlı biçimleri de kullanılabilir. "env" komutlarının listesi şöyledir:

    env ask name [message] [size]
    env callbacks
    env default [-f] (-a | var [...])
    env delete [-f] var [...]
    env edit name
    env erase
    env exists name
    env export [-t | -b | -c] [-s size] addr [var ...]
    env flags
    env grep [-e] [-n | -v | -b] string [...]
    env import [-d] [-t [-r] | -b | -c] addr [size] [var ...]
    env info [-d] [-p] [-q]
    env load
    env print [-a | name ...]
    env print -e [-guid guid] [-n] [name ...]
    env run var [...]
    env save
    env select [target]
    env set [-f] name [value]
    env set -e [-nv][-bs][-rt][-at][-a][-i addr:size][-v] name [value]
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												34. Ders 23/07/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    U-Boot komut satırında aygıtlara birer isim verilmektedir. Bu isimler flash bellekler için mm0, mmc1, ... biçiminde, USB 
    aygıtı için "usb" biçimindedir. O anda hangi disk aygıtlarına erişilebileceği bilgisi lsblk komutuyla elde edilebilir. (Bu 
    "lsblk" komutu Linux'un "lsblk" komutu değildir. U-Boot isim benzerliği oluşturmuştur.) Örneğin:

    => lsblk
    Block Driver          Devices
    -----------------------------
    efi_blk             : <none>
    mmc_blk             : mmc 0, mmc 1
    usb_storage_blk     : <none>

    Burada mmc 0 ve mmc 1 biçiminde iki aygıtın olduğu görülmektedir. Bu aygıt isimleri izleyen paragraflarda açıklayacağımız 
    bazı komutlarda kullanılacaktır. Eğer ilgili blok aygıtlarında disk bölümü varsa bu disk bölümleri 1'den başlatılmaktadır.
    Çeşitli komutlarda disk bölümü aşağıdaki kalıpla belirtilmektedir:

    mmc 0:1
    mmc 1:1

    Burada ':' karakterinin solundaki sayı aygıtın numarasını sağındaki sayı ise onun disk bölümünü belirtmektedir. Genel 
    olarak SD kart yuvasına takılan SD kartın aygıt ismi mmc 0, internal eMMC'nin ise mmc 1 biçimindedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    - Belli bir dosya sisteminin içerisindeki dosyaları görebilmek için "ext2ls", "lls" "fatls" gibi komutlar bulunmaktadır. Bu 
    komutlar birinci argüman olarak disk bölümünü almaktadır. Bu disk bölümü yukarıda açıkladığımız kalıpta mmc x:y biçiminde 
    belirtilmelidir. Örneğin:

    => load mmc 0:1
   110272   MLO
        0   u-boot.img

    2 file(s), 0 dir(s)

    => lls mmc 0:2 /boot
    <DIR>       4096 .
    <DIR>       4096 ..
            7719588 initrd.img-5.10.168-ti-r71
    <DIR>       4096 dtbs
            190939 config-5.10.168-ti-r71
            11342336 vmlinuz-5.10.168-ti-r71
            4782766 System.map-5.10.168-ti-r71
                1713 uEnv.txt
                542 SOC.sh
    <DIR>       4096 uboot
            11342336 vmlinuz
            89880 u-boot.dtb
            93494 am335x-boneblack.dtb

    - "fatls" ya da "lls" gibi komutlar yerine yalnızca "ls" komutunu da kullanabiliriz. Bu durunda ls komutu dosya sistemini 
    kendisi belirleyip o dosya sistemine göre görüntüleme yapar. Örneğin:

    => ls mmc 0:1
   110272   MLO
        0   u-boot.img

    2 file(s), 0 dir(s)

    - Belli bir disk bölümündeki dosya sisteminin ne olduğunu anlamak için "fstype" komutu kullanılabilir. Örneğin:

    => fstype mmc 0:2
    ext4
    => fstype mmc 0:1
    fat
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    - "mmc list" komutu bağlı olan disklerin listesini ve numaralarını elde etmek için kullanılmaktadır. Örneğin:

    => mmc list
    OMAP SD/MMC: 0 (SD)
    OMAP SD/MMC: 1 (eMMC)

    Bu komut sayesinde biz hangi mmc numarasının hangi medya olduğunu anlayabiliriz. Örneğin yukarıdaki çıktıdan 0 numaralı diskin 
    SD kart olduğu, 1 numaralı diskin internal SD (eMMC) olduğu anlaşılmaktadır.

    - mmc komutunun bazı argümanlı biçimleri default disk üzerinde işlem yapmaktadır. Default diskin değiştirilmesi "mmc dev <numara>" 
    komutuyla yapılmaktadır. Örneğin:

    => mmc dev 0
    switch to partitions #0, OK
    mmc0 is current device

    - "mmc dev" komutu disk numarası verilmeden kullanılırsa aktif olan diskin hangisi olduğunu yazdırmaktadır. Örneğin:

    => mmc dev
    switch to partitions #0, OK
    mmc0 is current device

    - "mmc part" komutu aktif diskin disk bölümlemesi hakkında bilgi vermektedir. Örneğin:

    => mmc part

    Partition Map for MMC device 0  --   Partition Type: DOS

    Part    Start Sector    Num Sectors     UUID            Type
    1     2048            122853          58501095-01     0b
    2     124928          62209024        58501095-02     83

    - "mmc read" ve "mmc write" komutları disk sektörlerini belleğe okumak ve bellekten disk sektörlerine yazma yapmak için 
    kullanılmaktadır. Bu komutların genel biçimi şöyledir:

    mmc read <adres> <sektör_numarası> <sektör_sayısı>
    mmc write <adres> <sektör_numarası> <sektör_sayısı>

    Bu komutların dosya sisteminden dosya okuyup yazmadığına sektör temelinde işlem yaptığına dikkat ediniz. Komutlar default
    disk üzerinde işlem yapmaktadır. Diskin bir disk bölümü üzerinde işlem yapmamaktadır.

    - "mmc rescan" komutu ile hang disklerin ve disklerdeki hangi disk bölümlerinin mevcut olduğu bilgisi güncellenmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    - U-Boot komut satırında diskteki dosyaları belleğe yüklemek için bir grup komut bulunmaktadır. Komutlar dosya sistemlerine 
    göre "xxxload" biçiminde isimlendirilmiştir. Örneğin ext-4 dosya sistemindeki bir dosyayı belleğe yüklemek için "ext4load", 
    ext2 dosya sistemindeki bir dosyayı belleğe yüklemek için "ext2load", FAT dosya sistemindeki bir dosyayı belleğe yüklemek 
    için "fatload" komutu kullanılmaktadır.

    BBB'de U-Boot'un komut satırında dosyaları belleğe yüklerken BBB özelinde bazı noktalara dikkat etmek gerekir. BBB'de TI
    firmasının 335X SoC çiplerinde fiziksel RAM 4 GB'lik bellek alanın başına değil ortasına yerleştirilmiştir. 4 GB'lik bellek 
    alanının ilk 2 GB'si bazı aygıtlara (memory mapped IO) ayrılmıştır. Bu nedenle BBB'nin bellek haritalandırması kabaca aşağıdaki 
    gibidir:

    00000000
        Aygıtlar İçin Memory Mapped IO
    80000000
        DRAM Bellek
    FFFFFFFF

    U-Boot çalışırken işlemcinin sayfalama mekanizması (paging) aktive edilmemiştir. Dolayısıyla U-Boot'taki tüm adresler 
    gerçek fiziksel adreslerdir. O halde BBB'de bizim bellek adresi olarak kullanacağımız adreslerin 0x80000000'dan başlaması 
    gerekir. Tabii U-Boot'un ikinci düzey boot loader'ı (u-boot.img) o anda bellektedir. BBB'de U-Boot'un kendisi default 
    durumda DRAM başlangıcından itibaren (yani 0x80000000'dan itibaren) belleğe yüklenmiş durumdadır. O halde bizim bellek 
    adresi olarak biraz daha öte adresleri kullanmamız gerekir. Örneğin default durumda genellikle çekirdek imajı 0x82000000
    adresine aygıt ağacı ise 0x88000000 adresine yüklenmektedir. Tabii bu değerlerin bir özelliği yoktur.

    "xxxload" komutlarının genel biçimi şöyledir:

    xxxload mmc x:y <adres> <dosyanın_yol_ifadesi>

    Aslında "ext4load" gibi "fatload" gibi "xxxload" komutlarının yanı sıra doğrudan "load" isimli bir komut da vardır. Bu komut 
    önce ilgili aygıttaki dosya sistemini kendisi tespit etmekte ve o dosya sistemine göre otomatik yükleme yapmaktadır. load 
    komutları kullanıldıktan sonra son load edilen dosyaya ilişkin yükleme adresi (bu adresi zaten biz veriyoruz) "fileaddr" 
    isimli çevre değişkeninden, yüklenen dosyanın uzunluğu da "filesize" isimli çevre değişkeninden elde edilebilir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Örneğin biz ext4 dosya sistemi içerisindeki "/boot" dizininde bulunan "vmlinuz-5.10.168-ti-r71" isimli çekirdek imajını 
    bellekte 0x82000000 fiziksel adresine şöyle yükleyebiliriz:

    => ext4load mmc 0:2 0x82000000 /boot/vmlinuz-5.10.168-ti-r71

    Bu komut uygulandığında U-Boot bize kaç byte'lık bir bilginin transfer edildiğini rapor edecektir:

    => ext4load mmc 0:2 0x82000000 /boot/vmlinuz-5.10.168-ti-r71
    11342336 bytes read in 731 ms (14.8 MiB/s)

    Biz şimdi çekirdek imajını belleğe yüklemiş olduk. Aslında yalnızca U-Boot'ta değil tüm boot loader'larda bir biçimde 
    çekirdek imajının RAM'e yüklenmesi gerekmektedir. Biz bunu manuel bir biçimde yapmış olduk. Ancak tek başına çekirdek imajı
    Linux'u boot etmek için yeterli değildir. En azından bir aygıt ağacının da yüklenmesi gerekir. Hazır BBB imajımızda
    aygıt ağacı "/boot/dtbs/5.10.168-ti-r71" dizininde "am335x-boneblack.dtb" ismiyle bulunmaktadır. O halde aygıt ağacını da
    şöyle yükleyebiliriz:

    => ext4load mmc 0:2 0x88000000 /boot/dtbs/5.10.168-ti-r71/am335x-boneblack.dtb

    Tabii biz aslında U-Boot'u BBB için derlediğimizde elde ettiğimiz "u-boot.dtb" aygıt ağacı dosyasını da kullanabilirdik.

    Bundan sonra çekirdek komut satırı parametrelerinin oluşturulması gerekmektedir. U-Boot çekirdek komut satırı parametreleri 
    için "bootargs" çevre değişkenine başvurmaktadır. O halde bizim "bootargs" çevre değişkenini oluşturmamız gerekir. Minimal 
    çekirdek komut satırı parametreleri şöyle oluşturulabilir:

    => setenv bootargs 'console=ttyS0,115200 root=/dev/mmcblk0p2 rw'

    Burada "root=/dev/mmcblk0p2" parametresi kök dosya sisteminin mmcblk0 aygıtındaki (SD kart) 2 numaralı disk bölümünde olduğunu
    belirtmektedir. (1 numaralı disk bölümünün FAT disk bölümü olduğuna dikkat ediniz.) Artık her şey hazırlanmıştır. boot işlemi 
    yapılabilir. u-Boot'ta bir grup boot komutu vardır. Sıkıştırılmış çekirdek ile (Buna "zimage" de denilmektedir) boot işlemi 
    yapmak için "bootz" komutu kullanılmaktadır. bootz komutunun genel biçimi şöyledir:

    bootz [çekirdek_imajının_adresi] [geçici_kök_dosya_sisteminin_adresi] [aygıt_ağacının_adresi]

    Eğer komutta başlangıçtaki ramdisk (geçici kök dosya sistemi) belirtilmeyecekse onun yerine '-' karakteri girilmelidir. 
    O halde biz boot işlemini şöyle gerçekleştirebiliriz:

    => bootz 0x82000000 - 0x88000000
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												35. Ders 25/07/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    - U-Boot'ta script çalıştırma işlemi için iki temel komut kullanılmaktadır: "run" ve "source" komutları. "run" komutu bir 
    çevre değişkeninin içerisindeki komutları çalıştırmaktadır. Örneğin biz bir çevre değişkenine noktalı virgüller ile komutlar
    girebiliriz. Sonra o komutları "run" komutuyla çalıştırabiliriz. "run" komutunun genel biçimi şöyledir:

    run <çevre_değişkeninin_ismi>

    Örneğin:

    => setenv myscript "echo \"this is a test script\"; mmc list;"
    => run myscript
    "this is a test script"
    OMAP SD/MMC: 0 (SD)
    OMAP SD/MMC: 1 (eMMC)

    U-Boot'un da bir script dili vardır. Bu script dili bash kabuğunun diline oldukça benzemektedir. Örneğin biz tıpkı bash'te 
    olduğu gibi döngüler kurabiliriz, if deyimini kullanabiliriz.

    "source" komutu derlenmiş bir biçimde bellekte bulunan komutları çalıştırmak için kullanılmaktadır. Bir script dosyasını 
    binary hale getirerek (derleyerek) onu belleğe yükleyip "source" komutuyla çalıştırabiliriz. Script dosyasını derlemek için 
    U-Boot projesindeki "mkimage" isimli program kullanılmaktadır. Bu program "u-boot-tools" paketi içerisindedir. Paketi şöyle 
    install edebilirsiniz:

    $ sudo apt-get install u-boot-tools

    "mkimage" programının çeşitli komut satırı argümanları vardır. Örneğin "-A (architecture)" seçeneği derlemenin hangi işlemci
    ailesine göre yapılacağını belirtmektedir. Biz ARM işlemcileriyle çalıştığımıza göre "-A arm" seçeneğini kullanmalıyız. 
    "-d" seçeneği kaynak dosyanın yol ifadesini belirtmektedir. "-T (type)" seçeneği kaynak dosyanın ne dosyası olduğunu 
    belirtmektedir. Biz bu bağlamda script dosyasını derleyeceğimize göre bu seçeneği "-T script" biçiminde kullanmalıyız. 
    "-n (name)" seçeneği derlenmiş dosyaya içsel isim vermek için kullanılmaktadır. "-C (compression)" seçeneği üretilen binary 
    kodda sıkıştırma biçimine belirlemekte kullanılmaktadır. Biz burada sıkıştırma istemediğimiz için bu seçeneği "-C none" 
    biçiminde girebiliriz. O halde örneğin "test.cmd" dosyası içerisindeki U-Boot script'ini "mkimage" programı ile şöyle 
    derleyebiliriz:

    $ mkimage -A arm -T script -C none -n "My Script" -d test.cmd test.scr

    Burada "test.cmd" script dosyası ARM için derlenerek "test.scr" haline getirilmiştir. Artık derlenmiş olan bu script'i 
    belleğe yükleyerek "source" komutuyla çalıştırabiliriz:

    => ext4load mmc 0:2 0x85000000 /home/debian/test.scr
    => source 0x85000000
    ## Executing script at 85000000
    script starts...
    OMAP SD/MMC: 0 (SD)
    OMAP SD/MMC: 1
    script ends...

    Buradaki örnek "test.cmd" dosyasının içeriği şöyledir:

    echo "script starts..."
    mmc list
    echo "script ends..."

    Pekiyi bizim bir script dosyasını derleyip yukarıdaki gibi çalıştırabilmemizin ne faydası olabilir? İşte buradan amaç 
    aslında kullanıcının oluşturduğu bir dosyadakilerin boot zamanı sırasında devreye sokulabilmesidir. Yani amaç U-Boot'un
    komut satırına düşmeden tamamen Linux'ta bir dosyanın içerisine komutları yazarak U-Boot'un bunları otomatik olarak 
    çalıştırmasını sağlamaktır. İzleyen paragraflarda bunun başka bir yolunun da olduğunu göreceksiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Daha önceden de belirttiğimiz gibi default durumda boot işlemi "bootcmd" isimli bir çevre değişkenindeki script'in çalıştırılması 
    ile yapılmaktadır. "boot" komutu ile "run bootcmd" komutunun aynı anlama geldiğini anımsayınız. O halde biz "bootcmd" çevre 
    değişkenini kalıcı bir biçimde değiştirirsek boot işleminde istediğimiz etkiyi yaratabiliriz. Bunun için komut satırına düşmemiz 
    gerekmez. U-Boot çevre değişkenlerini kalıcı hale getirmek için birkaç yol söz konusu olabilir. Çevre değişkenleri komut 
    satırında değiştirilip "saveenv" komutu uygulanırsa disk üzerinde çevre değişkenleri saklanacağı için bir sonraki boot 
    işleminde değişiklikler devreye girebilmektedir. Diğer bir yol default durumda (bu konfigürasyon sırasında değiştirilebilir) 
    U-Boot'un çevre değişkenlerini bir dosyadan okumasıdır. Böylece bu dosya üzerinde değişiklik yapılarak uygulamacı boot süreci 
    üzerinde etkili olabilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												36. Ders 01/08/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    - Normal olarak çevre değişkenleri saveenv komutu ile boot edilen medyada saklanabilmektedir. Böylece U-Boot yeniden açılırken
    bu yeni evre değişkenlerini dikkate alacaktır. Ancak çevre değişkenlerinin save edilmesi konusunda bazı problemlerle karşılaşılabilir.
    Örneğin U-Boot konfigüre edilirken bu save özelliği devre dışı bırakılmış olabilir. Ancak default durumda bu save işleminin 
    yapılabilmesi gerekir. Save işleminin hangi dosya sistemine yapılabileceği de yine U-Boot konfigüre edilirken belirlenebilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												37. Ders 06/08/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    U-Boot'ta reset işlemi yapıldığında U-Boot default durumda "botcmd" isimli bir çevre değişkenindeki script'i çalıştırdığına
    göre biz bu çevre değişkenine kendi script'imizi girip "bootargs" çevre değişkenini de istediğimiz gibi oluşturup "saveenv" 
    işlemini yaparsak boot işleminin otomatik olarak bizim istediğimiz gibi yapılmasını sağlayabiliriz. Örneğin:

    => setenv bootcmd "ext4load mmc 0:2 0x82000000 /boot/vmlinuz-5.10.168-ti-r71;ext4load mmc 0:2 0x88000000
    /boot/dtbs/5.10.168-ti-r71/am335x-boneblack.dtb;bootz 0x82000000 - 0x88000000"
    => setenv bootargs "console=ttyS0,115200 root=/dev/mmcblk0p2 rw"
    => saveenv
    Saving Environments to FAT... OK

    Artık boot komutunu uyguladığımızda ya da yeniden reset işlemi yaptığımızda bizim yönergelerimizle boot işlemi gerçekleşecektir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												38. Ders 08/08/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    U-Boot'u derlediğimizde "bootcmd" çevre değişkeni default bir değere sahip olmaktadır. Böylece boot işlemi bu default "bootcmd"
    değişkenindeki script ile yapılmaktadır. Pekiyi bu default "bootcmd" script'i nasıl belirlenmektedir? İşte aslında U-Boot 
    derlenirken bu script ilgili hedef platforma göre default değerini almaktadır. Ancak U-Boot'un belli bir versiyonundan sonra
    hiç kaynak kodlarda değişiklik yapmadan bu "bootcmd" script'i konfigürasyon parametreleriyle değiştirilebilir. hale getirilmiştir. 
    "make menuconfig" yaptığımızda "Boot options ---> Enable a default value for bootcmd" girişinden bu default "bootcmd" 
    scirpt'i elle değiştirilebilmektedir. BBB için default "bootcmd" script'i şöyledir:

    "run findfdt; run init_console; run finduuid; run distro_bootcmd"

    Ancak BBB'nin kendi sitesinden indirdiğimiz imajı içerisindeki U-Boot'un "bootcmd" script'i ise şöyledir:

    "bootcmd=run findfdt; run init_console; run envboot; run distro_bootcmd"

    Buradaki en önemli script "distro_bootcmd" isimli script'tir. Bu script kabaca önce SD karta bakmakta SD kartın FAT bölümünde 
    "/boot.scr" dosyası varsa onu çalıştırmakta yoksa "/uEnv.txt" dosyasındaki çevre değişkenlerini import edip oradaki "uenvcmd"
    script'ini çalıştırmaktadır. Eğer SD kartın FAT bölümünde bu dosyalar yoksa boot işlemi internal eMMC'den hareketle yapılmaktadır.

    Orijinal siteden indirilen imajdaki U-Boot'ta bulunan konu ilgili çevre değişkenlerini aşağıda veriyoruz:

    ******************************************************
    => printenv bootcmd
    bootcmd=run findfdt; run init_console; run envboot; run distro_bootcmd

    => printenv findfdt
    findfdt=echo board_name=[$board_name] ...; if test $board_name = A335BLGC; then setenv fdtfile am335x-beaglelogic.dtb; fi; 
    if test $board_name = A335BONE; then setenv fdtfile am335x-bone.dtb; fi; if test $board_name = A335BNLT;
    then echo board_rev=[$board_rev] ...; if test $board_rev = GH01; then setenv fdtfile am335x-boneblack.dtb;
    elif test $board_rev = BBG1; then setenv fdtfile am335x-bonegreen.dtb; elif test $board_rev = BP00;
    then setenv fdtfile am335x-pocketbone.dtb; elif test $board_rev = GW1A; then setenv fdtfile am335x-bonegreen-wireless.dtb;
    elif test $board_rev = GG1A; then setenv fdtfile am335x-bonegreen-gateway.dtb; elif test $board_rev = AIA0;
    then setenv fdtfile am335x-abbbi.dtb; elif test $board_rev = EIA0; then setenv fdtfile am335x-boneblack.dtb;
    elif test $board_rev = ME06; then setenv fdtfile am335x-bonegreen.dtb; elif test $board_rev = OS00;
    then setenv fdtfile am335x-osd3358-sm-red.dtb; elif test $board_rev = OS01; then setenv fdtfile am335x-osd3358-sm-red-v4.dtb;
    else setenv fdtfile am335x-boneblack.dtb; => printenv init_console init_console=if test $board_name = A335_ICE;
    then setenv console ttyS3,115200n8;elif test $board_name = A335BLGC; then setenv console ttyS4,115200n8;
    else setenv console ttyS0,115200n8;fi;

    => printenv envboot
    envboot=mmc dev ${mmcdev}; if mmc rescan; then echo SD/MMC found on device ${mmcdev};if run loadbootscript; then run bootscript;
    else if run loadbootenv; then echo Loaded env from ${bootenvfile};run importbootenv;fi;if test -n $uenvcmd;
    then echo Running uenvcmd ...; run uenvcmd;fi;fi;fi;

    => printenv loadbootscript
    loadbootscript=load ${devtype} ${bootpart} ${loadaddr} ${scriptfile};

    => printenv bootpart
    bootpart=0:2

    => printenv scriptfile
    scriptfile=${script}

    => printenv script
    script=boot.scr

    => printenv loadbootenv
    loadbootenv=load ${devtype} ${bootpart} ${loadaddr} ${bootenvfile}

    => printenv bootenvfile
    bootenvfile=uEnv.txt

    => printenv importbootenv
    importbootenv=echo Importing environment from ${devtype} ...; env import -t ${loadaddr} ${filesize}

    => printenv distro_bootcmd
    distro_bootcmd=for target in ${boot_targets}; do run bootcmd_${target}; done

    => printenv boot_targets
    boot_targets=mmc0 legacy_mmc0 mmc1 legacy_mmc1 usb0 pxe dhcp

    => print bootcmd_mmc0
    bootcmd_mmc0=devnum=0; run mmc_boot

    => print bootcmd_mmc1
    bootcmd_mmc1=devnum=1; run mmc_boot

    => printenv mmc_boot
    mmc_boot=if mmc dev ${devnum}; then devtype=mmc; run scan_dev_for_boot_part; fi

    => printenv scan_dev_for_boot_part
    scan_dev_for_boot_part=part list ${devtype} ${devnum} -bootable devplist; env exists devplist || setenv devplist 1; 
    for distro_bootpart in ${devplist}; do if fstype ${devtype} ${devnum}:${distro_bootpart} bootfstype; 
    then run scan_dev_for_boot; fi; done; setenv devplist

    ******************************************************
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												39. Ders 13/08/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    U-Boot'ta diskteki bir text script dosyasını load komutlarıyla belleğe yükleyip doğrudan çalıştırma mümkün değildir. Ancak 
    script dosyasını önce ".scr" ya da ".fit" formatına dönüştürüp dönüştürülmüş dosyayı yükleyerek "source" komutu ile çalıştırma 
    olanağımız vardır. Fakat U-Boot'ta ayrıca "değişken=değer" biçiminde satırların bulunduğu bir text dosya yüklenerel "import env"
    komutu ile onun içerisindeki çevre değişkenleri U-Boot çevre değişkenlerine eklenebilir. Örneğin diskimizin FAT disk bölümünde
    "myenv.txt" isimli bir dosya bulunuyor olsun. Bu dosyayı yükleyip bu dosya içerisindeki çevre değişkenlerini U-Boot çevre
    değişken listesine şöyle ekleyebiliriz:

    => load mmc 0:1 0x88000000 /myenv.txt
    15 bytes read in 2 ms (6.8 KiB/s)
    => env import -t 0x88000000
    ## Info: input data size = 33232 = 0x81D0

    "env import" komutundaki "-t" seçeneği import işleminin text dosyadan hareketle yapılacağını belirtmektedir. Eğer dosyadaki 
    bir çevre değişkeni zaten U-Boot çevre değişkeni olarak varsa default durumda eski çevre değişkeni ezilmektedir.

    Ayrıca anımsanacağı gibi eğer bir çevre değişkeni bir script içeriyorsa "run" komutuyla o çevre değişkeninin içerisindeki 
    script çalıştırılabiliyordu.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de boot sürecini bir dosyadan hareketle gerçekleştirmek için kendimiz "bootcmd" script'ini oluşturalım. Bu işlemi yine 
    iki biçimde yapabiliriz:

    1) "xxx.scr" isimli dosyayı yükleyerek "source" komutuyla onun içerisindeki script'i çalıştırabiliriz. Uyumluluk bakımından
    dosyanın ismini "boot.scr" olarak verebiliriz.

    2) "xxx.txt" isimli bir dosyadan çevre değişkenlerini belleğe yükleyip "env import" komutuyla onu çevre değişken listesine 
    ekleyip oradaki bir script'i çalıştırabiliriz. Burada da uyumluluk bakımından dosyanın ismini "uEnv.txt" olarak verebiliriz. 
    Çalıştırılacak çevre değişkenini ise uyumluluk bakımından "uenvcmd" olarak alabiliriz.

    Aslında siteden indirdiğimiz imajdaki "bootcmd" script'i zaten yukarıdaki işlemleri yapmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    "bootcmd" script'inin ""xxx.scr" dosyasını yükleyerek "source" komutuyla o script'i çalıştırmasını adım adım şöyle 
    sağlayabiliriz:

    1) Önce bir dosyaya script'imizi yazarız. Örneğin bu dosya "boot.cmd" isminde olsun. Script'imizin içeriği şöyle olabilir:

    load mmc 0:2 0x82000000 /boot/vmlinuz-5.10.168-ti-r71
    load mmc 0:2 0x88000000 /boot/dtbs/5.10.168-ti-r71/am335x-boneblack.dtb
    setenv bootargs "console=ttyS0,115200 root=/dev/mmcblk0p2 rw"
    bootz 0x82000000 - 0x88000000

    Bu dosyayı aşağıdaki gibi derleyerek ".scr" uzantılı hale getirebiliriz:

    $ mkimage -A arm -T script -C none -n "Boot Script" -d boot.cmd boot.scr

    2) U-boot'a geçilir. "bootcmd" çevre değişkeni aşağıdaki biçimde ayarlanır ve "saveenv" komutuyla save edilir:

    => setenv bootcmd "load mmc 0:1 0x8A000000 /boot.scr;source 0x8A000000"
    => saveenv
    Saving Environment to FAT... OK

    Burada yazmış olduğumuz "bootcmd" script'inde "boot.scr" dosyasının FAT disk bölümünün kök dizininde olduğu varsayılmıştır. 
    Bu durumda bizim birinci adımda elde ettiğimiz "boot.scr" dosyasını FAT disk bölümünün kök dizinine çekmeliyiz.

    Ancak burada dikkat edilmesi gereken bir nokta vardır. Default durumda "am335x_evm_defconfig" dosyasında "source" komutunun
    "scr" dosya formatı desteği disable edilmiştir. Bunun enable edilerek U-Boot'un derlenmesi gerekmektedir. Bu seçeneğin
    enable edilmesi "make menuconfig" menüsünde "Boot options / Boot images / Enable support for the legacy image format" 
    girişiyle saplanabilir. Ya da doğrudan ".config" dosyasında "CONFIG_LEGACY_IMAGE_FORMAT=y" yapılabilir. (Siteden indirilen 
    orijinal BBB imajındaki U-Boot'ta bu seçenek zaten enable edilmiş durumdadır.)
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de çevre değişkenlerinin bulunduğu bir text dosyadan hareketle boot işlemini otomatize etmeye çalışalım. Burada text
    dosya herhangi bir isimde olabilir. Ancak orijinal imajdaki "uEnv.txt" ismini kullanabiliriz. O halde işlemler şöyle 
    yürütülebilir:

    1) Önce FAT disk bölümünde ilgili text dosyaya aşağıdaki gibi çevre değişkenleri script'ler içerecek biçimde girilir. 
    Buradaki dosyanın "uEnv.txt" isimli dosya olduğunu varsayalım:

    loadkernel=load mmc 0:2 0x82000000 /boot/vmlinuz-5.10.168-ti-r71
    loadfdt=load mmc 0:2 0x88000000 /boot/dtbs/5.10.168-ti-r71/am335x-boneblack.dtb
    bootargs=console=ttyS0,115200 root=/dev/mmcblk0p2 rw
    bootsys=bootz 0x82000000 - 0x88000000
    uenvcmd=run loadkernel;run loadfdt;run bootsys

    Burada aslında boot işlemini asıl yapan script "uenvcmd" isimli script'tir. O halde bu çevre değişken listesi U-Boot'ta
    dahil edilip "uenvcmd" isimli script çalıştırılırsa boot işlemi otomatik gerçekleşecektir.

    2) Şimdi de U-Boot komut satırına düşüp "bootcmd" çevre değişkenini uygun biçimde set edelim:

    => setenv bootcmd "load mmc 0:1 0x8A000000 /uEnv.txt;env import -t 0x8A000000;run uenvcmd"
    => saveenv
    Saving Environment to FAT... OK

    Burada "bootcmd" script'i önce "uEnv.txt" dosyasındaki çevre değişkenlerini çevre değişken listesine eklemiş sonra da 
    "uenvcmd" çevre değişkeninde belirtilen script'i çalıştırmıştır.

    Bu biçimdeki otomatik boot yaklaşımı kullanıcılar için biraz daha kolaydır. Çünkü önceki yaklaşımda olduğu gibi bir derleme 
    işlemi yapılmamaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aslında daha önce de belirttiğimiz gibi siteden indirdiğimiz orijinal imajdaki "bootcmd" script'i yukarıdakilere benzer işlemler 
    yapmaktadır. Orijinal imajdaki "bootcmd" script'inin yaptığı işlemi kabaca şöyle özetleyebiliriz:

    1) Önce SD karttaki FAT bölümünde sırasıyla "/boot.scr" sonra "/uEnv.txt" dosyalarının olup olmadığına bakmaktadır. Eğer bu 
    dosyalardan biri varsa boot işlemi bu dosyalardan hareketle yürütülmektedir. Eğer yükleme için "/uEnv.txt" dosyası bulunmuşsa 
    buradaki çevre değişkenleri import edilip eğer varsa "uenvcmd" script'i çalıştırılmaktadır.

    2) Eğer SD karttaki FAT bölümünde "/boot.scr" veya "/uEnv.txt" dosyaları yoksa internal eMMC'den boot işlemi yürütülmektedir.
    Bu durumda internal eMMC içerisindeki "/boot/uEnv.txt" dosyası da işleme sokulmaktadır.

    Orijinal "bootcmd" script'inin bazı ayrıntıları vardır. Biz bu ayrıntıların üzerinde durmayacağız Ancak bu script'in ayrıntılarını 
    U-Boot komut satırında gözle inceleyebilirsiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												40. Ders 15/08/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    U-Boot'taki komut satırındaki komutların bir bölümü bash komutlarına benzemektedir. U-Boot'un script dili de bash'in script
    diline benzemektedir. Ancak bu iki komut satırı ortamının benzerlik dışında birbiriyle bir ilgisi yoktur. U-Boot'taki 
    script dili bash'in küçük bir alt kümesi biçimindedir. Bu tür bash benzeri basit script dillerine genel olarak "hush" 
    denilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi U-Boot'u derlemeden önce "make menuconfig" yaptığımızda karşımıza çıkan menülerdeki seçenekler ne anlama gelmektedir?
    Anımsanacağı gibi biz "make menuconfig" yapıp seçenekleri değiştirdiğimizde aslında ".config" isimli dosya üzerinde değişiklikler
    yapılmaktadır. Yani aslında "make menuconfig" yapmak yerine doğrudan bu ".config" dosyası üzerinde de değişiklikler yapabiliriz.
    Konfigürasyon dosyaları genel olarak "anahtar=değer" biçimindeki satırlardan oluşmaktadır. Buradaki anahtarlar büyük harflerle
    oluşturulmuştur. Aynı zamanda kaynak kodlardaki sembolik sabitlerle aynı isimdedirler. ".config" dosyasının bir bölümünü 
    aşağıda veriyoruz:

    ...
    CONFIG_SPL_MUSB_NEW=y
    CONFIG_SPL_NAND_SUPPORT=y
    # CONFIG_SPL_NAND_RAW_ONLY is not set
    CONFIG_SPL_NAND_DRIVERS=y
    CONFIG_SPL_NAND_ECC=y
    # CONFIG_SPL_NAND_SOFTECC is not set
    # CONFIG_SPL_NAND_SIMPLE is not set
    CONFIG_SPL_NAND_BASE=y
    # CONFIG_SPL_NAND_IDENT is not set
    # CONFIG_SPL_UBI is not set
    # CONFIG_SPL_DM_SPI_FLASH is not set
    CONFIG_SPL_NET=y
    CONFIG_SPL_NET_VCI_STRING="AM335x U-Boot SPL"
    # CONFIG_SPL_NOR_SUPPORT is not set
    # CONFIG_SPL_XIP_SUPPORT is not set
    # CONFIG_SPL_ONENAND_SUPPORT is not set
    CONFIG_SPL_OS_BOOT=y
    CONFIG_SPL_PAYLOAD_ARGS_ADDR=0x88000000
    CONFIG_SYS_NAND_SPL_KERNEL_OFFS=0x200000
    CONFIG_SPL_FALCON_BOOT_MMCSD=y
    CONFIG_SYS_MMCSD_RAW_MODE_KERNEL_SECTOR=0x1700
    CONFIG_SYS_MMCSD_RAW_MODE_ARGS_SECTOR=0x1500
    ...

    Konfigürasyon seçenekleri oldukça fazladır. Bazı konfigürasyon seçenekleri aygıta özgüdür. Bazı seçenekler ise geneldir. 
    Biz burada önemli bazı seçenekler ve seçenek grupları hakkında açıklamalar yapacağız.

    - "Command line interface" ana girişinde komut satırına ilişkin alt seçenekler bulunmaktadır.
        - "Shell prompt" U-Boot'un default "=>" prompt'unu değiştirmek için kullanılmaktadır.
        - "Hush shell secondary prompt" ise ikincil prompt'u değiştirmek için kullanılır.
        - Bu ana girişteki "Xxxx commands" girişleri komut satırında uygulanabilecek komutları seçmemizi sağlamaktadır.
    - "Environment " ana girişinde çevre değişkenlerinin kullanımına ilişkin çeşitli seçenekler bulunmaktadır.
        - "Environment is in FAT file system" seçeneği "uboot.cmd" çevre değişken dosyasının FAT dosya sisteminde bulundurulacağını
        ve buradan yükleneceğini belirtmektedir.
        - "Device and partition for where to store the environment in FAT" seçeneği çevre değişkenlerinin hangi FAT disk bölümünde
        saklanıp geri alınacağını belirtmektedir.
        - "Name of the FAT file to use for the environment" çevre değişkenlerinin "saveenv" komutu uygulandığında hangi dosya 
        ismiyle saklanacağını belirtmektedir. Buradaki default dosya ismi "uboot.env" biçimindedir.
    - "Device drivers" ana girişinde U-Boot komut satırında bir takım komutları kullanabilmek için hangi aygıtları tanıyabilen 
    bir U-Boot imajının oluşturulacağına ilişkin seçenekler bulunmaktadır.
        - Örneğin U-Boot tarafından kullanılan seri port'un baud rate'i burada set edilebilir. Bunun default değeri 115200'dür.
        - Örneğin eğer U-Boot'ta USB kullanılacaksa buradan USB sürücüsü seçilmelidir. Aksi takdirde U-Boot komut satırına 
        düştüğümüzde U-Boot USB'ye erişemeyecektir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de U-Boot'u Raspberry Pi'ya kurmaya çalışalım. Bunun için öncelikle Raspberry'ın GPIO seri port uçlarına USB seri 
    port modülümüzü bağlamamız gerekir. Yine bağlantı BBB'de olduğu gibi üç uçla yapılmaktadır. Raspberry'ın seri port uçları
    şöyledir:

    6 => Ground
    8 => TxD
    10 => RxD

    Burada GPIO uçlarının fiziksel numaralandırılmasına dikkat ediniz. Düşük numara SD kart slotu tarafından başlamaktadır. (Yani 
    USB ve Ethernet portlarının ters tarafından başlamaktadır.) Yukarıdaki üç pin SD kart tarafında ikili sütunların dışa bakan 
    sütunlarında iki satır boşluktan sonraki 3 pindir. Yine bağlantı RxD ile TxD uçlarının karşılıklı bağlanması ile yapılmaktadır:

    GND (6) --- Ground
    TxD (8) ---> RxD
    RxD (10) <--- TxD

    Kablo bağlantısı yapıldıktan sonra Raspberry Pi'ın ilgili uçlarının seri port olarak kullanmasının sağlanması gerekmektedir. 
    Bunun için Raspberry Pi OS'de Ana Menüde "Preferences / Raspberry Pi Configuration" diyalog penceresi açılır. Burada 
    "Interfaces" sekmesinden "Serial Port" enable edilir. Tabii aynı işlem komut satırından "raspi-config" programıyla da 
    yapılabilmektedir. Aslında burada yapılan değişiklikler "config.txt" isimli bir dosyaya yazılmakta ve Raspberry Pi 
    yeniden açılırken ilgili donanımsal ayarlamalar yapılmaktadır.

    Yukarıdaki kablo bağlantısı ve seri port açma işlemi yapıldıktan sonra mutlaka seri port bağlantısını test etmelisiniz. 
    Test işlemi için Raspberry Pi'ın kendisini kullanabilirsiniz. GPIO uçlarını bağladığınız USB seri port modülünün (CP2102) 
    USB ucunu Raspberry Pi'ın USB soketlerinin birine takabilirsiniz. Raspberry Pi'ın GPIO seri uçları "dev/ttyAMA0" aygıt 
    dosyası ile kullanılmaktadır. USB sokete taktınız seri porta ise yine "/dev/ttyUSB0" aygıt ismiyle erişilmektedir. Tabii 
    test işlemi Raspberry Pi ile Windows arasında ya da Raspberry Pi ile Linux arasına da yapılabilir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Maalesef yukarıda açıkladığımız GPIO seri port'ları Raspberry Pi 4 ve önceki modellerde U-Boot'ta sorun oluşturmazken 
    Rapsberry Pi 5 modelinde sorun oluşturmaktadır. Muhtemelen U-Boot ekibi Raspberry Pi 5'teki GPIO seri port uçlarını kullanırken
    birtakım böcekler (bugs) oluşmuştur. Bunun için birkaç patch yayınlanmışsa da kursun yapıldığı zamanda bu patch'ler de 
    problemi çözememiştir. Ancak Raspberry Pi 5'lerdeki iki HDMI portunun arasındaki küçük seri portun kullanımı U-Boot'ta 
    bir sorun çıkarmamaktadır. Bu seri port soketi sık karşılaşılan bir soket değildir. Bu soket için kablo bulmak da biraz 
    zahmetlidir. Ancak orijinali Raspberry Pi Pico'lar için üretilmiş olan "Raspberry Pi Debug Probe" denilen ürünün içerisinde 
    bu porta ilişkin soketler bulunmaktadır. Bu ürün her zaman Türkiye'deki şirketlerde hazır bulunmayabilmektedir. Ancak 
    yabancı bazı şirketlerde (örneğin "aliexpress") bir ucu bu soket olan diğer ucu standart USB soket olan kablolar satılmaktadır. 
    Biz kurusumuzda "Raspberry Pi Debug Probe" ürününden çıkan kabloları kullanacağız. Buradaki soket yine 3 uçludur. Bu 3 uç 
    aşağıdaki gibidir:

    x       x       x
    RXD    GND     TxD

    Bu seri prot'un Raspberry Pi OS'deki aygıt dosyası "/dev/ttyAMA10" biçimindedir. (GPIO seri uçlarının aygıt dosyasının 
    "/dev/ttyAMA0" olduğunu anımsayınız.)

    Burada da kablo bağlantısını yine test etmelisiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Anımsanacağı gibi Raspberry Pi reset edildiğinde aşağıdaki kodlar otomatik olarak çalıştırılmaktadır:

    ROM Kod ---> boot.bin (FAT) ---> start.elf (FAT) ---> İşletim sistemi Dosyaları yükleniyor

    start.elf programının "config.txt" isimli bir dosyaya baktığını ve çekirdek imajını o dosyadaki "kernel=xxxxxx" satırından 
    elde ettiğini belirtmiştik. İşte Raspberry Pi'a U-Boot kurarken biz yukarıdaki akış üzerinde bir değişiklik yapmayız. 
    Ancak "start.elf" programının çekirdek imajını değil U-Boot'u yüklemesini sağlarız. Bunun için "config.txt" dosyasının 
    "kernel" satırını aşağıdaki gibi değiştirmemiz gerekir:

    kernel=u-boot.bin

    Buradaki U-Boot dosyasının neden "u-boot.img" değil de "u-boot.bin" olduğunu merak edebilirsiniz. BBB'de biz U-Boot'un
    MLO programını da SD karta yüklemiştik. Bu MLO programı U-Boot'un ".img" formatını tanımaktadır. Ancak Raspberry Pi'daki 
    "start.elf" programı bu formatı tanımamaktadır. Buradaki "u-boot.bin" dosyası "pure binary" U-Boot dosyasıdır. Burada dosya
    isminde bir yol ifadesi olmadığına dikkat ediniz. "start.elf" programı zaten FAT dosya sisteminin kök dizinini default olarak 
    kullanmaktadır. Aslında bu "config.txt" içerisindeki bu "kernel" satırı bulundurulmazsa bazı modeller için "kernel.img", 
    bazı modeller için "kernel7.img" bazı modeller için ise "kernel8.img" girilmiş gibi işlem yapılmaktadır. Raspberry 5'te 
    default olarak önce "kernel_2712.img" imajı eğer bu imaj bulunamazsa "kernel8.img" imajı aranmaktadır. Bu işlemin yanı sıra 
    ayrıca eğer U-Boot'u GPIO seri port uçlarından kullanacaksanız "config.txt" dosyasında aşağıdaki satırı bulundurmalısınız:

    enable_uart=1

    Aksi taktirde default durumda GPIO seri uçları kullanılamayacaktır. (Tabii aslında Raspberry Pi OS'de "Preferences/Raspberry 
    Pi configuration" diyalog penceresinden "Interfaces" sekmesine geçilerek "Serial Port" enable edilirse zaten "config.txt"
    dosyasına bu satır eklenmektedir. Bu menüdeki "Serial Console" iki HDMI portunun arasındaki debug seri port'unu enable etmek
    kullanılmaktadır.)

    Raspberry Pi'daki "start.elf" dosyasının ele aldığı "config.txt" dosyasına ilişkin içerik aşağıdaki bağlantıda dokümante 
    edilmiştir:

    https://www.raspberrypi.com/documentation/computers/config_txt.html
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi U-Boot boot loader'ını Raspberry Pi'ya nasıl yükleyebiliriz?

    1) Raspberry Pi'ya uygun bir araç zincirinin elde edilmesi gerekir. Raspberry Pi 4 ve 5'te biz genellikle 64 bit Linux 
    kullanmaktayız. (Halbuki BBB'de 32 bit Linux kullanılmaktadır). O halde derlemeyi biz 64 bit ARM araç zinciri ile yapmalıyız. 
    Tabii bu araç zinciri sıfırdan crosstool-NG ile oluşturulabilir ya da hazır araç zincirlerini kullanabiliriz. Örneğin söz konusu 
    araç zincirini yine aşağıdaki bağlantıdan indirebiliriz:

    https://developer.arm.com/downloads/-/arm-gnu-toolchain-downloads

    Burada "x86_64 Linux hosted cross toolchains" başlığı altındaki "AArch64 GNU/Linux target (aarch64-none-linux-gnu)" 
    araç zinciri indirilebilir.

    2) Derleme öncesinde daha önce görmüş olduğumuz çevre değişkenleri ayarlanır:

    $ export CROSS_COMPILE=aarch64-none-linux-gnu-
    $ PATH=$PATH:/home/kaan/Study/EmbeddedLinux/U-Boot/arm-gnu-toolchain-13.3.rel1-x86_64-aarch64-none-linux-gnu/bin

    3) Şimdi Raspberry Pi için hazır bir konfigürasyon dosyası set edilebilir. u-boot dizinindeki configs dizini içerisinde 
    Raspberry Pi'a ilişkin aşağıdaki config dosyaları bulunmaktadır:

    kaan@kaan-virtual-machine:~/Study/EmbeddedLinux/U-Boot/u-boot/configs$ find . -name "*rpi*"
    ./rpi_4_defconfig
    ./rpi_3_defconfig
    ./rpi_4_32b_defconfig
    ./rpi_arm64_defconfig
    ./rpi_2_defconfig
    ./rpi_3_32b_defconfig
    ./rpi_defconfig
    ./rpi_3_b_plus_defconfig
    ./rpi_0_w_defconfig

    Burada rpi_5 ile başlayan bir konfigürasyon dosyasının olmadığında dikkat ediniz. Biz "rpi_4_defconfig" dosyasını ya da 
    "rpi_arm64_defconfig" dosyasını kullanabiliriz:

    $ make rpi_arm64_defconfig

    4) Konfigürasyonda değişiklikler için yine "make menuconfig" yapılabilir. Buradaki default konfigürasyon BBB'deki default 
    konfigürasyondan farklıdır.

    5) Artık make işlemi yapılabilir:

    $ make

    U-Boot'un derlenmesi sonucunda elde edilen dosyaları Raspberry Pi'yın SD kartına nasıl yerleştireceğimizi izleyen paragraflarda
    ele alacağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz daha önce BBB'de U-Boot'ta çekirdek imajını yüklerken genellikle 0x82000000 adresini, aygıt ağacını yüklerken de 
    0x88000000 adresini kullanmıştık. Çünkü BBB'de fiziksel DRAM bellek 0x80000000 adresinden başlamaktadır. Oysa Raspberry Pi'da
    fiziksel DRAM bellek 0x00000000 adresinden başlamaktadır. Dolayısıyla bizim bu dosyaları bu orijini temel alarak belleğe 
    yüklememiz gerekir. Tıpkı BBB'de olduğu gibi Raspberry Pi'da da çekirdek yükleme adresi, aygıt ağacı yükleme adresi, geçici 
    kök dosya sistemi için ramdisk yükleme adresi aşağıdaki çevre değişkenlerinde default biçimde oluşturulmuş durumdadır:

    kernel_addr_r
    fdt_addr_r
    ramdisk_addr_r

    Bunların default değerleri şöyledir:

    U-Boot> echo $kernel_addr_r
    0x00080000
    U-Boot> echo $fdt_addr_r
    0x02600000
    U-Boot> echo $ramdisk_addr_r
    0x02700000

    U-Boot'un default prompt'unun bu konfigürasyonda "=>" biçiminde değil "U-Boot>" biçiminde olduğuna dikkat ediniz. O halde 
    gerekli dosyaları aşağıdaki gibi yükleyebiliriz:

    U-Boot> load mmc 0:1 ${kernel_addr_r} kernel8.img
    8751247 bytes read in 368 ms (22.7 MiB/s)
    U-Boot> load mmc 0:1 ${fdt_addr_r} bcm2712-rpi-5-b.dtb
    76676 bytes read in 5 ms (14.6 MiB/s)

    Buradaki "kernel_addr_r" çevre değişkeni çekirdeğin tavsiye edilen yükleme adresini, "fdt_addr_r" çevre değişkeni ise aygıt
    ağacının tavsiye edilen yükleme adresini belirtmektedir. Tabii yine bootargs çevre değişkeninin çekirdek boot parametrelerini 
    içerecek biçimde oluşturulması gerekmektedir:

    bootargs=console=ttyAMA10,115200 root=/dev/mmcblk0p2 rw

    Linux çekirdek imajları birkaç formatta karşımıza çıkabilmektedir. Biz bu konuyu çekirdek derlemesi kısmında ele alacağız. 
    BBB'deki çekirdek imaj formatına "zImage" denilmektedir. Bu imaj formatında çekirdek dosyası sıkıştırılmıştır ancak kendi 
    kendini açabilme yeteneğine sahiptir. Halbuki Raspberry Pi'daki çekirdek imajı "uImage" denilen formattadır. Burada çekirdek 
    dosyası yine sıkıştırılmıştır ancak dosyanın kendi kendini açabilme yeteneği yoktur. Dosyanın açılması bootloader tarafından 
    yapılmaktadır. Raspberry Pi'daki FAT disk bölümünde bulunan "kernel8.img" dosyası uImage formatındadır. Yani sıkıştırılmış 
    ancak kendi kendini açamayan imaj formatı türündendir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												42. Ders 22/08/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
     Biz BBB'yi boot ederken U-Boot komut satırında "bootz" komutunu kullanmıştık. Halbuki Raspberry Pi'yı U-Boot ile boot ederken
    "booti" komutunu kullanacağız. "booti" komutu sıkıştırılmış ancak kendi kendini açamayan çekirdek imajları ile boot işlemi
    için kullanılmaktadır. Ancak "booti" komutunda önce komut sıkıştırılmış çekirdek imajını açıp sonra o imaja dallanmaktadır. 
    Bu nedenle bu komutta bu imajın açılacağı adres ve sıkıştırılmış imajın uzunluğu U-Boot'a "kernel_comp_load_addr" ve 
    "kernel_comp_size" çevre değişkenleri yoluyla belirtilmelidir. Bu belirlemeler aşağıdaki gibi yapılabilir:

    U-Boot> setenv kernel_comp_addr_r 0x10000000
    U-Boot> setenv kernel_comp_size 0x1000000

    Sıkıştırılmış imajın uzunluğu zaten load komutunda decimal olarak verilmektedir. Ancak buradaki uzunluğu fazla almanın 
    bir sakıncası yoktur.

    Ancak Raspberry Pi boot edilirken aygıt ağacı konusunda dikkat etmek gerekir. Aygıt ağacını uygulamacının yüklemesi yerine
    zaten "start.elf" tarafından yüklenmiş olan aygıt ağacının kullanılması daha pratik bir yöntemdir. "start.elf" tarafından 
    yüklenmiş olan aygıt ağacı fdt_addr adresinde bulunmaktadır. Bu nedenle "booti" komutu aşağıdaki gibi kullanılabilir:

    U-Boot> booti $kernel_addr_r - $fdt_addr

    Pekiyi neden biz FAT dosya sistemindeki aygıt ağaçlarından birini ya da u-boot derlemesi sonucunda elde ettiğimiz aygıt 
    ağaçlarından birini yüklemedik de "start.elf" tarafından zaten yüklenmiş olan aygıt ağacını kullandık? Aslında biz kendi
    aygıt ağacımızı da yükleyebiliriz. Ancak bu bağlamda bazı noktaların bilinmesi gerekmektedir. Biz burada şimdilik pratik 
    bir yola saptık.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Yukarıdaki boot işlemini kalıcı hale getirmek için yine "bootcmd" çevre değişkenini ve ilgili çevre değişkenlerini oluşturup
    "saveenv" komutunu kullanabiliriz. Örneğin:

    U-Boot> setenv bootcmd "load mmc 0:1 $kernel_addr_r kernel8.img;booti $kernel_addr_r - $fdt_addr"
    U-Boot> setenv bootargs "console=ttyAMA10,115200 root=/dev/mmcblk0p2 rw"
    U-Boot> setenv kernel_comp_addr_r 0x10000000
    U-Boot> setenv kernel_comp_size 0x01000000
    U-Boot> saveenv
    Saving Environment to FAT... OK

    Artık Raspberry Pi'ımızı reset ettiğimizde otomatik boot işlemi gerçekleşecektir. Tabii buradaki otomatik boot işlemi 
    dışarıdan müdahaleye açık değildir. Bunu sağlayabilmek için BBB'de yaptığımız işlemlerin benzerlerini yapabiliriz. Örneğin 
    burada yine FAT dizininde bir çevre değişkeni script'i yazıp bu script'i "bootcmd" içerisinde yükleyip çalıştırabiliriz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi boot işlemini FAT dosya bölümündeki bir dosyayı temel alarak gerçekleştirelim. Yine bu dosyanın ismini "uEnv.txt" 
    biçiminde verelim. (Tabii böyle bir zorunluluğumuz yok.) Dosyanın içeriği dışarıdan sistem yöneticisi tarafından değiştirilebileceği
    için bu sayede boot işlemi customize edilebilecektir. Örnek "uEnv.txt" dosyamız aşağıdaki gibi olabilir:

    loadkernel=load mmc 0:1 $kernel_addr_r /kernel8.img
    bootargs=console=ttyAMA10,115200 root=/dev/mmcblk0p2 rw
    bootsys=booti $kernel_addr_r - $fdt_addr
    uenvcmd=run loadkernel;run bootsys

    Şimdi bu dosyayı yükleyip buradaki "uenvcmd" çevre değişkeni ile belirtilen script'i çalıştıran "bootcmd" çevre değişkenini
    oluşturup save edelim:

    U-Boot> setenv bootcmd "load mmc 0:1 0x02000000 /uEnv.txt;env import -t 0x02000000; run uenvcmd"
    U-Boot> saveenv
    Saving Environment to FAT... OK

    Artık sistemi reset ettiğimizde boot işlemi yine otomatik biçimde u_boot tarafından gerçekleştirilecektir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz şimdiye kadar zaten kurulu olan bir Linux dosya sistemini kullanarak boot işlemini gerçekleştirdik. Örneğin BBB'de biz 
    zaten BBB'nin kök dosya sistemini hiç değiştirmeden kullandık. Benzer biçimde Raspberry Pi'da da onun oluşturulmuş kök dosya
    sistemini doğrudan kullandık. Şimdi sıfır bir disk üzerinde Linux üzerinde çalışma için gerekebilecek dosyaları içeren kök 
    dosya sistemini kendimiz oluşturacağız.

    Sistem boot edilirken yalnızca çekirdek imajı (kernel image), aygıt ağacı dosyası (device tree) ve geçici kök dosya sistemi
    (initial ramdisk) yeterli değildir. Çünkü sistem boot edilirken doğrudan ya da dolaylı olarak diskte hazır bulunması gereken 
    birtakım dosyalar da işleme sokulmaktadır. İşte en azından gerekli lan bu dosyaların sıfır bir diskte uygun yerlere 
    konuşlandırılması gerekmektedir. Örneğin eğer diskimizde bir kabuk programı bulunmazsa biz komut satırına düşemeyiz. Standart
    UNIX komutları olan "ls", "cat", "cp", "mv" gibi komutların çok büyük çoğunluğu aslında çalıştırılabilen dosyalardır. Bu 
    programların da uygun yerlerde bulunuyor olması gerekir. Yine birtakım konfigürasyon dosyalarının da bulundurulması gerekebilmektedir. 
    Örneğin bazı programlar bazı dinamik kütüphaneleri kullanıyor olabilir. Bu durumda bu dinamik kütüphane dosyalarının da 
    uygun yerlere konuşlandırılması gerekmektedir. İşte biz "kök dosya sisteminin (root file system)" oluşturulması demekle 
    tüm bu hazırlıkların yapılmasını kastetmekteyiz. Şüphesiz hedef diske kurulacak olan tüm programların hedef makine için 
    "çapraz derleyicilerle" derlenmiş olması gerekir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi sıfırdan kök dosya sistemi nasıl oluşturulabilir? Bu işlem tamamen manuel sıfırdan yapılabilir. Yani uygulamacı 
    kök dizin içerisindeki gerekli dizinleri elle yaratır. Sonra gerekli programları kaynak kodlarından hareketle hedef makine 
    için derler ve onları konuşlandırır. Sonra yine gerekli birtakım konfigürasyon dosyalarını elle oluşturur. Ancak bu manuel 
    yöntem zahmetlidir. Bunun yerine bu işlemi pratik bir biçimde yapan araçlar geliştirilmiştir. Örneğin "BusyBox" bu amaçla
    sıkça kullanılmaktadır. Kullanımı da oldukça kolaydır. Buildroot ve Yocto projeleri daha genel amaçlar için gerçekleştirilmiştir
    ancak bunlarla kök dosya sistemi de oluşturulabilmektedir. Bazı dağırımların bu işi yapan özel utility programları da 
    vardır. Örneğin "debootstrap" programı Debian tabanlı kök dosya sistemini internetten indirerek oluşturabilmektedir. Ancak 
    bu araçların bazıları esnek değildir. Özellikle gömülü sistemlerde düşük bir sistem kaynağı olduğu dikkate alındığında bu 
    araçların bazıları minimalist bir kurulum sağlayamamaktadır. Biz kursumuzda bu işi yapan temel araçları çeşitli konularda 
    göreceğiz. Önce çok kullanılan ve basit bir kullanıma sahip olan "busybox" ile başlayacağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Busybox minimalist biçimde kök dosya sistemini kolay bir biçimde oluşturabilmek için esnek ve yaygın kullanılan bir araçtır. 
    Projenin orijinal bağlantısı şöyledir:

    https://www.busybox.net/

    Projenin kaynak kodları üzerinde gezinti yapabilmek için aşağıdaki bağlantıyı kullanabilirsiniz:

    https://elixir.bootlin.com/busybox/1.36.1/source

    BusyBox kullanımının tipik adımları U-Boot'takine çok benzemektedir. BusyBox ile çalışmak için tipik olarak şu adımlardan 
    geçilmelidir:

    1) BusyBox sitesinden kaynak kod olarak indirilir.

    2) Kaynak kodların bulunduğu kök dizine geçilir ve "make defconfig" işlemi ile default konfigürasyon dosyası ".config" 
    dosyası biçiminde oluşturulur. Örneğin:

    $ make defconfig

    Burada "defconfig" dışında birkaç seçenek daha vardır. Ancak bu seçenekler başka özel durumlar için kullanılmaktadır:

    $ ls -l configs
    total 244
    -rw-r--r-- 1 kaan kaan 26836 Oca  1  2021 android2_defconfig
    -rw-r--r-- 1 kaan kaan 28578 Eyl 30  2021 android_502_defconfig
    -rw-r--r-- 1 kaan kaan 27282 Oca  1  2021 android_defconfig
    -rw-r--r-- 1 kaan kaan 27743 Eyl 30  2021 android_ndk_defconfig
    -rw-r--r-- 1 kaan kaan 25892 Oca  1  2021 cygwin_defconfig
    -rw-r--r-- 1 kaan kaan 26551 Oca  1  2021 freebsd_defconfig
    -rw-r--r-- 1 kaan kaan 20881 Oca  1  2021 TEST_nommu_defconfig
    -rw-r--r-- 1 kaan kaan 28599 Oca  1  2021 TEST_noprintf_defconfig
    -rw-r--r-- 1 kaan kaan 22005 Oca  1  2021 TEST_rh9_defconfig

    3) "make menuconfig" komutu ile görsel bir biçimde default konfigürasyon üzerinde değişiklikler yapılarak dosya save edilebilir. 
    Buradaki menüde kök dosya sisteminin customize edilmesine ilişkin pek çok seçenek bulunmaktadır. Tabii uygulamacı isterse 
    doğrudan ".config" dosyasının içerisindeki satırlar üzerinde de değişiklikler yapabilir.

    4) Derleme işlemine başlamadan önce yine CROSS_COMPILE çevre değişkeni U-Boot'ta yaptığımız gibi oluşturulmalıdır (yani 
    export edilmelidir). Yine çapraz derleyicinin araçlarının bulunduğu "bin" dizini PATH çevre değişkenine eklenmelidir. 
    Örneğin biz BBB için kök dosya sistemi oluşturmak amacıyla derleme yapacak olalım:

    $ export CROSS_COMPILE=arm-none-linux-gnueabihf-
    $ PATH=$PATH:/home/kaan/Study/EmbeddedLinux/arm-gnu-toolchain-13.3.rel1-x86_64-arm-none-linux-gnueabihf/bin

    Artık make işlemini yapabiliriz:

    $ make

    Bu işlemden sonra artık proje hedef sistem için derlenmiştir.

    5) Şimdi oluşturulan kök dosya sistemine ilişkin birtakım dosyaların bir dizinin altına konuşlandırılması gerekmektedir. 
    Bu işlem "make install" komutuyla yapılmaktadır:

    $ make install

    Aslında yukarıda dördüncü maddede "make" yerine tek hamlede "make install" işlemi de yapabilirdik. Biz "make install" 
    yaptığımızda tüm ürün default olarak "_install" isimli bir dizine kopyalanmaktadır. Eğer bu dizinin ismini değiştirmek 
    istiyorsanız (genellikle istenir) bunun için menuconfig'te "Settings/Destination path for 'make install'" seçeneği üzerinde
    değişiklik yapılabilir ya da doğrudan konfigürasyon dosyasındaki "CONFIG_PREFIX" satırı değiştirilebilir.

    Kurulum yapıldıktan sonra aslında kök dosya sisteminin önemli bazı dizinlerindeki programlar oluşturulmuş olmaktadır. Artık 
    bu programları uygun yerlere kopyalamamız gerekir.

    Kurulumdan sonra bazı dizinlere baktığımızda (örneğin "bin" dizinine) aşağıdaki gibi ilginç bir durumla karşılaşırız:

    lrwxrwxrwx 1 kaan kaan      7 Ağu 22 22:29 arch -> busybox
    lrwxrwxrwx 1 kaan kaan      7 Ağu 22 22:29 ash -> busybox
    lrwxrwxrwx 1 kaan kaan      7 Ağu 22 22:29 base32 -> busybox
    lrwxrwxrwx 1 kaan kaan      7 Ağu 22 22:29 base64 -> busybox
    -rwxr-xr-x 1 kaan kaan 760960 Ağu 22 22:29 busybox
    lrwxrwxrwx 1 kaan kaan      7 Ağu 22 22:29 cat -> busybox
    lrwxrwxrwx 1 kaan kaan      7 Ağu 22 22:29 chattr -> busybox
    lrwxrwxrwx 1 kaan kaan      7 Ağu 22 22:29 chgrp -> busybox
    lrwxrwxrwx 1 kaan kaan      7 Ağu 22 22:29 chmod -> busybox
    lrwxrwxrwx 1 kaan kaan      7 Ağu 22 22:29 chown -> busybox
    lrwxrwxrwx 1 kaan kaan      7 Ağu 22 22:29 conspy -> busybox
    ...

    Burada ilginç olan nokta aslında tüm komutların "busybox" isimli asıl programa sembolik link yapıldığıdır. O halde burada 
    aslında tek bir program vardır, o da "busybox" isimli programdır. Buradaki diğer programlar çalıştırıldığında aslında hep 
    "busybox" programı çalıştırılacaktır. Ancak "busybox" kendisinin hangi sembolik link ismiyle çalıştırıldığını argv[0] 
    parametresiyle anlayıp o komut için gereğini yapmaktadır. Yani örneğin bu sistemde aşağıdaki gibi bir çalıştırma yapılmış olsun:

    $ chmod 666 x.txt

    Burada aslında "busybox" programı çalıştırılacaktır. Ancak "busybox" programının komut satırı argümanları şöyle olacaktır:

    argv[0] ---> "chmod"
    argv[1] ---> "666"
    argv[2] ---> "x.txt"
    argv[3] ---> NULL

    BusyBox'ta kabuk komutları için çalıştırılan kodlara "applet" denilmektedir. BusyBox konfigüre edilirken applet seçimi
    yapılabilmektedir. BusyBox applet'leri aslında "busybox" programıyla da çalıştırılabilmektedir. Örneğin:

    $ busybox chmod 666 x.txt

    Bu biçimde çalıştırmada komut satırı argümanları aşağıdaki gibi olacaktır:

    argv[0] ---> "busybox"
    argv[1] ---> "chmod"
    argv[2] ---> "666"
    argv[3] ---> "x.txt"
    argv[4] ---> NULL

    "busybox" programı argv[0] argümanına bakarak kendisinin bir sembolik bağlantıyla mı yoksa doğrudan mı çalıştırıldığını 
    anlamakta ve diğer komut satırı argümanlarını bu biçimde belirleyebilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												43. Ders 12/09/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Anımsayacağınız gibi BusyBox'ı "make install" yaptığımızda default kurulum "_install" isimli dizine yapılıyordu. Kurulum 
    sonrasındai "_install" dizininin görünümü şöyledir:

    $ tree -d _install

    _install
    ├── bin
    ├── sbin
    └── usr
        ├── bin
        └── sbin

    Bildiğiniz "/bin" dizininde temel POSIX kabuk komutlarına ilişkin çalıştırılabilir programlar bulundurulmaktadır. "/sbin" 
    dizini "sudo" kullanılarak çalıştırılabilecek olan program komutlarının bulundurulduğu dizindir. "/usr/bin" ve "/usr/sbin" 
    dizinleri ise sistemin çalışması için birinci derece önemli olmayan POSIX komutlarının ve üçüncü parti programların 
    çalıştırılabilir dosyalarının yerleştirildiği dizinlerdir.

    Kök dosya sisteminin iş görür biçimde oluşturulması için bu "_install" dizinindeki dosyaların hedef kök dizine (örneğin micro 
    SD karta) kopyalanması yeterli değildir. BusyBox kendi içerisinde minimalist bir "init" sistemi kullanmaktadır. Bu "init" sistemi 
    klasik System-5 "init" sistemine benzemektedir. BusyBox'ın init sistemi boot işleminden sonra bazı dizinlerdeki bazı dosyalara 
    başvurmaktadır. Dolayısıyla sistemin düzgün bir biçimde açılabilmesi için yukarıdaki dizin içeriğini kopyalamanın yanı sıra 
    hedef kök sistemde başka bazı hazırlık işlemlerinin de yapılması gerekir. Yapılması gereken diğer işlemler maddeler halinde 
    aşağıda açıklanmaktadır:

    1) Kök dosya sisteminin hazırlanması hedef aygıt üzerinde (yani micro SD kart üzerinde) yapılabileceği gibi bir dizin üzerinde 
    yapılıp en sonunda bu dizin hedef aygıta kopyalanabilir. Biz burada işlemleri "rootfs" isimli bir dizinde yapıp sonra bu dizin'in 
    içeriğini hedef aygıta (yani micro SD karta) kopyalayacağız. Önce bu dizinimizi oluşturalım:

    $ mkdir rootfs

    Biz işlemleri bu dizin içerisinde yapıp sonra bu dizini hedef aygıta kopyalayacağız. Yani bu dizin aslında hedeflediğimiz 
    kök dosya sisteminin kök dizini olacaktır.

    2) Şimdi yarattığımız bu dizinde kök dosya sisteminde olması gereken dizinleri yaratalım. Kök dosya sisteminde olması gereken 
    dizinler şunlardır:

    bin
    sbin
    lib
    etc
    home
    dev
    proc
    sys
    tmp
    boot
    root
    usr
        bin
        lib
        sbin
    var
        log
    mnt

    Dizinleri şöyle yaratabiliriz:

    $ cd rootfs
    $ sudo mkdir bin sbin lib etc home dev proc sys tmp boot root usr var mnt
    $ sudo mkdir usr/bin usr/lib usr/sbin var/log

    Buradaki dizinlerin kullanıcı ve grup id'lerinin "root" olması güvenlik bakımından şiddetle tavsiye edilmektedir. Bu nedenle
    dizinleri sudo ile yarattık.

    3) Artık "_install" dizinindeki dosyaları kök dosya sistemini temsil eden "rootfs" dizinine kopyalayabiliriz:

    $ sudo cp -r ../busybox-1.36.1/_install/* .

    Burada "cp" komutunu "-r" seçeneği ile kullandığımıza dikkat ediniz. Artık "_install" dizinindeki tüm dosyalar aynı isimli 
    dizinlerin içerisine kopyalanmış olacaktır. Bazı uygulamacılar önce kök dizindeki dizinleri yaratıp "busybox"ın "_install"
    yerine bu kök dizine install işlemi yapmasını sağlayarak da aynı işlemleri yapmaktadır. Kopyalamayı sudo ile yaptığımız 
    için kopyalanan dosyaların ve dizinlerin de kullanıcı ve grup id'lerinin "root" olacağına dikkat ediniz.

    4) Burada bir sorunun çözülmesi gerekmektedir. Biz BusyBox'ı derlediğimizde default durumda "busybox" çalıştırılabilir 
    dosyası dinamik kütüphaneler kullanmaktadır. Biz bu haliyle bu programı hedef makineye taşıdığımızda bu dinamik kütüphaneler
    orada bulunmayacağı için sorun oluşacaktır. Bu dinamik kütüphanelerin "_install" dizininde bulunmadığını çapraz derleme
    için kullandığımız araç zincirinde bulunduğunu belirtmek istiyoruz. Bu kütüphaneleri oradan alarak hedef kök dizine kopyalamamız 
    gerekir. Minimal bir kopyalama yapmak istiyorsanız "busybox" çalıştırabilir dosyasının hangi dinamik kütüphaneleri kullandığını 
    "readelf" programı ile tespit edebilirsiniz:

    $ readelf -d busybox | grep NEEDED
    0x00000001 (NEEDED)                     Shared library: [libm.so.6]
    0x00000001 (NEEDED)                     Shared library: [libresolv.so.2]
    0x00000001 (NEEDED)                     Shared library: [libc.so.6]

    Tabii bu kütüphane dosyalarının araç zincirinin içerisindeki yerinin tespit edilmesi gerekir. Bu tespit iki biçimde yapılabilir. 
    Çapraz derleyicilerde genellikle -print-sysroot seçeneği bulunmaktadır. Bu seçenek kütüphanelerin nerede olduğuna ilişkin bilgi
    vermektedir. Örneğin:

    $ arm-none-linux-gnueabihf-gcc -print-sysroot
    /home/kaan/Study/EmbeddedLinux/arm-gnu-toolchain-13.3.rel1-x86_64-arm-none-linux-gnueabihf/bin/../arm-none-linux-gnueabihf/libc

    Diğer yöntem doğrudan ilgili dosyayı "find" komutu ile aramaktır. Komutu uygulamadan önce araç zincirinin kök dizininde 
    olduğumuzu varsayıyoruz:

    $ find . -name libc.so.6
    ./arm-none-linux-gnueabihf/libc/lib/libc.so.6

    Görüldüğü gibi bu kütüphane dosyaları "./arm-none-linux-gnueabihf/libc/lib" dizini içerisindedir. Bunları oradan hedef kök 
    dizin'in "/lib" dizinine kopyalayabiliriz. Bu dosyaların dinamik kütüphanelerin "so isimleri" olduğuna dikkat ediniz. Zorunlu 
    olmamakla birlikte eğer hedef kök sistemde bir derleme yapılması isteniyorsa bu kütüphanelerin "linker" isimlerinin de hedefe 
    kopyalanması tercih edilebilir. Bunu sağlamak için tümden araç zinciri içerisindeki "libc" dizini özyineleme olarak da kopyalayabiliriz. 
    Biz burada minimal bir kopyalama yapalım:

    $ sudo cp libc.so.6 libm.so.6 libresolv.so.2 ~/Study/EmbeddedLinux/BusyBox/rootfs/lib

    Sistem (dinamik yükleyici) dinamik kütüphaneleri ararken her zaman "/lib" dizinine de bakmaktadır.

    Alternatif olarak BusyBox statik biçimde de derlenebilir. Bu durumda "busybox" çalıştırılabilir dosyası bir dinamik kütüphane
    kullanmayacak ancak boyutu büyüyecektir. Statik derleme için "make menuconfig" işleminde "Settings/Build static binary (no shared 
    libs)" seçeneği checked hale getirilir.

    Biz yukarıda "busybox" çalıştırılabilir programının kullandığı dinamik kütüphaneleri hedef kök dosya sistemine kopyaladık. 
    Anımsanacağı gibi Linux sistemlerinde aslında dinamik kütüphanelerin yüklenmesi ismine "dinamik linker" denilen bir program 
    tarafından yapılmaktadır. Bizim onu da hedef kök dosya sistemine kopyalamamız gerekir. "busybox" programının kullandığı dinamik 
    linker'ın yeri aşağıdaki gibi bulunabilir:

    $ readelf -a busybox | grep "program interpreter"
    [Requesting program interpreter: /lib/ld-linux-armhf.so.3]

    Genellikle araç zincirlerinde dinamik linker da diğer kütüphanelerin bulunduğu yerdedir. Ancak o yerini de yine istersek aşağıdaki 
    gibi "find" komutuyla öğrenebiliriz:

    $ find . -name "ld-linux-armhf.so.3"
    ./arm-none-linux-gnueabihf/libc/lib/ld-linux-armhf.so.3

    Bu dinamik linker'ı da hedef kök dizinin "/lib" dizinine kopyalamamız gerekir:

    sudo cp ld-linux-armhf.so.3 ~/Study/EmbeddedLinux/BusyBox/rootfs/lib

    Artık hedef kök dizinin "/lib" dizininde şu dosyalar vardır:

    $ ls
    ld-linux-armhf.so.3 libc.so.6 libm.so.6 libresolv.so.2

    Burada bir noktaya dikkat etmek gerekir. Bazı araç zincirlerinde kütüphane dosyaları başka dosyalara sembolik link yapılmış
    olabilmektedir. Bu tür durumlarda hem sembolik link dosyasını hem de onun gösterdiği dosyayı aynı biçimde hedefe kopyalamak
    iyi bir yöntemdir. (Sembolik link dosyalarının kendisini kopyalamak için "cp" komutunda "-P" seçeneği kullanılmaktadır.)

    5) Şimdi hedef kök dosya sisteminde bazı önemli dosyaları manuel bir biçimde oluşturmamız gerekir. Bazı komutlar "/dev" 
    dizininin altındaki bazı aygıt dosyalarını kullanabilmektedir. Minimal biçimde bu aygıt dosyalarının uygun majör ve minör 
    numaralar ile yaratılması gerekir. Hedef kök dosya sistemindeki "dev" dizininde olduğumuzu varsayalım Bu işlem şöyle yapılabilir:

    $ sudo mknod console c 5 1
    $ sudo mknod null c 1 3
    $ sudo mknod zero c 1 5
    $ ls -l
    total 0
    crw-r--r-- 1 root root 5, 1 Eyl 12 22:21 console
    crw-r--r-- 1 root root 1, 3 Eyl 12 22:21 null
    crw-r--r-- 1 root root 1, 5 Eyl 12 22:22 zero

    Buradaki aygıtların majör ve minör numaralarının gelişigüzel biçimde verilmediğine önceden tespit edilmiş olan numaraların 
    kullanıldığına dikkat ediniz.

    6) Sistemin açılması için BusyBox "init" sistemi "/etc" dizini "inittab" isimli dosyaya başvurur. Bu dosyada çeşitli 
    işlemlerde çalıştırılacak programlar ve onların "çalıştırma seviyeleri (run level)" belirtilmektedir. (BusyBox "çalıştırma 
    seviyelerini desteklememektedir) Bu dosyanın minimal içeriği de şöyle oluşturulabilir:

    ::sysinit:/bin/mount -a
    ::sysinit:/bin/hostname -F /etc/hostname
    ::respawn:/bin/cttyhack /bin/ash

    "/etc/inittab" dosyası klasik System 5 init sistemleri ("SysVinit" biçiminde de ifade edilmektedir) ve BusyBox init sistemi 
    tarafından okunmaktadır. Modern "systemd" init sistemi bu dosyaya başvurmamaktadır. Buradaki "mount -a" komutu "/etc/fstab" 
    isimli dosyayı okuyarak orada belirtilen mount işlemlerini yapmaktadır. Örneğimizde "/etc/fstab" dosyasında aşağıdaki mount 
    direktiflerini de yerleştirmeliyiz:

    proc    /proc    proc   defaults  0 0
    sysfs   /sys     sysfs  defaults  0 0

    Böylece "init" programı çalıştırıldığında "proc" ve "sys" dosya sistemleri de mount edilmiş olacaktır.

    BusyBox'ta "ash" isimli kabuk programı (shell programı) kullanılmaktadır. ash (Almquist shell) bourne shell benzeri kompakt
    bir kabuk programıdır. Özellikle gömülü sistemlerde az yer kaplaması nedeniyle tercih edilmektedir. BusyBox'ta bu "ash" isimli
    kabuk programı da bir "applet" biçiminde "busybox" çalıştırılabilir programının içerisinde bulunmaktadır:

    $ ls -l ash
    lrwxrwxrwx 1 root root 7 Eyl 17 20:04 ash -> busybox

    Bizim boot işleminden sonra "ash" isimli kabuk programını çalıştırabilmemiz için "/etc/passwd" (bu mutlak zorunlu değildir)
    "/etc/group" dosyalarında "root" kullanıcısı için bir giriş oluşturmamız gerekir. "/etc/passwd" dosyasını bir editörle 
    açıp içerisine aşağıdaki satırı yerleştirebilirsiniz:

    root::0:0::/root:/bin/ash

    Editörünüzü "sudo" ile çalıştırmayı unutmayınız. Örneğin hedef kök dosya sisteminin "etc" dizininde olduğumuzu varsayalım. Bu
    işlemi şöyle yapabiliriz:

    $ sudo vim passwd

    "/etc/group" dosyasının içerisine de şu satırı ekleyebiliriz:

    root::0:

    Ayrıca zorunlu olmamakla birlikte "/etc" dizininde "hostname" isimli bir dosya oluşturup o dosyanın içerisine network haberleşmeleri
    için "host ismini" yazabiliriz. Dosya içeriği şöyle olabilir:

    busybox-test

    7) Şimdi bizim çekirdek dosyalarını, çekirdeğin kullandığı modülleri, aygıt ağacı (device tree) dosyasını "/boot" dizinine 
    kopyalamamız gerekir. Aslında sıfırdan kök dosya sistemi oluştururken muhtemelen uygulamacı çekirdeğin ve aygıt ağacı dosyasının 
    kendisini de kaynak kodlarından sıfırdan derleyerek oluşturmak isteyecektir. Ancak kursumuzda çekirdeğin derlenmesi ve aygıt 
    ağacı dosyasının oluşturulması ayrı bir başlık halinde ele alınmaktadır. O halde biz burada BBB için kendi sitesinden indirdiğimiz 
    imajın içerisindeki "/boot" dizinini hedef kök dizinindeki "/boot" dizinine kopyalabiliriz. Bu işlem şöyle yapılabilir:

    $ sudo losetup -o 4194304 /dev/loop0 am335x-debian-11.7-iot-armhf-2023-09-02-4gb.img
    $ mkdir ext
    $ sudo mount /dev/loop0 ext
    $ cd ext
    $ sudo cp -r boot/* ~/Study/EmbeddedLinux/BusyBox/rootfs/boot
    $ sudo umount ext
    $ sudo losetup -d /dev/loop0

    Kök dosya sistemini hazırladıktan sonra "chroot" komutuyla artık istersek kurduğumuz kök dizine de geçebiliriz:

    $ sudo chroot rootfs /bin/sh

    Bu işlemi yapabilmemiz için aşağıdaki kurulumun yapılmış olması gerekmektedir:

    $ sudo apt install qemu qemu-user-static binfmt-support

    Bu konuda "debootstrap" programını anlatacağımız konuda açıklamalar yapacağız.

    8) Şimdi de hedef kök dosya sisteminin kopyalacağı micro SD kartın hazırlanması gerekir. Biz burada kök dosya sistemini BBB 
    için oluşturacak olalım. Bu durumda micro SD kartımızda bir FAT disk bölümü bir de ext4 disk bölümünü oluşturmamız gerekir. 
    Bu işlemin nasıl yapıldığını daha önce görmüştük. Biz burada FAT disk bölümünün "fat" isimli dizine, Linux disk bölümünün
    ise "ext" isimli dizine mount edildiğini varsayalım. Bu durumda oluşturduğumuz kök dosya sistemini micro SD kartın Linux 
    disk bölümüne şöyle kopyalayabiliriz:

    $ sudo cp -r rootfs/* ext

    9) Artık BBB'yi U-Boot ile boot edebilmek için FAT dosya sistemine "MLO", "u-boot.img" dosyalarını yerleştirmemiz gerekir. 
    Bunun için önce FAT dosya sistemini mount edelim:

    $ mkdir fat
    $ sudo mount /dev/sdc1 fat

    U-Boot dosyalarının bulunduğu dizinde olduğumuzu varsayalım. Kopyalamayı şöyle yapabiliriz:

    $ sudo cp MLO u-boot.img /home/kaan/Study/EmbeddedLinux/BusyBox/fat

    10) Artık micro SD kartı BBB'ye takarak micro SD karttan boot işlemi yapıp U-Boot'un komut satırına düşebiliriz. Ancak boot 
    işlemini otomatize etmek için daha önce görmüş olduğumuz yöntemi de kullanabiliriz. Bunun için FAT dosya sisteminde aşağıdaki 
    içeriğe sahip "uEnv.txt" dosyasını (tabii dosyanın ismi böyle olmak zorunda değil) oluşturalım:

    loadkernel=load mmc 0:2 0x82000000 /boot/vmlinuz-5.10.168-ti-r71
    loadfdt=load mmc 0:2 0x88000000 /boot/dtbs/5.10.168-ti-r71/am335x-boneblack.dtb
    bootargs=console=ttyS0,115200 root=/dev/mmcblk0p2 rw
    bootsys=bootz 0x82000000 - 0x88000000
    uenvcmd=run loadkernel;run loadfdt;run bootsys

    Sonra U-Boot'un komut satırında aşağıdaki komutu girip çevre değişkenlerini save edebiliriz:

    => setenv bootcmd "load mmc 0:1 0x8A000000 /uEnv.txt;env import -t 0x8A000000;run uenvcmd"
    => saveenv
    Saving Environment to FAT... OK
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												45. Ders 19/09/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz yukarıdaki örnekte BusyBox ile minimalist bir kök dosya sistemi oluşturduk. Oluşturduğumuz kök dosya sisteminde bir masaüstü
    Linux sisteminde hazır kurulu olarak bulunan pek araç yoktur. Örneğin sistemimizde bir "paket yönetici (package manager)" 
    program da yoktur. Aygıtımız henüz internete de girememektedir. Çünkü henüz Linux'ta bir ağ yapılandırması da yapmadık. 
    Dolayısıyla örneğin aygıtımıza "ssh" ile de henüz bağlanamayız. Çünkü ne kök dosya sistemimizde ağ konfigürasyonu yapılmıştır 
    ne de "ssh sunucu" programı kök dosya sisteminde yüklü durumdadır. Bu araçların kurulması ve işletilmesi aslında başka bir 
    konudur. Biz bu konu üzerinde de izleyen bölümlerde duracağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    BusyBox sisteminin en önemli özelliği minimalist olması ve küçük bir disk alanı kullanmasıdır. Bu nedenle gömülü sistemlerde
    tercih edilen bir kök dosya sistemi oluşturma aracıdır. Ancak bu bağlamda BusyBox'ın da alternatifleri bulunmaktadır. 
    Bunlardan biri "toybox" denilen araçtır. Toybox'ın genel kullanımı BusyBox'a oldukça benzemektedir. Toybox'ta da yine tek 
    bir çalıştırılabilir dosya vardır.

    BusyBox ile toybox arasındaki farklar şunlardır:

    - BusyBox daha geniş bir kitle tarafından kullanılmakta ve sürdürümü daha geniş bir kitle tarafından yapılmaktadır.
    - BusyBox daha fazla komuta (applet'e) sahiptir. Toybox daha minimalist durumdadır.
    - Toybox daha yeni bir projedir. Zaten BusyBox'tan ilham alınarak geliştirilmiştir. Kaynak kodları daha sade ve daha anlaşılabilir
    biçimde organize edilmiştir.
    - Toybox daha minimalist olduğu için biraz daha aşağı seviyeli bir görünümdedir. Yani BusyBox kullanımda daha pratiktir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Toybox ile kök dosya sistemi şu aşamalardan geçilerek oluşturulmaktadır:

    1) Toybox kaynak kodları indirilir. Tıpkı BusyBox'ta olduğu gibi CROSS_COMPILE ve PATH çevre değişkenleri hedef makineye 
    ilişkin araç zincirine göre ayarlanır. Toybox'ın resmi sitesi şöyledir:

    https://landley.net/toybox/

    Kaynak kodlar bu siteden indirilebilir. Ya da aşağıdaki gibi git repository'inden indirme yapılabilir:

    $ git clone https://github.com/landley/toybox

    2) Önce default ".config" dosyasını oluşturmak için "make defconfig" komutu uygulanır:

    $ make defconfig

    3) Yine menülü konfigürasyon seçenekleri için "make menuconfig" komutu uygulanır:

    $ make menuconfig

    Aslında "make defconfig" yapmadan da "make menuconfig" yapılabilmektedir.

    4) Artık derleme işlemi yapılabilir. Ancak default olarak make dosyası derleyiciyi "cc" ismi ile çalıştırmaktadır. Bu isim 
    CC çevre değişkeninden gelmektedir. Dolayısıyla make yaparken bu çevre değişkenini de make prosesine eklememiz gerekir. 
    Örneğin:

    $ CC=gcc make

    5) Eskiden toybox'ta BusyBox'ta olduğu gibi "make install" işlemi yoktu. Ancak bir zaman sonra toybox'a "make install" 
    komutu da eklendi. Bu komut uygulandığında default olarak "install" dizini oluşturulup tıpkı BusyBox'ta olduğu gibi 
    sembolik bağlantı dosyaları ilgili dizinlerin içerisine yerleştirilmektedir.

    Toybox'taki init sistemi de BusyBox'takine çok benzemektedir. Yani yukarıda BusyBox için açıkladığımız diğer adımlar tamamen
    toybox için de geçerlidir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Yukarıda incelemiş olduğumuz BusyBox ve toybox araçları dar kapasiteli gömülü Linux sistemlerinde oldukça tercih edilmektedir. 
    Ancak bu araçların dışında bazı ana dağıtımlar sıfırdan kök dosya sistemi oluşturmak için çeşitli araçlar da sunmaktadır. 
    Örneğin Debian tabanlı bir kök dosya sistemini internetten indirip sıfırdan oluşturmak için yaygın kullanılan ismine 
    "debootstap" denilen bir araç vardır. Bu araç default olarak sisteminizde yüklü değildir. Bunu aşağıdaki gibi kurabilirsiniz:

    $ sudo apt-get install debootstrap

    debootstrap programının pek çok komut satırı argümanı vardır. Biz burada en önemli birkaç argüman üzerinde duracağız. 
    --arch komut satırı seçeneği hedef CPU mimarisini belirtmektedir. BBB gibi 32 bit ARM işlemcileri için burada "armhf", 
    64 bit ARM işlemcileri için "arm64", Intel tabanlı işlemciler için bu seçeneğe "amd64" girilmelidir. Programın ilk seçeneksiz 
    argümanı Debian sisteminin varyantını belirtmektedir. Bu argüman için "buster" girebilirsiniz. İkinci komut satırı argümanı
    hedef kök dosya sisteminin oluşturulacağı dizini belirtmektedir. Üçüncü komut satırı argümanı ise paketlerin indirileceği 
    depoyu (repository) belirtmektedir. Örneğin BBB için "debootstrap" programını aşağıdaki gibi çalıştırabiliriz:

    $ sudo debootstrap --include=systemd --arch armhf buster bbb-debian-rootfs http://deb.debian.org/debian/

    Eğer --arch armhf seçeneği girilmemişse programın çalıştırıldığı makine için kök dosya sistemi indirilip kurulmaktadır. 
    Örneğin biz Intel tabanlı bir makinede çalışıyorsak ve Intel tabanlı bir Debian kök dosya sistemi oluşturmak istiyorsak 
    programı şöyle çalıştırabiliriz:

    $ sudo debootstrap --include=systemd buster intel-debian-rootfs http://deb.debian.org/debian/

    Default durumda "debootstrap" pek çok paketi kök dosya sistemine dahil ettiği için paketlerin indirilmesi ve kök dosya 
    sisteminin oluşturulması biraz zaman alacaktır.

    Uygulamacı isterse programın "--include" ve "--exclude" komut satırı seçenekleriyle birtakım paketleri dahil edebilir ya da
    dışlayabilir. Ancak bu işlem biraz yorucudur. Örneğin biz "systemd" dışında "sudo" ve "gcc" paketlerini de aşağıdaki gibi 
    kuruluma dahil edebiliriz:

    $ sudo debootstrap --include=systemd,sudo,gcc --arch armhf buster bbb-debian-rootfs http://deb.debian.org/debian/

    debootstrap programı önce internetten gerekli paketleri indirip yerel makinede oluşturmakta sonra da indirdiği dizin için 
    "chroot" işlemini yapıp ikinci aşama bazı işlemleri yapmaktadır. Eğer başka bir sistem için indirme yapıyorsanız (örneğin host 
    sistem Intel tabanlı bir makineyse ve siz ARM tabanlı bir Debian kök dosya sistemi oluşturmak istiyorsanız) yukarıdaki debootstrap 
    yüklemesini yapmadan önce aşağıdaki gibi "qemu" emülatör paketinin statik versiyonunu ve "binfmt" destek paketini yüklemelisiniz:

    $ sudo apt install qemu-user-static binfmt-support

    Bu işlemden sonra artık debootstrap programını yukarıda belirttiğimiz biçimde çalıştırabilirsiniz:

    $ sudo debootstrap --include=systemd --arch armhf buster bbb-debian-rootfs http://deb.debian.org/debian/

    Artık isterseniz chroot işlemini de yapabilirsiniz:

    $ sudo chroot bbb-debian-rootfs

    Artık bu ARM tabanlı kök dosya sistemindeki her komutu çalıştırırken "qemu" devreye girecek ve ARM kodlarını emüle ederek 
    çalıştıracaktır. Kurulumu yapıp "chroot" uyguladıktan sonra artık "apt-get" ile istediğiniz paketleri de kuruluma ekleyebilirsiniz.

    Bu biçimde kök dosya sistemini oluşturduğunuzda "/boot" dizininde çekirdek ile ilgili dosyaların bulunuyor olduğundan ve
    "/lib/modules" dizininde de çekirdek modüllerinin bulunduğundan emin olmalısınız. Biz burada gerekli olan dosyaların bulundurulduğunu
    varsayıyoruz. Bu konu "çekirdek derlemesinin" anlatıldığı bölümde ayrıntılı bir biçimde ele alınmaktadır.

    Yukarıdaki biçimde emülasyonun nasıl otomatik bir biçimde gereçekleştirilebildiğini merak ediyor olabilirsiniz. İşte "binfmt"
    desteği bir program çalıştırılmak istendiğinde onun dosya formatına bakılarak otomatik emülasyon yapılabilmesini sağlamaktadır.

    Bu biçimde oluşturduğunuz kök dosya sistemini BBB'ye "cp -a" komutuyla aktarabilirsiniz. Örneğin:

    $ sudo mkfs.ext4 /dev/mmcblk0p2
    $ sudo mount /dev/mmcblk0p2 ext
    $ sudo cp -a bbb-debian-rootfs/* ext
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												46. Ders 24/09/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çalışmakta olan programlara işletim sistemleri dünyasında "proses (process)" denilmektedir. Program terimi bazen "çalıştırılabilir
    program dosyaları" için bazen de "kaynak kodlar" için kullanılan bir terimdir. Bir program çalıştırıldığında artık işletim 
    sistemi için o bir prosestir. İşletim sistemleri çalışmakta olan programları (yani prosesleri) sürekli izlemektedir. İşletim 
    sistemlerinin prosesler için tuttuğu veri yapısına kavramsal olarak "proses kontrol blok (process control block)" denilmektedir. 
    Bir prosesin user id'si, grup id'si, çalışma dizini (current working directory), açtığı dosyalara ilişkin bilgiler ve daha 
    pek çok bilgiler proses ilişkin proses kontrol bloğunda tutulmaktadır. UNIX/Linux sistemlerinde bir proses fork fonksiyonuyla 
    yaratıldığında yeni bir proses kontrol blok oluşturulur. Yeni yaratılan prosese ilişkin proses kontrol blok bilgileri büyük 
    ölçüde onu yaratan üst prosesten kopyalayarak aktarılmaktadır. Bu nedenle bir program başka bir programı çalıştırdığında çalıştırılan 
    programın tüm yetkisel (credential) bilgileri ve diğer bilgileri büyük ölçüde üst prosesteki gibi olmaktadır. Örneğin biz kabuk 
    üzerinde program çalıştırdığımızda çalıştırdığımız programın kullanıcı id'leri, grup id'leri, çalışma dizini, çevre değişkenleri 
    vs. kabuk ile aynı olmaktadır.

    Linux işletim sisteminde proses kontrol blok task_struct isimli bir yapıyla temsil edilmiştir. Linux geliştikçe bu task_struct 
    yapısı da büyümüş, dallı budaklı hale gelmiştir. task_struct yapısının içerisinde pek çok gösterici eleman vardır. Bu 
    göstericiler başka yapıları göstermektedir. Onların gösterdiği yapılarda da başka yapıları gösteren göstericiler vardır. 
    Biz bir bilginin proses kontrol bloğunda olduğunu söylediğimiz zaman bunun task_struct yapısının doğrudan içinde olduğunu 
    kastetmeyeceğiz. task_struct yoluyla erişilebilen tüm bilgiler bizim için task_struct yapısı içerisindedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Göreli yol ifadelerinin proses kontrol blok içerisindeki "çalışma dizini (current working directory)" temel alınarak çözüldüğünü
    belirtmiştik. Örneğin biz "a/b/c.txt" biçiminde bir yol ifadesi belirtsek Linux burada "a" dizinini proses kontrol blokta
    belirtilen prosesin çalışma dizininde arayacaktır. Mutlak yol ifadelerinin her zaman kök dizinden itibaren çözüldüğünü biliyorsunuz.
    İşte aslında UNIX/Linux sistemlerinde proseslerin kök dizinleri de değiştirilebilmektedir. Proseslerin kök dizininin yeri 
    de de aslında proses kontrol bloklarında tutulmaktadır. En yeni çekirdeklerde proses kontrol bloğunu tyemsil eden task_struct 
    yapısının ilgili bölümü şöyledir:

    struct task_struct {
        ...
        /* file system info */
        int tty;		/* -1 if no tty, so it must be signed */
        unsigned short umask;
        struct m_inode * pwd;
        struct m_inode * root;
        unsigned long close_on_exec;
        struct file * filp[NR_OPEN];
        ...
    };

    Normal olarak prosesin kök dizini dosya sisteminin kök dizinidir. Ancak istenirse bu dizin de programcı tarafından değiştirilebilir. 
    Ancak kök dizinin değiştirilmesi noktasında dikkatli olunması gerekir. Çünkü kök dizin değiştirildikten sonra artık tüm 
    mutlak yol ifadeleri bu dizine dayalı biçimde çözülecektir.

    Linux sistemlerinde prosesin kök dizinini değiştirmek için sys_chroot isimli bir sistem fonksiyonu bulunmaktadır. libc 
    kütüphanesinde bu sistem fonksiyonunu sarmalayan chroot isimli fonksiyon da bulundurulmuştur. (chroot bir POSIX fonksiyonu
    değildir. Çünkü bu özellik tüm UNIX türevi sistemlerde olmak zorunda değildir.) chroot fonksiyonunun prototipi şöyledir:

    #include <unistd.h>

    int chroot(const char *path);

    Fonksiyon yeni köke ilişkin dizinin yol ifadesini parametre olarak alır. Başarı durumunda 0 değerine başarısızlık durumunda 
    -1 değerine geri döner ve errno uygun biçimde set edilmektedir.

    Aşağıda chroot fonksiyonun kullanımına bir örnek verilmiştir. Bu programda chroot yapıldıktan sonra kök dizindeki dosyaların 
    listesi yazdırılmıştır. Artık bu dizin gerçek kök dizin değil chroot ile belirtilen dizin olacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

#include <stdio.h>
#include <stdlib.h>
#include <errno.h>
#include <unistd.h>
#include <dirent.h>

void exit_sys(const char *msg);

int main(void)
{
	DIR *dir;
	struct dirent *de;

	if (chroot(".") == -1)
		exit_sys("chroot");

	if ((dir = opendir("/")) == NULL)
		exit_sys("opendir");

	while (errno = 0, (de = readdir(dir)) != NULL)
		printf("%s\n", de->d_name);

	if (errno != 0)
		exit_sys("readdir");

	closedir(dir);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
    Aslında prosesin çalışma kök dizinini değiştirmek için "chroot" isimli bir kabuk komutu da bulundurulmuştur. Tabii bu komut
    aslında chroot fonksiyonu kullanılarak yazılmıştır. Bu kabuk komutunun kullanım biçimi şöyledir:

    chroot <hedef_kök_dizin> [çalıştırılacak_program_ve_onun_argümanları]

    Komut önce prosesin kök dizinini değiştirir sonrada fork yapmadan exec fonksiyonlarıyla ilgili programı çalıştırır. Eğer program 
    ismi belirtilmezse default olarak "/bin/sh" programı çalıştırılmaktadır. Tabii komutun yine "sudo" çalıştırılması gerekir. 
    Örneğin:

    $ sudo chroot . /sample

    Burada "/sample" programı çalıştırılacak ancak bu çalıştırmadan önce prosesin kök dizini o andaki dizin olarak değiştirilecektir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    "chroot" komutunu biz de chroot fonksiyonunu kullanarak yazabiliriz. Aşağıda böyle bir örnek verilmiştir. Burada örnekte 
    önce komut satırı argümanlarının sayısını kontrol ettik:

    if (argc < 2) {
        fprintf(stderr, "wrong number of arguments!...\n");
        exit(EXIT_FAILURE);
    }

    Program çalıştırılırken program isminden sonra en azından bir argüman verilmek zorundadır. Programda argv[1] hedef kök 
    dizini, argv[2] de çalıştırılacak programı belirtmektedir. Bu durumda argv[1] de belirtilen dizin için chroot fonksiyonunu 
    çağırdık:

    if (chroot(argv[1]) == -1)
        exit_sys("chroot");

    if (chdir("/") == -1)
        exit_sys("chdir");

    Bu tür durumlarda prosesin çalışma dizinini değiştirmek iyi bir fikirdir. Çünkü prosesin çalışma dizininin geçersiz bir dizinde 
    kalması sorunlara yol açabilecektir. Programımızda daha sonra exec işlemi uyguladık:

    if (argc == 2) {
        if (execl("/bin/sh", "/bin/sh", (char *)NULL) == -1)
            exit_sys(argv[2]);
    }
    else {
        if (execv(argv[2], &argv[2]) == -1)
            exit_sys("execv");
    }

    Pekiyi orijinal "chroot" programını ya da bizim yazdığımız "mychroot" programını nasıl test edebiliriz? Bunun için de belli bir 
    dizininin listesini alan bir "sample" programı yazdık. Bu program normalde aşağıdaki gibi çalıştırılmaktadır:

    $ ./sample /

    Burada kök dizinin listesi elde edilecektir. Şimdi "chroot" yaparak bu programı çalıştıralım:

    $ ./mychroot . /sample /

    Burada çalışılan dizin kök dizin yapılıp kök dizindeki "sample" programı çalıştırılmıştır. Burada önemli bir noktaya değinmek 
    istiyoruz. Biz "sample" programını dinamik kütüphane kullanacak biçimde derlersek "dinamik linker" ve diğer dinamik kütüphaneler
    artık bulunamayacaktır. Çünkü bu kütüphaneler "/lib" ve "/usr/lib" dizinlerinde aranmaktadır. Biz kök dizini değiştirdiğimize
    göre artık bu yol ifadeleri bizim dizinimizin altında yer belirtecektir. O halde bu örneğimizde "sample" programını aşağıdaki
    gibi static kütüphane kullanılacak biçimde derlememiz gerekir:

    $ gcc -static -o sample sample.c

    "mychroot" programını normal bir biçimde derleyebiliriz:

    $ gcc -o mychroot mychroot.c

    Programları bir bütün olarak aşağıda veriyoruz.
-----------------------------------------------------------------------------------------------------------------------------*/

/* mychroot.c */

#include <stdio.h>
#include <stdlib.h>
#include <unistd.h>

void exit_sys(const char *msg);

int main(int argc, char *argv[])
{
	if (argc < 2) {
		fprintf(stderr, "wrong number of arguments!...\n");
		exit(EXIT_FAILURE);
	}
	if (chroot(argv[1]) == -1)
		exit_sys("chroot");

	if (chdir("/") == -1)
		exit_sys("chdir");

	if (argc == 2) {
		if (execl("/bin/sh", "/bin/sh", (char *)NULL) == -1)
			exit_sys(argv[2]);
	}
	else {
		if (execv(argv[2], &argv[2]) == -1)
			exit_sys("execv");
	}

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/* sample.c */

#include <stdio.h>
#include <stdlib.h>
#include <errno.h>
#include <unistd.h>
#include <dirent.h>

void exit_sys(const char *msg);

int main(int argc, char *argv[])
{
	DIR *dir;
	struct dirent *de;

	if (argc != 2) {
		fprintf(stderr, "wrong number of arguments!...\n");
		exit(EXIT_FAILURE);
	}

	if ((dir = opendir(argv[1])) == NULL)
		exit_sys("opendir");

	while (errno = 0, (de = readdir(dir)) != NULL)
		printf("%s\n", de->d_name);

	if (errno != 0)
		exit_sys("readdir");

	closedir(dir);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
    Örneğin biz kendi mimarimiz için "debootstrap" programı ile aşağıdaki gibi bir kök dosya sistemini oluşturmuş olalım:

    $ sudo debootstrap --include=systemd --arch amd64 buster rootfs-amd64 http://deb.debian.org/debian/

    Biz burada şu anda bulunduğumuz dizinin altında "rootfs-amd64" isimli bir dizinde kök dosya sistemini oluşturmuş olduk. 
    Şimdi aşağıdaki gibi "chroot" işlemini yapalım:

    # sudo chroot rootfs-amd64

    Burada bir sorun çıkar mı? İşte aslında burada muhtemelen bir sorun çıkmayacaktır. Çünkü bu dizin kök olduğu zaman zaten 
    orada gerekli olan tüm dizinler ve dosyalar hazır bulunmaktadır. Gerekli olan "dinamik linker", "/lib" ve "/usr/lib" dizinlerindeki 
    dosyalar, "/bin" ve "/sbin" dizinlerindeki kabuk komutları vs. hepsi zaten bu dizin altında hazır bir biçimde bulunmaktadır.

    Pekiyi biz login olan olan kişiyi "~/.bashrc" ya da "~/bash_profile" dosyalarında "chroot" komutunu uygulayarak kendi 
    dizinlerine hapsedebilir miyiz? Bu biçimde hapsedebiliriz ancak login olan kişinin "home" dizini kök dizin gibi olacağı 
    için o kişinin gerekli dosyalara erişme olanağı ortadan kalkacak ve kişi komut çalıştıramaz hale gelecektir.

    Biz yukarıdaki gibi yeni bir kök dosya sistemi oluşturup "chroot" yaptıktan sonra artık paket yöneticisi ile ("apt" ya da 
    "apt-get" ile) kurulum yaptığımızda bu kurulumu yeni kök dosya sistemine yapmış olacağız. Örneğin:

    $ sudo chroot rootfs-amd64
    $ root@kaan-virtual-machine:/# apt-get install vim

    Bu örnekte "vim" programı yeni kök dosya sistemine kurulacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												47. Ders 26/09/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi chroot yaptıktan sonra yeni kök dosya sisteminden eski kök dosya sistemine hiçbir biçimde erişim yok mudur? Aslında 
    Linux'ta bunun iki yolu vardır. Bunlardan birisi eski kök dosya sistemini "--bind" seçeneği ile yeni kök dosya sistemine 
    mount etmektir. Tabii biz eski kök dosya sistemindeki herhangi dizinleri (örneğin "/bin" dizini, "/lib" dizini gibi) de 
    mount edebiliriz. mount komutundaki "--bind" seçeneği orijinal dosya sistemindeki belli bir dizini mount etmekte kullanılmaktadır. 
    Ancak chroot yapıldığında da bu etki devam etmektedir. Bu işlem şöyle yapılabilir:

    sudo mount --bind <orijinal_dosya_sistemindeki_dizin> <mount_edilecek_hedef_dizin>

    Örneğin:

    $ sudo mkdir rootfs-amd64/original-root
    $ sudo mount --bind / rootfs-amd64/original-root/
    $ sudo chroot rootfs-amd64
    root@kaan-virtual-machine:/#

    İkinci yöntem "pivot_chroot" işlemi uygulamaktır. Bunu burada açıklamayacağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de boot loader'dan sonraki aşamalar üzerinde duralım. Boot loader'ın işi ne zaman bitmektedir ve sonra neler olmaktadır?
    Anımsayacağınız gibi biz U-Boot'ta çekirdek imajını ve aygıt ağacı dosyasını belleğe yükledikten sonra bu adresleri kullanarak 
    "bootz" komutu ile boot işlemini başlatıyorduk. "bootz" komutunda geçici kök dosya sistemi için kullanılan imajın (initial 
    ramdisk) bellek adresi de komutta belirtilebilmektedir. Ancak biz geçici kök dosya sistemi kullanmadığımızdan dolayı burada 
    geçici kök dosya sisteminin imaj adresini "-" ile geçmiştik. U-Boot'un boot loader'lık işlevi "bootz" komutuyla sona ermektedir. 
    Diğer boot loader'larda da durum benzerdir. Boot loader programlar "çekirdek imajını", "aygıt ağacı dosyasını", "geçici kök 
    dosya sistemini" belleğe yükledikten sonra çekirdek kodu içerisindeki bir noktaya dallanmaktadır. (Çekirdek imajı sıkıştırılmışsa
    burada atlanılan kod imajı aynı zamanda açmaktadır.) Bu işlemden sonra Linux kaynak kodlarındaki start_kernel isimli fonksiyon
    çalıştırılmaktadır. Bunu şekilsel olarak şöyle gösterebiliriz:

    boot loader çekirdek imajını, aygıt ağacını ve geçici kök dosya sistemini yüklüyor ---> çekirdek imajı içerisindeki start_kernel
    fonksiyonu çalıştırılıyor.

    start_kernel fonksiyonu ve bu fonksiyonun çağırdığı fonksiyonların önemli bölümü Linux kaynak kodlarında "init/main.c" dosyası 
    içerisindedir. start_kernel fonksiyonu içerisinde işletim sisteminin çalışabilmesi için gerekli olan ilk işlemler yapılmaktadır. 
    (Linux kaynak kodlarında ilgili alt sistemler için birtakım ilk işlemleri yapan fonksiyonlar genellikle setup_xxx ve xxx_init 
    biçiminde isimlendirilmiştir.) start_kernel fonksiyonun sonunda geri kalan ilkdeğerleme işlemlerini yapan rest_init isimli bir 
    fonksiyon çağrılmaktadır. rest_init fonksiyonu içerisinde bir proses oluşturulmaktadır. Bu proses sistemdeki resmi olan ilk 
    prosestir ve bu prosesin proses id'si 1'dir. Bu proses akışı kernel_init isimli bir fonksiyondan başlamaktadır. Bu fonksiyon 
    içerisinde önce geçici kök dosya sisteminin olup olmadığında bakılmaktadır, eğer geçici kök dosya sistemi yoksa çekirdeğin 
    "root" parametresinde ile belirtilen aygıttaki dosya sistemi kök dosya sistemi biçiminde mount edilmektedir. Yani başka 
    bir deyişle bu proses önce geçici kök dosya sistemi varsa onu mount etmekte, yoksa "root" çekirdek parametresi ile belirtilen 
    kök dosya sistemini mount etmektedir.

    start_kernel ---> rest_init ---> kernel_init ---> Geçici dosya sistemi varsa onu mount et yoksa "root" çekirdek parametresiyle 
    belirtilen dosya sistemini mount et.

    Eğer sistemde geçici kök dosya sistemi varsa (bu konunun bazı ayrıntıları izleyen paragraflarda açıklanacaktır) bu proses
    yeni "initramfs" sisteminde "/init" isimli programı eski "initrd sisteminde" ya da "/linuxrc" isimli program dosyasını exec 
    yaparak çalıştırmaktadır. Eğer geçici kök dosya sistemi yoksa kernel_init fonksiyonu "root" çekirdek parametresi ile belirtilen 
    ve mount edilen aygıttaki "/sbin/init" programını çalıştırmaktadır. Aslında çekirdeğin bu kısmı (kernel_init fonksiyonun sonu) 
    aşağıdaki gibidir:

    if (!try_to_run_init_process("/sbin/init") ||
        !try_to_run_init_process("/etc/init") ||
        !try_to_run_init_process("/bin/init") ||
        !try_to_run_init_process("/bin/sh"))
        return 0;

    Burada gerçek kök dosya sistemindeki "/sbin/init" çalıştırılmazsa sırasıyla "/etc/init", "/bin/init", "/bin/sh" programlarının 
    çalıştırılması sağlanmıştır. Eğer boot işlemi sırasında geçici kök dosya sistemi varsa çekirdeğin bu kök dosya sistemini mount 
    ettiğine dikkat ediniz. Bu durumda gerçek kök dosya sisteminin mount edilmesi artık geçici kök dosya sisteminin sorumluluğundadır.

    Bir Linux sistemindeki çekirdeğin çalıştırdığı bu "init" programları başka proje grupları tarafından yazılmış programlardır. 
    Bu programların çekirdekle bir ilgisi yoktur. Çekirdek bu programı çalıştırdıktan sonra artık kendi işlevine devam etmektedir. 
    Buradaki "init" programları Linux'un tarihsel gelişimi içerisinde çeşitli evrimler geçirmiştir. Eskiden ilk zamanlarda 
    "klasik System 5 init" paketi kullanılıyordu. Sonra "upstart" denilen bir init paketi kullanılmaya başlandı. Ancak günümüzde 
    artık "systemd" isimli init paketi yoğun biçimde kullanılmaktadır. Kursun yapıldığı masaüstü Linux dağıtmındaki "/sbin/init" 
    dosyası şöyledir:

    $ ls -l /sbin/init
    lrwxrwxrwx 1 root root 20 Kas 21 2023 /sbin/init -> /lib/systemd/systemd

    Yani çekirdek (ya da geçici kök dosya sistemi) "/sbin/init" programını çalıştırmak isterken aslında bu sistemde "systemd" 
    isimli programı çalıştırmaktadır. BusyBox'ın ve toybox'ın ayrı init sistemleri olduğunu ve bu init sistemlerinin klasik 
    System 5 init sistemine benzediğini belirtmiştik. Şimdi BusyBox içerisindeki "/sbin/init" dosyasına bakalım:

    lrwxrwxrwx 1 root root 14 Eyl 17 20:04 sbin/init -> ../bin/busybox

    Burada "init" programının dahi bir applet olarak "busybox" programın içerisinde olduğu görülmektedir. Ayrıca BusyBox'ta
    kök içerisinde "linuxrc" isimli bir dosya da vardır. Bu dosya da aşağıdaki gibi bir sembolik link içermektedir:

    lrwxrwxrwx 1 root root 11 Eyl 17 20:04 linuxrc -> bin/busybox
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi biz kök dosya sistemindeki "/sbin/init" dosyasını bir mesaj çıkartan basit bir program dosyası ile değiştirirsek ne 
    olur? Bunu bir deney olarak yapabiliriz. Tabii böyle bir deneyde orijinal "/sbin/init" dosyasının ismini değiştirmemiz uygun 
    olacaktır. Böylece eski duruma daha kolay dönebiliriz:

    $ cd /rootfs/sbin
    $ mv init backup_init

    init programı yerine yerine ekrana bir mesaj çıkartan basit bir C programı yerleştirmiş olalım. (Tabii deneyi BBB kullanarak 
    yapacaksınız bu programı da çapraz derleyiciyle derlemelisiniz.) İşte Linux'un kaynak kodlarına göre "init" programının başarılı 
    çalıştırılması sonucunda bu program bittiğinde çekirdek çalışmaya devam edecektir. Ancak kullanıcıların devreye girmesi tamamen 
    "init" programının çalışmasıyla gerçekleşen bir dizi olay sonucunda sağlanmaktadır. Başka bir deyişle Linux sistemini çalışan 
    bir sistem haline getiren "init" programı ve sonrasında bu programın çalıştırdığı programlardır. Ancak yukarıda da belirttiğimiz 
    gibi bu programların çekirdek kodlarıyla bir ilgisi yoktur.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Kursumuzun çeşitli yerlerinde "bir geçici kök dosya sisteminin" bulunabileceğini bu dosya sisteminin gerçek kök dosya 
    sistemini mount ettiğini belirtmiştik. Pekiyi bu geçici kök dosya sistemi ne amaçla kullanılmaktadır? İşte geçici kök dosya 
    sisteminin önemli kullanım nedenlerinden bazıları şunlardır:

    - Gerçek kök dosya sistemi fiziksel bir yerde olmayabilir. Ağda yayılmış bir biçimde bulunabilir. (Bu tür dosya sistemlerinin 
    yaygın kullanılanlarından birine "NFS (Network File System)" denilmektedir.) Bu durumda böyle bir sistemi mount edebilmek için 
    geçici bir kök dosya sistemine sahip olunması gerekir.

    - Bazı kök dosya sistemleri bazı çekirdek modül dosyalarını barındırmayabilir. Bu durumda bu dosyaları barındıran geçici kök
    dosya sistemleri daha standart bir kullanım sağlayabilmektedir. (Yani geçici kök dosya sisteminde tüm yaygın modüller bulundurulur. 
    Böylece gerçek kök dosya sistemine bu modüller yüklü biçimde geçilmiş olur.)

    - Sistem güncellemelerinde disk üzerindeki sistem dosyaları da güncellenmektedir. Çalışan bir kök dosya sisteminde bazı 
    güncellemeleri yapmak mümkün olmayabilir. Bunun için sistem RAM'de bulunan geçici bir kök dosya sistemi ile mount edilir.

    - Bazı test işlemlerinde diski devreye sokmadan RAM'deki geçici kök dosya sisteminde denemeler yapılabilmektedir. Bu tür 
    testlerde de geçici kök dosya sistemleri kullanılabilir.

    - Birtakım bozukluklar söz konusu olduğunda geçici kök dosya sistemi bir "safe mode" ortamı oluşturabilmektedir.

    - Gerçek kök dosya sistemindeki disk organizasyonu bozulmuş olabilir. Bunu onaran programların kendisi de bozulmuş olabilir. 
    Bu tür durumlarda onarma işlemlerinde geçici kök dosya sisteminin aktif tutulması uygun bir çözümdür.

    Bugünkü masaüstü Linux dağıtımlarının hemen hepsi bir geçici kök dosya sistemi sunmaktadır. Ancak kendine yeter olan sistemlerde
    geçici kök sistemine de mutlak anlamda gereksinim duyulmamaktadır. Zaten şimdiye kadar U-Boot ile yaptığımız boot denemelerinde 
    geçici kök dosya sistemi kullanmadık.

    Geçici kök dosya sistemi terimi yerine halk arasında "initial ramdisk", "initrd", "initramfs" gibi terimler de kullanılmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												48. Ders 1/10/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Geçici kök dosya sisteminin RAM'de oluşturulması için Linux'ta iki yöntem kullanılmaktadır. Bunlardan birine "initrd" 
    denilmektedir. Bu eski yöntemdir. Bu yöntemde arka planda ramdiskin oluşturulması için "/dev/ramN" aygıtları mount edilmektedir. 
    Modern sisteme "initramfs" denilmektedir. Bu sistemde ramdisk "tmpfs" dosya sistemi yardımıyla oluşturulmaktadır. Eski "initrd"
    yöntemi neredeyse kullanım dışı kalmıştır. Artık hep "initramfs" yöntemi kullanılmaktadır. Ancak her iki yöntemde de henüz 
    işletim sisteminin çekirdeği yüklenmeden geçici kök dosya sistemine ilişkin dosyalar önce RAM'e yüklenir (tabii bu işlem 
    boot loader tarafından yapılmaktadır) sonra yüklenen yerin adresi çekirdeğe çekirdek boot parametreleriyle aktarılır. Bu eski 
    yöntemle yeni yöntem arasında geçici kök dosya sisteminin nasıl bir biçiminde oluşturulacağı konusunda farklılıklar vardır. 
    Biz burada eski "initrd" yöntemini açıklamayacağız. Doğrudan "initramfs" biçiminde isimlendirilen yeni sistemi açıklayacağız.

    Geçici kök dosya sistemini "initramfs" yöntemiyle oluşturmak için sırasıyla şunlar yapılmalıdır:

    1) Önce geçici kök dosya sistemi diskte oluşturulur. Aslında diskte oluşturduğumuz gerçek kök dosya sistemini biz geçici 
    kök dosya sistemi olarak da kullanabiliriz. Ancak geçici kök dosya sisteminin makul uzunlukta olması gerekir. Bu nedenle
    geçici kök dosya sistemini özel olarak kompakt bir biçimde oluşturmak gerekebilmektedir. Biz burada BusyBox ile oluşturduğumuz
    gerçek kök dosya sistemini aynı zamanda geçici kök dosya sistemi olarak kullanacağız. Ancak Debian tabanlı sistemlerde geçici 
    kök dosya sistemi oluşturmak için "update-initramfs" isminde bir yardımcı program da bulunmaktadır. Bu program şöyle çalıştırılır:

    $ sudo update-initramfs -c -k <çekirdek sürümü>

    Bu komut default olarak "boot" dizinin altına geçici kök dosya sistemini oluşturmaktadır. Bu komut "lib/modules<çekirdek-sürümü>"
    dizinindeki modül bilgilerini ve o andaki çalışan sistemde yüklü olan modüllere ilişkin bilgileri de kullanmaktadır.

    2) Biz geçici kök dosya sistemiyle boot işlemi yaptıktan sonra neyin olmasını isteriz? İşte uygulamacı geçici kök dosya 
    sistemiyle boot işlemini yaptıktan sonra kendi amaçlarına göre birtakım işlemler yapmak isteyebilir. Ancak genellikle yapılan 
    işlem gerçek kök dosya sisteminin mount edilip gerçek kök dosya sistemine geçilmesidir. Linux çekirdeği eğer "initramfs" 
    yöntemiyle oluşturulmuş geçici dosya sistemiyle başlatılıyorsa sistem yüklendikten sonra "/init" programını çalıştırmaktadır. 
    Genellikle "initrd" yöntemi kullanılan geçici dosya sistemi ile başlatma durumunda "/linuxrc" programı çalıştırılmaktadır.
    Yani sistem başlatıldıktan sonra çekirdek tarafından ilk çalıştırılacak program başlatmanın nasıl yapıldığına göre değişmektedir.
    Eğer başlatma "initramfs" yöntemiyle yapılmışsa ilk çalıştırılan program "/init" programıdır. Eğer sistem "initrd" yöntemiyle
    başlatılmışsa ilk çalıştırılan program "/linuxrc" programıdır. Eğer sistem geçici kök dosya sistemi kullanılmadan çekirdeğin
    "root" parametresi yoluyla başlatılmışsa bu durumda daha önceden de belirttiğimiz gibi ilk çalıştırılan program "/sbin/init"
    programıdır. (Anımsanacağı gibi bu program yoksa "/etc/init", "/bin/init", "/bin/sh" programları da çalıştırılmaya çalışmaktadır.)
    Eğer çekirdeğe hem "initramfs" hem de "initrd" yöntemleriyle geçici kök dosya sistemi iletilmişse çekirdek önce "initramfs" 
    yöntemiyle belirtilen geçici kök dosya sistemine sonra "initrd" yöntemiyle belirtilen geçici kök dosya sistemine bakmaktadır. 
    Ayrıca eğer geçici kök dosya sistemi kullanılacaksa artık çekirdeğin "root" parametresi çekirdek tarafından kullanılmamaktadır. 
    Geçici kök dosya sisteminin kök dizinindeki "/init" programının oluşturulması ve işlevi maddeler bittiğinde ayrı bir paragrafta 
    ele alınacaktır. Biz bu noktada böyle bir "init" programının kabuk komutunu çalıştıracak biçimde aşağıdaki gibi oluşturulduğunu 
    varsayalım:

    #!/bin/sh
    mount -t proc proc /proc
    mount -t sysfs sys /sys
    mount -t devtmpfs dev /dev
    exec setsid cttyhack /bin/sh

    Burada önce önemli dosya sistemleri mount edilmiştir. Sonra "/bin/sh" programı yani "ash" çalıştırılmıştır. Ancak bu kabuk 
    programının doğrudan çalıştırılmadığına setsid komutu ile çalıştırıldığında dikkat ediniz:

    exec setsid cttyhack /bin/sh

    Burada setsid bir oturum (session) oluşturur ve oturumun terminalini (controlling terminal) ayarlar. cttyhack programı aslında
    kabuk programını çalıştırmaktadır. Biz doğrudan kabuk programını aşağıdaki gibi de çalıştırabilirdik:

    exec /bin/sh

    Ancak bu durumda kabuk programı terminala erişemeyeceği için "job control" özelliğini pasif hale getirirdi. Buradaki "cttyhack" 
    BusyBox'a özgü bir programdır. Tabii bizim "/init" dosyasını çalıştırılabilir yapmamız gerekir:

    $ sudo chmod +x init

    3) Linux çekirdeğinde geçici kök dosya sisteminin sistem boot edilirken ".cpio.gz" formatında olması gerekmektedir. Yani önce
    kök dosya sistemini oluşturan dosyalar "cpio" formatı denilen bir formatta uç uca eklenir sonra bu uç uca eklenmiş olan 
    dosya gzip programıyla zip'lenir. "cpio" formatı bir sıkıştırma formatı değildir arşiv formatıdır. Yani dosyaları tek bir 
    dosya altında birleştirmektedir. Bu dosya formatı işlev olarak "tar" formatına çok benzerdir. Ancak aralarında kullanım 
    senaryolarına göre farklılıklar bulunmaktadır. Fakat bu geçici kök dosya sisteminde "tar" yerine bu "cpio" formatı kullanılmaktadır.
    Tabii aslında bu bağlamın dışında "tar" formatının kullanımı "cpio" formatına göre çok daha yaygındır. "cpio" formatı ile 
    dosyaları arşivlemek için "cpio" isimli yardımcı program kullanılmaktadır. Ancak bu program arşivlenecek dosyaları stdin 
    dosyasında alıp arşiv çıktısını stdout dosyasına yazmaktadır. Dolayısıyla IO yönlendirmesi yapılarak kullanılmaktadır. 
    "cpio" programının pek çok komut satırı argümanı vardır. Biz burada bu komut satırı argümanlarını açıklamayacağız. Ancak 
    bu bağlamda programı tipik olarak aşağıdaki gibi kullanabilirsiniz (geçici kök dosya sistemine ilişkin dizinde ve ""root"" 
    kullanıcı ile kabuk üzerinde bulunduğunuzu bulunduğunuzu varsayıyoruz. Bunun için "sudo bash" yapabilirsiniz):

    $ find . | cpio -H newc -o > ../initrd.cpio

    Burada "-H newc" komut satırı argümanı arşiv formatının türünü belirtmektedir. "-o" argümanı ise stdout dosyasına çıktı 
    vermek için kullanılmaktadır. Buradaki dosya isminin "initrd" ile başlatılması gelenekseldir. Her ne kadar bu "initrd" ismi
    eski geçici kök dosya sistemi yöntemini çağrıştırıyorsa da yeni yöntemde de dosya ismi genellikle böyle başlatılmaktadır.

    Şimdi bu dosyayı gzip programı ile zip'leyelim:

    $ gzip initrd.cpio

    Buradan "initrd.cpio.gz" isminde bir dosya elde edilmiştir:

    $ ls -l initrd.cpio.gz
    -rw-r--r-- 1 kaan study 26516115 Eki 1 21:19 initrd.cpio.gz

    Görüldüğü gibi dosyanın sıkıştırılmış hali 26 MB civarındadır.

    Linux çekirdeği "cpio.gz" formatını kullanabilmektedir. Ancak U-Boot ile çalışırken bizim "bootz" gibi boot komutlarını 
    kullanabilmemiz için elde ettiğimiz bu dosyayı U-Boot'un kullanabileceği hale getirmemiz gerekir. Bu işlem yine "mkimage"
    programıyla yapılmaktadır:

    $ mkimage -A arm -O linux -T ramdisk -C gzip -d initrd.cpio.gz uinitrd

    "mkimage" programındaki komut satırı argümanlarına dikkat ediniz. "-A arm" zaten default durumdur. Ancak "-T ramdisk" seçeneğinin
    kullanılması gerekmektedir. Buradaki "-C gzip" dosyanın sıkıştırma formatını belirtir. "-d" komut seçeneğinin işleme sokulacak 
    dosyayı belirttiğini anımsayınız. Nihayet "uinitrd" hedef olarak elde edilecek dosyayı belirtmektedir. Yukarıda da belirttiğimiz 
    gibi eğer U-Boot kullanmıyorsak bu "mkimage" işlemine gerek yoktur.

    4) Bu işlemlerden elde etmiş olduğumuz geçici kök dosya sistemi dosyası ("uinitrd" dosyası ) FAT disk bölümüne ya da gerçek 
    kök dosya sisteminin "/boot" dizinine kopyalanır. Biz örneğimizde bu dosyayı "ext4" disk bölümündeki "/boot" dizinine yerleştirelim. 
    Bizim örneklerimizde çekirdek imajı, aygıt ağacı dosyası "ext4" disk bölümündeki "/boot" dizinindeydi. Aslında "çekirdek 
    imajını", "aygıt ağacı dosyasını" ve "geçici kök dosya sistemine ilişkin dosyayı" FAT disk bölümüne yerleştirmek daha uygundur.

    5) Artık geçici kök dosya sistemi ile boot işlemini yapabiliriz. Önce bu işlemi manuel bir biçimde yapalım. Bunun için 
    önce U-Boot'un komut satırında önce çekirdek imaj dosyasını, sonra aygıt ağacı dosyasını sonra da geçici kök dosya sistemi 
    dosyasını yükleyelim:

    => load mmc 0:2 0x82000000 /boot/vmlinuz-5.10.168-ti-r71
    11342336 bytes read in 748 ms (14.5 MiB/s)
    => load mmc 0:2 0x88000000 /boot/dtbs/5.10.168-ti-r71/am335x-boneblack.dtb
    93494 bytes read in 13 ms (6.9 MiB/s)
    => load mmc 0:2 0x90000000 /boot/uinitrd
    26516276 bytes read in 1718 ms (14.7 MiB/s)
    => bootz 0x82000000 0x90000000 0x88000000

    Burada biz artık kök dosya sisteminde kabuğun komut satırına düşmüş olacağız. Default bulunulan dizin "/root" dizini olacaktır.

    Bu işlem daha önce gördüğümüz "uEnv.txt" dosyası yoluyla otomatize edilebilir. Bu durumda "uEnv.txt" dosyasının içeriği 
    şöyle olacaktır:

    loadkernel=load mmc 0:2 0x82000000 /boot/vmlinuz-5.10.168-ti-r71
    loadfdt=load mmc 0:2 0x88000000 /boot/dtbs/5.10.168-ti-r71/am335x-boneblack.dtb
    loadinitrd=load mmc 0:2 0x90000000 /boot/uinitrd
    bootargs=console=ttyS0,115200 root=/dev/mmcblk0p2 rw
    bootsys=bootz 0x82000000 0x90000000 0x88000000
    uenvcmd=run loadkernel;run loadfdt;run loadinitrd; run bootsys

    Daha sonra U-Boot'un komut satırına geçip aşağıdaki çevre değişkenini set edip tüm çevre değişkenlerini saklamak gerekir:

    => setenv bootcmd "load mmc 0:1 0x8A000000 /uEnv.txt;env import -t 0x8A000000;run uenvcmd"

    Artık işlem otomatize edilmiştir.

    Boot işlemi sırasında "init" sistemlerinin ilk çalıştıracağı program aslında "rdinit" ve "init" isimli çekirdek komut satırı
    argümanlarıyla belirlenebilmektedir. Anımsanacağı gibi biz geçici kök dosya sistemini kullanıyorsak ilk çalıştırılacak 
    program "/init" programıydı. İşte "rdinit" komut satırı argümanı ile bunu değiştirebiliriz. Örneğin:

    => setenv bootargs console=ttyS0,115200 rdinit=/bin/sh root=/dev/mmcblk0p2 rw

    Artık boot işleminde "/init" programı yerine "/bin/sh" programı çalıştırılacaktır. Tabii biz kök dizinde oluşturduğumuz 
    "init" script dosyasında "proc" ve "sys" dosya sistemlerini mount etmiştik. O halde biz "rdinit=/bin/sh" çekirdek parametresi 
    ile boot işlemi yaptığımızda bu dosya sistemleri mount edilmemiş olacaktır. İşte aslında bu dosya sistemleri heniz "/init"
    ya da "rdinit" çekirdek parametresi ile belirtilen program çalıştırılmadan okunan script dosyalarında mount edilebilir.

    "init" isimli çekirdek parametresi de benzer amaçla kullanılmaktadır. Ancak bu parametre geçici kök dosya sistemi için değil 
    "root" parametresi ile mount edilen dosya sistemindeki çalıştırılacak ilk programı belirtir. Anımsanacağı default durumda 
    önce "/sbin/init" dosyası çalıştırılmaya çalışılıyordu.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												49. Ders 03/10/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    6) Pekiyi biz geçici kök dosya sistemine düşüp birtakım işlemleri yaptıktan sonra gerçek kök dosya sistemine nasıl geçeceğiz?
    Geçici kök dosya sisteminde kök dizin ramdisk biçiminde RAM'de bulunmaktadır. Bizim bir biçimde diskteki gerçek dosya sistemine
    geçmemiz gerekir. Biz daha önce bir prosesin kök dizinini chroot fonksiyonuyla ya da "chroot" komutuyla değiştirmiştik. Ancak
    geçici kök dosya sisteminden gerçek kök dosya sistemine geçilirken "chroot" komutu uygun değildir. Çünkü "chroot" komutu 
    (anımsanacağı gibi bu komut chroot isimli sistem fonksiyonunu çağırmaktadır) tek bir prosesin kök dizinini değiştirir. Halbuki
    bu noktaya gelinene kadar başka programlar ve daemon'lar çalıştırılmış olabilir. Bu nedenle bu geçişin "pivot_root" ya da
    "switch_root" komutlarıyla yapılması uygun olur.

    pivot_root komutu aslında sys_pivot_root isimli sistem fonksiyonu çağrılarak yazılmıştır. sys_pivot_root sistem fonksiyonunun 
    parametrik yapısı şöyledir:

    #include <sys/syscall.h>		/* Definition of SYS_* constants */
    #include <unistd.h>

    int syscall(SYS_pivot_root, const char *new_root, const char *put_old);

    libc kütüphanesinde bu sistem fonksiyonunu çağıran bir kütüphane fonksiyonu (wrapper) bulunmamaktadır. Fonksiyonun birinci 
    parametresi mount edilmiş yeni kök dosya sistemine ilişkin dizini belirtmektedir. İkinci parametre ise eski kök dosya sisteminin
    yeni kök dosya sisteminde taşınacağı dizini belirtmektedir. Yani bu fonksiyon proseslerin kök dosya sistemlerini değiştirirken 
    aynı zamanda eski kök dosya sistemini de yeni kök dosya sistemi içerisinde erişilebilir yapmaktadır. Tabii programcı isterse
    bu eski kök dosya sistemini umount fonksiyonu ile unmount edebilir. Tabii pivot_root sistem fonksiyonunu çağıran bir kabuk 
    komutu da vardır. Komutun kullanımı şöyledir:

    pivot_root <yeni_kök_dizin> <eski_kök_dizin>

    Burada yeni_kök_dizin mount edilmiş gerçek kök dosya sisteminin yol ifadesini belirtmektedir. eski_kök_dizin ise geçici kök 
    dosya sisteminin kök dizininin (/ dizininin) yeni kök dosya sistemindeki yerini belirtir. Örneğin:

    $ sudo pivot_root /mnt/new_root /mnt/old_root

    Burada gerçek kök dosya sistemi "/mmt/new_root" dizinine mount edilmiştir. Yani artık bu işlemden sonra kök dizin bu dizin 
    olacaktır. Ancak yeni kök dizine geçildiğinde o kök dizinin "/mnt/old_root" dizini eski yani geçici kök dosya sistemi 
    olacaktır. Yani biz bu komutla gerçek kök dosya sistemine geçtiğimizde gerçek kök dosya sisteminin "/mnt/old_root" dizini 
    artık geçici kök dosya sisteminin kök dizini gibi olacaktır. Tabii programcı bu eski kök dizini hiç kullanmak istemeyebilir. 
    O zaman bu işlemden sonra aşağıdaki gibi onu unmount edebilir:

    $ sudo umount /mnt/old_root

    switch_root komutu daha basit ve kullanışlı bir komuttur. Komutun kullanımı şöyledir:

    switch_root <yeni_kök_dizin> <yeni_kök_dizinde_çalıştırılacak_program>

    Komutun birinci parametresi yeni kök dizinin yerini, ikinci parametresi ise yeni kök dizine geçildikten sonra orada çalıştırılacak 
    programın yol ifadesini belirtmektedir. Kullanımının chroot komutuna benzediğine dikkat ediniz. Ancak pivot_root ve switch_root
    komutları tek bir prosesin değil tüm proseslerin (aslında mount isim alanındaki tüm proseslerin) kök dizinlerini değiştirmektedir. 
    switch_root komutu eski kök dosya sistemini (yani geçici kök dosya sistemini) kendisi unmount etmektedir. Bu nedenle geçiş için
    pivot_root komutu yerine switch_root komutu tercih edilebilir.

    switch_root komutunu kullanırken bu komut prosesin proses id'sinin 1 olup olmadığını kontrol etmektedir. Dolayısıyla 
    bizim geçici kök dosya sistemindeki "/init" programında exec ile switch_root uygulamamız gerekir. Çünkü exec yapmazsak 
    shell programı (örneğimizde "ash") switch_root komutu için önce fork yapacaktır. Bu durumda komutu uygulayan prosesin proses
    id değeri 1 olmayacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												50. Ders 08/10/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bizim switch_root uygulayabilmemiz için önce gerçek kök dosya sistemini "mount" etmemiz gerekir. Örneğin geçmek istediğimiz
    gerçek kök dosya sistemi micro SD karttaki "/dev/mmcblk0p2" Ext4 dosya sistemi olsun. Bizim şöyle switch_root yapmamız gerekir:

    $ mkdir /newroot
    $ mount /dev/mmcblk0p2 /newroot
    $ switch_root /newroot /sbin/init

    Tabii switch_root yaptığımızda gerçek kök dosya sisteminin hazır olarak bulunuyor olması gerekir. Ancak burada bir noktaya 
    dikkatinizi çekmek istiyoruz. /dev dizinini mount ettiğinizde çekirdeğin çalıştığı makinenin hızına bağlı olarak henüz 
    bazı aygıt dosyaları oluşturulmamış olabilir. Böylesi bir durumda da "/dev/mmcblk0p2" dosyası henüz oluşturulmadığı 
    için gerçek kök dosya sisteminin mount edilme işlemi başarısızlıkla sonuçlanabilir. Bu nedenle bizim mount işleminden önce
    ilgili aygıt dosyası yaratılan kadar beklememiz gerekir. İlgili aygıt dosyası yaratılana kadar beklemek için iki yöntem önerebiliriz. 
    Birincisi "mdev -s" komutunu uygulamaktır. (Aslında mount işlemi "devtmpfs" dosya sistemi ile yapıldığında aygıt dosyaları 
    zaten bu dosya sistemi tarafından oluşturulmaktadır. Dolayısıyla "mdev -s" komutuna gerek kalmaz. Ancak bizim örneğimizde
    bu komutun aygıt dosyalarının yaratılmasına kadar bekleme yapmasından faydalanıyoruz.) İlgili aygıt dosyası yaratılana kadar 
    bekleme yapmanın diğer bir yolu da bir döngü içerisinde sürekli kontrol etmek olabilir. Bu işlemi de şöyle yapabiliriz:

    while [! z-e /dev/mmcblk0p2 ]; do
        echo "Device files are being created, waiting..."
        sleep 1
    done

    Bu işlemlerin hepsini otomatize edebilmek için geçici kök dosya sistemindeki "/init" dosyasını aşağıdaki gibi güncelleyebiliriz:

    #!/bin/sh
    mount -t proc proc /proc
    mount -t sysfs sys /sys
    mount -t devtmpfs dev /dev
    mdev -s
    mkdir /newroot
    mount /dev/mmcblk0p2 /newroot
    exec switch_root /newroot /sbin/init

    Artık biz sistemi önce geçici kök dosya sistemi ile boot ettik. Oradan da gerçek kök dosya sistemine geçtik. Ancak yine de
    şöyle bir sorun da vardır: Biz geçici kök dosya sistemindeki "/init" script'inde gerçek kök dosya sistemini "/dev/mmcblk0p2"
    olarak aldık. Bu durumda gerçek kök dosya sistemi kullanıcı tarafından değiştirilemez. Bizim bu gerçek kök dosya sistemini 
    çekirdeğin "root" parametresinden alıp mount işlemini ona göre yapmamız daha esnek bir kullanım sunacaktır. Pekiyi biz 
    "/init" script'i içerisinde çekirdeğin "root" parametresini nasıl elde edebiliriz? Bunu elde etmenin tek yolu "proc" dosya 
    sistemi içerisindeki "cmdline" dosyasını parse etmektir. Çekirdeğin bütün komut satırı "/proc/cmdline" dosyasının içerisinde
    bulunmaktadır. Biz bu dosyayı okuyup "root=..." çekersek elde edersek bu parametreyi elde edebiliriz. Bu dosyanın parse
    edilmesi bir C programıyla yapılabilir ya da doğrudan kabuk komutlarıyla da yapılabilir. Bu işlemin yapıldığı bir "/init" 
    programı şöyle yazılabilir:

    #!/bin/sh

    mount -t proc proc /proc
    mount -t sysfs sys /sys
    mount -t devtmpfs dev /dev

    ROOT_DEVICE=$(cat /proc/cmdline | sed -n 's/.*root=\([^ ]*\).*/\1/p')

    if [ -z "$ROOT_DEVICE" ]; then
        echo "Root device not specified in kernel parameters."
        exec /bin/sh
    fi

    echo "Mounting root device: $ROOT_DEVICE"

    mkdir -p /newroot
    mount "$ROOT_DEVICE" /newroot

    if [ $? -ne 0 ]; then
        echo "Failed to mount root device: $ROOT_DEVICE"
        exec /bin/sh
    fi

    while [ ! -e "$ROOT_DEVICE" ]; do
        echo "Root device $ROOT_DEVICE not available, waiting..."
        sleep 1
    done

    exec switch_root /newroot /sbin/init
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												51. Ders 10/10/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Daha önceden de belirttiğimiz gibi Linux sistemlerinde tarih boyunca üç init sistemi kullanılmıştır:

    1) Klasik System 5 init sistemi (Buna "SysVinit" de denilmektedir.)
    2) Upstart init sistemi
    3) systemd init sistemi

    BusyBox ve toybox kendi init sistemlerini kullanmaktadır. Burada kullanılan init sistemi daha önce de belirttiğimiz gibi 
    SysVinit sistemine oldukça benzemektedir. Onun daraltılmış hafifletilmiş bir versiyonu gibidir. Bu nedenle biz kursumuzda
    SysVinit sistemini ve systemd init sistemlerini inceleyeceğiz. Klasik SysVinit sistemi artık Linux sistemlerinde kullanılmıyor 
    olsa da gömülü sistemlerde kullanılabilmektedir. Upstart arada kalmış bir sistemdir. Zaten çok kısa bir süre kullanılmıştır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Anımsanacağı gibi çekirdek boot işleminin son aşamasında kök dosya sisteminde "/init" ya da "/sbin/init" programlarını 
    çalıştırıyordu. ("/init" programının geçici kök dosya sistemi için "/sbin/init" programının geçici kök dosya sistemi olmayan
    sistemlerde gerçek kök dosya sistemi için çalıştırıldığını anımsayınız.) Pekiyi çekirdek akışı bu "init" programlarına 
    devrettiğinde neler olmaktadır?
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Klasik "System 5 init" programı çalışmaya başladığında bu program önce "/etc/inittab" dosyasına başvurup oradaki yönergeleri
    elde edip gerekli ilk işlemleri yapmaktadır. Bu dosya aşağıdaki gibi formata sahip satırlardan oluşmaktadır:

    id:runlevel:action:executable [command_line_args]

    "inittab" dosyası "hangi durumlarda hangi programların çalıştırılacağını" belirten bir dosyadır. Burada "id" o satıra özgü 
    herhangi bir belirteçtir, "runlevel" sistemin çalışma düzeyini belirtmektedir. İzleyen paragraflarda açıklanacaktır. "action"
    ilgili programın nasıl ve ne zaman çalıştırılacağını belirtir. Nihayet executable çalıştırılacak programın yol ifadesini 
    belirtmektedir. Örnek bir satır şöyle olabilir:

    tty1:2345:respawn:/sbin/getty -L tty1

    Buradaki "tty1" satırı temsil eden id değeridir. Bu ismin işleyişte bir önemi yoktur. run level için 2, 3, 4, 5 değerleri 
    girilmiştir. Run level tek bir sayıdan oluşmaktadır. Dolayısıyla burada dört farklı run level belirtilmiştir. Çalıştırma 
    biçimi (action) "respawn" olarak belirtilmiştir. Nihayet çalıştırılacak program "/sbin/getty" isimli terminal programıdır. 
    "-L tty" bu programın komut satırı argümanlarıdır. Satırdaki "action" belirten belirteçler şunlardan biri olabilir:

    sysinit: init çalıştığında toplamda bir kez çalıştırılacak programları belirtir. Çalışma düzeyi (run level) bu eylemde 
    etkili olmamaktadır.

    respawn: Eğer ilgili proses bir biçimde sonlanırsa init bunu izleyerek yeniden çalıştırmaktadır. Bu da belli çalışma 
    düzeyleri için belirtilmektedir.

    wait: Belli çalışma düzeylerinde çalıştırılacak programları belirtir. Ancak programın çalışması bitene kadar init başka 
    program çalıştırmadan bekler.

    boot: Sistem reboot edilirken çalıştırılacak programları belirtmektedir. Çalışma düzeyleri etkilidir.

    Pekiyi çalışma düzeyi (run level) ne anlama gelmektedir? Aslında çalışma düzeyi "init" başlatıldığında çalıştırılacak 
    script grubunu belirtmektedir. Tabii bu script'ler belli senaryoları sağlamak için oluşturulmuştur. "init" programı aslında 
    çalışma düzeylerine özel bir anlam vermemektedir. Ancak Linux'ta hazır "SysVinit paketleri kullanıldığında çalışma düzeylerinin
    nasıl bir sistemi başlatacağı belirlenmiştir. Aşağıda Linux'un SysVinit paketinin tanımladığı çalışma düzeylerinin anlamlarını
    listeliyoruz:

    0: Sistemin tamamen kapatıldığı durumdur. Güç düğmesine basmak gibi.
    1: Tek kullanıcı modu. Sadece root kullanıcısı giriş yapabilir.
    2: Çok kullanıcı modu, ancak ağ hizmetleri etkin değil.
    3: Tam çok kullanıcı modu. Tüm ağ hizmetleri aktiftir ve grafiksel arayüz genellikle bu seviyede aktif hale getirilir.
    4: Kullanıcıların kendilerinin konfigüre ettiği çalışma düzeyi
    5: Grafiksel arayüzün varsayılan olarak çalıştırıldığı seviyedir.
    6: Sistemi yeniden başlatır.

    İşte "inittab" dosyasındaki satırlar "hangi çalışma düzeyi aktif ise hangi programların çalıştırılacağını" belirtmektedir. 
    Default çalışma düzeyi yine genellikle bu "inittab" dosyasının tepesinde bir satırda aşağıdaki gibi belirtilmektedir:

    id:5:initdefault:

    Burada eylem (action) olarak "initdefault" default çalışma düzeyini belirtmektedir. Pekiyi bir dolu bir "inittab" dosyası 
    neye benzemektedir? Aşağıda örnek bir "inittab" dosyası verilmiştir:

    ******************************************************
    # Varsayılan runlevel
    id:3:initdefault:

    # Sistem başlatma script'i
    si::sysinit:/etc/rc.d/rc.sysinit

    # Runlevel geçiş script'leri

    l0:0:wait:/etc/rc.d/rc 0
    l1:1:wait:/etc/rc.d/rc 1
    l2:2:wait:/etc/rc.d/rc 2
    l3:3:wait:/etc/rc.d/rc 3
    l4:4:wait:/etc/rc.d/rc 4
    l5:5:wait:/etc/rc.d/rc 5
    l6:6:wait:/etc/rc.d/rc 6

    # Konsol getty süreçleri
    1:2345:respawn:/sbin/getty --noclear tty1 linux
    2:2345:respawn:/sbin/getty tty2 linux
    3:2345:respawn:/sbin/getty tty3 linux
    4:2345:respawn:/sbin/getty tty4 linux
    5:2345:respawn:/sbin/getty tty5 linux
    6:2345:respawn:/sbin/getty tty6 linux

    # Ctrl+Alt+Del tuş kombinasyonu için
    ca::ctrlaltdel:/sbin/shutdown -r now

    # Güç kesintisi durumunda
    pf::powerfail:/sbin/shutdown -h +2 "Güç kesintisi algılandı, sistem 2 dakika içinde kapanacak."

    # Sistem kapanırken
    sh:0123456:shutdown:/sbin/killall5 -15
    ******************************************************

    SysVinit sistemindeki "init" programı aslında "/etc/inittab" dosyasını parse edip belli çalışma düzeylerinde burada belirtilen 
    programları çalıştırmaktadır. Ancak bu "init" paketi kurulduğunda aslında pek çok script dosyası da "/etc/rc.d" dizininin
    içerisine yerleştirilmektedir. Bu dizindeki script'ler çeşitli çalışma düzeylerine geçildiğinde çalıştırılırlar. Yukarıdaki 
    örnekte bu çalıştırmayı "/etc/rc.d/rc" programı yapmaktadır. Böylece sistem yöneticisi "/etc/inittab" dosyasına hiç dokunmadan 
    belli bir çalışma düzeyinde çalıştırılacak olan programları bir script olarak hazırlayıp "/etc/rc.d" dizinindeki dizinlerin 
    içerisinde aşağıda belirtildiği gibi yerleştirir.

    "/etc/rc.d" dizini içerisinde "rcN.d" isimli (burada N çalışma düzeyini belirtiyor) dizinler bulundurulmaktadır:

    /etc/rc.d/rc0.d/: Runlevel 0 için (sistemin kapanması)
    /etc/rc.d/rc1.d/: Runlevel 1 için (tek kullanıcı modu)
    /etc/rc.d/rc2.d/: Runlevel 2 için
    /etc/rc.d/rc3.d/: Runlevel 3 için (çok kullanıcılı mod, ağ ile)
    /etc/rc.d/rc4.d/: Runlevel 4 için (kullanıcı tanımlı)
    /etc/rc.d/rc5.d/: Runlevel 5 için (grafik arayüz ile)
    /etc/rc.d/rc6.d/: Runlevel 6 için (sistemin yeniden başlatılması)

    Örneğin biz 3 numaralı çalışma düzeyi için kendi script'lerimizi çalıştıracak olalım. Bunun için yapacağımız şey "/etc/rc.d/rc3.d" 
    dizinine script'lerimizi çalıştırılabilir dosya olarak kopyalamaktır. Böylece bu script'ler otomatik olarak çalıştırılacak ve 
    bizim servislerimiz da sistem boot edildiğine otomatik devreye girmiş olacaktır. "/etc/rc.d/rcN.d" dizinlerindeki script'ler 
    aşağıdaki gibi isimlendirilmelidir:

    SXXservisadı: Servisin çalışma düzeyine girerken başlatılacağını belirtir.
    KXXservisadı: Servisin çalışma düzeyinden çıkarken durdurulacağını belirtir.
    XX: İki basamaklı sıra numarasıdır ve script'lerin hangi sırayla çalıştırılacağını belirler.

    Görüldüğü gibi script isimlerinin ilk karakteri 'S' ya da 'K' biçimindedir. 'S' scriptleri çalışma düzeyine girilirken 'K' 
    script'leri ise çalışma düzeyinden çıkılırken çalıştırılmaktadır. XX burada iki basamaklı sayı belirtmektedir. Buradaki 
    'S' script'leri düşük sayıdan yüksek sayıya doğru 'K' scriptleri ise yüksek sayıdan düşük sayıya doğru çalıştırılırlar. Nihayet 
    XX sayılarından sonra çalıştırılacak programın ismini belirtilir. Tabii aslında bu script'ler bazen doğrudan bazı servislere 
    sembolik link de yapılmış olabilirler. Örnek bir dizin içeriği şöyle verilebilir:

    /etc/rc.d/rc3.d/S10network
    /etc/rc.d/rc3.d/S50apache
    /etc/rc.d/rc3.d/K20nfs

    Burada bir noktaya dikkatinizi çekmek istiyoruz. Burada bütün çalıştırmalar "/etc/inittab" dosyasındaki script'ler tarafından
    yapılmaktadır. Eğer bu script'ler "/etc/inittab" dosyası içerisinde çalıştırılmazsa bu durumda "/etc/rc.s/rcN.d" dizinlerindeki
    script'ler de çalıştırılmayacaktır.

    "/etc/rc.d/rcN.d" dizinindeki script'ler genellikle "/etc/init.d" içerisindeki script'lere sembolik link yapılmaktadır. 
    "/etc/rc.d/rcN.d" dizini içerisindeki script'ler çalıştırılırken onlara genellikle "start", "stop", "restart", "status" biçiminde
    parametreler geçirmektedir. Yani "/etc/init.d" dizinindeki script'ler bu komut satırı argümanlarını dikkate alacak biçimde 
    yazılmış durumdadır.

    Klasik System 5 init sisteminde sistem açıldığında bazı aygıtların otomatik mount edilmesini sağlamak için "/etc/fstab" 
    dosyası kullanılmaktadır. Biz bu dosyanın formatını daha önce belirtmiştik. "mount" komutu "-a" ile çalıştırıldığında 
    bu komut "/etc/fstab" dosyasına bakarak oradaki bilgilerden hareketle mount işlemini yapmaktadır. SysVinit sisteminde
    genellikle bu "mount -a" komutu "/etc/inittab" içerisindeki bir script tarafından çalıştırılmaktadır.

    Aslında Sysvinit init programı komut satırı argümanı da alabilmektedir. Komut satırı argümanı ile başlangıç çalışma düzeyi 
    belirtilebilmektedir.

    Eski SysVinit sistemlerinde o andaki çalışma düzeyi "runlevel" komutuyla elde edilebilir. "init" programı aynı zamanda 
    RUNLEVEL isimli bir çevre değişkenini de default çalışma düzeyi olarak set etmektedir. Mevcut çalışma düzeyi "telinit" 
    komutuyla değiştirilebilmektedir. Örneğin:

    $ telinit 5

    Burada 5'inci çalışma düzeyine geçilmektedir.

    SysVinit sistemi belli bir süredir artık kullanılmadığı için bunun hakkında internette kaynak bulmak da zorlaşmıştır. 
    Daha ayrıntılı bilgi için "man init 8" aramasını yapabilirsiniz. Projenin eski kodlarını inceleyebilirsiniz. Aşağıdaki
    doküman nispeten diğerlerinden daha iyidir:

    https://wiki.gentoo.org/wiki/Sysvinit
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Klasik SysVinit sistemi ve sonrasında oluşturulan yapının bir özetini yapmak istiyoruz:

    1) Sistem boot edildiğinde çekirdeğin kendisi ya da geçici kök dosya sistemindeki script "/sbin/init" programını çalıştırıyor.

    2) SysVinit sisteminin "/sbin/init" programı çalıştırılıyor.

    3) "/sbin/init" programı "/etc/inittab" dosyasındaki programları çalıştırır.

    4) "/etc/inittab" dosyasında belirtilen "rc" script'i o andaki çalışma düzeyine ilişkin "/etc/rc.d/rcN.d" dizinindeki 
    script'leri "start", "stop", "restart", "status" komut satırı argümanlarıyla çalıştırır.

    5) "/etc/rc.d/rcN.d" dizinindeki script'ler "/etc/init.d" dizinindeki script'lere sembolik link yapılmıştır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi BusyBox init sistemi nasıldır? Yukarıda da belirttiğimiz gibi BusyBox init programı SysVinit'teki init programına 
    benzemektedir. Ancak önemli bazı farklılıklar şunlardır:

    - BusyBox'ta "çalışma düzeyi (runlevel)" kavramı yoktur. Dolayısıyla BusyBox'ta "/etc/inittab" dosyasındaki satırlarda 
    çalışma düzeyi alanına bir şey girilmemektedir.
    - BusyBox'ta SysVinit sistemindeki eylemlerin (action) hepsi yoktur.

    Ancak BusyBox init programı yine "/etc/inittab" dosyasını okumaktadır. Bu dosyanın satırları SysVinit sistemiyle aynı 
    formattadır. (Çalışma düzeyi alanının kullanılmadığını anımsayınız.) Burada dikkat edilmesi gereken bir nokta şudur: 
    BusyBox ve toybox gibi araçlar bize minimal bir kök dosya sistemi sunmaktadır. Dolayısıyla bu araçlarla oluşturduğumuz 
    kök dosya sistemlerinde hazır bir "/etc/inittab" dosyası da yoktur. Yani uygulamacının bu dosyayı da kendisinin hazırlaması 
    gerekir.

    Pekiyi BusyBox için gerçek kök dosya sistemindeki "/etc/inittab" dosyasını nasıl hazırlamalıyız? Genellikle uygulamacılar 
    SysVinit sistemlerine benzeterek işin başında aşağıdaki "rcS" isimli bir script'i çalıştırmaktadır:

    ::sysinit:/etc/init.d/rcS

    Böylece artık bu dosyaya dokunmadan sistem açıldığında çalıştırılacak öğeleri bu script'in içerisine yerleştirebiliriz. 
    "/etc/fstab" dosyasındaki mount yönergelerinin işleme sokulması isteniyorsa aşağıdaki gibi bir satırın bulundurulması 
    uygun olur:

    ::sysinit:/bin/mount -a

    Sistem restart edildiğinde reboot programının çalıştırılması için aşağıdaki satır bulundurulabilir:

    ::restart:/sbin/reboot

    Bu durumda minimalist bir "/etc/inittab" dosyasını şöyle oluşturabiliriz:

    ::sysinit:/etc/init.d/rcS
    ::sysinit:/bin/mount -a
    ::sysinit:/bin/hostname -F /etc/hostname
    ::respawn:/bin/cttyhack /bin/ash

    Burada "/etc/init.d/rcS" dosyası içeriğini değiştirebileceğiniz bir script dosyasıdır. Şimdilik bu dosyayı içi boş olarak 
    yaratabilirsiniz. Bu script dosyası da isteğe bağlı olarak "/etc/rcS.d" dizinindeki script'leri çalıştırabilir. Tabii buradaki
    organizasyon tamamen sistem yöneticisinin isteğine göre oluşturulabilir. Burada SysVinit ile aynı işlemleri yapabilirsiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												52. Ders 15/10/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bu durumda BusyBox init sisteminin işleyişini şöyle özetleyebiliriz:

    1) Sistem boot edildiğinde çekirdeğin kendisi ya da geçici kök dosya sistemindeki script "/sbin/init" programını çalıştırıyor.

    2) BusyBox sisteminin "/sbin/init" programı çalıştırılıyor.

    3) BusyBox "init" programı "/etc/inittab" dosyasını okur ve oradaki yönergeleri çalıştırır.

    4) "/etc/inittab" dosyasında genellikle genellikle "/etc/init.d/rcS" isimli bir script çalıştırılır. Bu script de "/etc/rcS.d" 
    dizinindeki diğer script'leri çalıştırır. Tabii bunların hiçbiri zorunlu değildir. Yani "/etc/inittab" içerisinde "rcS" script'i 
    çalıştırılmayabilir. "rcS" script'i de"/etc/rcS.d" dizinindeki scriptleri çalıştırmayabilir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz yukarıda kök dosya sistemindeki "/etc/inittab" dosyasını minimal biçimde şöyle hazırlamıştık:

    ::sysinit:/etc/init.d/rcS
    ::sysinit:/bin/mount -a
    ::sysinit:/bin/hostname -F /etc/hostname
    ::respawn:/bin/cttyhack /bin/ash

    Burada doğrudan kabuk programını çalıştırdığımıza dikkat ediniz. Bize herhangi bir kullanıcı ismi ve parola sorulmamaktadır. 
    Pekiyi biz nasıl kullanıcı ismi ve parola ile girişi sağlayabiliriz? İşte bunun için geleneksel olarak UNIX/Linux sistemlerinde 
    şu yöntem izlenmektedir: Sistem yöneticisi "/etc/inittab" (ya da diğer init sistemlerinde başka konfigürasyon dosyalarında) 
    dosyasına "getty" isimli bir programın çalıştırılmasına ilişkin yönerge yerleştirir. "init" programı da bu "getty" programını
    çalıştırır. "getty" programının "agetty", "mingetty" gibi farklı sistemlerde farklı versiyonları bulunabilmektedir. Bu "getty"
    programı bir oturum yaratır. Sonra terminal aygıtını açar. Böylece oturumun "kontrol eden terminalini (controlling terminal)"
    oluşturur. Sonra ekrana "user name:" yazısını çıkartır. Klavyeden (stdin dosyasından) kullanıcı adını ister. Kullanıcı kullanıcı
    adını girince bu "getty" programı fork işlemi yapmadan, exec fonksiyonlarıyla "login" programını çalıştırır. "login" 
    programına kullanıcının girdiği kullanıcı ismini komut satırı argümanı yoluyla iletir. "login" programı kullanıcıdan parolayı
    ister. Girilen parolayı şifreleyerek "/etc/passwd" ya da "/etc/shadow" dosyalarındaki şifrelenmiş parolayla karşılaştırır. 
    Eğer parola uyuşuyorsa "/etc/passwd" dosyasında belirtilen programı yine fork uygulamadan exec fonksiyonlarıyla çalıştırır. 
    Bu program da genellikle (ama her zaman değil) kabuk programıdır. Kabuk programından "exit" komutuyla çıkıldığında "init" 
    programları genellikle aynı silsileyi yeniden başlatmaktadır. (SysVinit sisteminde "respawn" eyleminin bu işi yaptığını 
    anımsayınız.)

    init (fork/exec)---> getty (exec)---> login (exec)---> shell

    Burada kullanıcı isminin "getty" programı tarafından parolanın ise "login" programı tarafından sorulduğuna dikkat ediniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bilindiği gibi UNIX/Linux sistemlerinde her prosesin (yani çalışmakta olan programın) Proses Kontrol Bloğunda saklanan 
    "gerçek kullanıcı id'si (real user id)", "etkin kullanıcı id'si (effective user id)", "gerçek grup id'si (real group id)"
    ve "etkin grup id'si (effective group id)" vardır. Genellikle "gerçek id'lerle etkin id'ler aynı değerdedir. Dosya erişim 
    işleminde teste etkin id'ler sokulmaktadır. Okunabilirliği artırmak için kullanıcı id'leri kullanıcı isimleriyle, grup id'leri 
    grup isimleriyle eşleştirilmiştir. 0 numaralı kullanıcı id'si "root" ya da "super user" anlamına gelmektedir. Bu id'ye sahip 
    prosesler her türlü erişimleri yapabilirler. "sudo" ile program çalıştırırken aslında "sudo" ilgili programı 0 numaralı etkin
    kullanıcı id'si ile çalıştırmaktadır.

    "login" programı "getty" tarafından, "getty" ise "init" tarafından çalıştırıldığı için "login" programının etkin kullanıcı 
    id'si 0'dır. İşte login programı parola doğrulamasını yaparsa kabuk programını 0 numaralı etkin kullanıcı id'si ile değil
    "/etc/paswd" dosyasında belirtilen kullanıcı ve grup id'leriyle çalıştırmaktadır.

    "/etc/passwd" dosyası satırlardan oluşmaktadır. Her satır bir kullanıcının bilgilerini belirtmektedir. Kullanıcı bilgileri 
    ':' karakterleriyle ayrılmış 7 alandan oluşmaktadır. "/etc/passwd" dosyasının satırları aşağıdaki formattadır:

    <kullanıcı_adı>:<parola>:<UID>:<GID>:<GECOS>:<ev_dizini>:<çalıştırılacak_program>

    Birinci alanda kullanıcının ismi, ikinci alanda şifrelenmiş parolası, üçüncü ve dördüncü alanda gerçek ve etkin kullanıcı 
    ve grup id'leri, beşinci alanda kullanıcıya ilişkin şahsi bilgiler, yedinci alanda (con alanda) çalıştırılacak program, 
    altıncı alanda ise o programın çalışma dizini (current working directory) bulunmaktadır. Örnek bir satır şöyle olabilir:

    student::1001:1000::/home/student:/bin/bash

    Burada kullanıcının ismi "student" biçimindedir. Parola alanı boş olduğu için parola sorulmayacaktır. Kullanıcı id'si 1001, 
    grup id'si 1000'dir. Şahsi bilgiler bulundurulmamıştır. Parola doğrulanırsa "/bin/bash" programı çalıştırılacaktır. Bu 
    programın çalışma dizini de "/home/student" biçimindedir.

    Sistemdeki tüm gruplar "/etc/group" isimli bir dosyada tutulmaktadır. Bu dosyadaki her satır bir grubun bilgisini tutar. 
    Her satır 4 girişten oluşmaktadır. Satırların formatı şöyledir:

    <grup_adı>:<parola>:<GID>:<kullanıcı_listesi>

    Birinci alanda grubun ismi bulunur. İkinci alanda grup parolası bulunabilir. Üçüncü alanda grubun sayısal id'si tutulmaktadır. 
    Son alanda da virgüllerle ayrılmış gruba ek grup (supplementary groups) olarak kayıtlı olan kullanıcıların listesi tutulmaktadır.
    Örnek bir satır şöyle olabilir:

    study::1000:

    Burada grup ismi "study" biçimindedir. Grup parolası kullanılmamıştır. Grup id'si 1000'dir. Bu gruba ek grup olarak üye olan 
    kullanıcı yoktur.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aslında UNIX/Linux sistemlerinde yeni kullanıcı oluşturmak için tek yapılacak şey "/etc/passwd" ve "/etc/group" dosyalarına 
    satır eklemektir. Bu sistemlerde her kullanıcı için "/home" dizini altında bir dizin oluşturmak gelenekselleşmiştir. Bu 
    sistemlerde kullanıcı yaratmak için kullanılan "adduser" gibi "useradd" gibi komutlar da aslında "/etc/passwd" ve gerekirse
    "/etc/group" dosyalarına satır eklemektedir.

    İşte "login" programı önce kullanıcıdan parola ister. Eğer parolu doğru ise prosesin gerçek ve etkin kullanıcı ve group 
    id'lerini setuid ve setgid fonksiyonlarıyla "/etc/passwd" dosyasında belirtildiği gibi değiştirir. Sonra yine 
    "/etc/passwd" dosyasında belirtilen programı exec fonksiyonlarıyla çalıştırır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de BusyBox init sistemi için "getty" programının nasıl devreye sokulacağını açıklayalım. (burada kabukta BusyBox için 
    hazırladığımız kök dosya sisteminin kök dizininde bulunduğunu varsayıyoruz) Bunun için tek yapılacak şey aslında "etc/inittab" 
    dosyasında "getty" çalıştırılmasına yönelik bir satır eklemektir. Tabii biz böyle bir satırı ekleyeceksek artık getty bizi 
    sisteme sokacağına göre dosyadan kabuk programının çalıştırılmasına ilişkin satırı da kaldırmalıyız. "etc/inittab" "getty" 
    için dosyasına aşağıdaki satırı ekleyebiliriz:

    ttyS0::respawn:/sbin/getty -L ttyS0 115200 vt100

    Burada "ttyS0" satırın id değeridir. Bunun bir önemi yoktur. Eylem olarak "respawn" kullanıldığına dikkat ediniz. Böylece 
    biz kabuk programından exit ile çıktığımızda yeniden "getty" çalıştırılacaktır. Satırdaki diğer öğeler "getty" programının 
    komut satırı argümanlarıdır. "-L ttyS0" "getty" programının kullanacağı terminali belirtir. Biz uygulamamızda seri port 
    kullandığımız için buraya "ttyS0" argümanını yazdık. Sanal terminaller için burada "tty1", "tty2" gibi terminal isimleri 
    kullanılacaktır. Artık minimalist "etc/inittab" dosyasımız şöyle olacaktır:

    ::sysinit:/etc/init.d/rcS
    ::sysinit:/bin/mount -a
    ::sysinit:/bin/hostname -F /etc/hostname
    ttyS0::respawn:/sbin/getty -L ttyS0 115200 vt100

    Testimizi daha iyi yapabilmek için yeni bir kullanıcı da yaratabiliriz. Bunun için "etc/passwd" dosyasına aşağıdaki gibi 
    bir satır ekleyelim:

    kaan::1000:1000:Kaan Aslan:/home/kaan:/bin/ash

    Buradaki "kaan" kullanıcısının kullanıcı id'si 1000, grup id'si de 1000'dir. Yeni kullanıcılara ilişkin id'lerin 1000 
    başlatılması tavsiye edilmektedir. "etc/group" dosyasında da 1000 numaralı grup id'si için aşağıdaki gibi bir satır 
    oluşturabiliriz:

    study::1000:

    Şimdi kullanıcı için "home" dizinin altında bir dizin yaratmalıyız:

    $ sudo mkdir home/kaan

    Eğer bu işlemleri ana bilgisayarda yapacaksak komutları sudo ile çalıştırmak zorunda kalabiliriz. Yarattığımız dizinin kullanıcı 
    ve grup id'lerini kendi kullanıcı ve grup id'si biçiminde düzeltmek uygun olur:

    $ sudo chown 1000:1000 home/kaan

    Artık gerçek kök dosya sistemine geçildiğinde bizden kullanıcı ismi istenecektir. Biz "etc/passwd" dosyası içerisinde 
    parola alanını boş geçmiştik. Bu nedenle "login" programı bizden parola istemeyecektir. Tabii biz "passwd" komutuyla daha 
    sonra da parolamızı değiştirebiliriz.

    Artık bu kök dosya sistemini mikro SD karta kopyalayıp sistemi boot ettikten sonra gerçek kök dosya sistemine geçince Linux sistemlerinde 
    gördüğümüz klasik "user name/password"ekranıyla karşılaşacağız.

    Burada BusyBoox için dikkat edilmesi gereken bir nokta daha vardır. BusyBox'ta bütün komutlar aslında "/bin/busybox" programını
    çalıştırmaktadır. Oysa normal sistemlerde "su" gibi "passwd" gibi komutlara ilişkin çalıştırılabilir dosyaların "set-user-id"
    bayrakları set edilmiştir. O halde bizim "eğer root dışında bir kullanıcı ile çalışacaksak" "busybox programın set-user-id 
    bayrağını aşağıdaki gibi set etmeliyiz:

    $ sudo chmod u+s bin/busybox

    Tabii bu komutu uyguladığımız kullanıcıya göre sudo ile çalıştırmak durumunda kalabiliriz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												53. Ders 22/10/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bugün UNIX/Linux sistemlerinde en yaygın kullanılan init sistemi "systemd" isimli init sistemidir. Bu sistem klasik SysVinit
    ve Upstart init sistemlerinin bazı eksiklerini ve dezavantajlarını ortadan kaldırmak için geliştirilmiştir. Anımsanacağı gibi 
    Raspberry Pi'da en fazla kullanılan Linux dağıtımı olan "Raspberry Pi OS" ve BBB'deki default Debian imajı init sistemi 
    olarak "systemd" kullanmaktadır. systemd için iki kaynak kitap kursumuzun ebooks klasöründe bulunmaktadır:

    - Linux Service Management Made Easy with systemd (Donald A. Tevault)
    - Raspberry Pi OS System Administration with systemd (Özellikle 2. Bölüm) (Robert M. Koretsky)

    Konu ile ilgili Web'teki temel kaynaklar da şunlardır:

    - https://systemd.io/
    - https://0pointer.de/blog/projects/systemd-docs.html
    - https://wiki.debian.org/systemd/documentation
    - https://wiki.debian.org/systemd
    - https://docs.redhat.com/en/documentation/red_hat_enterprise_linux/7/html/system_administrators_guide/index (10. Bölüm)

    systemd init sistemi 2009 yılında geliştirildi ve Linux sistemlerinde Upstart init sisteminin yerini aldı. systemd init 
    sisteminin klasik SystemVinit sistemine göre şu olumlu özellikleri vardır:

    - Paralel Servis Başlatma, Daha Hızlı ve Verimli Açılış
    - Bağımlılık Yönetimi
    - Soket Temelli Aktivasyon
    - Kolay Servis Yönetimi
    - Taşınabilirlik
    - Log kayıtları

    Çekirdek akışı klasik SystemVinit programına devrettiğinde bu program "/etc/inittab" dosyasından hareketle script'lerle 
    belirtilen servisleri sırasıyla çalıştırmaktadır. Az sayıda servisin çalıştırıldığı sistemlerde bu durum probleme yol 
    açmasa da çok sayıda servisin çalıştırıldığı server sistemlerinde bu durum açılışın yavaşlamasına yol açmaktadır. İşte 
    systemd init sisteminde servisler mümkün olduğunca paralel biçimde (yani birisi başlatıldıktan sonra diğeri değil, beraber
    başlatılma durumu kastedilmektedir) başlatılmaktadır. Bu durum da servislerin daha hızlı bir biçimde hizmet edecek duruma 
    gelmelerine yol açmaktadır. systemd init sisteminde servislerin birbirlerine göre bağımlılıkları yönetilebilmektedir. Örneğin
    bir servisin çalışabilmesi için başka bir servisin yüklü olması gerekebilir. Klasik SystemVinit sisteminde otomatik bir 
    bağımlılık yönetimi yoktur. Sistem yöneticisi bu konuda script'lerle manuel kontrol sağlamaktadır. Soket temelli aktivasyon 
    belli bir etkinlikte belli bir soketin otomatik yaratılmasını sağlamaktadır. systemd init sisteminde servis yönetimi sistem 
    yöneticisi açısından daha kolaydır. Çünkü sistem yöneticisi script yazmak zorunda kalmaz. systemd yalnızca Linux sistemlerinde 
    değil BSD ve diğer UNIX türevi sistemlerde de aynı biçimde kullanılabilmektedir. systemd init sistemi yerine getirdiği ya da 
    getiremedi faaliyetler için log kayıtlarını kendisi tutmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Sistemimizde hangi init sisteminin yüklü olduğunu anlamanın birkaç yolu vardır. En basit yol "/sbin/init" dosyasına bakmaktır:

    $ ls /sbin/init -l
    lrwxrwxrwx 1 root root 20 Jun 18 14:55 /sbin/init -> /lib/systemd/systemd

    Görüldüğü gibi buradaki "init" programı aslında "systemd" init programına sembolik bağlantı yapılmıştır. Ya da örneğin "ps" 
    komutunu "-p 1" seçeneği ile kullanarak da çalışmakta olan "init" programını görebiliriz:

    $ ps -p 1
    PID TTY          TIME CMD
    1 ?        00:00:11 systemd

    Buradan systemd init sisteminin çalışmakta olduğu anlaşılmaktadır.
 -----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    systemd init sisteminde "birim dosyaları (unit files)" en önemli unsurlardır. Sistem yöneticisi istediği işlem için bir 
    "birim dosyası" oluşturur. Onu belli bir dizine yerleştirir. Sonra da onun işleme sokulmasını ister. Birim dosyaları çeşitli 
    sınıflara ayrılmaktadır. En çok kullanılan birim dosyaları şunlardır:

    - Service unit dosyası (.service)
    - Socket unit dosyası (.socket)
    - Slice unit dosyası (.slice)
    - Mount ve Automount unit dosyası (.mount, .automount)
    - Target unit dosyası (.target)
    - Timer unit dosyası (.timer)
    - Nework unit dosyası (.network)
    - Path unit dosyası (.path)
    - Swap unit dosyası (.swap)

    Görüldüğü gibi her birim dosyasının farklı bir uzantısı vardır. systemd init programı birim dosyalarını sırasıyla aşağıdaki 
    dizinlerde aramaktadır:

    /etc/systemd/system
    /run/systemd/system
    /lib/systemd/system
    /usr/lib/systemd/system
    /usr/local/lib/systemd/system

    systemd programı "--system" ya da "--user"" komut satırı seçeneği ile başlatılabilir. Burada belirttiğimiz arama sırası 
    default olan "--system" seçeneği ile uygulanan sıradır.

    Bu amaçla en fazla kullanılan dizin "/lib/systemd/system" dizinidir. Bu dizin genellikle sistemin kurulumu sırasında oluşturulan 
    temel birim dosyalarını barındırır. Kullanıcılar genellikle birim dosyalarını "/etc/systemd/system" dizini içerisine 
    yerleştirirler.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bir birim dosyası (unit file) bölümlerden (sections) bölümler de "direktif=değer" satırlarından oluşmaktadır. ('=' karakterinin 
    iki tarafında boşluk bırakılmamaktadır.) Bölümler köşeli parantezler içerisinde belirtilmektedir. Formatın Windows sistemlerinde 
    eskiden kullanılan ".ini" dosya formatına benzediğine dikkat ediniz. Örneğin bir birim dosyası şöyle olabilir:

    [Unit]
    Description=OpenBSD Secure Shell server
    Documentation=man:sshd(8) man:sshd_config(5)
    After=network.target auditd.service
    ConditionPathExists=!/etc/ssh/sshd_not_to_be_run

    [Service]
    EnvironmentFile=-/etc/default/ssh
    ExecStartPre=/usr/sbin/sshd -t
    ExecStart=/usr/sbin/sshd -D $SSHD_OPTS
    ExecReload=/usr/sbin/sshd -t
    ExecReload=/bin/kill -HUP $MAINPID
    KillMode=process
    Restart=on-failure
    RestartPreventExitStatus=255
    Type=notify
    RuntimeDirectory=sshd
    RuntimeDirectoryMode=0755

    [Install]
    WantedBy=multi-user.target
    Alias=sshd.service

    Birim dosyalarındaki köşeli parantez içerisinde belirtilen bölümler birim dosyasının türüne göre (service, mount gibi)
    farklılık gösterebilmektedir. Bazı bölümler geneldir ve her türden birim dosyasında bulunabilmektedir. Hangi türden birim
    dosyasında hangi bölümlerin olduğu dokümanlardan öğrenilmelidir. Benzer biçimde bölümler içerisindeki direktifler de o birim 
    dosyasına ve bölüme özgüdür. Yani biz istediğimiz gibi bölüm ve direktif oluşturamayız. Bu nedenle birim dosyalarının yazımı 
    ve işlevi tür tür ele alınarak incelenmelidir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    En temel birim dosyalarından biri "hedef birim (target unit)" dosyalarıdır. Bu birim dosyalarının uzantıları ".target" biçimindedir.
    Genellikle bu birim dosyası ile aynı isimli sonu ".wants" ile biten dizinler de bulundurulmaktadır. Örneğin "/lib/systemd/system"
    dizini içerisinde aşağıdaki gibi iki "hedef birim (target unit) dosyası" ve dizini bulunmaktadır:

    $ ls -ld graphical.target graphical.target.wants
    -rw-r--r-- 1 root root  606 Mar 11  2022 graphical.target
    drwxr-xr-x 2 root root 4096 Mar 19  2024 graphical.target.wants

    Hedef birim dosyaları SystemVinit init sistemindeki "run level" kavramının yaptığı işlevi yerine getirmektedir. Yani bu 
    hedef birim dosyaları sistemin belli bir konfigürasyonda açılmasını sağlamaktadır. Genellikle eski SystemVinit sistemleri ile 
    uyumu korumak için eski "run level" kategorilerinin işlevini yerine getiren sembolik bağlantılar da oluşturulmuştur:

    $ ls -ld run*.target
    lrwxrwxrwx 1 root root 15 Kas 21  2023 runlevel0.target -> poweroff.target
    lrwxrwxrwx 1 root root 13 Kas 21  2023 runlevel1.target -> rescue.target
    lrwxrwxrwx 1 root root 17 Kas 21  2023 runlevel2.target -> multi-user.target
    lrwxrwxrwx 1 root root 17 Kas 21  2023 runlevel3.target -> multi-user.target
    lrwxrwxrwx 1 root root 17 Kas 21  2023 runlevel4.target -> multi-user.target
    lrwxrwxrwx 1 root root 16 Kas 21  2023 runlevel5.target -> graphical.target
    lrwxrwxrwx 1 root root 13 Kas 21  2023 runlevel6.target -> reboot.target

    systemd init sistemi ile sistem açıldığında default bir hedef birimin yönergeleri işletilmektedir. Örneğin default hedef 
    "graphical.target" ise bu durum sistemin XWindow sistemi ile grafik arayüze sahip bir biçimde açılacağını belirtmektedir. 
    Default hedefi SystemVinit sistemindeki default run level'a benzetebiliriz. Aslında bu init sistemi açılışta "default hedef
    birim" dosyasından hareketle default hedefi belirlemektedir. Default hedef de "default.target" isimli dosya ile belirlenmektedir. 
    Bu dosya da asıl hedef birim dosyasına sembolik link yapılmıştır:

    $ ls -l default.target
    lrwxrwxrwx 1 root root 16 Kas 21  2023 default.target -> graphical.target
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    systemd init sistemi yalnızca "systemd" init programından oluşmamaktadır. Bu sistemde sistem yöneticileri için bazı yardımcı
    (utility) programlar da bulundurulmuştur. Bu programların en önemlisi "systemctl" isimli programdır. Biz bu yardımcı programlar 
    için "komut" terimini de kullanacağız. Sistem yöneticisi pek çok işlemi manuel olarak değil bu "systemctl" komutunu kullanarak 
    yapar. "systemctl" dışındaki diğer önemli komutlar şunlardır:

    journalctl
    timedatectl
    loginctl
    hostnamectl
    nmcli

    Ancak en önemli işlemler yukarıda da belirttiğimiz gibi "systemctl" komutu ile yapılmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Sistemin default hedef birimi "systemctl get-default" komutu ile öğrenilebilir. Örneğin:

    $ systemctl get-default
    graphical.target

    Tüm hedef birimlerin listesi de "systemctl list-units -t target" komutu ile elde edilmektedir. Örneğin:

    $ systemctl list-units -t target
    UNIT                   LOAD   ACTIVE SUB    DESCRIPTION
    basic.target           loaded active active Basic System
    cryptsetup.target      loaded active active Local Encrypted Volumes
    getty.target           loaded active active Login Prompts
    graphical.target       loaded active active Graphical Interface
    local-fs-pre.target    loaded active active Preparation for Local File Systems
    local-fs.target        loaded active active Local File Systems
    multi-user.target      loaded active active Multi-User System
    network-online.target  loaded active active Network is Online
    network-pre.target     loaded active active Preparation for Network
    network.target         loaded active active Network
    nss-lookup.target      loaded active active Host and Network Name Lookups
    nss-user-lookup.target loaded active active User and Group Name Lookups
    paths.target           loaded active active Path Units
    remote-fs.target       loaded active active Remote File Systems
    slices.target          loaded active active Slice Units
    sockets.target         loaded active active Socket Units
    swap.target            loaded active active Swaps
    sysinit.target         loaded active active System Initialization
    time-set.target        loaded active active System Time Set
    timers.target          loaded active active Timer Units
    veritysetup.target     loaded active active Local Verity Protected Volumes
    zfs-import.target      loaded active active ZFS pool import target

    Default hedef birimi değiştirmek için "systemctl set-default <name>.target" komutu kullanılır. Örneğin:

    $ sudo systemctl set-default multi-user.target

    multi-user.target SysemVinit sistemindeki "runlevel 4"e karşılık geşmektedir. Bu hedef ile sistemi başlattığımızda sistem 
    tamamen text modda açılacaktır. Dolayısıyla bu hedef tipik olarak server sistemlerinin kullandığı hedeftir. (Server sistemleri
    genellikle grafik arayüze sahip olmazlar. Grafik arayüz onların çalışmasını yavaşlatabilmekte ve gereksiz bir kaynak harcamasına 
    yol açabilmektedir.)

    Default hedefi kalıcı olarak değiştirmeden o anda hedefi işletmek için "systemctl isolate <name>.target" komutu kullanılabilir. 
    Örneğin:

    $ sudo systemctl isolate multi-user.target

    Aşağıda klasik SystemVinit komutlarının systemctl karşılıkları verilmiştir:

    halt                    systemctl halt
    poweroff                systemctl poweroff
    reboot                  systemctl reboot
    pm-suspend              systemctl suspend
    pm-hibernate            systemctl hibernate
    pm-suspend-hybrid       systemctl hybrid-sleep

    Tabii aslında yukarıdaki klasik SystemVinit sistemlerinde bulunan açma kapatma komutları artık systemctl programına sembolik
    link yapılmıştır. Yani biz systemd sistemlerinde bu eski komutları kullanmaya devam edebiliriz. Örneğin:

    $ ls -l /usr/sbin/reboot
    lrwxrwxrwx 1 root root 14 Kas 21  2023 /usr/sbin/reboot -> /bin/systemctl
    $ ls -l /usr/sbin/shutdown
    lrwxrwxrwx 1 root root 14 Kas 21  2023 /usr/sbin/shutdown -> /bin/systemctl
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Girişte de belirttiğimiz gibi "systemd"" init sisteminde "bağımlılık yönetimi" olgusu vardır. Bağımlılık yönetimi "bu servis 
    çalıştırılırsa şu servis de çalıştırılsın", "bu servis şu servis çalıştırılıyorsa çalıştırılsın" demenin bir yöntemidir. 
    Bunu uygulamak için tipik olarak aşağıdaki direktifler kullanılmaktadır. (Direktifler ve bölümlerdeki isimlerin büyük harf 
    küçük harf duyarlılığı yoktur):

    WantedBy        [install]
    RequiredBy      [install]
    Wants           [unit]
    Requires        [unit]

    Biz burada ikinci sütuna bu direktiflerin hangi bölüm içerisinde kullanılabileceğini belirttik. Burada "by" soneki olmayan 
    direktifler ("Wants", "Requires") "bu birimi çalıştıracaksan direktifte belirtilen birimi de çalıştırmalısın" anlamına 
    gelmektedir. "By" soneki olan direktifler ("WantedBy", "RequiredBy") ise "eğer direktifte belirtilen birimi çalıştırıyorsan 
    bu birimi de çalıştırmalısın" anlamına gelmektedir. Yani By'sız direktiflerle By'lı direktifler ters yönlüdür. Pekiyi "want" 
    ile "require" arasında ne fark vardır? İşte "require" katı bir istek, "want" ise "zayif bir istek belirtmektedir. İstek
    "require" ile belirtilmişse eğer bu istek karşılanmazsa ilgili birimin çalıştırılması gerçekleştirilmez. Ancak istek "want"
    ile belirtilmişse istek karşılanmasa bile ilgili birim çalıştırılır. Örneğin A birim dosyasında "Wants" ile B birimi belirtilmiş 
    olsun. Bu durumda A çalıştırılırken eğer B bir nedenden dolayı çalıştırılamazsa A yine çalıştırılır. A birim dosyasında "Required" 
    ile B belirtilmişse bu durumda B çalıştırılamazsa A servisi de çalıştırılmaz. Aynı durum ters yönde "WantedBy" ve "RequiredBy" 
    için de geçerlidir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												54. Ders 24/10/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Birimlerin çalıştırılmasında öncelik-sonralık ilişkisi de kurulabilmektedir. Eğer böyle bir ilişki belirtilmediyse "systemd"
    ilgili birimleri paralel bir biçimde çalıştırmaktadır. Öncelik sonralık ilişkisi için "Before" ve "After" biçiminde iki 
    direktif bulundurulmuştur. Before direktifi "içinde bulunulan birim direktifte belirtilen birimden önce", After direktifi 
    ise "içinde bulunulan birim direktifte belirtilen birimden sonra çalıştırılacak" anlamına gelmektedir. Before ve After direktifleri 
    [Unit] bölümü içerisinde bulunabilir. Örneğin:

    [Unit]
    Description=The nginx HTTP and reverse proxy server
    After=network.target
    [Service]
    Type=forking
    PIDFile=/run/nginx.pid
    ExecStartPre=/usr/sbin/nginx -t
    ExecStart=/usr/sbin/nginx
    ExecReload=/bin/kill -s HUP $MAINPID
    ExecStop=/bin/kill -s QUIT $MAINPID
    [Install]
    WantedBy=multi-user.target

    Burada bir "servis birim (service unit)" dosyası örneği verilmiştir. Buna göre önce "network.target" isimli birim çalıştırılacak
    sonra bu servis çalıştırılacaktır.

    Pekiyi bizim After ya da Before ile "bizden önce çalıştırılsın ya da sonra çalıştırılsın" biçiminde bir belirleme yaptığımızı 
    ancak buradaki birimler için "require" ya da "want" ile bir bellirleme yapmadığımızı varsayalım, bu durumda ne olacaktır? 
    İşte bu durumda yalnızca After ya da Before "eğer bu direktifte belirtilen birim çalıştırılırsa önce ya da sonra çalıştırılsın" 
    anlamına gelmektedir. Yani bu direktifte belirtilen birimler çalıştırılmazsa bu direktiflerin bir anlamı kalmamaktadır. İlgili 
    birim yine çalıştırılacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Hedef birim dosyaları bir durum karşısında çalıştırılan dosyalardır. Diğer birim dosyaları hep hedef birim dosyaları 
    çalıştırıldığında bir biçimde çalıştırılmaktadır. Hedef birim dosyalarıyla aynı isimli ".wants" uzantılı dizinler olduğunu
    belirtmiştik. İşte bu dizinler içerisinde ilgili hedef çalıştırıldığında devreye girecek olan birimler belirtilmektedir. Örneğin
    "multi-user.target" hedefi için "multi-user.tartget.wants" dizini bulunmaktadır. systemd bir hedef birimi işletirken onun 
    ".wants" dizinindeki birimleri çalıştırmaktadır. O halde sistem yöneticisi belli bir hedef için belli bir birimi çalıştırmak 
    istiyorsa o birimi o hedefin ".wants" dizinine yerleştirmelidir. Ancak hemen her zaman sistem yöneticisi bunu yapmak yerine 
    kendi birim dosyasını "/etc/systemd/system" ya da "/lib/systemd/system" dizinlerine yerleştirip ilgili ".wants" dizinininde 
    bu birim dosyasına ilişkin bir sembolik link oluşturmaktadır. Özetlersek sistemin işleyişinin aşamaları şöyledir:

    systemd belli bir hedefi çalıştırmak istiyor ----> hedefin ".wants" dizinine bakıp oradaki birimleri çalıştırıyor ---> 
    ".wants" dizininde birim dosyalarının kendileri değil sembolik bağlantıları var, bunların kendileri "/etc/systemd/system" 
    ya da "/lib/systemd/system" içerisinde bulunuyor.

    Örneğin biz bir servis (daemon) yazmış olalım ve bu servisin boot sırasında devreye girmesini isteyelim. Servisimiz için 
    için servis birim dosyasını "myservice.service" ismiyle şöyle oluşturulmuş olalım:

    [Unit]
    Description=My Service
    [Service]
    Type=simple
    ExecStart=/usr/local/bin/myserviced
    [Install]
    WantedBy=multi-user.target

    Burada "myservice.service" dosyasını "/etc/systemd/system" dizini içerisine yerleştirip ilgili hedefin dizininde bu dosyaya 
    sembolik bağlantı oluşturmamız gerekir.

    Aslında ilgili birim dosyasını "/etc/systemd/system" dizini içerisine yerleştirip sembolik bağlantıyı manuel oluşturmak yerine
    bu işlemi "systemctl" komutuna da yaptırabiliriz. "systemctl" komutunun iki argümanı vardır:

    systemctl enable <birim_dosyasının_ismi>
    systemctl disable <birim_dosyasının_ismi>

    Enable işlemi servis birim dosyasını inceleyip sentaks hatalarını görüntüler ve onun için sembolik bağlantıyı ilgili hedefin
    ".wants" dizinine yerleştirmektedir. Disable işlemi ise ".wants" dizinindeki sembolik bağlantıyı yok etmektedir. Tabii "enable 
    işleminde "systemctl" komutunun ilgili birim dosyasını inceleyip oradaki "want" ve "require" direktiflerini dikkate alarak 
    ilgili sembolik bağlantıları birim dosyasında belirtilen hedeflerin ".wants" dizinlerine yerleştirdiğine dikkat ediniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aslında hedef birimler (target units) birbirinden bağımsız değil, birbirini gerektirecek biçimde oluşturulmuştur. Örneğin 
    aslında sistemimiz "graphical.target" ile açıldığında bu durum "mult-user.target" hedefinin de çalıştırılmasını gerektirmektedir. 
    Buradaki temel "Requires" ilişkisi şöyledir:

    graphical.target ---> multi-user.target ---> basic.target ---> sysinit.target

    ilgili hedef birim dosyalarında bu "Requires" direktifinde belirtilen hedefler "After" olarak belirtilmiştir. Dolayısıyla 
    aslında bu hedeflerin çalıştırılması ters sırada şöyle yapılacaktır:

    sysinit.target ---> basic.target ---> multi-user.target ---> graphical.target

    Yukarıdaki vermiş olduğumuz örnek servis birim dosyasına bir kez daha dikkat ediniz:

    [Unit]
    Description=My Service
    [Service]
    Type=simple
    ExecStart=/usr/local/bin/myserviced
    [Install]
    WantedBy=multi-user.target

    Burada biz sistemi "graphical.target" ile de başlatsak, "multi-user.target" ile de başlatsak servisimiz devreye girecektir. 
    Ancak "basic-target" ile başlatırsak servisimiz devreye girmeyecektir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi biz bir servis birim dosyası oluşturup onun üzerinde birtakım işlemler yapalım. Servis birim dosyamız yine "myservice.service"
    biçiminde olsun. Yukarıdaki basit dosyanın aynısını kullanalım:

    [Unit]
    Description=My Service
    [Service]
    Type=simple
    ExecStart=/usr/local/bin/myserviced
    [Install]
    WantedBy=multi-user.target

    Bu servis birim dosyamızı "/etc/systemd/system" dizinine çekelim:

    $ sudo cp myservice.service /etc/systemd/system

    Burada çalıştırılacak servis programı ExecStart direktifi ile belirtilmektedir. Biz bu direktifte servis programının aşağıdaki
    yol ifadesinde bulunduğunu belirttik:

    ExecStart="/usr/local/bin/myserviced"

    O halde bizim örnek için "myserviced" isimli bir servis programı oluşturup onu "/usr/local/bin" dizinine çekmemiz gerekir. 
    Normal olarak servis programları (daemon'lar) bazı adımlardan geçilerek oluşturulmaktadır. Bu adımlar bu servis programlarının
    terminalden çalıştırılabilmesini sağlamaktadır. Ancak eğer biz "systemd" init sistemini kullanıyorsak bu adımları zaten 
    bizim için "systemd" yapmaktadır. Dolayısıyla biz örneğimizde normal bir C programı yazar gibi servis programımızı yazabiliriz. 
    Aslında servis programları bu bağlamda bir shell script olarak da yazılabilir. Servimize ilişkin C programı şöyle olsun:

    /* myserviced.c */

    #include <stdio.h>
    #include <unistd.h>

    int main(void)
    {
        for (int i = 0;;++i) {
            printf("Step: %d\n", i);
            fflush(stdout);
            sleep(10);
        }

        return 0;
    }

    Servis programları UNIX/Linux sistemlerinde geleneksel olarak "d" sonekiyle isimlendirilmektedir. Bu programı aşağıdaki 
    gibi derleyebiliriz:

    $ gcc -o myserviced myserviced.c

    Şimdi programı "/usr/local/bin" dizinine çekelim:

    $ sudo cp myserviced /usr/local/bin

    Artık temel işlemleri yaptık. Ancak servisimizin nasıl devreye gireceğini de belirlememiz gerekir. Bir servisi komut satırından
    "systemctl start <servis_birim_dosyası_ismi>" komutuyla başlatıp, "systemctl stop <servis_ismi.service>" komutuyla sonlandırabiliriz. 
    Örneğin:

    $ sudo systemctl start myservice.service

    Pekiyi bizim program içerisinde printf ile stdout dosyasına yazdırdığımız şeylere ne olacaktır? Servis programlarının bir
    terminal bağlantısının olmadığını belirtmiştik. İşte "systemd" programı bizim servisimizi çalıştırırken default olarak stdout
    dosyasını kendi "journaling log" dosyasına yönlendirmektedir. Yani bizim servis programında ekrana yazdığımız şeyler default 
    durumda log mekanizmasına dahil edilmektedir. Biz de bunları "journalctl -u <servis_birim_dosyası_ismi>" komutu ile görüntüleyebiliriz. 
    "journalctl" komutunun komut satırı argümanları da vardır. Örneğin "-n <sayı>" seçeneği log dosyasındaki son n satırı görüntülemek 
    için, "-f" seçeneği gerçek zamanlı görüntüleme yapmak için kullanılmaktadır. Örneğin:

    $ journalctl -n 10 -u myservice.service
    Eki 24 22:29:50 kaan-virtual-machine myserviced[1986]: Step: 126
    Eki 24 22:30:00 kaan-virtual-machine myserviced[1986]: Step: 127
    Eki 24 22:30:10 kaan-virtual-machine myserviced[1986]: Step: 128
    Eki 24 22:30:20 kaan-virtual-machine myserviced[1986]: Step: 129
    Eki 24 22:30:30 kaan-virtual-machine myserviced[1986]: Step: 130
    Eki 24 22:30:40 kaan-virtual-machine myserviced[1986]: Step: 131
    Eki 24 22:30:50 kaan-virtual-machine myserviced[1986]: Step: 132
    Eki 24 22:31:00 kaan-virtual-machine myserviced[1986]: Step: 133
    Eki 24 22:31:10 kaan-virtual-machine myserviced[1986]: Step: 134
    Eki 24 22:31:20 kaan-virtual-machine myserviced[1986]: Step: 135

    Çalışan servisimizi şöyle durdurabiliriz:

    $ sudo systemctl stop myservice.service

    Genellikle servis programları çalışmaya başlayınca bazı konfigürasyon dosyalarını okumaktadır. Sistem yöneticisi de bu 
    konfigürasyon dosyalarında değişiklik yaptığında bu değişikliğin servis tarafından görülmesini sağlamak için onu restart 
    eder. Restart işlemi "systemctl restart <servis_birim_dosyası_ismi>" komutuyla yapılmaktadır. Örneğin:

    $ sudo systemctl restart myservice.service

    Pekiyi restart önce stop sonra start anlamına mı gelmektedir? İşte aslında her zaman bu anlama gelmek zorunda değildir. 
    İnit programları restart işlemi sırasında ilgili servis prosesine SIGHUP sinyali gönderir. Servis programları da bu 
    sinyal oluştuğunda sanki restart işlemi yapılıyormuş gibi ilgili konfigürasyon dosyalarını yeniden okuyabilirler. Tabii 
    bu sinyal işlenmemişse gerçekten proses sonlandırılır. Bu durumda init programları onları yeniden çalıştırmaktadır.

    Aslında start, stop ve restart yalnızca servis birimleri ile değil diğer bazı birimlerle de kullanılabilmektedir. Örneğin 
    bir hedef (target) birim de start edilebilir, stop edilebilir ve restart edilebilir.

    Şimdi buradaki servis birim dosyasının boot sırasında otomatik devreye girmesini sağlayalım. Bu işlemi "systemctl enable 
    <servis_birim_dosyası_ismi>" komutu ile yapabiliriz:

    $ sudo systemctl enable myservice.service

    Bu komut uygulandığında önce systemctl bir servis birim dosyası üzerinde bir sentaks kontrolü uygulayacak sonra da 
    "multi-user.target.wants" dizininde bir sembolik bağlantı dosyası oluşturacaktır. Artık makinemiz reboot edildiğinde bu 
    servis eğer default hedef "graphical.target" ya da "multi-user.target" ise otomatik devreye girecektir. Servisimizi boot 
    sırasında devreden çıkartmak için "systemctl disable <servis_birim_dosyası_ismi>" komutu kullanılmaktadır:

    $ sudo systemctl disable myservice.service
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												55. Ders 31/10/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirttiğimiz gibi birim dosyalarındaki bölümlerde kullanılan direktiflerle ilgili pek çok ayrıntı vardır. Biz 
    yukarıda servis birim dosyasını şöyle oluşturmuştuk:

    [Unit]
    Description=My Service
    [Service]
    Type=simple
    ExecStart=/usr/local/bin/myserviced
    [Install]
    WantedBy=multi-user.target

    Buradaki [Service] bölümü içerisindeki "ExecStart" direktifi servis programının yol ifadesini belirtmektedir. Yani başka bir 
    deyişle bu servis birim dosyası çalıştırıldığında çalıştırılacak programı belirtmektedir. Bazen servis durdurulurken de bazı 
    programların çalıştırılması istenebilir. Bunun için de "ExecStop" direktifi kullanılmaktadır. Benzer biçimde servis restart 
    edildiğinde de ayrıca bir programın çalıştırılması "ExecRestart" direktifiyle sağlanabilmektedir. Yine aynı bölümde 
    "WorkingDirectory" direktifi ile servis programının çalışma dizini (current working directory) belirlenebilir "StandardInput", 
    "StandardOutput" ve "StandardError" direktifleri ile de servis programının stdin, stdout ve stderr dosyalarının nereye 
    yönlendirileceği belirtilebilmektedir. (Default olarak bu direktifler kullanılmazsa yönlendirme "journaling log" sistemine 
    yapılmaktadır.)
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Sistem açıldığında default hedeften (default target) hareketle işlemlerin yapıldığını belirtmiştik. Hedeflerin de ayrık 
    değil birbirine bağlı biçimde oluşturulduğunu anımsayınız. İşte biz de istersek kendi hedeflerimizi oluşturturabiliriz. 
    Örneğin biz "mytarget.target" isimli bir hedef birim oluşturup bu hedefte "myservice.service" biriminin çalıştırılmasını 
    sağlayalım. "mytarget.target" birimi de "multi-user.target" birimi çalıştırıldığı zaman çalıştırılacak olsun. Bu işlemi 
    şu adımlardan geçerek gerçekleştirebiliriz:

    1) "mytarget.target" birim dosyasını minimal olarak aşağıdaki gibi oluşturabiliriz:

    [Unit]
    Description=My Target
    [Install]
    WantedBy=multi-user.target

    Burada [install] bölümünde bu hedef birim dosyasının "multi-user.target" hedefi ile ilişkilendirildiğini görüyorsunuz.

    2) "myservice.service" birim dosyasının "mytarget.target" ile ilişkilendirilmesi gerekir. Dosya şöyle oluşturulabilir:

    [Unit]
    Description=MyService
    [Service]
    Type=simple
    ExecStart=/usr/local/bin/myserviced
    [Install]
    WantedBy=mytarget.target

    Burada [Install] bölümü içerisinde WantedBy direktifi ile ilişkilendirmenin yapıldığını görüyorsunuz.

    3) Şimdi iki birimi de enable etmemiz gerekir:

    $ sudo systemctl enable mytarget.target
    Created symlink /etc/systemd/system/multi-user.target.wants/mytarget.target → /etc/systemd/system/mytarget.target.
    $ sudo systemctl enable myservice.service
    Created symlink /etc/systemd/system/mytarget.target.wants/myservice.service → /etc/systemd/system/myservice.service.

    4) Artık "mytarget.target" birimini start ve stop edip test işlemini yapabiliriz. Örneğin:

    $ sudo systemctl start mytarget.target

    Tabii artık reboot yapıldığında da "mytarget.target" dolayısıyla da "myservice.service" çalıştırılacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Hedef ve servis birim dosyalarının dışında çok kullanılan bir birim dosyası da mount birim dosyasıdır. Bu mount birim dosyası 
    tipik olarak sistem açıldığında birtakım dosya sistemlerinin otomatik mount edilmesini sağlamak için kullanılmaktadır. Gerçi 
    daha önce de belirttiğimiz gibi "systemd" init sisteminde standart bazı hedeflerin çalıştırdığı programlar "mount -a" komutuyla
    "/etc/fstab" dosyasındaki mount işlemlerinin yapılmasına yol açmaktadır. Yani biz "systemd" init sisteminde de aslında 
    "/etc/fstab" dosyasından hareketle otomatik mount işlemlerini yapabiliriz. Ancak mount birimi bize daha fazla olanaklar sunmaktadır.

    Bir mount birim dosyasının tipik içeriği aşağıdaki gibidir:

    [Unit]
    Description=Mount my external drive
    After=multi-user.target
    [Mount]
    What=/dev/sdb1
    Where=/mnt/external
    [Install]
    WantedBy=multi-user.target

    Burada mount birimi için önemli olan asıl bölüm [Mount] isimli bölümdür. Bu bölümde "What" direktifi mount işleminde kullanılacak 
    blok aygıtını "Where" direktifi ise mount noktasını belirtmektedir. Ancak mount birim dosyalarının isimleri mount noktasıyla
    ilişkili olacak biçimde tirelenerek verilmelidir. tireleme her dizin geçişi arasında bir '-' karakteri kullanılarak yapılmalıdır. 
    Örneğin yukarıdaki mount birim dosyasının ismi "mnt-external.mount" biçiminde olmalıdır. Ya da örneğin mount noktası 
    "/home/kaan/Study/EmbeddedLinux/fat16" ise bizim de mount birim dosyasının ismini "home-kaan-Study-EmbeddedLinux-fat16.mount"
    biçiminde vermemiz gerekir.

    Yukarıdaki gibi bir mount birim dosyası oluşturduğumuzda artık onu "systemctl" komutu ile start ve stop edebiliriz. Start 
    işlemi mount işlemini gerçekleştirecek stop işlemi de unmount işlemini gerçekleştirecektir. Örneğin:

    $ sudo systemctl start mnt-external.mount
    $ sudo systemctl stop mnt-external.mount

    Tabii bizim asıl amacımız sistem açıldığında otomatik mount işleminin gerçekleştirilmesidir. Örneğimizde bu mount birimi 
    "multi-user.target" ile ilişkilendirilmiştir. Bizim yine bu mount biriminin boot sırasında devreye girmesini sağlamak için 
    enable işlemini yapmamız gerekir. Örneğin:

    $ sudo systemctl enable mnt-externel.mount
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												56. Ders 05/11/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi biz loop aygıtını kullanarak mount işleminin mount birimi tarafından yapılmasını nasıl sağlayabiliriz? Buradaki 
    sorun mount biriminin çalıştırılması öncesinde "losetup" gibi bir işlemin de yapılması zorunluluğudur. İşte bunu sağlayabilmek 
    için mount birimine ek olarak bir de servis birim dosyasının oluşturulması ve mount birimi çalıştırıldığında servis biriminin 
    de mount biriminden önce çalıştırılması gerekir. Bu sırada servis birimi "losetup" programı ile loop aygıtını kullanıma hazır 
    hale getirecektir. Örneğin loop0 aygıtı için mount birimi şöyle oluşturulabilir:

    # mnt-fat16.mount (mount point: /mnt/fat16)

    [Unit]
    Description=Mount Loop Device
    Requires=loop0.service
    After=loop0.service
    [Mount]
    What=/dev/loop0
    Where=/mnt/fat16
    [Install]
    WantedBy=multi-user.target

    Burada Requires direktifinde "loop0.service" dosyası belirtilmiştir. "After" direktifinde de önce bu servis dosyasının 
    çalıştırılması gerektiği belirtilmektedir. Birimimizin "Install" bölümünde birimimiz "multi-usr.target" birimi ile 
    ilişkilendirilmiştir. Bu birimden anlamamız gereken "/dev/loop0" aygıtının "/mnt/fat16" noktasına mount edileceği ancak bu 
    işlemden önce "loop0.service" biriminin çalıştırılacağıdır. Burada mount birimine bağlı olan service biriminde de bazı 
    direktiflerin yerleştirilmesi gerekmektedir. Bu service birimi aşağıdaki gibi olabilir:

    [Unit]
    Description=loop0-Service
    BindsTo=mnt-fat16.mount
    Before=mnt-fat16.mount
    [Service]
    Type=simple
    ExecStart=/sbin/losetup /dev/loop0 /mnt/fat16.dat
    ExecStop=/sbin/losetup -d /dev/loop0
    RemainAfterExit=yes
    [Install]
    WantedBy=multi-user.target

    Burada kritik iki direktif vardır. "RemainAfterExit" ve "BindsTo" direktifleridir. Buradaki "BindsTo" direktifi mount birimi 
    ile servis biriminin birbirine bağlı olduğunu belirtmektedir. Yani bunlardan biri çalıştırılır ya da durdurulursa diğeri de 
    çalıştırılıp durdurulacaktır. "RemainAfterExit" eğer "yes" yapılmazsa bu servis çalıştırıldıktan sonra hemen bitiminde "ExecStop" 
    çalıştırılır ve istediğimiz şey gerçekleşmez. Buradaki "RemainAfterExit=yes" direktifi servis çalıştırıldıktan sonra "stop" 
    yapılana kadar ExecStop direktifinde belirtilen programın çalıştırılmamasını sağlamaktadır.

    Pekiyi servis birim dosyasında "Requires" ile mount birim dosyası belirtildiği halde (diğerinde de diğeri belirtildiği 
    halde) neden hala "BindsTo" direktifine gereksinim duyulmaktadır? İşte require ve want direktifleri "çalıştırma için" için 
    bağımlılık belirtmektedir. Durdurma için bağımlılık belirtmemektedir. "BindsTo" direktifi "durdurma için de bağımlılık" 
    belirtir. Eğer biz yukarıdaki örnekte servis birim dosyasındaki "BindsTo" direktifini kaldırırsak bu birimlerin çalıştırılmasında
    bir sorun oluşmaz. Ancak bu birimlerden biri durudurulmak istendiğinde yalnızca durdurulmak istenen birim durdurulur, diğeri 
    durdurulmaz. "BindsTo" direktifi diğerinin de durdurulmasını sağlamaktadır. "BindsTo" direktifi genellikle servis birim dosyalarına 
    yerleştirilmektedir. Ancak mount birim dosyalarına da yerleştirilebilir. Ancak "BindsTo" direktifinin bağlanma ilişkisi kurulan 
    tüm iki birime de (bunlar daha fazla da olabilir) yerleştirilmesi gerekmez.

    Yukarıdaki işlemin kalıcı hale getirilebilmesi için bizim hem mount birim dosyasını hem de servis birim dosyasını enable 
    etmemiz gerekir. Örneğin:

    $ sudo systemctl enable mnt-fat16.mount
    $ sudo systemctl enable loop0.service
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Diğer çok kullanılan bir birim de "zamanlayıcı" birimidir. Zamanlayıcı birimi UNIX/Linux sistemlerinde kullanılan klasik 
    "cron" mekanizmasına benzer amaçlarla kullanılıyor olsa da daha fazla özellikleri ve kullanım yeri vardır.

    Bir zamanlayıcı birim dosyasının tipik görünümü aşağıdaki gibidir:

    # mytimer.timer

    [Unit]
    Description=Run Timer Unit
    [Timer]
    OnActiveSec=1s
    OnUnitActiveSec=10s
    Persistent=true
    Unit=mytask.service
    [Install]
    WantedBy=multi-user.target

    Buraki [Unit] bölümü diğer birimlerdeki gibi bağımlılıklarla ve öncelik sonralık ilişkisi ile ilgili direktifleri bulundurmaktadır.
    Birimin en önemli bölümü [Timer] isimli bölümdür. Bu bölümdeki "Unit" direktifi çalıştırılacak olan servisi belirtir. Buradaki 
    servis bir kez çalıştırılabileceği gibi periyodik olarak da çalıştırılabilmektedir. Burada "OnUnitActiveSec" direktifi ilgili 
    servisin (örneğimizdeki "mytask.service") hangi periyotta çalıştırılacağını belirtmektedir. OnActiveSec" ya da "OnBootSec" 
    servisin ilk kez ne zaman çalıştırılacağını belirlemekte kullanılmaktadır. (Eğer bu ilk çalışma belirlemesi yapılmazsa zamanlayıcı 
    birimi çalıştırılır fakat bir etki göstermez.) Burada belirtilen zamanlar konusunda şaşmalar olabilmektedir. Eğer zamanlamaya 
    daha katı bir biçimde uyulması gerekiyorsa bu durumda "OnAccuracySec" direktifi ile duyarlılık belirtilmelidir. Örneğin:

    # mytimer.timer

    [Unit]
    Description=Run Timer Unit
    [Timer]
    OnActiveSec=1s
    OnUnitActiveSec=10s
    Persistent=true
    Unit=mytask.service
    [Install]
    WantedBy=multi-user.target

    Tıpkı "cron" mekanizmasında olduğu gibi bir işin belli bir tarihte ve zamanda yapılmasını da sağlayabiliriz. Bunun için [Timer]
    bölümündeki "OnCalender" direktifi kullanılmaktadır. Aşağıda çeşitli giriş örnekleri verilmiştir:

    OnCalendar=15:00
    OnCalendar=Mon 08:00
    OnCalendar=1 12:00
    OnCalendar=1 Jan 00:00

    Örneğin:

    [Unit]
    Description=Run MyTask Service Every Minute
    [Timer]
    OnCalendar=22:24
    Persistent=true
    AccuracySec=1
    Unit=mytask.service
    [Install]
    WantedBy=multi-user.target

    Burada her gün saat 22:24'te söz konusu servis çalıştırılacaktır.

    Zamanlayıcı birim hakkındaki ayrıntılar için dokümanlara başvurabilirsiniz.

    Tabii yine bu timer mekanizmasının boot zamanında otomatik devreye girmesi isteniyorsa buradaki servis birimi ile birlikte
    enable edilmeleri gerekir. Örneğin:

    $ sudo systemctl enable mytimer.timer
    $ sudo systemctl enable mytask.service

    O anda aktif olan (start edilmiş olan) timer birimlerinin listesini almak için "systemctl "list-timer" komutu kullanılabilir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												57. Ders 07/11/2024 - Persembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    İşletim sistemlerinin o anda çalışılan donanımda hangi donanım birimlerinin bulunduğunu ve bunların kullandığı kaynakların 
    neler olduğunu bilmesi gerekir. Örneğin Linux işletim sisteminin söz konusu bilgisayar donanımında kaç tane CPU ya da çekirdek
    olduğunu, kullanılan RAM'in miktarını, network arayüzünün (network biriminin) donanımda olup olmadığını vs. bilmesi gerekir. 
    Eğer işletim sistemi bazı donanım birimlerini otomatik tespit edebilirse onları yöneten "aygıt sürücü (device driver)" denilen
    programları da otomatik yükleyebilir. Böylece hem kendisi hem de user mod programlar bunları kullanabilirler. Pekiyi işletim 
    sistemi donanımdaki donanım birimlerini ve bunların gereksinim duydukları kaynakları nasıl bilecektir? İşte kişisel bilgisayarların
    ve gömülü sistemlerin tarihsel gelişimi içerisinde bunun için bazı yöntemler uygulanmıştır.

    Eskiden PC'ler ilk çıktığında (Aralık-1980) onlar Microsoft'un DOS işletim sistemiyle çalışıyordu. Bu bilgisayarlara en fazla
    640K RAM bağlanıyordu. Ancak kullanıcıların çoğu RAM pahalı olduğu için daha düşük RAM ile çalışıyordu. İşte bu ilk PC'lerde
    sistem reset edildiğinde çalışma BIOS denilen EPROM bellekteki programdan başlatılıyordu. Bu program da donanım birimlerini
    kendisi kontrol ediyor ve bu birimlerin neler olduğunu ve bunların kullandığı kaynakları RAM'in "BIOS Haberleşme Alanı (BIOS 
    Communication Area) özel bir yerine yazıyordu. DOS da bu değerleri oradan okuyarak kendini başlatıyordu. Bu sistem DOS süresince
    bu biçimde devam ettirilmiştir. Zaten o zamanlarda Linux işletim sistemi yoktu ve gömülü sistemlerde genellikle Intel 8080, 
    Zilog Z80, Motorola 6800 gibi işlemciler ve mikrodenetleyiciler kullanılıyordu. Zaten o zamanlar aygıtlar mobil değildi.

    1990'lı yılların ilk yarısında Linux işletim geliştirildi. Ancak yaygın kullanıma sahip değildi. O zamanların Linux sistemlerinde
    donanımın tespit edilmesi BIOS Haberleşme Alanındaki bilgilerle ve bizzat Linux çekirdeğinin kendisinin birtakım çabalarıyla 
    yapılıyordu. Zaten Linux ilk zamanlarda geniş bir işlemci ailesine port edilmemiştir.

    90'lı yıllarla kişisel bilgisayarlarda Windows İşletim Sisteminin kullanılmaya başlanmasıyla donanım birimlerinin tespit 
    edilmesi ağırlıklı olarak Windows tarafından yapılmaya başlandı. O zamanlardaki en önemli sorunlardan biri genişleme yuvalarına 
    takılan kartların işletim sistemi tarafından otomatik tanınamamasıydı. Genişleme yuvasına kartı takan kullanıcılar aygıt 
    sürücüleri de kendileri manuel olarak yüklüyordu. Bu zamanlardaki önemli sorunlardan biri de bilgisayarın genişleme yuvasına 
    takılan birden fazla kartın kullandığı kaynakların çakışmasıydı. Bunun için kart üreten firmalar bu kaynakların yerlerinin 
    değiştirilmesini sağlayan kart üzerinde jumper'lar da bulundurabiliyordu.

    90'lı yılların ortalarında teknolojinin de gelişmesiyle programlanabilen IO portları oluşturulmaya başlandı. Böylece 
    karta donanımsal olarak çakılan kaynaklar kullanım bilgileri (IO portları gibi, kesme numaraları gibi) yazılımsal olarak 
    değiştirilebilmeye başlandı. Bunun sonucunda "Plug and Play (PnP)" denilen donanımsal arayüz oluşturuldu. Artık PC'lere 
    bir kart takıldığında BIOS bu kartla konuşup onun ne kartı olduğunu, onun kullandığı kaynakları öğrenebiliyordu. İşletim 
    sistemi de bu bilgilere erişip bunlardan faydalanabiliyordu. Kaynak çatışması da bu yıllarda yazılımsal olarak çözüldü.
    BIOS bir kartın kullandığı kaynak başka bir kartla çakışıyorsa o karta kaynakları değiştirmesi gerektiğini donanımsal olarak 
    iletebiliyordu. Böylece artık kullanıcının işi oldukça kolaylaşmıştı. Kullanıcı kartını genişleme yuvasına takıp bilgisayarı 
    açtığında BIOS kartı tanıyıp bu bilgileri bir yere yazıyor ve Windows da bu bilgilerden hareketle kartın kullandığı aygıt 
    sürücüyü otomatik yükleyebiliyordu. Tabii o yıllarda Windows'un karta ilişkin aygıt sürücüyü yükleyebilmesi için o aygıt 
    sürücünün kendi listesi içerisinde olması gerekiyordu. Eğer aygıt sürücü Windows içerisinde yoksa ekrana bir yazı çıkartılıyor
    aygıt sürücünün manuel olarak yüklenmesi isteniyordu. Sonraları özellikle laptop ve notebook bilgisayarların yaygınlaşmasıyla
    bilgisayarın güç tüketimi de önemli bir konu haline gelmeye başladı. İşte bunların sonucu olarak ACPI (Advanced Configuration
    Power Interface) denilen standart geliştirildi. BIOS'lar güncellendi ve bu ACPI standardına uygun hale getirildi. 
    ACPI arayüzünde yine BIOS donanım birimlerini belirleyip isimine "ACPI Tablosu (ACPI Table)" denilen RAM'de belli bir bölgedeki 
    bir tabloya yazmaktadır. İşletim sistemleri de bu tablodan PC'lerin ve taşınabilir bilgisayarların donanım birimlerini ve 
    onların kullandığı kaynakları öğrenebilmektedir. Bugün halen masaüstü bilgisayarlarda ve taşınabilir bilgisayarlarda bu ACPI
    yöntemi kullanılmaktadır. ACPI bugün hem Windows tarafından hem de Linux ve macOS sistemleri tarafından kullanılan bir 
    yöntemdir.

    Pekiyi gömülü Linux sistemlerinde işletim sistemi kart üzerindeki donanım birimlerini nasıl öğrenmektedir? Gömülü sistemlerde
    donanım birimlerinin otomatik tespit edilmesine yönelik bir mekanizma yoktur. Bu sistemlerde PC'ler ve taşınabilir bilgisayarlarda
    olduğu gibi donanımda sabit birimler de bulunmak zorunda değildir. (Örneğin masaüstü ve taşınabilir bilgisayarlardaki donanım 
    mimarisi olduk bellidir. Bu mimari büyük ölçüde 70'lerin sonlarında IBM tarafından tasarlanmıştır. Sonra çeşitli geliştirmeler 
    yapılmıştır.) Örneğin bir gömülü sistem kartında bulunan bir donanım birimi diğerinde bulunmayabilir. SoC üretici firmalar 
    SoC içerisinde değişik birimler yerleştirebilmektedir. Gömülü sistemler standart bir donanım içermediği için ve kapasiteleri 
    düşük olduğu için donanım aygıtların otomatik tespit edilmesi de genellikle mümkün olamamaktadır. İşte gömülü aygıtlar için 
    ACPI yönteminin yerine "Aygıt Ağacı (Device Tree)" denilen yöntem kullanılmaktadır. Bu yöntemde üretici firma ve kart tasarlayan 
    kişiler donanım birimlerini "aygıt ağacı denilen" bir sentaksla yazısal olarak belirtirler. Sonra bu yazısal bilgi derlenerek 
    binary bir formata dönüştürülür. Bu binary aygıt ağacı da işletim sisteminin çekirdeğine iletilir. İşletim sistemi bu aygıt 
    ağacı bilgilerini parse ederek gömülü aygıtın kullandığı donanım birimlerini tespit eder.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Donanım birimlerini iki kısma ayırabiliriz:

    1) Kendini Tanıtabilen (Discoverable) Birimler
    2) Kendini Tanıtamayan (Non-discoverable) Birimler

    Kendini tanıtabilen birimler donanıma dahil edildiğinde otomatik olarak işletim sistemi ile konuşup kendisi hakkındaki 
    bilgiyi ve kullandığı kaynakları işletim sistemine iletebilmektedir. Örneğin biz USB portuna bir aygıt taktığımızda buradaki
    kendini işletim sistemine tanıtabilmekte ve işletim sistemi de bu aygıt için gereken aygıt sürücüleri otomatik yükleyebilmektedir. 
    Böylece örneğin USB ile çalışan birimlerin ACPI ya da aygıt ağacı konusuyla bir ilgisi yoktur. Kendini tanıtabilen (discoverable)
    aygıtların bazıları şunlardır:

    - PC'lerdeki genişleme yuvasına (PCI yuvasına) takılan her türlü kartlar. Örneğin ses kartları, görüntü kartları disk 
    denetleyicileri gibi.
    - USB portuna takılarak kullanılan aygıtlar. Örneğin klavye, fare, yazıcı, flash bellekler, kameralar gibi.
    - Bluetooth Arayüzünü kullanan aygıtlar: Bluetooth kulaklıklar, bluetooth ile haberleşen aygıtlar (saatler vs.).

    Kendini tanıtamayan aygıtların bazıları da şunlardır:

    - SoC içerisindeki birimler. Örneğin kesme denetleyicileri, zamanlayıcılar vs.
    - I2C, SPI ve 1-wire protokollerini kullanan aygıtlar
    - GPIO pinlerine bağlanarak kullanılan aygıtlar
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aygıt ağaçları daha çok gömülü sistemler tarafından kullanılan bir yöntemdir. Aygıt ağaçları ilk kez Linux'ta PowerPC mimarisinde
    kullanılmaya başlanmıştır. Linux'un 2.6.20 çekirdeğinde PowerPC mimarisine özgü olarak aygıt ağacını ele alan kodlar eklenmiştir. 
    Aygıt ağaçları ARM mimarisin 2011 yılında çekirdeğin 3.0 sürümüyle birlikte ARM platformuna özgü bir biçimde eklenmiştir. 
    Ancak aygıt ağaçları platformdan bağımsız bir biçimde (yani platform ne olursa olsun çalışacak biçimde) Linux çekirdeğine 
    Linux çekirdeğinin 3.7 sürümüyle 2012 yılında eklenmiştir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aygıt ağaçlarına olan gereksinimi (yani aygıt ağaçlarının neden kullanıldığını) şöyle açıklayabiliriz:

    1) Linux çekirdeğinin çalışması ve bazı işlevleri yerine getirmesi için o anda çalışılan donanımın kaynakları hakkında 
    temel bilgileri edinmesi gerekmektedir. Bu bilgileri çekirdek PC'lerde "ACPI Tabloları" yoluyla gömülü sistemlerde ise aygıt 
    ağaçları yoluyla elde etmektedir. Örneğin Linux çekirdeğinin en azından sistemde kaç CPU olduğunu, ne kadar RAM olduğunu, 
    CPU frekansının ne olduğunu, sisteme bağlı UART işlemcilerine hangi adreslerle erişeceğini vs. bilmesi gerekmektedir.

    2) Aygıt ağaçlarından donanıma donanım tasarımcıları tarafından eklenmiş olan birimlerin çekirdeğe bildirilmesi için de 
    faydalanılmaktadır. Örneğin bir kart üzerinde 2 UART varken donanım tasarımcısı ona 2 UART daha eklemiş olsun. Bu durumda 
    çekirdeğin onları iç işleyişinde kullanabilmesi için onları tanıması gerekir. İşte sistem programcısı bu bilgileri aygıt 
    ağacına ekleyerek Linux çekirdeğine iletebilir.

    3) Birtakım donanım aygıtlarına ilişkin aygıt sürücülerin daha init prosesi çalışmadan daha erken aşamada yüklenmesi gerekebilmektedir. 
    Bu tür durumlarda bu aygıt sürücülerin aygıt ağacı yoluyla yüklenmesi daha uygun bir seçenek oluşturabilmektedir.

    4) Aygıt ağaçları birbirine benzeyen ama farklı olan donanımlar söz konusu olduğunda taşınabilirliği artırmaktadır. 
    Örneğin bir Linux kartının çeşitli versiyonları olsun. Bunların bazılarında 2 UART bazılarında 4 UART bulunuyor olsun. 
    Bu iki versiyon için aygıt ağaçlarını değiştirerek onlar hakkındaki bilgileri çekirdeğe iletebiliriz.

    Pekiyi aygıt ağaçlarıyla ilgili olmayan durumlar nelerdir? İşte erken yüklenmesi gerekmeyen, donanım birimleriyle bir ilgisi 
    olmayan aygıt sürücülerin aygıt ağaçlarıyla bir ilgisi yoktur. Aygıt bir donanım biriminin çekirdeğe tanıtılıp erken aşamada
    ona ilişkin sürücülerin yüklenmesi gerektiği durumlarda kullanılmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi aygıt ağaçları kimler tarafından oluşturulmaktadır? Gömülü sistemler birbirinden farklı donanım birimleri içerebildiğine 
    göre her gömülü sistem için o sistemi oluşturan ekibin aygıt ağacını oluşturması gerekir. Tabii gömülü sistem tasarımında
    donanımı tasarlayanlar zaten bilinen ve kullanılan donanım birimlerini kartlarına yerleştirebilmektedir. Bu birimler için 
    zaten hazırlanmış olan aygıt ağaçlarından faydalanılabilir. Örneğin biz bir gömülü Linux kartımızda belli bir firmanın SoC'unu 
    kullanıyor olabiliriz. Zaten bu firma ya da başka topluluklar bu SoC için aygıt ağacını oluşturmuş olabilirler. Biz de o 
    aygıt ağacını temel alarak ona eklemeler yapabiliriz. Pek çok gömülü Linux projesinde gömülü yazılım mühendisleri zaten var 
    olan aygıt ağaçları üzerinde özelleştirmeler yapmaktadır.

    Çeşitli üretici firmaların çeşitli SoC modellerine ilişkin pek çok hazır aygıt ağacı bulunmaktadır. Aslında bu aygıt 
    ağaçları bir süredir Linux'un çekirdek kod dağıtımının içerisine de yerleştirilmiştir. Linux kaynak kodlarında "arch" dizini 
    içerisinde ilgili işlemci ailesine ilişkin dizine girildiğinde buradaki "boot" dizinini altında "dts" dizininde çeşitli 
    SoC'lar için ve donanım birimleri için hazır aygıt ağacı dosyası bulunmaktadır. Örneğin BBB için hazır aygıt ağacı dosyası
    çekirdek kod dağıtımında "arch/arm/boot/dts/ti/omap" dizininde "am335x-boneblack.dts" ismiyle bulunmaktadır. Biz de eğer 
    bu SoC'u kullanıyorsak bu aygıt ağacı dosyasını temel alabiliriz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aygıt ağaçları bir metin dosyası (text file) biçiminde belli sentaks kurallarına uyarak oluşturulmaktadır. Biz burada 
    bu kurallar üzerinde duracağız. Bu biçimde oluşturulmuş olan dosyalara ".dts (device tree source)" uzantısı verilmektedir. 
    Sonra bu aygıt ağacı kaynak dosyası "aygıt ağacı derleyicisi (device tree compiler)" denilen bir programla binary biçime 
    dönüştürülür. Bu derlenmiş ve binary biçime dönüştürülmüş dosyanın uzantısı ".dtb" biçimindedir. Binary biçime dönüştürülmüş 
    olan bu dosyaya İngilizce "device tree blob" dosyası ya da "flatten device tree" dosyası denilmektedir. Bu dönüştürmeyi 
    yapan aygıt ağacı derleyicisi Linux sistemlerinde "dtc" isminde temel araç biçiminde bulundurulmaktadır. (Yani pek çok 
    dağıtımda biz özellikle yüklemesek de bu program bulunuyor durumdadır.)

    .dts (device tree source file) ----> dtc (device tree compiler) ---> .dtb (device tree blob / flattened device tree)

    Biz kursumuzda "device tree blob" ya da "flattened device tree" terimleri yerine "binary aygıt ağacı dosyası" ya da ".dtb"
    dosyası terimlerini kullanacağız.

    Neden aygıt ağacı kaynak dosyasının binary biçime dönüştürüldüğünü merak edebilirsiniz. Bunun nedeni binary bilgilerin 
    daha etkin bir biçimde parse edilmesi ve daha az yer kaplamasıdır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi oluşturulan bu binary aygıt ağacı dosyası işletim sisteminin çekirdeğine nasıl iletilmektedir? İşte bu iletme işlemi
    tipik olarak boot loader program tarafından yapılmaktadır. Biz de daha önce U-Boot'ta bu işlemi yapmıştık. Önce bu ".dtb" 
    dosyasını belleğe "load" komutuyla yüklemiştik. Sonra "bootz" komutunda yüklediğimiz yerin adresini vermiştik. U-Boot'da 
    bu dosyayı Linux çekirdeğine iletmişti. Boot loader'ın aygıt ağacı dosyasının yerini çekirdeğe iletmesi işleminin aşağı 
    seviyeli bazı ayrıntıları vardır. Biz burada bu ayrıntılar üzerinde durmayacağız. Aslında U-Boot kullanılıyorsa diğer bir 
    seçenek "binary aygıt ağacı dosyasını" U-Boot programının içine gömmektir. Bu durumda u-Boot kendi içerisine gömülmüş olan 
    bu dosya içeriğini çekirdeğe iletir. Aslında binary aygıt ağacı dosyası tamamen işletim sisteminin çekirdeğine de gömülebilmektedir. 
    Ancak bunu yapabilmek için çekirdeğin yeniden derlenmesi gerekir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												58. Ders 12/11/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aygıt ağacı derleyicisi tipik olarak aşağıdaki komut satırı argümanlarıyla kullanılmaktadır:

    dtc -I <girdi_formatı> -O <çıktı_formatı> -o <hedef_dosyanın_yol_ifadesi> <girdi_dosyası>

    -I ve -O seçeneklerinin parametreleri "dts" ya da "dtb" olabilir. dtc programı hem compile hem de decompile yapabilmektedir. 
    Yani biz bu program ile ".dts" dosyasını ".dtb" haline getirebileceğimiz gibi ".dtb" dosyasını da ".dts" haline getirebiliriz.

    Aşağıdaki gibi "mydt.dts" isimli anlamsız bir aygıt ağacı dosyamız olsun:

    /dts-v1/;

    / {
        test = "this is a test";
    };

    Bu dosyayı biz "dtc" ile şöyle binary aygıt ağacı dosyasına dönüştürebiliriz:

    $ dtc -I dts -O dtb -o mydt.dtb mydt.dts

    Burada girdi formatı "dts", çıktı formatı "dtb" biçimindedir. "-o" seçeneği kullanılmazsa çıktı "stdout" dosyasına yazdırılmaktadır.
    Tabii biz stdout dosyasına yazılan çıktıyı kabuk üzerinden ">" sembolü ile de yönlendirebiliriz. Örneğin:

      $ dtc -I dts -O dtb mydt.dts > mydt.dtb

    Şimdi bu işlemin tersini yapalım:

    dtc -I dtb -O dts -o decompiled.dts mydt.dtb

    Burada "mydt.dtb" dosyası "decompiled.dts" dosyasına geri dönüştürülmüştür.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aygıt ağaçlarının text ve binary formatını açıklayan "Devicetree Specification" dokümanı aşağıdaki bağlantıdan indirilebilir:

    https://github.com/devicetree-org/devicetree-specification/releases/tag/v0.4

    Bu dokümanda önce aygıt ağacı mantıksal olarak açıklanmış sonra da kaynak ve binary dosya formatları verilmiştir. İnternette
    çeşitli kişi ve kurumlar tarafından oluşturulmuş olan açıklayıcı başka dokümanlar da bulunmaktadır. Aşağıdaki dokümanlardan 
    da faydalanabilirsiniz:

    https://docs.zephyrproject.org/latest/build/dts/index.html

    Bootlin sitesindeki "Devicetree 101" ve "petazzoni-device-tree-dummies" dokümanlarından da faydalanılabilir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aygıt ağacı dosyalarının başında bir versiyon alanı bulundurulmaktadır. Bu alan şimdilik aşağıdaki gibi olmalıdır:

    /dts-v1/;

    Aygıt ağaçları isminden anlaşılacağı gibi ağaç yapısına sahiptir. Ağaç bir kök düğümden oluşmaktadır. Kök düğümün içerisinde 
    alt düğümler, alt düğümlerin içerisinde de başka alt düğümler olabilir. Bir düğüm düğüm ismi ve küme parantezleriyle bildirilmektedir. 
    Düğüm ismi olarak / karakteri kök düğümü belirtmektedir. Küme parantezlerinin sonunda ';' atomu bulunmalıdır. Yalnızca aygıt 
    ağaçlarında değil bu tür diğer bazı ağaç yapılarında da (örneğin Web dünyasında kullanılan CSS dosyalarında olduğu gibi) 
    alt düğümdeki öğeler üst düğümdeki öğelerden bazı özellikleri alabilmektedir.

    Düğüm isimlerinde aşağıdaki karakterlerin hepsi kullanılabilmektedir:

    0-9     digit
    a-z     lowercase letter
    A-Z     uppercase letter
    ,       comma
    .       period
    _       underscore
    +       plus sign
    -       dash

    Aygıt ağaçlarında bazı düğümler önceden tanımlanmış isimlere ve işlevlere sahiptir. Bu düğümler "Devicetree Specification" 
    dokümanında ayrı bölümde ele alınmıştır. Bir düğüm isminin sonunda @ işaretli ile belirtilmiş bir "birim adresi (unit address)
    de bulunabilir. Örneğin:

    uart@fe001000
    ethernet@fe002000
    ethernet@fe003000

    Burada ismin sonuna getirilen @ sembolünün amacı ismi "çakışma durumunda ayrıştırmak" ve "mantıksal anlamlandırılabilirliği" 
    artırmaktır. Aynı üst düğümün içerisinde aynı isimli alt düğümler olamaz. Bunların ayrıştırılabilmesi için birim adres verilebilir. 
    Ancak birim adresler "reg" özelliğinin ilk değeri olmak zorundadır. Örneğin:

    /dts-v1/;

    / {
            ethernet@fe002000 {
                ...
            };
            ethernet@fe003000 {
                ...
            };
            ...
    };

    Burada iki düğümün de ismi "ethernet" olamazdı. Bu nedenle bu isimler "birim isimleri" ile ayrıştırılmak istenmiştir. 
    Tabii ayrıştırmanın @ ile birim ismi verilerek yapılması yerine doğrudan ismi değiştirme yoluna da gidilebilirdi. Ancak 
    birim isimleri ismi değiştirmeden onların kullandığı bellek ya da port adreslerinin belirtilmesi ile okunabilirliği sağlamaktadır.

    Bir düğüm isminin soluna isteğe bağlı olarak bir "etiket (label)" ismi de getirilebilir. Bu etiket ismi bu düğümü "tek olarak 
    (unique)" betimlemek amacıyla kullanılmaktadır. Bir düğüme referans edileceği zaman (tipik olarak "phandle" özelliği ile)
    bu etiket isimlerinden faydalanılır. Etiket isimleri tüm dosya genelinde tek olmak zorundadır. (Yani örneğin farklı düğümlerin
    alt düğümlerinde aynı düğüm isimleri bulunabilir. Bu nedenle referans işleminde düğümler "tek (unique)" olmadığından dolayı
    iş görmeyebilir. Ancak toplamda dosya genelinde her etiket "tek (unique)" olmak zorundadır.)
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bir aygıt ağacı dosyası başka bir aygıt ağacı dosyasını include edebilir. include işlemi "Devicetree Specification" dokümanına 
    göre aşağıda gibi yapılmalıdır:

    /include/ "dts_dosyasının_yol_ifadesi"

    Genellikle aygıt ağacı dosyasından include edilen dosyalara ".dtsi" uzantısı verilmektedir.

    Örneğin "mydt.dts" dosyası kendi içerisinde "mydt-other.dtsi" dosyasını include etmiş olsun:

    /* mydt.dts */

    /dts-v1/;

    / {
        test = "this is a test";
        /include/ "mydt-other.dtsi"
    };

    Buradaki "mydt-other.dtsi" dosyası da aşağıdaki gibi olsun:

    /* mydt-other.dtsi */

    other {
        msg = "this is a test";
    };

    Derlemeyi aşağıdaki gibi yapabiliriz:

    $ dtc -I dts -O dtb -o mydt.dtb mydt.dts

    include dosyaları default olarak bulunulan dizinde aranmaktadır. Ancak başka dizinlere de bakılması isteniyorsa "-i" seçeneği 
    ile ek dizinler belirtilebilir. Örneğin:

    $ dtc -I dts -O dtb -i /home/kaan -o mydt.dtb mydt.dts

    Ancak aygıt dosyaları yazanlar include işlemini C tarzı #include ile de yapabilmektedir. Örneğin:

    /* mydt.dts */

    /dts-v1/;

    / {
        test = "this is a test";
        #include "mydt-other.dtsi"
    };

    Bu tür durumlarda genellikle uygulamacılar önce kaynak aygıt ağacı dosyasını C'nin önişlemcisinden geçirirler. Böylece 
    C'nin önişlemcisi include direktiflerinin bulundurulduğu yere dosyanın içeriğini yerleştirir. Bilindiği gibi C'nin önişlemcisi 
    "cpp (C Preprocessor)" isimli programdır. Yani "gcc" ve ""clang" derleycileri aslında önişlem işlemlerini bu "cpp" programını 
    çalıştırarak yapmaktadır. (Tabii "gcc", "g++" ve "clang" derleyicilerinde -E seçeneği ile bu derleyicilerin önişlemi yapıp 
    sonlanmasını da sağlayabilmekteyiz.)

    O halde biz yukarıdaki aygıt ağacı dosyasını aşağıdaki gibi önişlemden geçirebiliriz:

    $ cpp mydt.dts -o preprocessed.dts

    Artık biz tek dosya haline getirilmiş olan aygıt ağacı dosyasını derleyebiliriz:

    $ dtc -I dts -O dtb -o mydt.dtb preprocessed.dts
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bir aygıt ağacı kaynak dosyasındaki düğümün en önemli özelliği "compatible" özelliğidir. Bu "compatible" özelliği ilgili 
    düğüm için yüklenecek aygıt sürücüyü belirtmektedir. Bu tür aygıt sürücülerin "platform aygıt sürücüleri" biçiminde yazılmış 
    olması gerekir. "compatible" özelliğinin değeri genellikle tek bir string olarak karşımıza çıkar. Ancak bunu değeri virgüllerle
    ayrılmış olan bir string listesi biçiminde de olabilir. Değer olarak bulundurulan string tipik olarak "vendor,device" biçiminde 
    virgülle ayrılmış ki yazıdan oluşmaktadır. Buradai "vendor" üretici firmayı, "device" ise aygıt sürücünün ilişkin olduğu aygıtı 
    belirtmektedir. Linux çekirdeği aygıt ağacını parse ettiğinde bu "compatible" özelliğine bakarak ilgili düğüm için hangi aygıt 
    sürücünün yükleneceğini belirlemektedir. İlgili aygıt sürücünün aranması işlemi biraz ayrıntı içermektedir. Bir aygıt sürücü 
    çekirdek dosyasının içerisine gömülmüş olarak da bulunabilir. Çekirdek dosyasının yanı başında ayrı bir dosya olarak da bulunabilir. 
    Bu iki durumda da çekirdek aygıt ağacı düğümünü ele alırken ilgili aygıt sürücüyü yüklemektedir. Tabii aygıt sürücüler 
    ayrıca işletim sistemi çalışır duruma geldikten sonra "init" programları tarafından ya da sistem yöneticileri tarafından 
    da yüklenebilmektedir. Aygıt sürücü kodlarının çekirdek imajının içine gömülüp gömülmeyeceği çekirdeğin derleme öncesinde 
    konfigüre edilmesi sırasında belirlenmektedir. Özellikle temel donanımlara ilişkin aygıt sürücü kodlarının çekirdeğin 
    içerisine gömülmesi uygun olabilir. Böylece kırılganlık azaltılabilir, güvenlik artırılabilir ve daha hızlı bir yükleme 
    sağlanabilir. Örneğin:

    my_uart@0x1000 {
        compatible = "mycompany,myuart";
        reg = <0x1000 0x100>;
    };

    Burada "mycompany" isimli şirketin myuart isimli aygıt sürücüsü yüklenecektir. İşletim sisteminin bu üretici firma ve aygıta
    ilişkin aygıt sürücüyü nasıl aradığını merak edebilirsiniz. Yukarıda da belirttiğimiz gibi bu işlemin aygıt sürücü yazımını 
    da ilgilendiren ayrıntıları vardır. Platform aygıt sürücülerine de bir "vendor" ve "device" ismi verilmektedir. Arama bu 
    isimlere göre yapılmaktadır.

    Düğümlerde en çok karşılaşılan özelliklerden bir de "reg" özelliğidir. Bu "reg" özelliğinin değeri genellikle açısal parantezler 
    içerisinde ve genellikle 16'lık sistemde (zorunlu değil) sayılardan oluşturulmaktadır. "reg" özelliği ilgili aygıta erişmek 
    için gereken donanım adreslerini belirlemek için kullanılmaktadır. ARM gibi "bellek tabanlı IO (memory mapped IO)" kullanan 
    işlemcilerde burada bellek adresleri bulunur. Ancak port IO kullanabilen Intel gibi işlemcilerde burada aygıtın port numarası 
    da belirtilebilmektedir. Tabii "reg" özelliği daha geneldir. Yani buradaki adresler CPU söz konusu olduğunda CPU'nun numarasını 
    belirtir, IRQ'lar söz konusu olduğunda ise IRQ numaralarını belirtir. "reg" özelliğinin değerinde virgül ayrılmış çiftler 
    de görebilirsiniz. Bu durumda virgülün solunda aygıtın adresi sağında ise adres uzunluğu bulunacaktır.

    Aygıt ağacı düğümlerindeki bilgiler aynı zamanda doğrudan platform aygıt sürücülerine aktarılmaktadır. Yani işletim sisteminin 
    çekirdeği ilgili aygıt sürücüyü yüklerken onun kullanacağı adresleri ve diğer bilgileri de aygıt sürücüye geçirmektedir. 
    Örneğin biz bir UART işlemcisini kendi tasarladığımız karta yerleştirmiş olalım. Bu UART işlemcisinin CPU ile haberleşmek
    için kullandığı donanım adresleri vardır. Aygıt sürücüsü de bu adresleri bilerek CPU vasıtasıyla URAT'a iş yaptırmaktadır. 
    UART'ı kontrol eden aygıt sürücü genel yazıldığına göre ve değişik sistemlerde donanım tasarımcısının isteğine bağlı olarak
    bu haberleşme adresleri değişebildiğine göre bu adreslerin aygıt sürücüye aktarılması zorunludur.

    Düğümlerde standart olarak karşılaşılan diğer bir özellik de "status" özelliğidir. Bu özellik ilgili donanım biriminin 
    durumunu ayarlamak için kullanılmaktadır. Bu özelliğin değeri bir string olur. Bu string'in nasıl oluşturulacağı düğüme 
    göre farklılık gösterebilmektedir. Ancak örneğin "disabled" özelliği ilgili birimin devre dışı bırakılacağı anlamına gelmektedir.
    Eğer biz bir donanım birimini devre dışı bırakmak istersek (yani işletim sisteminin onu yokmuş gibi varsaymasını istersek)
    bu "status" özelliğine "disabled" değerini vermemiz gerekir. Örneğin:

    my_uart@0x1000 {
        compatible = "mycompany,myuart";
        reg = <0x1000 0x100>;
        status = "disabled";
    };
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aygıt ağaçlarında "kaplama (overlay)" denilen bir kavram da vardır. Kaplama mevcut bir aygıt ağacını bozmadan oradaki bazı 
    özellikleri değiştirmek için ya da aygıt ağacına yeni düğümler ve özellikler eklemek için kullanılan bir yöntemdir. Örneğin
    elimizde BBB için oluşturulmuş olan bir ".dts" dosyası olsun. Biz BBB'deki bazı aygıtların bazı özelliklerini değiştirmek 
    isteyelim. Bunu yapmanın bir yolu değişiklikleri ".dts" dosyası üzerinde yapmak ve ".dts" dosyasını yeniden derlemektir. 
    Tabii bunun için elimizde ".dts" dosyasının olması gerekir. (Gerçi elimizde ".dts" dosyası yok fakat ".dtb" dosyası varsa
    biz bu dosyayı decompile da edebiliriz.) İşte orijinal ".dts" dosyasını değiştirmek yerine bir kaplama (overlay) dosyası 
    oluşturup değişiklikleri o dosya üzerinde yapabiliriz. Böylece orijinal dosyayı bozmamış oluruz. Örneğin BBB'nin GPIO soketlerine 
    isteğe bağlı olarak takılan çeşitli kartlar vardır. İşte bu kartların her biri için ayrı kaplama dosyaları oluşturulabilir 
    ve bu kartlardan hangisi kullanılacaksa o kaplama dosyası ana aygıt dosyası ile birlikte yüklenebilir.

    Kaplama kaynak dosyalarının uzantıları genellikle yine ".dts" biçimindedir. Ancak bunlara derleme işlemi sonucunda ".dtbo" 
    uzantısı verilmektedir. Kaplama dosyaları derlenirken ayrıca -@ seçeneği de belirtilmelidir. Örneğin:

    $ dtc -I dts -O dtb -@ -o myoverlay.dtbo myoverlay.dts

    Kaplama dosyası oluşturulduktan sonra bunun boot loader'a verilmesi gerekir. Bootloader'da bu kaplama dosyasını ana aygıt
    dosyası ile birleştirerek çekirdeğe iletecektir. U-Boot'ta bu işlemin nasıl yapıldığını izleyen paragraflarda göreceğiz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Kaplama dosyaları aslında "Devicetree Specification" dokümanında açıklanmamıştır. Bir çeşit uzantı gibidir. Bu nedenle 
    kaplama (overlay) sentaksını resmi (formal) biçimde açıklayan bir doküman yoktur. Kaplama dosyası oluştururken versiyon 
    direktifinin yanı sıra "plugin" direktifinin de yerleştirilmesi gerekir. Yani tipik olarak kaplama dosyasının başı şu 
    biçimde olmalıdır:

    /dts-v1/;
    /plugin/;

    "plugin" direktifinin /plugin/ biçiminde belirtildiğine dikkat ediniz. Kaplama dosyası oluştururken yine bir kök düğüm alınır. 
    Kaplama bilgileri bu kök düğümün içerisinde belirtilir. Örneğin:

    / {
            /* kaplama düğümleri hakkında bilgiler */
    };

    Kaplamalar basit ya da ayrıntılı oluşturulabilmektedir. Basit kaplamalarda hiç fragment düğümü ve __overlay__ düğümü 
    kullanılmaz. Ancak basit kaplamalar ancak tek bir özelliğin değiştirileceği durumlarda kullanılmaktadır. Kaplama dosyasındaki
    her düğüm değişikliği ya da özellik eklemesi için "fragment" düğümleri kullanılmaktadır. Zorunlu olmasa da "fragment" belirtilirken
    @ soneki ile ona bir numara da verilir. Numaranın ne olduğunun bir önemi yoktur. Tipik olarak numaralar 0'dan başlatılarak verilir. 
    Örneğin:

    /dts-v1/;
    /plugin/;

    / {
        compatible = "ti,beaglebone", "ti,beaglebone-black";

        fragment@0 {
           /* ... */
        };
    };

    Aslında buradaki compatible özelliği hiç kullanılmayabilir. Bu özellik ilgili kaplamanın hangi satıcı (vendor) ve modeli 
    için geçerli olduğunu belirtmektedir. BBB için yukarıdaki compatible satırını kullanabilirsiniz. "fragment" bölümlerinin 
    içerisinde yapılacak değişiklikler ve eklemeler yerleştirilir. "fragment" bölümleri bir "target" ya da "target-path" özelliği 
    ile başlatılır. Bu özelliklerden amaç aygıt ağacı üzerindeki hangi düğümün hedeflendiğinin belirlenmesidir. ""target" 
    özelliğinin değeri tipik olarak açısal parantezler içerisinde &'lı düğüm ya da etiket ismidir. Örneğin:

    target = <&leds>;

    Buradaki & semboli ilgili düğüme referans edileceği anlamına gelmektedir.

    target-path özelliğinin değeri ise hedeflenen düğümün kök itibaren yol ifadesini belirtir. Örneğin "leds" düğüm eğer 
    kök dizinin altındaysa biz "target-path" özelliğini şöyle kullanabiliriz:

    target-path = "/leds";

    Örneğin:

    /dts-v1/;
    /plugin/;

    / {
        compatible = "ti,beaglebone", "ti,beaglebone-black";

        fragment@0 {
           target-path = "/leds";
           /* ... */
        };
    };

    "fragment" düğümünün içerisinde değişikler ve eklemeler için __overlay__ düğümü oluşturulmalıdır. Örneğin:

    /dts-v1/;
    /plugin/;

    / {
        compatible = "ti,beaglebone", "ti,beaglebone-black";

        fragment@0 {
           target-path = "/leds";
           __overlay__ {
                /* ... */
           }
        };
    };

    Artık bu __overlay__ düğümünün içerisinde değişiklikler ve eklemeler yapılabilir. Buradaki her özellik hedefte belirtilen 
    düğümdeki özelliğin üzerine bindirilmektedir. Örneğin:

    /dts-v1/;
    /plugin/;

    / {
        compatible = "ti,beaglebone", "ti,beaglebone-black";

        fragment@0 {
            target-path = "/leds";
            __overlay__ {
                status = "disabled";
            };
        };
    };

    Burada ilgili düğümün "status" özelliği "disabled" haline getirilmiştir. Örneğin biz Raspberry Pi'da 3 numaralı CPU'yu 
    aşağıdaki gibi bir kaplama dosyası yazarak devre dışı bırakabiliriz. (BBB'de toplam tek bir CPU bulunduğunu anımsayınız.)

    /dts-v1/;
    /plugin/;

    / {
        compatible = "brcm,bcm2837";

        fragment@0 {
            target = <&cpu0>;
            __overlay__ {
                status = "disabled";
            };
        };
    };
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi basit bir uygulama yapalım. Amacımız BBB üzerindeki LED'lerin yanıp sönmesini engellemek yani o led'leri işlev olarak 
    devre dışı bırakmak olsun. Anımsanacağı gibi BBB'de bir tane güç kaynağı led'i d tane de "aktivasyon led'i" bulunmaktadır. 
    Kenara en yakın led 0 numaralı led'tir. Biz bu işlemi led'lere ilişkin düğümlerin "status" özelliklerini "disabled" biçime
    getirerek sağlayabiliriz. Bu işlem yukarıda da belirttiğimiz gibi iki biçimde yapılabilir. Birincisi ana aygıt ağacı dosyası
    üzerinde değişiklerin yapılmasıdır. İkincisi ana aygıt ağacı dosyasına hiç dokunmadan bir kaplama dosyası yoluyla değişikliğin 
    yapılmasıdır. Biz burada her iki yönteme de örnek vereceğiz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    BBB'deki ana aygıt ağacı dosyasında değişiklik yapabilmemiz için bizim bu ağaca ilişkin ".dts" dosyasına sahip olmamız gerekir. 
    Daha önceden de belirttiğimiz gibi Linux'un çekirdek kodları içerisinde bu dosyalar vardır. Ancak bu dosyalar orada tek 
    parça halinde değil birkaç dosya halinde bulunmaktadır. Bu dosyaların oradan alınıp derlenmesi biraz zahmetlidir. Bu nedenle 
    biz burada ".dtb" dosyasını decompile ederek ondan ".dts" elde edelim. Bu dosya zaten BBB'nin orijinal imajında bulunmaktadır.
    Bu işlemi adım adım şöyle yapabiliriz:

    1) Önce orijinal ".dtb" dosyasından ".dts" dosyasını decompile işlemi ile elde ederiz:

    $ dtc -I dtb -O dts -o am335x-boneblack.dtb am335x-boneblack.dts

    2) ".dts" dosyasında "leds" düğümünü bulup oraya "status" özelliğini "disabled" biçimde ekleriz. Aygıt ağacı Dosyasının
    ilgili bölümünü aşağıda veriyoruz:

    ...
    leds {
        pinctrl-names = "default";
        pinctrl-0 = <0x5d>;
        compatible = "gpio-leds";
        status = "disabled";		/* =====> eklediğimiz satır */

        led2 {
            label = "beaglebone:green:usr0";
            gpios = <0x25 0x15 0x00>;
            linux,default-trigger = "heartbeat";
            default-state = "off";
        };

        led3 {
            label = "beaglebone:green:usr1";
            gpios = <0x25 0x16 0x00>;
            linux,default-trigger = "mmc0";
            default-state = "off";
        };

        led4 {
            label = "beaglebone:green:usr2";
            gpios = <0x25 0x17 0x00>;
            linux,default-trigger = "cpu0";
            default-state = "off";
        };

        led5 {
            label = "beaglebone:green:usr3";
            gpios = <0x25 0x18 0x00>;
            linux,default-trigger = "mmc1";
            default-state = "off";
        };
    };
    ...

    3) Artık ".dts" dosyasını yeniden derleyip yeni bir ".dtb" dosyası haline getirebiliriz:

    $ dtc -I dts -O dtb -o am335x-boneblack.dtb am335x-boneblack.dts

    4) Elde ettiğimiz ".dtb" dosyasını orijinal ".dtb" dosyasını ezerek oraya kopyalarız.

    Artık sistemi boot ettiğimizde BBB'nin aktivasyon led'lerinin yanmadığını göreceksiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de yukarıdaki örneği ana ".dtb" dosyasına hiç dokunmadan kaplama dosyası oluşturarak gerçekleştirelim. Biz yukarıda 
    kaplama dosyalarının nasıl oluşturulduğunu temel düzeyde gördük. Ancak kaplama dosyalarının nasıl devreye girdiğini açıklamadık.
    Örneğin biz yukarıdaki led'leri devre dışı bırakmak için "userled-disable.dtbo" dosyasını oluşturrmuş olalım. Bu dosyanın 
    ana "am335x-boneblack.dtb" dosyasının bir kaplaması olduğunu nasıl belirteceğiz? İşte kaplama dosyalarının asıl aygıt ağacı
    dosyası ile bir araya getirilip çekirdeğe verilmesi gerekir. Bu işlemi de bootloader yapmaktadır. O halde biz kaplama dosyasını 
    oluşturduktan sonra U-Boot'ta da bu amaçla birtakım işlemler yapmalıyız. Aşağıda gerekli bunun için olan tüm işlemleri maddeler 
    halinde açıklayalım:

    1) Önce kaplama kaynak dosyasını oluşturmamız gerekir. Bu dosya aşağıdaki gibi oluşturulabilir:

    /dts-v1/;
    /plugin/;

    / {
        compatible = "ti,beaglebone", "ti,beaglebone-black";

        fragment@0 {
            target-path = "/leds";
            __overlay__ {
                status = "disabled";
            };
        };
    };

    Bu dosya derlenerek ".dtbo" dosyası haline dönüştürülür:

    $ dtc -I dts -O dtb -@ -o userled-disable.dtbo userled-disable.dts

    2) Şimdi elde ettiğimiz ".dtbo" dosyasını hedef sisteme kopyalamamız gerekir. Kaplama dosyaları orijinal ".dtb" dosyalarının
    bulunduğu dizine çekilebilir. Ya da o dizinin altında "overlays" gibi bir dizin yaratılıp onun içerisine çekilebilir. 
    (Orijinal BBB imajında tüm kaplama dosyaları "overlays" dizinine yerleştirilmiştir.). Biz "overlays" dizinin içerisine 
    yerleştirmeyi yapmış olalım.

    3) Şimdi artık işin U-Boot'u ilgilendiren kısmına geldik. Önce işlemleri manuel yapıp sonra otomatize edeceğiz. 
    Bunun için U-Boot'un komut satırına düşmüş olalım. Şimdi ilk iş olarak çekirdek imajını yükleyelim:

    => load mmc 0:2 0x82000000 /boot/vmlinuz-5.10.168-ti-r71

    Sonra ana aygıt ağacı dosyasını yükleyelim:

    => load mmc 0:2 0x88000000 /boot/dtbs/5.10.168-ti-r71/am335x-boneblack.dtb

    Eskiden biz bu noktada "bootz" komutuyla boot işlemini başlatıyorduk. Ancak kaplama dosyası söz konusu olduğunda bizim ek
    birtakım işleri de yapmamız gerekir. Bunun için önce kaplama dosyasını aşağıdaki gibi belleğe yükleyelim:

    => load mmc 0:2 0x89000000 /boot/dtbs/5.10.168-ti-r71/overlays/userled-disable.dtbo

    Artık belleğe çekirdek imajı, aygıt ağacı dosyası ve kaplama dosyası yüklenmiş durumdadır. Şimdi bizim kaplama dosyasını 
    aygıt ağacı dosyası ile birleştirmemiz gerekir. Ancak bu birleştirme için öncelikle ".dtb" dosyasının yüklendiği bellek 
    alanı büyütülmelidir. Bu büyütme işlemi "fdt resize" komutuyla yapılmaktadır. Ancak bu işlem için de önce U-Boot'un aygıt 
    Örneğin:

    => fdt addr 0x880000
    Working FDT set to 88000000
    => fdt resize 0x10000

    Burada biz aygıt ağacı için ayrılan alanı 0x10000 boyutuna getirmiş olduk. Bu işlemle artık aygıt ağacının altında kaplama 
    dosyası için makul bir yer tahsis edilmiştir. Aslında "fdt resize" komutunda hiç unuluk da belirtilmeyebilir. Bu durumda kalan 
    tüm RAM alanı kullanılır. Resize işleminden sonra artık aygıt ağacı dosyası ile kaplama dosyasının birleştirilmesi gerekir. Bu 
    işlem de "fdt apply <kaplama_dosyasının_adresi>" komutuyla yapılmaktadır. Örneğin:

    => fdt apply 0x89000000

    Artık bootz komutunu uyguladığımızda kaplama işlemi etkisini gösterecektir:

    => bootz 0x82000000 - 0x88000000

    Tabii tüm bu işlemler "uEnv.txt" içerisinde otomatize edilebilir. "uEnv.txt" içeriği şöyle oluşturulabilir:

    loadkernel=load mmc 0:2 0x82000000 /boot/vmlinuz-5.10.168-ti-r71
    loadfdt=load mmc 0:2 0x88000000 /boot/dtbs/5.10.168-ti-r71/am335x-boneblack.dtb
    loadoverlay=load mmc 0:2 0x89000000 /boot/dtbs/5.10.168-ti-r71/overlays/userled-disable.dtbo
    joinoverlay=fdt addr 0x88000000;fdt resize 10000;fdt apply 0x89000000
    bootargs=console=ttyS0,115200 root=/dev/mmcblk0p2 rw
    bootsys=bootz 0x82000000 - 0x88000000
    uenvcmd=run loadkernel;run loadfdt;run loadoverlay;run joinoverlay;run bootsys

    bootcmd çevre değişkeni de şöyle oluşturulabilir:

    => setenv bootcmd "load mmc 0:1 0x8A000000 /uEnv.txt;env import -t 0x8A000000;run uenvcmd"
    => saveenv
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux'ta çeşitli sıkıştırma yöntemleri (formatları da diyebiliriz) kullanılmaktadır. Bunların bazıları şunlardır:

    - gzip formatı (dosyaların uzantıları genellikle ".gz" biçimndedir)
    - bz2 formatı (dosyaların uzantıları ".bz2" biçimindedir)
    - xz formatı (dosyaların uzantıları "xz" biçimindedir)
    - Klasik zip formatı (dosyaların uzantıları ".zip" ya da ".z" biçimindedir)

    Bu formatlar sıkıştırma bakımından farklı performans göstermektedir. Ancak formatın sıkıştırma performansı ne kadar yüksekse
    işlem yapma süresi de o kadar uzun olmaktadır. Tipik olarak bu formatların sıkıştırma performansları için aşağıdaki 
    ilişki söz konusudur:

    xz > bz2 > gzip == zip

    Yani en iyi sıkıştırma xz formatında, daha sonra bz2 formatında daha sonra da gzip formatındadır. gzip formatı ile zip formatı 
    aynı algoritmaları kullanmaktadır. Dolayısıyla bunların performansları birbirine benzerdir. Ancak yukarıda da belirttiğimiz 
    gibi sıkıştırma performansı yükselirken (yani daha iyi hale gelirken) sıkıştırma ve açma için gereken zaman da uzamaktadır.

    Yukarıdaki formatalara göre sıkıştıran ve açan programlar hazır biçimde bulunmaktadır. Bu programların isimleri şunlardır:

    gzip
    gunzip
    bzip2
    bunzip2
    xz
    unxz
    zip
    unzip

    zip programının dışındaki programların hepsi tek bir dosyayı sıkıştırıp açmaktadır. Dolayısıyla eğer birden fazla dosya
    sıkıştırılacaksa önce onların birleştirilmesi gerekir. Biz daha önce bu amaçla tar ve cpio formatları hakkında temel bazı 
    şeyleri söylemiştik. Bu programlar tek dosya üzerinde çalıştığı için genellikle önce tar'lanıp sıkıştırılmaktadır. O halde
    önce "tar" programının kullanımı hakkında bazı bilgiler verelim.

    tar programının pek çok komut satırı seçeneği olsa da en çok kullanıcıları seçenekler "-c" "-x" "-f" "-v" seçenekleridir. 
    "-c" tar'lamak için "-x" ise açmak için kullanılır. "-v" seçeneği programın daha fazla bilgi vermesini sağlamaktadır. 
    "-f" seçeneği bir argümanla kullanılır. Argüman ".tar" dosyasını belirtir. tar programı birden fazla dosyayı komut satırı 
    argümanıyla alabilir. Tabii kabuğun joker karakterlerinden faydalanabilirsiniz. Argüman olarak dosya yerine dizinler de 
    verilebilir. Bu durumda bu dizinin içerisindeki dosyaların hepsi tar'lanıp açılmaktadır. Örneğin:

    $ tar -c -f test.tar x.txt y.txt

    Genellikle kullanıcılar seçenekleri aşağıdaki gibi birleştirmektedir:

    $ tar -cf test.tar x.txt y.txt

    Tabii burada "f" harfinin seçenek listesinde en sonra olması gerekmektedir.

    gzip programı ile sıkıştırmak oldukça kolaydır. Örneğin:

    $ gzip test.tar

    Açma işlemi de şöyle yapılabilir:

    $ gunzip test.tar.gz

    Tabii buradan biz "test.tar" dosyasını elde edeceğiz. Onu yeniden açmamız gerekir. gzip ve gunzip programlarının eski dosyayı 
    da sildiğine dikkat ediniz. tar komutu ile hem tar'lamak hem de aynı zamanda gzip işlemini yapmak için tar komutunda "-z" 
    seçeneği kullanılmaktadır. Yani "-z" seçeneği "önce tar'la sonra gzip yap" anlamına gelmektedir. Tabii tar programı aslında 
    kendi içerisinde gzip programını çalıştırmaktadır. Örneğin:

    $ tar -cvzf test.tar.gz x.txt y.txt

    Burada biz dosyaları hem tar'ladık hem de sıkıştırdık. Açma işlemi de aynı biçimde yapılmaktadır:

    $ tar -xvzf test.tar.gz

    bzip2 programının kullanımı gzip programına oldukça benzemektedir. Örneğin:

    $ bzip2 test.tar

    Açım da benzer biçimde yapılmaktadır:

    $ bunzip2 test.tar.bz2

    Önzer tar'layıp sonra bzip2 ile sıkıştırma işlemi tek hamlede tar programı tarafından "-j" seçeneği ile yapılabilmektedir. 
    ("-z" seçeneğinin gzip için "-j" seçeneğinin bz2 için kullanıldığına dikkat ediniz.) Örneğin:

    $ tar -cvjf test.tar.bz2 x.txt y.txt

    Açım da benzer biçimde yapılabilir:

    $ tar -xvjf test.tar.bz2

    xz programı ile sıkıştırma yapma da benzer biçimdedir. Örneğin:

    $ xz test.tar

    Açım da benzerdir:

    $ unxz test.tar.xz

    hem tar'lamak hem de xz haline getirmek için tar programında "-J" seçeneği kullanılmaktadır. Örneğin:

    $ tar -cvJf test.tar.xz x.txt y.txt

    Açım işlemi de şöyle yapılabilir:

    $ tar -xvJf test.tar.xz
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Kursumuzun bu bölümünde Linux çekirdeğinin derlenmesi üzerinde duracağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bazı durumlarda çekirdeğin sıfırdan derlenmesi gerekebilmektedir. Çekirdeğin yeniden derlenmesinin gerektiği tipik durumlar 
    şunlardır:

    - Bazı çekirdek modüllerinin ve aygıt sürücülerin çekirdek imajından çıkartılması ve dolayısıyla çekirdeğin küçültülmesi için.
    - Yeni birtakım modüllerin ve aygıt sürücülerin çekirdek imajına eklenmesi için.
    - Çekirdeğe tamamen başka özelliklerin eklenmesi için.
    - Çekirdek üzerinde çekirdek parametreleriyle sağlanamayacak bazı konfigürasyon değişikliklerinin yapılabilmesi için.
    - Çekirdek kodlarında yapılan değişikliklerin etkin hale getirilmesi için.
    - Çekirdeğe yama yapılması için.
    - Yeni çıkan çekirdek kodlarının kullanılabilir hale getirilmesi için.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdeğin derlenmesi için öncelikle çekirdek kaynak kodlarının derleme yapılacak bilgisayara indirilmesi gerekir. Pek çok 
    dağıtım default durumda çekirdeğin kaynak kodlarını kurulum sırasında makineye çekmemektedir. Çekirdek kodları "kernel.org"
    sitesinde bulundurulmaktadır. Tarayıcdan "kernel.org" sitesine girilip "pub/linux/kernel" dizinine geçildiğinde tüm yayınlanmış
    çekirdek kodlarını göreceksiniz. İndirmeyi tarayıcıdan doğrudan yapabilirsiniz. Eğer indirmeyi komut satırından "wget" 
    programıyla yapmak istiyorsanız aşağıdaki URL'yi kullanabilirsiniz:

    https://cdn.kernel.org/pub/linux/kernel/v[MAJOR_VERSION].x/linux-[VERSION].tar.xz

    Buradaki MAJOR_VERSION "3", "4", "5" gibi tek bir sayıyı belirtmektedir. VERSION ise çekirdek büyük ve küçük numaralarını 
    belirtmektedir. Örneğin biz çekirdeğin 5.15.12 versiyonunu şöyle indirebiliriz:

    $ wget https://cdn.kernel.org/pub/linux/kernel/v5.x/linux-5.15.12.tar.xz

    Örneğin çekirdeğin 6.8.1 versiyonunu da şöyle indirebiliriz:

    $ wget https://cdn.kernel.org/pub/linux/kernel/v6.x/linux-6.8.1.tar.xz
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												62. Ders 28/11/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdek kodları indirildikten sonra onun açılması gerekir. Açma işlemi tar komutuyla aşağıdaki gibi yapılabilir:

    $ tar -xvJf linux-5.15.12.tar.xz

    Debian tabanlı sistemlerde o anda makinede yüklü olan mevcut çekirdeğin kaynak kodlarını indirmek için aşağıdaki komutu 
    kullanabilirisiniz:

    $ sudo apt-get install linux-source

    Burada yükleme "/usr/src" dizinine yapılacaktır.

    BBB için derleme yapmak istiyorsanız yine "kernel.org" deki kaynak kodları indirebilirsiniz. Ancak BBB için bazı özelleştirmelerin
    de yapılmış olduğu kaynak kodların indirilip derlenmesi birtakım kolaylıklar sağlamaktadır. Bu aşağıdaki komutla yapabilirsiniz:

    $ git clone https://github.com/beagleboard/linux.git

    Benzer biçimde Raspbbey Pi için de "kernel.org"deki kaynak kodlar kullanılabilir. Ancak Raspberry Pi'a özgü daha güncel 
    aygıt sürücüler ve aygıt ağacı dosyalarını içeren Linux kaynak kodlarının projenin kendi sitesinden indirilmesi daha uygun 
    olur. İndirmeyi aşağıdaki bağlantıdan yapabilirsiniz:

    $ git clone --depth=1 https://github.com/raspberrypi/linux.git
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux kaynak kodlarının verisyonlanması eskiden daha farklıydı. Çekirdeğin 2.6 versiyonlarından sonra versiyon numaralandırma 
    sistemi değiştirilmiştir. Eskiden (2.6 ve öncesinde) versiyon numaraları çok yavaş ilerletiliyordu. 2.6 sonrasındaki yeni 
    versiyonlamada versiyon numaraları daha hızlı ilerletilmeye başlanmıştır. Bugün kullanılan Linux versiyonları nokta ile ayrılmış 
    üç sayıdan oluşmaktadır:

    Majör.Minör.Patch-Extra (-rcX, -stable, -custom, -generic)

    Buradaki "majör numara" büyük ilerlemeleri "minör numara" ise küçük ilerlemeleri belirtmektedir. Eskiden (2.6 ve öncesinde) 
    tek sayı olan minör numaralar "geliştirme versiyonlarını (ya da beta versiyonlarını)", çift olanlar ise stabil hale getirilmiş 
    dağıtılan versiyonları belirtiyordu. Ancak 2.6 sonrasında artık tek ve çift minör numaralar arasında böyle bir farklılık kalmamıştır. 
    Patch numarası birtakım böceklerin ya da çok küçük yeniliklerin çekirdeğe dahil edildiği versiyonları belirtmektedir. Bu bağlamda 
    minör numaralardan daha küçük bir ilerlemenin söz konusu olduğunu anlatmaktadır. Burada Extra ile temsil edilen alanda "rcX 
    (X burada bir sayı belirtir) "stable", "custom", "generic", "realtime" gibi sözcükler de bulunmaktadır. "rc" harfleri "release 
    candidate" sözcüklerin kısaltmadır. Satabil sürümün öncesindeki son geliştirme sürümlerini belirtmektedir. "stable" sözcüğü 
    dağıtılan kararlı sürümü belirtir. Eğer sistem programcısı çekirdekte kendisi birtakım değişiklikler yapmışsa genellikle bunun 
    sonuna "custom" sözcüğünü getirir. Tabii bu "custom" sözcüğünü ayrıca "-<custom_version_number>" biçiminde numaralar da 
    izleyebilir. Buradaki numaralar sistem programcısının kendi özelleştirmesine ilişkin numaralardır. "generic" sözcüğü ise genel 
    kullanım için yapılandırılmış bir çekirdek olduğunu belirtmektedir. "realtime" yapılandırmanın gerçek zamanlı sistem özelliği 
    kazandırmak için yapıldığını belirtmektedir. "generic" ve "realtime" sözcüklerinin öncesinde "-N-" biçiminde bir sayı da 
    bulunabilmektedir. Bu sayı "dağıtıma özgü yama ya da derleme numarasını belirtmektedir.

    Çalışmakta olan Linux sistemi hakkında bilgiler "uname -a" komutu ile elde edilebilir. Örneğin:

    $ uname -a
    Linux kaan-virtual-machine 5.15.0-91-generic #101-Ubuntu SMP Tue Nov 14 13:30:08 UTC 2023 x86_64 x86_64 x86_64 GNU/Linux

    Bu bilgi içerisindeki çekirdek versiyonu "uname -r" ile elde edilebilir:

    $ uname -r
    5.15.0-91-generic

    Buradan biz çekirdeğin "5.15.0" sürümünün kullanıldığını anlıyoruz. Burada genel yapılandırılmış bir çekirdek söz konusudur. 
    91 sayısı dağıtıma özgü yama ya da derleme numarasını belirtir.

    Aslında "uname" komutu bu bilgileri "/proc" dosya sisteminin içerisinde almaktadır. Örneğin:

    $ cat /proc/version
    Linux version 5.15.0-91-generic (buildd@lcy02-amd64-045) (gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0, GNU ld
    (GNU Binutils for Ubuntu) 2.38) #101-Ubuntu SMP Tue Nov 14 13:30:08 UTC 2023
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdeğin derlenmesi için zaten çekirdek kodlarında bir "build sistemi" oluşturulmuştur. Buna "KConfig sistemi" ya da 
    "KBuild sistemi" denilmektedir. Biz önce çekirdek derleme işleminin hangi adımlardan geçilerek yapılacağını göreceğiz. 
    Sonra çekirdeğin önemli konfigürasyon parametreleri üzerinde biraz duracağız. Sonra da çekirdekte bazı değişiklikler yapıp
    değiştirilmiş çekirdeği kullanacağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux'ta çekirdeğin davranışını değiştirmek için farklı olanaklara sahip 5 yöntem kullanılabilmektedir:

    1) Çekirdeğin boot parametreleri yoluyla davranışının değiştirilmesi. Bunun için çekirdeğin yeniden derlenmesi gerekmez.

    2) Kernel mode aygıt sürücüsü yazmak yoluyla çekirdeğin davranışının değiştirilmesi. Bunun çekirdek kodlarının yeniden derlenmesi 
    gerekmez.

    3) Çekirdeğin konfigürasyon parametrelerinin değiştirilmesiyle davranışının değiştirilmesi. Bunun için çekirdeğin yeniden 
    derlenmesi gerekir.

    4) Çekirdeğin kodlarının değiştirilmesiyle davranışının değiştirilmesi. Bunun için de çekirdeğin yeniden derlenmesi gerekir.

    5) Çekirdeğin bazı özellikleri "proc" dosya sistemindeki bazı dosyalara birtakım değerler yazarak da değiştirilebilmektedir.
    Aslında bu tür değişiklikler "systemd" init sisteminde "systemctl" komutuyla da yapılabilmektedir. Örneğin sistem çalışırken 
    bir prosesin açabileceği dosya sayısını "proc" dosya sistemi yoluyla şöyle değiştirebiliriz:

    $ echo 2048 | sudo tee /proc/sys/fs/file-max
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												63. Ders 03/12/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux'ta çekirdek derlemesi tipik olarak aşağıdaki aşamalardan geçilerek gerçekleştirilmektedir:

    1) Derleme öncesinde derlemenin yapılacağı makinede bazı programların yüklenmiş olması gerekmektedir. Gerekebilecek tipik 
    programlar aşağıda verilmiştir:

    $ sudo apt update
    $ sudo apt install build-essential libncurses-dev bison flex libssl-dev wget gcc-arm-linux-gnueabihf \
    binutils-arm-linux-gnueabihf libelf-dev dwarves

    2) Çekirdek kodları indirilerek açılır. Biz bu konuyu yukarıda ele almıştık. İndirmeyi şöyle yapabiliriz:

    $ wget https://cdn.kernel.org/pub/linux/kernel/v6.x/linux-6.9.2.tar.xz

    Bu işlemden sonra "linux-6.9.2.tar.xz" isimli dosya indirilmiş durumdadır. Onu aşağıdaki gibi açabiliriz:

    $ tar -xvJf linux-6.9.2.tar.xz

    Bu işlemden sonra "linux-6.9.2" isminde bir dizin oluşturulacaktır.

    Ayrıca ek bir bilgi olarak eğer Ubuntu türevi bir dağıtımda çalışıyorsanız istediğiniz bir çekirdeği aşağıdaki gibi indirip 
    kurabilirsiniz:

    sudo apt install linux-image-<çekirdek_sürümü>

    Örneğin:

    $ sudo apt install linux-image-5.15.0-91-generic

    3) Çekirdek derlenmeden önce konfigüre edilmelidir. Çekirdeğin konfigüre edilmesi birtakım çekirdek özelliklerin belirlenmesi 
    anlamına gelmektedir. Konfigürasyon bilgileri çekirdek kaynak kod ağacının kök dizininde (örneğimizde "linux-6.9.2" dizini) 
    ".config" ismiyle bulunmalıdır. (Biz U-Boot ve BusyBox'ta da derleme öncesinde bir konfigürasyon işlemi yapmıştık. Orada da 
    konfigürasyon dosyası ".config" ismindeydi.) Bu ".config" dosyası default durumda kaynak dosyaların kök dizininde bulunmamaktadır. 
    Bunun çekirdeği derleyen kişi tarafından oluşturulması gerekmektedir. Çekirdek konfigürasyon parametreleri oldukça fazladır. 
    Biz izleyen paragraflarda önemli çekirdek konfigürasyon parametrelerini göreceğiz. Çekirdek konfigürasyon parametreleri çok 
    fazla olduğu için bunlar bazı genel amaçları karşılayacak biçimde default değerlerle önceden oluşturulmuş durumdadır. Bu önceden 
    oluşturulmuş default konfigürasyon dosyaları "arch/<mimari>/configs" dizininin içerisinde bulunmaktadır. Örneğin Intel X86 mimarisi 
    için bu default konfigürasyon dosyaları şöyledir:

    $ ls arch/x86/configs
    hardening.config  i386_defconfig  tiny.config  x86_64_defconfig  xen.config

    Burada biz 64 bit Linux sistemleri için "x86_64_defconfig" dosyasını kullanabiliriz. O halde bu dosyayı kaynak dosyaların 
    bulunduğu dizininin kök dizinine ".config" ismiyle kopyalayabiliriz:

    $ cp arch/x86/configs/x86_64_defconfig .config

    Biz bütün işlemlerde çekirdek kaynak kodlarının kök dizininde bulunduğumuzu (current working directory) varsayacağız. 
    Ancak burada bir noktaya dikkatinizi çekmek istiyoruz. Linux kaynak kodlarındaki default konfigürasyon dosyaları minimal biçimde
    konfigüre edilmiştir. Bu nedenle pek çok modül bu default konfigürasyon dosyalarında işaretlenmiş değildir. Bu tür denemeleri 
    zaten var olan konfigürasyon dosyalarını kullanarak yaparsanız daha fazla modül dosyası oluşturulabilir ancak daha az zahmet 
    çekebilirsiniz. Linux sistemlerinde genel olarak "/boot" dizini içerisinde "configs-<çekirdek_sürümü>" ismi altında mevcut
    çekirdeğe ilişkin konfigürasyon dosyası bulundurulmaktadır.

    Burada bir noktaya dikkatinizi çekmek istiyoruz. Çekirdek kaynak kodlarındaki "arch/<platform>/configs/x86_64_defconfig" 
    dizinindeki konfigürasyon dosyası ".config" ismiyle kopyalandıktan sonra ayrıca "make menuconfig" gibi bir işlemle onun 
    satırlarına bazı default değerlerin de eklenmesi gerekir. Bu default değerler "arch/<platform>" dizinindeki "Kconfig" dosyasından 
    gelmektedir. Bu nedenle bu default konfigürasyon dosyalarını kaynak kök dizine ".config" ismiyle kopyaladıktan sonra 
    aşağıda belirtildiği gibi "make menuconfig" yapmalısınız.

    Aslında ".config" dosyasını oluşturmanın başka alternatif yolları da vardır:

    make defconfig: Bu komut çalıştığımız sisteme uygun olan konfigürasyon dosyasını temel alarak mevcut donanım bileşenlerini 
    de gözden geçirerek sistemin açılması için gerekli minimal bir konfigürasyon dosyasını ".config" ismiyle oluşturmaktadır. Örneğin 
    biz 64 bit Intel sistemine ilişkin bir bilgisayarda çalışıyorsak "make defconfig" dediğimizde "arch/x86/configs/x86_64_defconfig" 
    dosyası temel alınarak o anda çalışılmakta olan çekirdek donanımları da dikkate alınarak nispeten minimal olan bir konfigürasyon
    dosyası oluşturmaktadır.

    make oldconfig: Bu seçeneği kullanmak için kaynak kök dizinde bir ".config" dosyasının bulunuyor olması gerekir. Ancak bu seçenek 
    KConfig dosyasındaki ve kaynak dosya ağacındaki diğer değişiklikleri de göz önüne alarak bu eski ".config" dosyasını eğer söz 
    konusu mimaride birtakım değişiklikler söz konusu ise o değişikliklere uyumlandırmaktadır. Yani örneğin biz eski bir ".config" 
    dosyasını kullanıyor olabiliriz. Ancak çekirdeğin yeni versiyonlarında ek birtakım başka konfigürasyon parametreleri de eklenmiş 
    olabilir. Bu durumda "make oldconfig" bize bu eklenenler hakkında da bazı sorular sorup bunların dikkate alınmasını 
    sağlayacaktır.

    make <platform>_defconfig: Bu seçenek belli bir platformun default konfig dosyasını ".config" dosyası olarak save etmektedir. 
    Örneğin biz Intel makinelerinde çalışıyor olabiliriz ancak BBB için default konfigürasyon dosyası oluşturmak isteyebiliriz. 
    Eğer biz "make defconfig" yaparsak Intel tabanlı bulunduğumuz platform dikkate alınarak ".config" dosyası oluşturulur. Ancak 
    biz burada örneğin "make bb.org_defconfig" komutunu uygularsak bu durumda Intel mimarisinde çalışıyor olsak da "bb.org_defconfig"
    konfigürasyon dosyası ".config" olarak save edilir. Tabii bu durumda biz aslında yine ilgili platformun konfigürasyon dosyasını 
    manuel olarak ".config" biçiminde de kopyalayabiliriz.

    make modules: Bu seçenek ile yalnızca modüller derlenir. Yani bu seçenek ".config" dosyasında belirtilen aygıt sürücü dosyalarını 
    derler ancak çekirdek derlemesi yapmaz. Yalnızca "make" işlemi zaten aynı zamanda bu işlemi de yapmaktadır.

    make uninstall: "make install" işlemi ile yapılanları geri alır.

    Aşağıdaki ilave konfig seçenekleri ise seyrek kullanılmaktadır:

    make allnoconfig: Tüm seçenekleri hayır (no) olarak ayarlar (minimal yapılandırma).
    make allyesconfig: Tüm seçenekleri evet (yes) olarak ayarlar (maksimum özellikler).
    make allmodconfig: Tüm aygıt sürücülerin çekirdeğin dışında modül (module) biçiminde derleneceğini belirtir.
    make localmodconfig: Sistemde o anda yüklü modüllere dayalı bir yapılandırma dosyası (".config" dosyası) oluşturur.
    make silentoldconfig: Yeni seçenekler için onları görmezden gelir ve o yeni özellikler ".config" dosyasına yansıtılmaz.
    make dtbs: Kaynak kod ağacında "/arch/platform/boot/dts" dizinindeki aygıt ağacı kaynak dosyalarını derler ve "dtb" 
    dosyalarını elde eder. Gömülü sistemlerde bu işlemin yapılması ve her çekirdek versiyonuyla o versiyonun "dtb" dosyasının 
    kullanılması tavsiye edilir.

    Yukarıda da belirttiğimiz gibi aslında pek çok dağıtım o anda yüklü olan çekirdeğe ilişkin konfigürasyon dosyasını "/boot" 
    dizini içerisinde "config-$(uname -r)" ismiyle bulundurmaktadır. Örneğin kursun yapılmakta olduğu Mint dağıtımında "/boot" 
    dizinin içeriği şöyledir:

    $ ls /boot
    config-5.15.0-91-generic  grub        initrd.img-5.15.0-91-generic  vmlinuz
    efi                       initrd.img  System.map-5.15.0-91-generic  vmlinuz-5.15.0-91-generic

    Buradaki "config-5.15.0-91-generic" dosyası çalışmakta olduğumuz çekirdekte kullanılan konfigürasyon dosyasıdır. Benzer biçimde 
    BBB'deki built-in eMMC içerisinde bulunan çekirdekteki "/boot" dizininin içeriği de şöyledir:

    SOC.sh                      dtbs                System.map-5.10.168-ti-r71
    initrd.img-5.10.168-ti-r71  uboot               config-5.10.168-ti-r71
    vmlinuz-5.10.168-ti-r71

    Buradaki konfigürasyon dosyası da "config-5.10.168-ti-r71" biçimindedir.

    Eğer çalışılan sistemdeki konfigürasyon dosyasını temel alacaksanız bu dosyayı Linux kaynak kodlarının bulunduğu kök dizine 
    ".config" ismiyle kopyalayabilirsiniz. Örneğin:

    $ cp /boot/config-$(uname -r) .config

    Fakat eski bir konfigürasyon dosyasını yeni bir çekirdekle kullanmak için ayrıca "make oldconfig" işleminin de yapılması 
    gerekmektedir.

    4) Şimdi elimizde pek çok değerin set edilmiş olduğu ".config" isimli bir konfigürasyon dosyası vardır. Artık bu konfigürasyon 
    dosyasından hareketle yalnızca istediğimiz bazı özellikleri değiştirebiliriz. Bunun için daha önce üzerinde çalıştığımız 
    "U-Boot", "BusyBox" gibi araçlardan anımsayacağınız "make menuconfig" komutunu kullanabiliriz:

    $ make menuconfig

    Bu komut ile birlikte yine grafik ekranda konfigürasyon seçenekleri listelenecektir. Tabii buradaki seçenekler default değerler 
    almış durumdadır. Bunların üzerinde değişiklikler yaparak ".config" dosyasını save edebiliriz. Aslında "make menuconfig" işlemi 
    hiç ".config" dosyası oluşturulmadan doğrudan da yapılabilmektedir. Bu durumda hangi sistemde çalışılıyorsa o sisteme özgü default 
    config dosyası temel alınmaktadır. Biz en azından "General stup/Local version - append to kernel release" seçeneğine "-custom" 
    gibi bir sonek girmenizi böylece yeni çekirdeğe "-custom" soneki iliştirmenizi tavsiye ederiz.

    ".config" dosyası elde edildiğinde çekirdek imzalamasını ortadan kaldırmak için dosyayı açıp aşağıdaki özellikleri belirtildiği 
    gibi değiştirebilirsiniz (bunların bazıları zaten default durumda aşağıdaki gibi de olabilir):

    CONFIG_SYSTEM_TRUSTED_KEYS=""
    CONFIG_SYSTEM_REVOCATION_KEYS=""
    CONFIG_SYSTEM_TRUSTED_KEYRING=n
    CONFIG_SECONDARY_TRUSTED_KEYRING=n

    CONFIG_MODULE_SIG=n
    CONFIG_MODULE_SIG_ALL=n
    CONFIG_MODULE_SIG_KEY=""

    Çekirdek imzalaması konusu daha ileride ele alınacaktır.

    Yukarıda a belirttiğimiz gibi derlenecek çekirdeklere yerel bir versiyon numarası da atanabilmektedir. Bu işlem Bu işlem 
    "make menuconfig" menüsünde "General Setup/Local version - append custom release" seçeneği kullanılarak ya da ".config" 
    dosyasında "CONFIG_LOCALVERSION" kullanılarak yapılabilir. Örneğin:

    CONFIG_LOCALVERSION="-custom"

    Artık çekirdek sürümüne "-custom" sonekini eklemiş olduk.

    5) Derleme işlemi için yine "make" komutu kullanılmaktadır. Örneğin:

    $ make

    Eğer derleme işleminin birden fazla CPU ile yapılmasını istiyorsanız "-j<cpu_sayısı>" seçeneğini komuta dahil edebilirsiniz. 
    Çalışılan sistemdeki CPU sayısının "nproc" komutuyla elde edildiğini anımsayınız:

    $ make -j$(nproc)

    Derleme işlemi bittiğinde ürün olarak biz "çekirdek imajını", "çekirdek tarafından yüklenecek olan modül dosyalarını 
    (aygıt sürücü dosyalarını)" ve diğer bazı dosyaları elde etmiş oluruz. Derleme işleminden sonra elde oluşturulan dosyalar ve
    onların yerleri şöyledir (buradaki <çekirdek_sürümü> "uname -r" ile elde edilecek değeri belirtiyor):

    - Sıkıştırılmış Çekirdek Imajı: "arch/<platform>/boot" dizininde "bzImage" ismiyle oluşturulmaktadır. Denemeyi yaptığımız Intel makinede 
    dosyanın yol ifadesi "arch/x86_64/boot/bzImage" biçimindedir.

    - Çekirdeğin Sıkıştırılmamış ELF İmajı: Kaynak kök dizininde "vmlinux" isminde dosya biçiminde oluşturulur.

    - Çekirdek Modülleri (Aygıt Sürücü Dosyaları): "drivers" dizininin altındaki dizinlerde ve "fs" dizininin altındaki dizinlerde 
    ve "net" dizininin altındaki dizinlerde. Ancak "make modules_install" ile bunların hepsi belirli bir dizine çekilebilir.

    Çekirdek Sembol Tablosu: Kaynak kök dizininde "System.map" ismiyle bulunuyor.

    Çekirdeğin derlemesi ne kadar zaman almaktadır? Şüphesiz bu derlemenin yapıldığı makineye göre değişebilir. Ancak derleme sürecinin
    uzamasına yol açan en önemli etken çekirdek konfigüre edilirken çok fazla modülün seçilmesidir. Pek çok dağıtım "belki lazım olur"
    gerekçesiyle konfigürasyon dosyalarında pek çok modülü dahil etmektedir. Bir dağıtımın konfigürasyon dosyasını kullandığınız zaman
    çekirdek derlemesi uzayacaktır. Ayrıca çekirdek konfigüre edilirken çok fazla modülün dahil edilmesi modüllerin çok fazla yer 
    kaplamasına da yol açabilmektedir. Çekirdek kodlarındaki platforma özgü default konfigürasyon dosyaları daha minimalist bir 
    biçimde oluşturulmuş durumdadır.

    6) Derleme sonrasında farklı dizinlerde oluşturulmuş olan aygıt sürücü dosyalarını (modülleri) belli bir dizine kopyalamak 
    için "make modules_install" komutu kullanılmaktadır. Bu komut seçeneksiz kullanılırsa default olarak "/lib/modules/<çekirdek_sürümü>"
    dizinine kopyalama yapar. Her ne kadar bu komut pek çok ".ko" uzantılı aygıt sürücü dosyasını hedef dizine kopyalıyorsa 
    da bunların hepsi çekirdek tarafından belleğe yüklenmemektedir. Çekirdek gerektiği zaman gereken aygıt sürücüleri bu dizinden 
    alarak yüklemektedir. Örneğin:

    $ sudo make modules_install

    Aslında "make modules_install" komutunun modül dosyalarını (aygıt sürücü dosyalarını) istediğimiz bir dizine kopyalamasını 
    da sağlayabiliriz. Bunun için INSTALL_MOD_PATH komut satırı argümanı kullanılmaktadır. Örneğin:

    $ sudo INSTALL_MOD_PATH=modules make modules_install

    Burada aygıt sürücü dosyaları "/lib/modules/<çekirdek_sürümü>" dizinine değil bulunulan yerdeki "modules" dizinine 
    kopyalanacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												65. Ders 10/12/2024 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi "make modules_install" komutu yalnızca modül dosyalarını mı hedef dizine kopyalıyor? Hayır aslında bu komut modül 
    dosyalarının kopyalanması dışında bazı dosyaları da oluşturup onları da hedef dizine kopyalamaktadır. Bu komut sırasıyla 
    şunları yapmaktadır:

    - Modül dosyalarını "/lib/modules/<çekirdek_sürümü>" dizinine kopyalar.
    - "modules.dep" isimli dosyayı oluşturur ve bunu "/lib/modules/<çekirdek_sürümü>" dizinine kopyalar.
    - "modules.alias" isimli dosyayı oluşturur ve bunu "/lib/modules/<çekirdek_sürümü>" dizinine kopyalar.
    - "modules.order" isimli dosyayı oluşturur ve "/lib/modules/<çekirdek_sürümü>" dizinine kopyalar.
    - "modules.builtin" isimli dosyayı "/lib/modules/<çekirdek_sürümü>" dizinine kopyalar.

    Aslında burada oluşturulan dosyaların bazıları mutlak anlamda bulunmak zorunda değildir. Ancak sistemin öngörüldüğü gibi 
    işlev göstermesi için bu dosyaların ilgili dizinde bulunması uygundur.

    Bir aygıt sürücü başka bir aygıt sürücüleri de kullanıyor olabilir. Bu durumda bu aygıt sürücü yüklenirken onun kullandığı
    tüm sürücülerin özyinelemeli olarak yüklenmesi gerekir. İşte "modules.dep" dosyası bir aygıt sürücünün yüklenmesi için 
    başka hangi sürücülerin yüklenmesi gerektiği bilgisini tutmaktadır. Aslında "modules.dep" bir text dosyadır. Bu text dosya"
    satırlardan oluşmaktadır. Satırların içeriği şöyledir:

    <modül_yolu>: <bağımlılık> <bağımlılık2> ...

    Dosyanın içeriğine şöyle örnek verebiliriz:

    ...
    kernel/arch/x86/crypto/nhpoly1305-sse2.ko.zst: kernel/crypto/nhpoly1305.ko.zst kernel/lib/crypto/libpoly1305.ko.zst
    kernel/arch/x86/crypto/nhpoly1305-avx2.ko.zst: kernel/crypto/nhpoly1305.ko.zst kernel/lib/crypto/libpoly1305.ko.zst
    kernel/arch/x86/crypto/curve25519-x86_64.ko.zst: kernel/lib/crypto/libcurve25519-generic.ko.zst
    ...

    Eğer bu "modules.dep" dosyası olmazsa bu durumda "modeprob" komutu çalışmaz ve çekirdek modülleri yüklenirken eksik 
    yükleme yapılabilir. Dolayısıyla sistem düzgün bir biçimde açılmayabilir. Eğer bu dosya elimizde yoksa ya da bir biçimde
    silinmişse bu dosyayı yeniden oluşturabiliriz. Bunun için "dempmod -a" komutu kullanılmaktadır. Komut doğrudan kullanıldığında 
    o anda çekirdek sürümü için "modules.dep" dosyasını oluşturmaktadır. Örneğin:

    $ sudo depmod -a

    Ancak siz yüklü olan başka bir çekirdek sürümü için "modules.dep" dosyasını oluşturmak istiyorsanız bu durumda çekirdek 
    sürümünü de komut satırı argümanı olarak aşağıdaki gibi komuta vermelisiniz:

    $ sudo depmod -a <çekirdek sürümü>

    Tabii depmod komutunun çalışabilmesi için "/lib/modules/<çekirdek_sürümü> dizininde modül dosyalarının bulunuyor olması gerekir. 
    Çünkü bu komut bu dizindeki modül dosyalarını tek tek bulup ELF formatının ilgili bölümlerine bakarak modülün hangi modülleri 
    kullandığını tespit ederek "modules.dep" dosyasını oluşturur.

    "modules.alias" dosyası belli bir isim ya da id ile aygıt sürücü dosyasını eşleştiren bir text dosyadır. Bu dosyanın 
    bulunmaması bazı durumlarda sorunlara yol açmayabilir. Ancak örneğin USB port'a bir aygıt takıldığında bu aygıta ilişkin 
    aygıt sürücünün hangisi olduğu bilgisi bu dosyada tutulmaktadır. Bu durumda bu dosyanın olmayışı aygıt sürücünün yüklenememesine
    neden olabilir. Dosyanın içeriği aşağıdaki formata uygun satırlardan oluşmaktadır:

    alias <tanımlayıcı> <modül_adı>

    Örnek bir içerik şöyle olabilir:

    ...
    alias usb:v05ACp*d*dc*dsc*dp*ic*isc*ip*in* apple_mfi_fastcharge
    alias usb:v8086p0B63d*dc*dsc*dp*ic*isc*ip*in* usb_ljca
    alias usb:v0681p0010d*dc*dsc*dp*ic*isc*ip*in* idmouse
    alias usb:v0681p0005d*dc*dsc*dp*ic*isc*ip*in* idmouse
    alias usb:v07C0p1506d*dc*dsc*dp*ic*isc*ip*in* iowarrior
    alias usb:v07C0p1505d*dc*dsc*dp*ic*isc*ip*in* iowarrior
    ...

    Bu dosya bir biçimde silinirse yine "depmod" komutu ile oluşturulabilir. (Yani depmod komutu yalnızca "modules.dep" dosyasını
    değil bu dosyayı da oluşturmaktadır.)

    "modules.order" dosyası aygıt sürücü dosyalarının yüklenme sırasını barındıran bir text dosyadır. Bu dosyanın her satırında 
    bir çekirdek aygıt sürücüsünün dosya yol ifadesi bulunur. Daha önce yazılmış aygıt sürücüler daha sonra yazılanlardan 
    daha önce yüklenir. Bu dosyanın olmaması genellikle bir soruna yol açmaz. Ancak modüllerin belli sırada yüklenmemesi 
    bozukluklara da neden olabilmektedir. Bu dosyanın da silinmesi durumunda yine bu dosya da "depmod" komutuyla oluşturulabilmektedir.

    7) Eğer gömülü sistemler için derleme yapıyorsanız kaynak kod ağacındaki "arch/<platform>/boot/dts" dizini içerisindeki aygıt
    ağacı kaynak dosyalarını da derlemelisiniz. Tabii elinizde zaten o versiyona özgü aygıt dosyası bulunuyor olabilir. Bu durumda 
    bu işlemi hiç yapmayabilirsiniz. Aygıt ağacı kaynak dosyalarını derlemek için "make dtbs" komutunu kullanabilirsiniz:

    $ make dtbs

    Derlenmiş aygıt ağacı dosyaları "arch/<platform>/boot/dts" dizininde ya da bu dizinin altındaki ilgili "vendor" dizininde 
    oluşturulacaktır.

    8) Bizim çekirdek imajını, geçici kök dosya sistemine ilişkin dosyayı ve aygıt ağacı dosyasını uygun yere yerleştirmemiz 
    gerekir. Bu dosyalar "/boot" dizini içerisinde bulunmalıdır. Ancak aslında bu işlem de "make install" komutuyla otomatik 
    olarak yapılabilmektedir. "make install" komutu aynı zamanda "grub" isimli bootloder programın konfigürasyon dosyalarında da 
    güncelleme yapıp yeni çekirdeğin "grub" menüsü içerisinde görünmesini de sağlamaktadır. Komut şöyle kullanılabilir:

    $ sudo make install

    Bu komut ile sırasıyla yapılanlar şunlardır:

    - Çekirdek imaj dosyası "arch/<platform>/boot/bzImage" hedef "/boot" dizinine "vmlinuz-<çekirdek_sürümü>"
    ismiyle kopyalanır.
    - "System.map" dosyası hedef "/boot" dizinine "System.map-<çekirdek_sürümü>" ismiyle kopyalanır.
    - ".config" dosyası "/boot" dizinine "config-<çekirdek_sürümü>" ismiyle kopyalanır.
    - "Geçici kök dosya sistemi dosyası oluşturulur ve hedef "/boot" dizinine "initrd.img-<çekirdek_sürümü>" ismiyle kopyalanır.
    - Eğer "grub" boot loader kullanılıyorsa "grub" konfigürasyonu güncellenir ve "grub"" menüsüne yeni girişler eklenir. Böylece
    sistemin otomatik olarak yeni çekirdekle açılması sağlanır.

    Yukarıda da belirttiğimiz gibi derleme işlemi sonucunda elde edilmiş olan dosyaların hedef sistemde bazı dizinlerde bulunuyor olması 
    gerekir. Aslında U-Boot'ta da gördüğümüz gibi çekirdek imajı ve geçici kök dosya sistemi dosyaları default yerlerin dışında 
    başka yerlerde de bulundurulabilir. Boot loader'a bu yerler belirtilebilir. Ancak yukarıdaki dosyaların hedef sistemde bulundurulduğu 
    default yerler şöyledir:

    - Çekirdek İmajı ---> "/boot" dizinine
    - Çekirdek Sembol Tablosu ---> "/boot" dizinine
    - Modül Dosyaları ---> "/lib/modules/<çekirdek_sürümü>/kernel" dizinin altında

    Ancak yukarıdaki dosyalar dışında isteğe bağlı olarak aşağıdaki dosyalar da hedef sisteme konuşlandırılabilir:

    - Konfigürasyon Dosyası ---> "/boot" dizini
    - Geçici Kök Dosya Sistemi Dosyası ---> "/boot" dizinine
    - Modüllere İlişkin Bazı Dosyalar ---> "/lib/modules/<çekirdek_sürümü>" dizinine

    Pekiyi yukarıda belirttiğimiz dosyalar hedef sistemdeki ilgili dizinlere hangi isimlerle kopyalanmalıdır? İşte tipik isimlendirme 
    şöyle olmalıdır (buradaki <çekirdek_sürümü> "uname -r" komutuyla elde edilecek olan yazıdır):

    - Çekirdek İmajı: "/boot/vmlinuz-<çekirdek_sürümü>". Örneğin "vmlinuz-6.9.2-custom" gibi.
    - Çekirdek Sembol Tablosu: "/boot/System.map-<çekirdek_sürümü>". Örneğin "System.map-6.9.2-custom" gibi.
    - Modüllere İlişkin Dosyalar: Bunlar yukarıda da belirttiğimiz gibi "/lib/modules/<çekirdek_sürümü>" dizininin içerisine
    kopyalanmalıdır.
    - Konfigürasyon Dosyası: "/boot/config-<çekirdek_sürümü>". Örneğin "config-6.9.2-custom" gibi.
    - Geçici Kök Dosya Sistemine İlişkin Dosya: "/boot/initrd.img-<çekirdek_sürümü>". Örneğin "initrd.img-6.9.2-custom" gibi.

    Ayrıca bazı dağıtımlarda "/boot" dizini içerisindeki "vmlinuz" dosyası default olan "vmlinuz-<çekirdek_sürümü>" dosyasına, 
    "inird.img" dosyası da "/boot/initrd.img-<çekirdek_sürümü>" dosyasına sembolik link yapılmış durumda olabilir. Ancak bu sembolik 
    bağlantıları "grub" kullanmamaktadır. Aşağıda Intel sistemindeki "/boot" dizinin default içeriğini görüyorsunuz:

    $ ls -l
    total 141168
    -rw-r--r-- 1 root root    261963 Kas 14  2023 config-5.15.0-91-generic
    drwx------ 3 root root      4096 Oca  1  1970 efi
    drwxr-xr-x 7 root root      4096 Ara  5 19:02 grub
    lrwxrwxrwx 1 root root        28 Ara  5 20:28 initrd.img -> initrd.img-5.15.0-91-generic
    -rw-r--r-- 1 root root 126391088 Tem 11 20:19 initrd.img-5.15.0-91-generic
    -rw------- 1 root root   6273869 Kas 14  2023 System.map-5.15.0-91-generic
    lrwxrwxrwx 1 root root        25 Ara  5 20:28 vmlinuz -> vmlinuz-5.15.0-91-generic
    -rw-r--r-- 1 root root  11615272 Kas 14  2023 vmlinuz-5.15.0-91-generic

    Pekiyi derleme sonucunda elde ettiğimiz dosyaları manuel isimlendirirken çekirdek sürüm yazısını nasıl bileceğiz?
    Bunun için "uname -r" komutunu kullanamayız. Çünkü bu komut bize o anda çalışmakta olan çekirdeğin sürüm yazısını verir. 
    Biz yukarıdaki denemede Linux'un "6.9.2" sürümünü derledik. Bunun sonuna da "-custom" getirirsek sürüm yazısının 
    "6.9.2-custom" olmasını bekleriz. Ancak bu sürüm yazısı aslında manuel olarak isim değiştirmekle oluşturulamamaktadır. 
    Bu sürüm yazısı çekirdek imajının içerisine yazılmaktadır ve bizim bazı dosyalara verdiğimiz isimlerin çekirdek içerisindeki 
    bu yazıyla uyumlu olması gerekir. Default olarak "kernel.org" sitesinden indirilen kaynak kodlar derlendiğinde çekirdek sürümü 
    "6.9.2" gibi üç haneli bir sayı olmaktadır. Yani yazının sonunda "-generic" gibi "-custom" gibi bir sonek yoktur. İşte çekirdeği 
    derlemeden önce daha önceden de belirttiğimiz gibi ".config" dosyasında "CONFIG_LOCALVERSION" özelliğine bu sürüm numarasından 
    sonra eklenecek bilgiyi girebilirsiniz. Örneğin:

    CONFIG_LOCALVERSION="-custom"

    Anımsayacağınız gibi bu işlem "make menuconfig" menüsünde "General Setup/Local version - append custom release" seçeneği kullanılarak 
    da yapılabilmektedir. Biz buradaki örneğimizde bu işlemi yaparak çekirdeği derledik. Dolayısıyla bizim derlediğimiz çekirdekte 
    çekirdek imajı içerisinde yazan sürüm ismi "6.9.2-custom" biçimindedir. Pekiyi biz bu ismi unutsaydık nasıl öğrenebilirdik. Bunun 
    basit bir yolu sıkıştırılmamış çekirdek dosyası içerisindeki (kaynak kök dizindeki "vmlinux" dosyası) string tablosunda "Linux version"
    yazısını aramaktır. Örneğin:

    $ strings vmlinux | grep "Linux version"
    Linux version 6.9.2-custom (kaan@kaan-virtual-machine) (gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0, GNU ld (GNU Binutils for 
    Ubuntu) 2.38) # SMP PREEMPT_DYNAMIC
    Linux version 6.9.2-custom (kaan@kaan-virtual-machine) (gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0, GNU ld (GNU Binutils for 
    Ubuntu) 2.38) #2 SMP PREEMPT_DYNAMIC Thu Dec 5 17:55:14 +03 2024

    Buradan sürüm yazısının "6.9.2-custom" olduğu görülmektedir. O halde bizim derleme sonucunda elde ettiğimiz dosyaları 
    manuel biçimde kopyalarken sürüm bilgisi olarak "6.9.2-custom" yazısını kullanmalıyız. Çekirdek imajının "/boot" dizinine 
    manuel kopyalanması işlemi şöyle yapılabilir (kaynak kök dizinde bulunduğumuzu varsayıyoruz):

    $ sudo cp arch/x86_64/boot/bzImage /boot/vmlinuz-6.9.2-custom

    Konfigürasyon dosyasını da şöyle kopyalayabiliriz:

    $ sudo cp .config /boot/config-6.9.2-custom

    Tabii bizim çekirdek modüllerini de "/lib/modules/6.9.2-custom/kernel" dizinine kopyalamamız gerekir. Ayrıca bir de 
    geçici kök dosya sistemine ilişkin dosyayı da kopyalamamız gerekir. Çekirdek modüllerinin kopyalanması biraz zahmetli bir 
    işlemdir. Çünkü bunlar derlediğimiz çekirdekte farklı dizinlerde bulunmaktadır. Bu kopyalamanın en etkin yolu "make modules_install"
    komutunu kullanmaktır. Benzer biçimde çekirdek dosyalarının ve gerekli diğer dosyaların uygun yerlere kopyalanması için 
    en etkin yöntem "make install" komutudur.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Normal olarak biz "make install" yaptığımızda eğer sistemimizde "grub" boot loader varsa komut "grub" konfigürasyon dosyalarında
    güncellemeler yaparak sistemin yeni çekirdekle açılmasını sağlamaktadır. Ancak kullanıcı bir menü yoluyla sistemin kendi
    istediği çekirdekle açılmasını sağlayabilir. Grub menüsü otomatik olarak görüntülenmemektedir. Boot işlemi sırasında ESC
    tuşuna basılırsa menü görüntülenir. Eğer "grub" menüsünün her zaman görüntülenmesi isteniyorsa "/etc/default/grub" dosyasındaki
    iki satır aşağıdaki gibi değiştirilmelidir:

    GRUB_TIMEOUT_STYLE=menu
    GRUB_TIMEOUT=5

    Buradaki GRUB_TIMEOUT satırı eğer menünün müdahale yapılmamışsa en fazla 5 saniye görüntüleneceğini belirtmektedir.

    Bu işlemden sonra "update-grub" programı da çalıştırılmalıdır:

    $ sudo update-grub

    Bu tür denemeler yapılırken "grub" menüleri bozulabilmektedir. Düzeltme işlemleri bazı konfigürasyon dosyalarının edit 
    edilmesiyle manuel biçimde yapılabilir. Konfigürasyon dosyaları güncellendikten sonra "update-grub" programı mutlaka 
    çalıştırılmalıdır. Ancak eğer "grub" konfigürasyon dosyaları konusunda yeterli bilgiye sahip değilseniz "grub" işlemlerini 
    görsel bir biçimde "grub-customizer" isimli programla da yapabilirsiniz. Bu program "debian depolarında" olmadığı için 
    önce aşağıdaki gibi programın bulunduğu yerin "apt" kayıtlarına eklenmesi gerekmektedir:

    $ sudo add-apt-repository ppa:danielrichter2007/grub-customizer
    $ sudo apt-get update

    Bu işlemden sonra kurulum yapılabilir:

    $ sudo apt-get install grub-customizer
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												66. Ders 12/12/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz yukarıda çekirdek derleme ve yeni çekirdeği kurma sürecini maddeler halinde açıkladık. Şimdi yukarıdaki adımları özet 
    hale getirelim:

    1) Çekirdek derlemesi için gerekli olan araçlar indirilir.

    2) Çekirdek kodları indirilir ve açılır.

    3) Zaten hazır olan konfigürasyon dosyası ".config" biçiminde kaynak kök dizine save edilir.

    4) Konfigürasyon dosyası üzerinde "make menuconfig" komutu ile değişiklikler yapılır.

    5) Çekirdek derlemesi "make -j$(nproc)" komutu ile gerçekleştirilir.

    6) Modüller ve ilgili dosyalar hedefe "sudo make modules_install" komutu ile konuşlandırılır.

    7) Çekirdek imajı ve ilgili dosyalar "sudo make install" komutu ile hedefe konuşlandırılır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi yeni çekirdeği derleyip sisteme dahil ettikten sonra nasıl onu sistemden tamamen çıkartabiliriz? Tabii yapılan işlemlerin
    tersini yapmak gerekir. Bu işlem manuel biçimde şöyle yapılabilir:

    - "/lib/modules/<çekirdek_sürümü>" dizini tamamen silinebilir.
    - "/boot" dizinindeki çekirdek sürümüne ilişkin dosyalar silinmelidir.
    - "/boot" dizininden çekirdek sürümüne ilişkin dosyalar silindikten sonra "update-grub" programı sudo ile çalıştırılmalıdır.
    Bu program "/boot" dizinini inceleyip otomatik olarak ilgili girişleri "grub" menüsünden siler. Yani aslında "grub" 
    konfigürasyon dosyaları üzerinde manuel değişiklik yapmaya gerek yoktur. "grub" işlemleri için diğer bir alternatif ise 
    "grub-customizer" programı ile görsel silme yapmaktır. Ancak bu program "/boot" dizini içerisindeki dosyaları ve modül 
    dosyalarını silmez. Yalnızca ilgili girişleri "grub" menüsünden çıkartmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux sistemleri ve diğer UNIX türevi sistemler belli bir zamandan sonra spesifik programların "root" önceliğinde çalışabilmesi
    için "sudo" komutunu ekledilir. (Böyle bir komut POSIX standartlarında bulunmamaktadır.). Ancak bu sistemlerde her kullanıcı
    "sudo" yapamamaktadır. "sudo" yapabilen kullanıcılara "sudoer"denilmektedir. Kurulum sırasında sistem yöneticisinin belirlediği 
    default kullanıcı otomatik olarak "sudoer" yapılmaktadır. Zaten yaratılmış olan bir kullanıcının ya da yeni yaratılan kullanıcının 
    "sudoer" yapılması için kullanıcının "/etc/group" dosyasında "sudo" grubuna dahil edilmesi gerekmektedir. Örneğin:

    sudo:x:27:kaan,ali

    Buradan "kaan" ve "ali" kullanıcılarının "sudo" yapabileceği anlaşılmaktadır.

    Aslında "/etc/group" dosyasını doğrudan düzenlemek yerine bu işlemi yapan" "usermod" komutu da kullanılabilir. Örneğin:

    $ sudo usermod -aG sudo student

    Bir program "sudo" ile çalıştırıldığında üst prosesin (sudo uygulayan prosesin) çevre değişkenleri default olarak yaratılan
    prosese aktarılmamaktadır. Bunun sağlanması için -E seçeneğinin kullanılması gerekir. Örneğin:

    $ sudo -E ./app

    Burada "app" programı çalıştırılırken artık kabuğun çevre değişkenlerini de barındırmış olacaktır. Ancak PATH çevre değişkeni
    bir güvenlik zafiyetine yol açabileceği için "-E" seçeneği kullanılsa bile yaratılan prosese aktarılmamaktadır.

    Sudoers olan kullanılacak için bazı default özellikler "/etc/sudoers" dosyasında bulundurulmaktadır. Bu dosyanın baş tarafı 
    şöyledir:

    Defaults	env_reset
    Defaults	mail_badpass
    Defaults	secure_path="/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin"
    Defaults	use_pty
    ...

    Eğer "-E" seçeneğinde PATH çevre değişkeninin de yaratılan prosese aktarılmasını istiyorsanız bu dosyadaki "secure_path"
    satırını # ile yorumlama satırı haline getirebilirsiniz. Birinci satır aşağıdaki gibi düzenlenirse bu durumda "-E" seçeneği 
    kullanılmadan da çevre değişkenleri otomatik olarak yaratılan prosese aktarılacaktır:

    Defaults	env_keep="*"
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi Raspberry Pi ve BBB için nasıl çekirdek derleyebiliriz? Raspberry Pi'ın ileri versiyonları zaten kişisel bilgisayarlar
    kadar hızlıdır. Dolayısıyla çekirdek derlemesi doğrudan bunların üzerinde yapılabilir. Ancak BBB gibi kısıtlı sistem kaynaklarına
    sahip donanımlar için çekirdek derlemesinin başka bir sistemde (muhtemelen Intel tabanlı bir masaüstü bilgisayarda) yapılması 
    gerekecektir.

    Yukarıda da belirttiğimiz gibi BBB ve Raspberry Pi için çekirdek kaynak dosyaları "kernel.org" sitesinden indirilebilir. 
    Ancak standart çekirdek kodlarının bu donanımlar için biraz özelleştirilmiş biçimlerinden de faydalanılabilir. Biz daha önce 
    BBB için çekirdek aşağıdaki gibi github deposundan indirilebileceğini belirtmiştir:

    $ git clone https://github.com/beagleboard/linux.git

    Yukarıdaki komut uygulandığında "linux" isimli bir dizin oluşturulacaktır. Bu dizin içerisinde BBB için özelleştirilmiş 
    Linux çekirdek kodları bulunmaktadır. Bu dizine geçip belli bir versiyon için checkout yapabilirsiniz:

    $ git checkout <sürüm>

    Örneğin kursun yapıldığı zamanda BBB içerisindeki orijinal Linux çekirdeğini aşağıdaki gibi elde edebilirsiniz:

    $ git checkout 5.10.168-ti-r71

    Bu iki işlemi tek hamlede de aşağıdaki gibi yapabiliriz:

    $ git clone --branch 5.10.168-ti-r71 --depth 1 https://github.com/beagleboard/linux.git

    BBB için Linux çekirdeğinin istediğiniz bir versiyonunu tarayıcınızı kullanarak aşağıdaki adresten de indirebilirsiniz:

    https://github.com/beagleboard/linux

    BBB için default konfigürasyon dosyası eskiden "bb.org_defconfig" biçimindeydi. Ancak bu dosya daha sonraları kaldırıldı. 
    Bugün için en uygun olanı "omap2plus_defconfig" dosyasıdır. Şimdi onu ".config" ismiyle kopyalayalım:

    $ cp arch/arm/configs/omap2plus_defconfig .config

    Tabii isterseniz BBB'nizdeki default config dosyasını ".config" olarak kopyalayıp "make oldconfig" yaparak kullanabilirsiniz.

    Şimdi artık çevre değişkenlerini set edebiliriz. Ancak burada dikkat edilmesi gereken bir nokta var. Derleme işlemi sudo ile 
    yapılırken oluşturduğumuz çevre değişkeni default durumda root prosesine aktarılmayacağı için çevre değişkenlerini root önceliğine 
    geçtikten sonra set edebiliriz:

    $ sudo bash
    [sudo] password for kaan: xxxxx

    $ export CROSS_COMPILE=arm-none-linux-gnueabihf-
    $ PATH=$PATH:/home/kaan/Study/EmbeddedLinux/arm-gnu-toolchain-13.3.rel1-x86_64-arm-none-linux-gnueabihf/bin
    $ export ARCH=arm

    Hedef sistemin mimarisinin de ARCH çevre değişkeni ile set edildiğini görüyorsunuz. Default hedef sistem Intel olduğu için 
    ARCH çevre değişkenini "arm" olarak belirledik. (Eğer ARCH çevre değişkeni set edilmemişse default olarak Intel makinelerde ,
    "intel", ARM makinelerde "arm" olarak alınmaktadır. Biz derlemeyi Intel tabanlı bir makinede yaptığımız için ARCH çevre değişkenini 
    "arm" biçiminde set etmeliyiz.)

    Burada bir noktaya daha dikkatinizi çekmek istiyoruz. Derleme işlemini yaptığınız araç zincirinin de çekirdek kodlarıyla uyumlu 
    olması gerekir. Örneğin BBB için indirdiğiniz "5.10.168-ti-r71" çekirdek sürümünün derlenmesi için en uygun çapraz derleyici 
    "gcc-arm-9.2-2019.12-x86_64-arm-none-linux-gnueabihf" sürümüdür. Bu sürümü aşağıdaki bağlantıdan indirebilirsiniz:

    https://developer.arm.com/downloads/-/gnu-a/9-2-2019-12

    Artık çekirdek yine "make menuconfig" ile konfigüre edilebilir:

    $ make menuconfig

    Biz bu aşamada çekirdeğimize "-custom" soneki vermiş olduğunuzu varsayacağız.

    Artık derlemeyi yapabiliriz:

    $ sudo make -j$(nproc) zImage

    Burada zImage oluşturulacak çekirdek dosyasının sıkıştırılma biçimini belirtiyor. ARM işlemcilerinin bulunduğu Linux sistemlerinde 
    genel olarak zImage formatı kullanılmaktadır. Ayrıca bu komut uygulandıktan sonra yeni konfigürasyona ilişkin bazı sorular da sorulabilir. 
    Bunları ENTER tuşuna basarak default değerlerle geçebilirsiniz. Derleme işleminin "sudo" ile yapıldığına dikkat ediniz. Çünkü buradaki 
    make dosyası erişim hakkı gereken bazı dosyalara erişmektedir.

    Çekirdeği derledikten sonra kurulumu nasıl yapacağız? Burada kurulum masaüstü sistemlerdeki gibi "make install" ile yapılamaz. 
    Çünkü kurulum çalışan bilgisayara değil hedef donanıma yapılacaktır. Bu durumda dosyaların manuel bir biçimde konuşlandırılması 
    daha uygundur. Ancak modül dosyalarının belli bir dizinde oluşturulması konuşlandırmayı kolaylaştırır. Örneğin:

    $ INSTALL_MOD_PATH=modules make modules_install

    Burada modül dosyaları "modules" isimli bir dizine çekilecektir. Eğer "make modules_install" yapılırken INSTALL_MOD_PATH
    çevre değişkeni set edilmezse bu durumda hedef sistem ARM bile olsa yine modüller o anda çalışılan sistemin 
    "/lib/modules/<çekirdek_sürümü>" dizinine kopyalanır.

    Bu işlemlerden sonra versiyona özgü bir biçimde aygıt ağacı kaynak dosyalarını da derleyebilirsiniz. Daha öncede belirttiğimiz 
    gibi aygıt ağacı kaynak dosyaları (".dts") dosyaları) kaynak kod ağacında "arch/<platform>/boot/dts" dizini içerisinde bulunmaktadır.
    Derleme işlemini aşağıdaki gibi yapabilirsiniz.

    $ make dtbs

    Derlenmiş aygıt ağacı dosyaları "arch/<platform>/boot/dts" dizininde ya da bu dizinin altındaki dizinlerde oluşturulacaktır. 

    Aygıt ağacı dosyaları derlendikten sonra yukarıda da belirttiğimiz gibi "arch/<platform>/boot/dts" dizinine ya da bu dizinin 
    altındaki "vendor" dizinlerine çekilmektedir. Onları oradan almak zahmetli olabilir. Bunun için make "dtbs_install" komutu da 
    kullanılabilmektedir. Dosyaların hangi dizine çekileceği INSTALL_DTBS_PATH çevre değişkeni ile belirlenebilmektedir. Örneğin:

    $ make INSTALL_DTBS_PATH=dtbs dtbs_install

    Burada kurulum dtbs isimli bir dizine yapılacaktır. Ancak bu durumda bütün aygıt ağacı dosyalarının bu dizine çekileceğine dikkat
    ediniz.

    Artık çekirdek derlenmiştir ve modüller de bir dizine çekilmiştir. Şimdi yapılacak şey elde edilen bu dosyaları hedef makinede
    uygun yerlere yerleştirmektir. Bu işlemler de madde madde şöyle yapılabilir:

    1) Çekirdek imajı "arch/arm/boot" dizinindeki "zImage" dosyası hedef sisteme ilişkin mikro SD kartın Linux disk bölümündeki 
    "/boot" dizinine kopyalanır.

    2) Kaynak kod kök dizininde oluşturulan "System.map" dosyası ismin sonuna "-<çekirdek_sürümü>" eklenerek hedef sisteme ilişkin 
    mikro SD kartın "/boot" dizinine kopyalanır. Çekirdek sürümünün tam ismini kaynak kod kök dizinindeki "vmlinux" dosyasına 
    "strings" komutunu kullanarak öğrenebilirsiniz. Örneğin:

    $ strings vmlinux | grep -i "linux version"

    Linux version 5.10.168-custom (root@kaan-virtual-machine) (arm-none-linux-gnueabihf-gcc (GNU Toolchain for the A-profile 
    Architecture 9.2-2019.12 (arm-9.10)) 9.2.1 20191025, GNU ld (GNU Toolchain for the A-profile Architecture 9.2-2019.12 
    (arm-9.10)) 2.33.1.20191209) #1 SMP PREEMPT Wed Jan 15 00:21:27 +03 2025

    Buradan çekirdek sürümünün "5.10.168-custom" olduğunu görüyoruz. Bu durumda "System.map" dosyası hedef sisteme ilişkin mikro 
    SD kartın "/boot" dizinine "System.map-5.10.168-custom" ismiyle kopyalanır.

    3) Çekirdek modüllerine ilişkin dizin hedef sisteme ilişkin mikro SD kartın "/lib/modules" dizinine çekirdek sürümü adıyla 
    kopyalanır. Örneğin çekirdek sürümü "5.10.168-custom" ise modüllerin bulunduğu dizini bu isimle kopyalamalısınız. Burada 
    dikkat edilmesi gereken nokta modüllerin dizine install edilmesinden sonra onun asıl başlangıç dizininin birkaç dizin içeride 
    olmasıdır. Örneğin kurulum yaptığınız yer "modules" dizini olsun. Bu durumda modül dizini "modules/lib/modules" içerisinde 
    çekirdek sürümüne ilişkin isme sahip dizinde bulunacaktır. Bu dizinde çekirdek kodlarının kök dizinine referans eden "source" 
    ve "build" isimli biriki sembolik bağlantı dosyası da bulunabilmektedir. Kopyalamadan önce bu sembolik bağlantı dosyalarını 
    silmelisiniz. Aksi takdirde tüm kaynak kod ağacı da kopyalamaya dahil edilir.

    4) Elde edilen aygıt ağacı dosyaları (".dtb" ve "dtbo" dosyaları) hedef sisteme ilişkin mikro SD kartın "/boot/dts/<çekirdek_sürümü>" 
    dizinine çekilebilir. Tabii aslında bunun yerinin bir önemi yoktur. Bu yer boot loader parametrelerinde zaten uygulamacı 
    tarafından belirtilmek zorundadır. Ancak genellikle aygıt ağacı dosyaları "/boot/dts/<çekirdek_sürümü>" dizinine konuşlandırılır.

    5) Çekirdek derlemesi için kullanılan konfigürasyon dosyasının hedef sisteme kopyalanması mutlak anlamda gerekli değilse de 
    iyi bir tekniktir. Bunun için kaynak kök dizinindeki ".config" dosyasını hedef sisteme ilişkin mikro SD kartın "/boot" 
    dizinine "config-<çekirdek_sürümü>" ismiyle kopyalayabilirsiniz. Örneğin çekirdek sürümünüz "5.10.168-custom" ise kopyalama
    "config-5.10.168-custom" ismiyle yapılabilir.

    6) Çekirdeğe yeni modüller eklemişseniz ve sisteminiz geçici kök dosya sistemine gereksinim duyuyorsa (BBB için Linux'un ileri 
    sürümleri gereksinim duymaktadır) sizin geçici kök dosya sistemini yukarıdaki öğeleri içerecek biçimde yeniden oluşturmanız
    gerekebilir. Geçici kök dosya sistemini daha önce yapmış olduğumuz oluşturduktan sonra onu mikro SD kartın "/boot" dizininin
    içerisine çekebilirsiniz. Geçici kök dosya sisteminin isminin de "initrd.img.<çekirdek_sürümü>" biçiminde verilmesi uygundur.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												68. Ders 19/12/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdeği yeniden derlemenin gerekçelerinden bahsetmiştik. Bunlardan biri de çekirdek kodları üzerinde değişikliklerin 
    yapılmış olmasıydı. Pekiyi çekirdek kodları üzerinde değişiklikler nasıl yapılabilir? Çekirdek kodları üzerinde tipik olarak 
    dört yolla değişiklik yapılmaktadır:

    1) Çekirdek kodlarındaki bir dosya içerisinde bulunan fonksiyon kodlarında değişiklik yapılması.
    2) Çekirdek kodlarındaki bir dosya içerisine yeni bir fonksiyon eklenmesi.
    3) Çekirdek kodlarındaki bir dizin içerisine yeni bir C kaynak dosyası eklenmesi.
    4) Çekirdek kodlarındaki bir dizin içerisine yeni bir dizin ve bu dizinin içerisinde çok sayıda C kaynak dosyalarının eklenmesi.

    Eğer biz birinci maddedeki ve ikinci maddedeki gibi çekirdek kodlarına yeni bir dosya eklemiyorsak çekirdeğin derlenmesini
    sağlayan make dosyalarında bir değişiklik yapmamıza gerek yoktur. Ancak çekirdeğe yeni bir kaynak dosya ya da dizin ekleyeceksek
    bu eklemeyi yaptığımız dizindeki make dosyasında bu ekleme izleyen paragraflarda açıklayacağımız biçimde belirtilmelidir. 
    Böylece çekirdek yeniden derlendiğinde bu dosyalar da çekirdek imajının içerisine eklenmiş olacaktır. Eğer kaynak kod ağacında 
    bir dizinin altına yeni bir dizin eklemek istersek bu durumda o dizini yine ana dizine ilişkin make dosyasında belirtmemiz ve
    o dizinde ayrı bir Makefile oluşturmamız gerekmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												69. Ders 26/12/2024 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux kaynak kod ağacında dizinlerin altında "Makefile" isimli make dosyaları bulunur. Eğer biz bir dizinin altına yeni bir
    dosya ekleyeceksek o dizinin içerisinde bulunan Makefile içerisine aşağıdaki gibi bir satır eklemeliyiz:

    obj-y += dosya_ismi.o

    Buradaki += operatörü obj-y isimli hedefe ekleme yapma anlamına gelmektedir. "obj" sözcüğünün yanındaki "-y" harfi ilgili 
    dosyanın çekirdeğin bir parçası biçiminde çekirdek imajının içerisine gömüleceğini belirtmektedir. Make dosyalarının bazı 
    satırlarında "obj-y" yerine "obj-m" de görebilirsiniz. Bu da ilgili dosyanın ayrı bir modül biçiminde derleneceği anlamına 
    gelmektedir. Eklemeler genellikle çekirdek imajının içine yapıldığı için biz de "obj-y" kullanırız. Eğer bir dosyayı biz 
    çekirdek imajının içine gömmek yerine ayrı bir çekirdek modülü olarak derlemek istiyorsak bu durumda dosyayı yerleştirdiğimiz 
    dizinin "Makefile" dosyasına aşağıdaki gibi bir ekleme yaparız:

    obj-m += dosya_ismi.o

    Eğer çekirdek kaynak kodlarına tümden bir dizin eklemek istiyorsak bu durumda o dizini oluşturduğumuz dizindeki "Makefile"
    dosyasına aşağıdaki gibi bir ekleme yaparız:

    obj-y += dizin_ismi/

    Burada dizin isminden sonra '/' karakterini unutmayınız. Tabii bu ekleme bir modül biçiminde de olabilirdi:

    obj-m += dizin_ismi/

    Fakat bu ekleme yapıldıktan sonra bizim ayrıca yarattığımız dizinde "Makefile" isimli bir dosya oluşturmamız ve o dosyanın 
    içerisinde o dizinde çekirdek kodlarına ekleyeceğimiz dosyaları belirtmemiz gerekir. Örneğin biz "drivers" dizininin altına
    "mydriver" isimli bir dizin oluşturup onun da içerisine "a.c" "b.c" ve "c.c" dosyalarını eklemiş olalım. Bu durumda önce 
    "drivers" dizini içerisindeki Makefile dosyasına aşağıdaki gibi bir satır ekleriz:

    obj-y += mydriver/

    Sonra da "mydriver" dizini içerisinde "Makefile" isimli bir dosya oluşturup bu dosyanın içerisinde de bu dizin içerisindeki 
    dosyaları belirtiriz. Örneğin:

    obj-y += a.o
    obj-y += b.o
    obj-y += c.o

    Ayrıca kaynak kod ağacındaki dizinler içerisinde Makefile dosyasının yanı sıra "Kconfig" isimli dosyalar da bulunabilmektedir. 
    Bu dosyaların içerisinde ilgili dosyaların ya da dizinlerin "konfigürasyon dosyasına" yansıtılması için gerekli bilgiler 
    bulundurulmaktadır. Örneğin biz bu "mydriver" dizinindeki dosyaların çekirdek kodlarına dahil edilip edilmeyeceğini çekirdeği 
    derleyenin konfigürasyon aşamasında belirlemesini sağlayabiliriz. Bunun için bu Kconfig dosyasına bir giriş eklememiz gerekir. 
    Böylece bu giriş de "menuconfig" yapıldığında bir seçenek olarak karşımıza gelecektir. Tabii ekleyeceğimiz dosya ve dizinleri 
    "Kconfig" dosyasında belirtmek zorunda değiliz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi çekirdeğin konfigüre edilmesi aşamasında "menuconfig" işleminde belirlediğimiz seçenekler kaynak kodlara nasıl yansıtılmaktadır?
    Örneğin biz "menuconfig" işleminde bir modülün çekirdek kodlarına dahil edilmesini ilgili girişi x ile seçerek sağlayabilmekteyiz. 
    Pekiyi bu durum nasıl build işlemine yansıtılmaktadır? Benzer biçimde biz konfigürasyon aşamasında bazı çekirdek çekirdek 
    parametrelerini de değiştirebilmekteyiz. Örneğin "timer tick" frekansı "menuconfig" menüsünde bir sayı biçiminde belirlenebilmektedir.

    İAnımsanacağı gibi "menuconfig" ve diğer config menülerinde yapılan seçimler daha önce de belirttiğimiz gibi ".config" isimli 
    bir text dosyaya save edilmektedir. Bu ".config" dosyası "özellik=değer" biçiminde satırlardan oluşmaktadır. Aşağıda dosyanın 
    birkaç satırını görüyorsunuz:

    ...
    CONFIG_CC_HAS_ASM_INLINE=y
    CONFIG_CC_HAS_NO_PROFILE_FN_ATTR=y
    CONFIG_PAHOLE_VERSION=125
    CONFIG_IRQ_WORK=y
    CONFIG_BUILDTIME_TABLE_SORT=y
    CONFIG_THREAD_INFO_IN_TASK=y
    ...

    Çekirdek derlenirken ilk aşamada bu ".config" dosyasının içeriği "include/generated/autoconf.h" dosyasının içerisinde #define
    önişlemci komutları biçiminde aktarılmaktadır. İşte eğer ilgili konsigürasyon dosyasındaki değer "y" ya da "m" ise bu "autoconf.h"
    dosyası içerisinde buna ilişkin sembolik sabit 1 olarak görünür. Eğer konfigürasyon dosyasında ilgili seçenek gerçekten 
    bir değer belirtiyora "autoconf.h" dosyası içerisinde bu sembolik sabit o değerde olur. Eğer konfigürasyon dosyasında ilgili 
    seçenek "n" biçiminde seçilmişse bu durumda ilgili sembolik sabit hiç define edilmemiş hale gelir. Özetle aslında ".conf" dosyası 
    içerisindeki satırlardan C'ce anlamlı #define önişlemci komutları oluşturulmaktadır. Aşağıda üretilmiş olan "autoconf.h" dosyasının
    birkaç satırını görüyorsunuz:

    ...
    #define CONFIG_IGB_HWMON 1
    #define CONFIG_ACPI_HOTPLUG_CPU 1
    #define CONFIG_DEV_DAX_KMEM_MODULE 1
    #define CONFIG_RIONET_RX_SIZE 128
    #define CONFIG_USB_SERIAL_KEYSPAN_PDA_MODULE 1
    #define CONFIG_BOOTTIME_TRACING 1
    ...

    Tabii üretilen bu "autoconf.h" dosyası kaynak kodu oluşturan dosyalarda doğrudan ya da dolaylı bir biçimde include edilmiş durumdadır. 
    Linux kaynak kodları da bu sembolik sabitleri kullanacak biçimde yazılmıştır.

    Pekiyi "Makefile" içerisindeki ilgili dosyanın çekirdek derlenirken derlenmesini sağlayan aşağıdaki gibi satırların anlamı nedir?

    ...
    obj-$(CONFIG_I8254)             += i8254.o
    obj-$(CONFIG_104_QUAD_8)        += 104-quad-8.o
    obj-$(CONFIG_INTERRUPT_CNT)     += interrupt-cnt.o
    obj-$(CONFIG_RZ_MTU3_CNT)       += rz-mtu3-cnt.o
    obj-$(CONFIG_STM32_TIMER_CNT)   += stm32-timer-cnt.o
    ...

    İşte KBuild sistemi aynı zamanda bu ".config" dosyasından hareketle make programı için anlamlı olan değişkenler de oluşturmaktadır.
    Bu değişkenleri yukarıda açıkladığımız sembolik sabitlerle karıştırmayınız. Bu değişkenler make dili için anlamlı olan make dilinin 
    değişkenleridir. Örneğin eğer ".config" dosyasında bir seçenek "y" olarak belirtilmişse bu konfigürasyon seçeneği için make dilinde 
    "y" değeri, eğer "m" olarak belirtilmişse de "m" değeri oluşturulmaktadır. Böylece aslında yukarıdaki make satırları ilgili seçenek 
    "y" olarak seçilmişse "obj-y" biçimine "m" olarak olarak seçilmişse "obj-m" biçimine dönüştürülmektedir.

    Çekirdeğe birtakım kodlar ekleyenler eğer eklemeleri "Kconfig" dosyası yoluyla konfigürasyona yansıtmışlarsa bu durumda kendi 
    "Makefile" dosyasına bu eklemeleri yukarıdaki gibi girebilirler. Örneğin biz Ya da biz "mymodule" ile temsil ettiğimiz bir 
    modül dosyası oluşturup bu modül dosyasının çekirdek kodlarına eklenip eklenmeyeceğini konfigürasyonda "Kconfig" dosyası 
    yoluyla belirtebiliriz. Bu durumda "Makefile" içerisindeki girişi aşağıdaki gibi de oluşturabiliriz:

    obj-$(CONFIG_MYMODULE) += mymodule.o

    Görüldüğü gibi burada aslında biz konfigüre eden nasıl seçmişse onun seçimini yansıtmış olmaktayız. Kconfig dosyasında bir 
    özellik "no" ise bu durumda ilgili Makefile satırı aşağıdaki gibi bir hale gelecektir:

    obj-n += mymodule.o

    obj-n biçiminde bir hedef olmadığı için zaten bu satır derleme aşamasında dikkate alınmayacaktır. Ancak bazen sistem programcıları 
    "yes" durumu için aşağıdaki gibi bir kontrol ile modülü koşullu bir biçimde de derleme sürecine ekleyebilmektedir:

    ifeq ($(CONFIG_MYSYSCALL), y)
        obj-y += mysyscall.o
    endif

    Burada eğer konfigürasyon yapılırken ilgili seçenek "yes" biçiminde (çarpılanarak) geçilmişse bu durumda biz de ilgili 
    dosyayı derlemeye dahil etmiş olduk.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												70. Ders 02/01/2025 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bir C dosyasını ya da dizini çekirdek kodlarına ekledikten sonra onun konfigürasyon sırasında (örneğin "make menuconfig")
    işlemi sırasında görünebilirliğini sağlamak için "Kconfig" dosyalarının kullanıldığını belirtmiştik. "Kconfig" dosyalarının 
    genel formatı için aşağıdaki bağlantılara başvurabilirsiniz:

    https://docs.kernel.org/kbuild/kconfig-language.html

    "Kconfig" dosyaları tıpkı "Makefile" dosyalarında olduğu gibi özyinelemeli biçimde işletilmektedir. Yani biz çekirdek kaynak
    kod ağacında bir dizin yaratmayıp zaten var olan bir dizinin içerisine bir ".c" dosyası yerleştiriyorsak Makefile ve "Kconfig"
    dosyaları oluşturmamıza gerek yoktur. Bu işlemi zaten dizin içerisinde var olan bir "Makefile" ve "Kconfig" dosyaları üzerinde 
    onlara ekleme yaparak sağlayabiliriz. Ancak eğer biz bir dizin oluşturup onun içerisine dosyalar yerleştireceksek o dizin 
    için bir tanem "Makefile" ve bir tane de "Kconfig" dosyası oluşturmamız gerekir.

    Linux kaynak kod ağacında bir dizin yaratıp onun içerisine dosyalar yerleştirirken o dizin için "Makefile" ve "Kconfig" 
    dosyalarının yazılması gerektiğini belirtmiştik. (Tabii aslında "Kconfig" dosyasının bulundurulması zorunlu değildir. Ancak 
    eklenen özelliğin konfigüre edilebilirliğinin sağlanması için gerekmektedir.) Bu dosyalar oluşturulduktan sonra dış dizindeki 
    "Makefile" ve "Kconfig" dosyalarında aşağıda belirtilen işlemler de yapılmalıdır:

    1) Dış dizindeki "Makefile" dosyasında alt dizinin dikkate alınacağı aşağıdaki gibi bir satırla belirtilmelidir:

    obj-y += <dizin_ismi>/

    2) Dış dizinin "Kconfig" dosyasında iç dizindeki "Kconfig" dosyasının dikkate alınması aşağıdaki gibi bir satırın eklenmesiyle
    sağlanmaktadır:

    source "kaynak_kod_ağacının_köküne_göreli_yol_ifadesi"

    Örneğin:

    source "drivers/mydriver/Kconfig"

    Biz Kconfig dosyasına girişi yerleştirdiğimizde artık "make menuconfig" gibi konfigürasyon menülerinde eklediğimiz "Kconfig"
    elemanı bir menü seçeneği biçiminde karşımıza çıkacaktır.

    Örneğin biz bir aygıt sürücüsü dosyasını çekirdeğin kaynak dos ağacında "drivers" dizinin altına "mydriver" dizini açarak
    eklemek isteyelim. Bu durumda şunların yapılması gerekir:

    1) "drivers" dizini içerisinde "mydriver" dizinini yaratıp içerisine "mydriver.c" dosyasını (belki de "mydriver.h" gibi 
    bir başlık dosyasını da) yerleştirilmelidir.

    2) "drivers/mydriver" dizininde aşağıdaki gibi bir "Kconfig" dosyası yaratılmalıdır:

    config MYDRIVER
    tristate "My Character Device Driver"
    default y
    help
      Enable this option to include support for My Device Driver.
      It can either be built as a module or statically linked into the kernel.

    3) Üst dizindeki ("drivers" dizinindeki) "Kconfig" dosyasına aşağıdaki satır yerleştirilmelidir:

    source "drivers/mydriver/Kconfig"

    4) "drivers/mydriver" dizinine aşağıdaki gibi bir satır eklenmelidir:

    obj-$(CONFIG_MyDRIVER) += mydriver.o

    5) Üst dizindeki (yani "drivers" dizinindeki) "Makefile" içerisine aşağıdaki satır eklenmelidir:

    obj-y += mydriver/
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi çekirdeğe bazı kodlar ekleyip onu yeniden derleyerek bazı denemeler yapacağız. Örneğin çekirdeğe yeni bir çekirdek 
    modülü ekleyelim ve çekirdeğin o modül gömülü olarak başlatılmasını sağlayalım. Ancak burada biz aynı zamanda bu çekirdek 
    modülünün "make menuconfig" ile seçilebilmesini de sağlayalım. Henüz çekirdek modüllerinin nasıl yazılacağını görmedik. Bu 
    nedenle bu örneğimizde "hiçbir şey yapmayan iskelet bir çekirdek modülü" oluşturacağız. Bu işlem şu adımlardan geçilerek 
    yapılabilir. (Kaynak kod ağacının kökünde bulunduğumuzu varsayıyoruz)

    1) "drivers/mydriver" dizini yaratılır.

    2) İskelet bir çekirdek modülü "mydriver.c" biçiminde "drivers/mydriver" dizininde oluşturulur. Dosya şöyle olabilir:

    /* mydriver.c */

    #include <linux/module.h>
    #include <linux/kernel.h>

    MODULE_LICENSE("GPL");
    MODULE_AUTHOR("Kaan Aslan");
    MODULE_DESCRIPTION("General Device Driver");

    static int __init mydriver_init(void)
    {
        printk(KERN_INFO "Hello World...\n");

        return 0;
    }

    static void __exit mydriver_exit(void)
    {
        printk(KERN_INFO "Goodbye World...\n");
    }

    module_init(mydriver_init);
    module_exit(mydriver_exit);

    3) "drivers/mydriver" dizininde bir "Kconfig" dosyası oluşturulmalıdır:

    config MYDRIVER
    tristate "My Character Device Driver"
    default y
    help
      Enable this option to include support for My Device Driver.
      It can either be built as a module or statically linked into the kernel.

    4) Üst dizinin (yani "drivers" dizinin) "Kconfig" dosyasına aşağıdaki ekleme yapılmalıdır:

    source "drivers/mydriver/Kconfig"

    5) "drivers/mydriver" dizininde aşağıdaki içeriğe sahip bir "Makefile" dosyası yaratılmalıdır:

    obj-$(CONFIG_MY_DRIVER) += my_driver.o

    6) Üst dizindeki ("drivers" dizinindeki) "Makefile" dosyasına aşağıdaki satır eklenmelidir:

    obj-y += mydriver/

    Artık çekirdeği derleyebiliriz. Artık "menuconfig" menüsünde kendi aygıt sürücümüze ilişkin seçenek de çıkacaktır.

    Çekirdek derlemesinde en önemli zaman kaybının aygıt sürücülerin derlenmesi aşamasında oluştuğunu belirtmiştik. Biz ".config"
    dosyasını default biçimde oluşturduğumuzda çok sayıda aygıt sürücü hiç kullanılmayacak olsa bile "m" biçiminde koda çekirdek
    derlemesine dahil edilmektedir. Bu tür durumlarda elinizde zaten default bir konfigürasyon dosyası varsa (çekirdeklere ilişkin 
    konfigürasyon dosyalarının "/boot" dizini içerisinde bulunduğunu anımsayınız) o konfigürasyon dosyasını ".config" biçiminde 
    kopyalayarak işlemlere oradan devam edebilirsiniz. Ancak aşağıdaki satırlarda değişiklik yapmayı unutmayınız:

    CONFIG_SYSTEM_TRUSTED_KEYS=""
    CONFIG_SYSTEM_REVOCATION_KEYS=""
    CONFIG_SYSTEM_TRUSTED_KEYRING=n
    CONFIG_SECONDARY_TRUSTED_KEYRING=n

    CONFIG_MODULE_SIG=n
    CONFIG_MODULE_SIG_ALL=n
    CONFIG_MODULE_SIG_KEY=""

    Yeni çekirdeğimize "-custom" ismini de ekleyebiliriz. Daha önceden de belirttiğimiz gibi eğer çekirdeğin eski versiyonundan
    konfigürasyon dosyası alınacaksa "make oldconfig" uygulanıp o versiyondan sonra eklenmiş olan özelliklerin gözden geçirilmesi 
    sağlanmalıdır.

    7) Artık çekirdek derlemesi aşağıdaki gibi yapılabilir:

    $ make -j$(nproc)

    8) Derleme işlemi bittikten sonra önce çekirdek modüllerini "sudo make modules_install" ile sonra da çekirdeğin kendisini de
    "sudo make install" ile install edebilirsiniz:

    $ sudo make modules_install
    ...
    $ sudo make install
    ...

    Anımsanacağı gibi "make install" komutu artık sistemin yeni çekirdekle açılmasını sağlayacaktır. "make install" aynı zamanda
    geçici kök dosya sistemini "update-initramfs" komutu ile oluşturup "/boot" dizinine yerleştirmektedir. Tabii "update-initramfs" 
    programını siz de gerektiğinde kullanabilirsiniz. Programın genel biçimi şöyledir:

    $ sudo update-initramfs -c -k <çekirdek_sürümü>

    Buradaki "çekirdek_sürümü" yalnızca çekirdeğin numarasını değil ona verdiğiniz ekleri de içermelidir. (Örneğin "6.9.2-custom"
    gibi.) Bu komut geçici kök dosya sistemini o anda çalışmakta olan sistemin konfigürasyonunu da dikkate alarak oluşturur ve 
    "/boot" dizinine kopyalar. Yukarıda da belirttiğimiz gibi "make install" zaten bu programı çalıştırarak geçici kök dosya 
    sistemini "/boot" dizininde oluşturmaktadır.

    Pekiyi çekirdeğin kaynak kodlarına yaptığımız eklemenin gerçekten yapılmış olduğunu nasıl anlayabiliriz? Bizim yazdığımız 
    iskelet aygıt sürücü kodlarında çekirdek aygıt sürücümüzü yüklediğinde "mydriver_init" fonksiyonu çağrılacaktır. Bu 
    fonksiyonun içinde de printk isimli çekirdek fonksiyonu ile biz bir log mesajı yazdırdık. Bu log mesajları "kernel ring 
    buffer" denilen bir kuyruk sistemine yazılmaktadır. "dmesg" komutuyla bu kuyruk sistemi görüntülenebilir. Eğer "dmesg" 
    yaptığımızda biz bu mesajları görürsek aygıt sürücümüzün yüklenmiş olduğu sonucunu çıkartabiliriz. Çekirdeğe gömülü olan 
    modüller "/proc/modules" dosyasında görünmezler, dolayısıyla da "lsmod" komutu ile de bunları göremeyiz. Bunlar için 
    "/sys/module" dizininde de bir giriş oluşturulmamaktadır. Ancak "modinfo" komutu çekirdeğe ilişkin bazı dosyalarda baktığı 
    için bize bu konuda bilgi verebilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de yeni bir sistem fonksiyonunu çekirdeğe eklemek isteyelim. Linux çekirdeğinde sistem fonksiyonlarının adresleri 
    bir fonksiyon gösterici dizisinde tutulmaktadır. Bu gösterici dizisinin her elemanı bir sistem fonksiyonun adresini içerir. 
    O halde çekirdeğe bir sistem fonksiyonu ekleyebilmek için sistem fonksiyonunu bir dosya içerisine yazmak ve bu tabloya 
    o fonksiyonu gösteren bir giriş eklemek gerekir. Bunun yapılış biçimi Linux'un çeşitli versiyonlarında değiştirilmiştir. 
    Aşağıda güncel bir versiyonda bu işlemin nasıl yapıldığına ilişkin bir örnek vereceğiz:

    1) Sistem fonksiyonumuz "mysyscall" biçiminde isimlendirmiş olalım. Önce yine çekirdek kaynak kod ağacında uygun bir dizine
    yine bir dosya eklemek gerekir. Bunun için en uygun dizin "kernel" dizinidir. Bu durumda sistem fonksiyonumuzu "kernel" 
    dizini içerisinde "mysyscall.c" ismiyle yazabiliriz:

    /* mysyscall.c */

    #include <linux/kernel.h>
    #include <linux/syscalls.h>
    #include <linux/uaccess.h>

    SYSCALL_DEFINE0(mysyscall)
    {
        printk(KERN_INFO "My system call\n");

        return 0;
    }

    2) Sistem fonksiyon tablosuna ilgili sistem fonksiyonu bir eleman olarak girilir. Sistem fonksiyon tablosu 
    "arch/<platform>/syscall/xxx.tbl" dosyasında belirtilmektedir. 64 bit Linux sistemleri için bu dosya 
    "arch/x86/entry/syscalls/syscall_64.tbl" biçimindedir. Ekleme bu dosyanın sonuna aşağıdaki gibi yapılabilir:

    ...
    544	x32	io_submit		compat_sys_io_submit
    545	x32	execveat		compat_sys_execveat
    546	x32	preadv2			compat_sys_preadv64v2
    547	x32	pwritev2		compat_sys_pwritev64v2
    # This is the end of the legacy x32 range. Numbers 548 and above are
    # not special and are not to be used for x32-specific syscalls.
    548    common   mysyscall    sys_mysyscall

    3) Eğer bu sistem fonksiyonunun çekirdek konfigüre edilirken çekirdek içerisine gömülüp gömülmemesi konusunda konfigüre 
    edene olanak tanınacaksa "Kconfig" dosyasına yine bir giriş eklenmelidir. Ancak "kernel" dizini içerisinde birden fazla
    "Kconfig" dosyası oluşturulmuş durumdadır. Aşağıda bu dosyaların listesini görüyorsunuz:

    Kconfig.freezer
    Kconfig.hz
    Kconfig.kexec
    Kconfig.locks
    Kconfig.preempt

    Burada örneğin biz konfigürasyon girişini "Kconfig.preempt" içerisine yerleştirebiliriz. Giriş şöyle olabilir:

    config MYSYSCALL
    bool "Enable My New Syscall"
    default y
    help
      Enable this option to include the new system function in the kernel.

    4) "kernel" dizinindeki "Makefile" dosyasına şu giriş eklenebilir:

    obj-$(CONFIG_MYSYSCALL) += mysyscall.o

    ya da bu girişi bir if kontrolü ile de ekleyebiliriz:

    ifeq ($(CONFIG_MYSYSCALL), y)
        obj-y += mysyscall.o
    endif

    Burada bir noktaya dikkatini çekmek istiyoruz. Belli bir versiyondan sonra çekirdeğe sistem fonksiyonu *.tbl" uzantılı dosyalar 
    yoluyla eklenmektedir. Sistem fonksiyonunun kodu sistem konfigüre edilirken çekirdekten çıkartılsa bile onun bu ".tbl" dosyasında 
    kalması link aşamasında sorun oluşturacaktır. (Eski sistemde bu ekleme doğrudan ".c" dosyasının içerisine yapıldığı için 
    CONFIG_MYSYSCALL sembolik sabitini burada kullanılabiliyorduk.) Bu sorunu çözmek için "msyscall.c" dosyasında aşağıdaki gibi 
    bir düzenleme yapılabilir:

    /* mysyscall.c */

    #include <linux/kernel.h>
    #include <linux/syscalls.h>
    #include <linux/uaccess.h>

    #ifdef CONFIG_MYSYSCALL
    SYSCALL_DEFINE0(mysyscall)
    {
        printk(KERN_INFO "My system call\n");

        return 0;
    }
    #else
    SYSCALL_DEFINE0(mysyscall)
    {
        printk(KERN_INFO "My system call\n");

        return -ENOSYS;
    }
    #endif

    5) Artık çekirdek aşağıdaki gibi derlenebilir:

    $ sudo make -j$(nproc)

    6) Çekirdek modüllerini aşağıdaki gibi install edebiliriz:

    $ sudo make modules_install

    7) Çekirdeğin kendisini de şöyle install edebiliriz:

    $ sudo make install
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi çekirdek kodlarında küçük değişikler yapıldığında yeniden "make modules_install" ve "make install" yapılmasına gerek 
    var mıdır? Küçük değişiklikler için bu işlemler yapılmazsa genellikle sorun ortaya çıkmaz. Yeni oluşturulan çekirdek imajı 
    doğrudan eskisinin üzerine kopyalanabilir. Ancak değişikliğin yerine ve kapsamına göre çekirdeğin sembol tabloları değişebileceği 
    için genel olarak her derlemeden sonra "make install" yapabilirsiniz. Modüller üzerinde bir işlem uygulamadıktan sonra 
    "make modules_install" genellikle gerekmez. Ancak modüllerde bir değişiklik yapılmışsa yine "make modules_install" yapılmalıdır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												72. Ders 09/01/2025 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz yukarıdaki çekirdek derlemesi işlemlerinde imzalama (signing) işlemlerini devre dışı bıraktık. Çekirdek kodlarının ve 
    özellikle aygıt sürücüler belli imzalara sahip bir biçimde derlenebilirler. Böylece onlar üzerinde birtakım istenmeyen 
    değişikliklerin yapılması engellenmiş olur. Yukarıda da gördüğünüz gibi çekirdek kodları ve aygıt sürücülerinde bu imzalama 
    işlemi devre dışı bırakılabilir. Bu imzalama süreci sistem güvenliğini artırmaktadır. Bu tür imzalama işlemleri yalnızca
    Linux sistemlerinde değil diğer UNIX türevi sistemlerde ve Windows ve macOS sistemlerinde de bulunmaktadır.

    İmzalama işlemi için öncelikle "openssl" kütüphanesinin yüklenmiş olması gerekir. Yükleme işlemi aşağıdaki gibi yapılabilir:

    $ sudo apt-get install openssl

    Daha sonra openssl programı ile aşağıdaki gibi bir ".pem" dosyası üretilmektedir.:

    openssl req -new -x509 -newkey rsa:4096 \
    -keyout signing_key.priv \
    -out signing_key.pem \
    -days 3650 -nodes \
    -subj "/CN=Custom Linux Kernel Signing Key"

    Üretilen ".pem" dosyası genellikle kaynak kod ağacında "certs" isimli bir dizine yerleştirilir.

    $ mkdir -p certs
    $ mv signing_key.pem /certs

    Daha sonra konfigürasyon dosyasında imzalama için aşağıdaki değişiklikler yapılmalıdır:

    CONFIG_MODULE_SIG=y
    CONFIG_MODULE_SIG_ALL=y
    CONFIG_SYSTEM_TRUSTED_KEYRING=y
    CONFIG_SYSTEM_TRUSTED_KEYS="certs/signing_key.pem"
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												73. Ders 14/01/2025 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de daha ilginç bir deneme yapalım. Çekirdekteki sys_open ve sys_openat sistem fonksiyonlarını manipüle edelim. Bu 
    sistem fonksiyonlarının içine bazı kodlar yerleştirerek eğer prosesin etkin kullanıcı id'si 1000 ise bu proses sanki 
    dosya açım işlemini etkin kullanıcı id'si 0 imiş gibi yapsın. Linux'ta dosya açmak için iki temel sistem fonksiyonu 
    bulunmaktadır: sys_open ve sys_openat fonksiyonları. sys_openat fonksiyonu daha sonraları POSIX standartlarına eklenmiştir. 
    Linux çekirdeği de belli bir versiyondan sonra bu sistem fonksiyonunu desteklemeye başlamıştır. Ayrıca "libc" kütüphanesindeki 
    open fonksiyonu belli bir zamandan sonra sys_open sistem fonksiyonunu değil sys_openat sistem fonksiyonunu çağırmaya başlamıştır. 
    (Bilindiği gibi fopen standart C fonksiyonu da zaten open POSIX fonksiyonunu çağıracak biçimde yazılmıştır.) Ancak Linux
    çekirdek kodlarında sys_open ve sys_openat fonksiyonları do_sys_open isimli fonksiyonu çağırmaktadır. O halde manipülasyonun
    bu fonksiyon içerisinde yapılması uygundur. Bunun için çekirdek kodlarında "fs/open.c" dosyası açılıp do_sys_open fonksiyonu
    aşağıdaki gibi düzenlenebilir:

    long do_sys_open(int dfd, const char __user *filename, int flags, umode_t mode)
    {
        struct cred *old_cred, *new_cred;
        long fd;

        printk(KERN_INFO "do_sys_open called\n");

        old_cred = (struct cred *)get_current_cred();

        if (from_kuid(&init_user_ns, old_cred->uid) == 1000) {

            new_cred = prepare_creds();
            if (new_cred) {
                new_cred->uid   = GLOBAL_ROOT_UID;
                new_cred->euid  = GLOBAL_ROOT_UID;
                new_cred->fsuid = GLOBAL_ROOT_UID;

                commit_creds(new_cred);
            }

            cap_clear(new_cred->cap_inheritable);
            cap_clear(new_cred->cap_permitted);
            cap_clear(new_cred->cap_effective);
            cap_clear(new_cred->cap_bset);

            cap_raise(new_cred->cap_permitted, CAP_DAC_OVERRIDE);
            cap_raise(new_cred->cap_effective, CAP_DAC_OVERRIDE);
        }

        struct open_how how = build_open_how(flags, mode);
        fd = do_sys_openat2(dfd, filename, &how);

        if (from_kuid(&init_user_ns, old_cred->uid) == 1000) {
                commit_creds(old_cred);
        }

        return fd;
    }

    Aslında fonksiyonun orijinal hali şöyledir:

    long do_sys_open(int dfd, const char __user *filename, int flags, umode_t mode)
    {
        struct open_how how = build_open_how(flags, mode);
        return do_sys_openat2(dfd, filename, &how);
    }

    Bu değişiklikten sonra etkin kullanıcı id'si 1000 olan kullanıcı ne zaman bir dosya açacak ya da yaratacak olsa sanki bu
    işlemi root imiş gibi yapacaktır. Tabii bu tür manipülasyonlarda dikkat etmek gerekir. Çünkü bu işlemden her türlü proses 
    etkilenecektir. Bu da mevcut programların çalışmasını bozabilir. Çekirdek kaynak kodlarında değişiklik yaparken çok dikkat
    etmek gerekir. Çok masum görünen değişiklikler bile sistemin stabil çalışmasını bozabilir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Özellikle gömülü sistemlerde en önemli çekirdek derleme nedenlerinden biri de çekirdeğin küçültülmesidir. Çekirdeğin küçültülmesi
    için bazı çekirdek modüllerinin derleme sırasında atılması gerekir. Çekirdek modüllerinin dahil edilmesi ve atılması için 
    "make menuconfig" menüsünde aşağıdaki seçeneklere dikkat etmek gerekir:

    - [*] seçeneği uygulamacı tarafından açılıp kapatılabilmektedir. Bu seçenek "*" ile seçilirse ilgili modül çekirdeğin bir
    parçası çekirdek imajına gömülür eğer bu seçenekteki "*" kaldırılırsa ilgili modül çekirdek imajına gömülmez. [*] seçenekleri
    konfigürasyon dosyasında (".config" dosyasında) "CONFIG_XXX=y" biçiminde bulunur. Örneğin menuconfig menüsünde aşağıdaki gibi 
    bir satır olsun:

    [*] xxx

    Bu seçeneğin konfügürasyon dosyasındaki satır karşılığı şöyledir:

    CONFIG_XXX=y

    Eğer seçenekteki "*" kaldırılırsa bu durumda ilgili satır tamamen konfigürasyon dosyasından kaldırılmaktadır. Örneğin 
    seçenek aşağıdaki gibi olsun:

    [ ] xxx

    Bu seçeneğin konfigürasyon dosyasındaki karşılığı şöyle olacaktır:

    # xxx is not set

    Eğer [*] seçeneği bir üst menüye ilişkinse (yani satırın sonunda ---> sembolü varsa) bu durum bazı alt seçeneklerin de 
    (ama hepsinin değil) otomatik biçimde seçileceğini belirtir. Örneğin:

    [*] Thermal drivers --->

    Burada eğer bu seçenek seçilmişse alt seçeneklerin bazıları de (ama hepsi değil) otomatik olarak seçilir. Ancak buradaki "*"
    kaldırılırsa alt seçeneklerin hiçbiri seçilmemiş olur. Buradaki "*" kaldırılırsa satırın sonundaki ---> sembolü ---- haline 
    gelmektedir.

    - <*> seçeneği ilgili aygıt sürücünün çekirdeğin içerisinde mi gömüleceğini yoksa modül olarak derlenip çekirdeğin yanına
    mı ("/lib/modules<çekirdek_sürümü>" dizinine) yerleştirileceğini belirtmektedir. Burada "*" varsa ilgili aygıt sürücü
    çekirdeğin içerisine gömülür. Burada "M" harfi varsa (<M> biçiminde) çekirdeğin içerisine gömülmez ancak modül olarak derlenir. 
    Burada açısal parantezlerin içi boşsa (<> biçiminde) bu durumda bu modül hiç derlenmez. Örneğin menuconfig menüsünde aşağıdaki 
    gibi bir satır olsun:

    <*> xxx

    Bu durumda bu aygıt sürücü çekirdeğin içerisine gömülür. Konfigürasyon dosyasındaki satır da şöyle olur:

    CONFIG_XXX=y

    Şimdi menuconfig satırının aşağıdaki gibi olduğunu varsayalım:

    <M> xxx

    Bu durumda bu aygıt sürücü çekirdeğin içerisine gömülmez, modül olarak derlenir. Konfigürasyon dosyasındaki satır da şöyle olur:

    CONFIG_XXX=y

    Şimdi de menuconfig menüsünde aşağıdaki gibi bir satırın bulunduğunu varsayalım:

    <> xxx

    Bu durumda bu aygıt sürücü ne çekirdeğin içerisine gömülecek ne de modül olarak derlenecektir. Konfigürasyon dosyasındaki satır 
    da şöyle olacaktır:

    # CONFIG_xxx is not set
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdeğin bellekte az yer kaplaması kısıtlı miktarda RAM'e sahip sistemlerde uygulama programları için daha geniş bir alanın 
    var olmasını sağlayabilmektedir. Bazı gömülü sistemler özel bir amaç için oluşturulmaktadır ve bunların RAM miktarı oldukça 
    düşük olabilmektedir.

    Gömülü sistemlerde çekirdeğin küçültülmesi için bazı çekirdek konfigüre edilirken hedef sistem için gerekmeyecek seçenekler 
    çekirdekten çıkartılabilir. Tabii bir öğeyi çekirdekten çıkartırken dikkat etmek gerekir. Eğer o öğe herhangi bir biçimde
    çekirdek tarafından ya da bir uygulama programı tarafından kullanılıyorsa sistem ya da çalıştırılan programlar çökebilecektir.
    Çekirdekten çıkartılabilecek tipik öğeler şunlar olabilir:

    - Ağ desteğine ilişkin çekirdek modülleri ve çekirdek kodları eğer hedef sistem bir ağ haberleşmesi kullanmıyorsa tamamen 
    çekirdekten çıkartılabilir. Bunun için "menuconfig" menüsünde ana menüdeki "[*] Networking support --->" seçeneği tamamen 
    kaldırılabilir. Böylece tüm ağ özellikleri kaldırılacaktır. Tabii bu alt menüye girerek yalnızca belirli ağr öğelerini de 
    çekirdek kodlarından kaldırabilirsiniz. Ağ ile ilgili tipik konfigürasyon seçenekleri aşağıda verilmiştir:

    CONFIG_NET
    CONFIG_INET
    CONFIG_NETFILTER
    CONFIG_IPV6
    CONFIG_IPV6_ROUTER
    CONFIG_NETDEVICES
    CONFIG_WLAN

    - Bazı dosya sistemleri için çekirdek desteği tamamen kaldırılabilir. Örneğin eğer ext-4 dosya sistemi kullanılıyorsa ext-2
    ve FAT dosya sistemleri çekirdek kodlarından kaldırılabilir. (FAT dosya sisteminin BBB'de ve pek çok gömülü sistemde boot 
    işlemi sırasında boot loader tarafından kullanıldığını anımsayınız. Ancak sistem açıldıktan sonra FAT dosya sistemi programlar
    tarafından artık hiç kullanılmayabilir.) Dosya sistemlerine yönelik tipik konfigürasyon seçenekleri aşağıda verilmiştir:

    CONFIG_EXT4_FS
    CONFIG_F2FS_FS
    CONFIG_NTFS_FS
    CONFIG_FAT_FS
    CONFIG_VFAT_FS
    CONFIG_UFS_FS
    CONFIG_TMPFS
    CONFIG_BTRFS_FS
    CONFIG_SQUASHFS

    - Çekirdeğin debug edilebilmesi için gerekli olan öğeler de çekirdekten atılabilir. Debug işlemleriyle ilgili "menuconfig" 
    menüsünde "Kernel hacking --->" isimli ana bir giriş vardır. Bununla ilgili tipik konfigürasyon seçenekleri aşağıda 
    verilmiştir:

    CONFIG_DEBUG_INFO
    CONFIG_KALLSYMS
    CONFIG_PRINTK
    CONFIG_TRACEPOINTS

    - Zaten kartımızın üzerinde var olmayan donanım özelliklerine yönelik öğeler de çekirdek kodlarından çıkarılabilirler. Örneğin
    kartımızda bir bluetooth devresi olmadıktan sonra çekirdek kodlarında bluetooth aygıtına yönelik aygıt sürücü kodlarının olması 
    gereksizdir. Aynı durum wireless için de söz konusudur. Bluetooth ile ilgili tipik konfigürasyon seçenekleri şöyledir:

    CONFIG_BT
    CONFIG_BT_BNEP
    CONFIG_BT_HCIUSB
    CONFIG_BT_HCIUART
    CONFIG_BT_RFCOMM

    - Ses ile ilgili (audio) çekirdek özellikleri de eğer bunları kullanan bir uygulama programı yoksa çekirdekten atılabilir. 
    Sesle ilgili tipik konfigürasyon seçenekleri şunlardır:

    CONFIG_SND_PCM
    CONFIG_SND_SOC
    CONFIG_SND_BCM2835
    CONFIG_SND_OMAP
    CONFIG_SND_SOC_TIVOLI

    - Video grafik desteğine ilişkin çekirdek kodları da eğer bunları kullanan uygulamalar yoksa çekirdekten atılabilir. Video 
    ile ilgili tipik konfigürasyon seçenekleri de şunlardır:

    CONFIG_V4L2
    CONFIG_VIDEO_V4L2
    CONFIG_FB
    CONFIG_FB_OMAP2
    CONFIG_DRM

    - Çekirdeği küçültmek için gerekmeyen aygıt sürücüler çekirdekten çıkartılabilir. Bunun için "menuconfig" menüsünde ana giriş 
    olan "Device driver --->" alt menülerini inceleyebilirsiniz. Örneğin "PCI support" pek çok gömülü sistem için gerekmemektedir. 
    Yine bazı blok aygıt sürücülerine gömülü sistemlerd ehiç gereksinim duyulmayabilir. "Serial ATA", "Paralel ATA" gibi aygıt 
    sürücülere de genel olarak gömülü sistemlerde gereksinim duyulmamaktadır. Eğer gömülü aygıtta "ethernet arayüzü" kullanılmıyorsa 
    ethernet birimine ilişkin aygıt sürücü kodları da tamamen çekirdekten atılabilir. Örneğin seri port haberleşmesi kullanılmıyorsa
    bunlara ilişkin aygıt sürücüler çekirdekten çıkartılabilir. Sanal terminaller de pek çok gömülü uygulamada kullanılmamaktadır. 
    Eğer gömülü aygıtımızda USB portu hiç kullanılmayacaksa "USB support" özelliği çekirdekten çıkartılabilir.

    Bir aygıt sürücünün <*> yerine <M> biçiminde belirtildiğini varsayalım. Bu durumda bu aygıt sürücü çekirdek imajının içerisine
    gömülmeyecektir. Ancak "/lib/modules/<çekirdek_sürümü>" dizininde bulunacaktır. Pekiyi bu biçimde <M> olarak belirtilmiş olan 
    aygıt sürücüler ne zaman yüklenmektedir? İşte tipik birkaç yüklenme senaryosu vardır:

    1) Kendi kendini tanıtabilen USB gibi port'lara ygıtlar takıldığında çekirdek bu aygıtı tespit edip o anda otomatik bir 
    biçimde gerekli olan aygıt sürücüyü yükleyebilmektedir.

    2) Aygıt ağacında bir aygıt belirtilmişse ve o aygıta ilişkin aygıt sürücü çekirdeğin içerisine gömülmemişse yine çekirdek 
    tarafından otomatik olarak yüklenecektir. Yani bir modülü <M> olarak işaretleyip aygıt ağacı dosyasından ilgili aygıtı çıkarmazsak
    yine bu modül çekirdek tarafından yüklenmektedir.

    3) Programcı da istediği bir zaman "modprobe" ya da "insmod" gibi komutlarla <M> biçiminde belirtilmiş olan aygıt sürücüleri
    yükleyebilmektedir.

    Tabii çekirdeğin küçültülmesi gömülü sistemler için aslında mutlak zorunlu bir etkinlik değildir. Zaten başkaları tarafından
    hazırlanmış default konfigürasyon dosyaları ilgili donanımı hedef alarak gereksiz öğeleri çekirdeğe dahil etmemektedir. 
    (Örneğin biz BBB için kullandığımız default konfigürasyon dosyası bu default haliyle zaten makul bir default seçenek sunmaktadır.)
    Eğer söz konusu donanım RAM bakımından kısıtlı değilse çekirdek öğelerinin çıkartılması için özel bir dikkat harcamaya 
    gerek yoktur.

    Her çekirdek öğesinin çekir imajındaki kod miktarı birbirinden farklıdır. Örneğin dosya sistemleri çekirdekte geniş bir 
    yer kaplamaktadır. Halbuki örneğin gerçek zaman saatiyle ilgili kodlar çekirdekte küçük yer kaplamaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												76. Ders 28/01/2025 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    BBB'de çekirdek yükseltirken dikkat edilmesi gerekir. Yeni çekirdeklerde uyumlandırma bakımından sorunlar ortaya çıkabilmektedir.
    Biz daha önce BBB için çekirdeğin kaynak kodlarının "https://github.com/beagleboard" sitesinden indirilmesini tavsiye 
    etmiştik. Buradaki kaynak kodlarda BBB için bazı patch'ler yapılmış durumdadır. Örneğin kursumuzda bu siteden "linux-6.1.80-ti-r34"
    sürümünün kaynak kodlarını indirerek derleme yaptık. Burada dikkat edilmesi gereken bir nokta vardır: Yeni çekirdeklerde geçici 
    dosya sistemi oluşturmadan boot işleminde sorunlar çıkabilmektedir. Bunun nedeni yeni çekirdeklerin yüklenmesi için gereken 
    bazı aygıt sürücülerin kök dosya sisteminde bulunmamasıdır. Bu nedenle yeni çekirdekleri derlerken geçici kök dosya sistemini 
    daha önce görmüş olduğumuz BusyBox ya da Debian dosya sistemi biçiminde oluşturup sistemin bu geçici dosya sistemini kullanacak
    biçimde boot edilmesini sağlamalısınız.

    Biz kursumuzdaki BBB için çekirdek yükseltme örneğinde aşağıdaki gibi bir "uEnv.txt" dosyası kullandık:

    loadkernel=load mmc 0:2 0x82000000 /boot/vmlinuz-6.1.80-custom-custom
    loadfdt=load mmc 0:2 0x88000000 /boot/dtbs/6.1.80-custom-custom/am335x-boneblack.dtb
    loadinitrd=load mmc 0:2 0x90000000 /boot/uinitrd
    bootargs=console=ttyS0,115200 root=/dev/mmcblk0p2 rw
    bootsys=bootz 0x82000000 0x90000000 0x88000000
    uenvcmd=run loadkernel;run loadfdt;run loadinitrd;run bootsys

    Buradaki "uinitrd" BusyBox'ta oluşturmuş olduğumuz kök dosya sistemidir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												77. Ders 30/01/2025 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de daha önce görmüş olduğumuz "debootstrap" programı ile BBB için kök dosya sistemini oluşturalım. Bu işlem adım
    adım şöyle yapılabilir:

    1) Önce qemu emülatörü ve binfmt desteği ana makinede kurulu değilse aşağıdaki gibi kurulur:

    $ sudo apt install qemu-user-static binfmt-support

    2) Debian dağıtımının kök dosya sistemi debootstrap programı ile aşağıdaki gibi indirilir:

    $ sudo debootstrap --include=systemd,sudo --arch armhf buster bbb-debian-rootfs http://deb.debian.org/debian/

    3) Kurulum gerçekleşmiştir. Artık chroot yapıldığında ARM programları qemu emülatörünün otomatik devreye girmesiyle
    çalıştırılabilecektir. Örneğin:

    $ sudo chroot bbb-debian-rootfs

    Burada artık biz apt-get ile istediğimiz paketleri ayrıca kurabiliriz. Çünkü artık ana makinenin çekirdeği ve aygıt sürücüleri
    kullanılacak ancak kök dosya sistemi ARM tabanlı sistem olduğu için programların ARM versiyonları indirilip kurulacaktır.

    4) Şimdi oluşturduğumuz kök dosya sistemine "/boot" dizinini ve "/lib/modules" dizinini kopyalayalım. Bu dosyaların 
    "bbb-ext-partition.img" isimli bir imajda olduğunu varsayalım:

    $ sudo losetup /dev/loop0 bbb-ext-partition.img
    $ sudo mount /dev/loop0 ext

    Kopyalamayı şöyle yapabiliriz:

    $ sudo cp -a ext/boot/* bbb-debian-rootfs/boot
    $ sudo cp -a ext/lib/modules/* bbb-debian-rootfs/lib/modules

    İmajı unmount edebiliriz:

    $ sudo losetup -d /dev/loop0
    $ sudo umount ext

    5) debootstrap ile oluşturduğumuz kök dosya sisteminde "/etc/passwd" dosyasında bir "root" kullanıcısı vardır. Bu dosyaya 
    girip kullanıcının parolasını sıfırlayabiliriz. Örneğin satır şöyle yapılabilir:

    root::0:0:root:/root:/bin/bash

    Tabii bunun yerine "chroot" yapıp "passwd" komutuyla "root" parolası da değiştirilebilirdi.

    6) Şimdi artık diskte oluşturduğumuz kök dosya sistemini SD karta kopyalayabiliriz. SD kartımızın SD kart okuyucuya 
    yerleştirilmiş olduğunu ve buna ilişkin blok aygıt dosyasının da "/dev/sdb2" olduğunu varsayalım. Önce mount işlemi 
    yapmalıyız:

    $ sudo mount /dev/sdb2 ext

    Kopyalamayı yine "cp -a" komutu ile yapabiliriz:

    $ sudo cp -a bbb-debian-rootfs/* ext

    Unmount işlemini de yapabiliriz:

    $ sudo umount ext

    Bu tür durumlarda Linux cache kullandığı için aslında kopyalananlar gerçek anlamda unmount işlemi sırasında kopyalanmaktadır. 
    Bu nedenle unmount işlemi sırasında uzun süre beklemeyle karşılaşırsanız şaşırmayınız.

    debootstrap programıyla BBB için geçici kök dosya sisteminin oluşturulmasını izleyen paragrafta açıklayacağız.

    8) Artık SD kartımızı BBB'ye takıp SD karttan boot işlemini yapabiliriz.

    Bu işlemler yapıldığında BBB Debian dağıtımıyla açılacaktır. Artık sistemimiz masaüstü sistemine çok benzemektedir. Tabii
    bazı gömülü uygulamalarda bu kadar büyük bir kök dosya sisteminin oluşturulması istenmeyebilir. Buradaki Debian kök dosya
    sisteminin BusyBox ile oluşturduğumuz minimal kök dosya sisteminden temel farklılıkları şunlardır:

    - Debian kök dosya sisteminde "init" istemi olarak oldukça geniş kapasiteli "systemd" sistemi bulunmaktadır. Halbuki anımsanacağı
    gibi BusyBox içerisindeki "init" sistemi "System 5" init sistemine benzemektedir.

    - Debian kök dosya sisteminde "apt" isimli en yaygın kullanılan oldukça yetenekli bir paket yönetim sistemi de kurulu 
    olmaktadır. Bu sayede biz paketleri kolay bir biçimde yükleyip kaldırabiliriz.

    - Debian kök dosya sisteminde pek çok Linux komutu masaüstü Linux sistemlerinde olduğu gibi yetenekli bir biçimde kurulmuş 
    durumdadır. Oysa BusyBox içerisindeki komutlar daha daraltılmış durumdadır. Yani Debian kök dosya istemi komut bakımından 
    BusyBox'a göre oldukça gelişmiş durumdadır. Aynı zamanda Debian kök dosya sisteminde pek çok statik ve dinamik kütüphane 
    yüklü durumdadır.

    - Debian kök dosya sisteminin toplamda SD kartta bellekte kapladığı alan BusyBox'a göre çok daha fazladır.

    - Debian kök dosya sisteminde komutlar çok fazla seçeneklere sahip olduğu için ve farklı dosyalar biçiminde bulunduğu için 
    bu dosya sisteminin çalışma performansı BusyBox'a göre daha düşüktür. Yani BusyBox kök dosya sisteminin minimalist olduğu 
    için daha hızlı çalıştığını söyleyebiliriz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    "debootstrap" programı ile biz Debian kök dosya sistemi için geçici kök dosya sistemi oluşturabiliriz. Bunun en pratik 
    yolu kök dosya sistemini kurduktan sonra "chroot" yapıp "update-initramfs" programı geçici kök dosya sistemini oluşturmaktır. 
    Ancak bunun için "/boot" dizinin ve "/lib/modules" dizinin uygun biçimde oluşturulmuş olması gerekir. "update-initramfs" 
    programı bu dizinlerdeki içerikten faydalanmaktadır. "update-initramfs" programı "initramfs-tools" isimli pakettedir. chroot 
    yaptıktan sonra öncelikle bu paketi aşağıdaki gibi kurmalısınız:

    $ sudo apt-get install initramfs-tools

    Bundan sonra geçici kök dosya sistemini aşağıdaki gibi oluşturabilirsiniz (Debian kök dosya sisteminin kökünde olduğumuzu 
    varsayıyoruz):

    $ update-initramfs -c -k 6.6.32-custom -b .

    Burada "6.6.32-custom" çekirdeğin sürüm ismidir. Geçici kök dosya sistemi "initrd.img-6.6.32-custom" ismiyle bulunulan 
    dizinde oluşturulacaktır. Burada "-b ." seçeneği oluşturulacak dosyanın dizinini belirtmektedir. Ancak burada oluşturduğumuz 
    geçici kök dosya sistemini U-Boot'un kabul ettiği formata dönüştürmemiz gerekir. Bunu chroot durumundan exit ile çıkıp yine
    "mkImage" programıyla aşağıdaki gibi yapabiliriz.

    $ sudo mkImage -A arm -O linux -T ramdisk -C gzip -d initrd.img-6.6.32-custom boot/initrd.img-6.6.32-custom

    Bu biçimde oluşturduğumuz kök dosya sistemini doğrudan SD karta kopyalayabiliriz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Her ne kadar Debian kök dosya sistemini BBB için "debootstrap" programı ile kolay bir biçimde oluşturmuş olsak da bazı ayarların
    yine de yapılması gerekmektedir. Örneğin oluşturulan kök dosya sisteminde henüz ağ ayarları tam yapılandırılmış değildir. 
    Ağ işlemlerine yönelik tüm paketler kurulmuş durumdadır ancak yapılandırma tam olarak yapılmamıştır. Bu Ethernet kablosu
    BBB'ye takılsa bile henüz internet erişimi sağlanamamıştır. İnternet erişiminin sağlanması için birkaç ayarın yapılması 
    gerekir.

    Debian kök dosya sistemini oluştururken --include komut satırı argümanında "net-tools" paketini de belirtebiliriz. Bu paket 
    "ifconfig" gibi çok kullanılan bazı komutları barındırmaktadır. Default durumda bu paket kök dosya sisteminde bulunmamaktadır. 
    Bu paketi "chroot" ile yükleyebiliriz. Burada bu paketin de yüklenmiş olduğunu varsayacağız.

    Ethernet bağlantısının yapılandırılması için aşağıdaki iki komutun çalıştırılması gerekir:

    $ ip link set eth0 up
    $ dhclient eth0

    Birinci komut Ethernet arayüzünü etkin hale getirmektedir. İkinci komut ise ethernet arayüzü için IP oluşturmaktadır. Eğer 
    bu komutların boot işlemi sırasında otomatik çalıştırılmasını istiyorsanız daha önceden görmüş olduğumuz "systemd" birim 
    dosyalarını kullanabilirsiniz. Yeni bir servis birimi oluşturmak yerine Debian dağıtımlarında zaten var olan "systemd-networkd" 
    daemon'ı için yeni bir birim dosyası da oluşturabilirsiniz. Bu ağ birim dosyası "/etc/systemd/network" dizinine yerleştirebilir. 
    İsmini de örneğin "10-eth0.network" biçiminde verebiliriz. Dosyayı aşağıdaki gibi yaratabilirsiniz:

    $ sudo nano /etc/systemd/network/10-eth0.network

    Bu ağ birim dosyasının içeriği aşağıdaki gibi olabilir:

    [Match]
    Name=eth0

    [Network]
    DHCP=ipv4

    Default durumda Debian dağıtımındaki bu ağ daemon programı pasif durumdadır. Bunun açılışta otomatik çalıştırılması için 
    "systermctl enable" yapılması gerekir:

    $ sudo systemctl enable systemd-networkd

    Tabii eğer sistemi reboot etmek istemiyorsanız yaptığınız değişikliklerin o anda etkili olması için restart işlemi yapabilirsiniz:

    sudo systemctl restart systemd-networkd

    Host isminizi "hostname" komutu ile elde edebilirsiniz:

    $ hostname
    kaan-Huawei

    "debootstrap" ile kök dosya sistemini oluşturduğunuzda yaptığınızda default host ismi host makinenin host ismi olur. Bunu 
    "/etc/hostname" dosyasını edit ederek değiştirebilirsiniz. Ancak bu değişikliği yaptıktan sonra sistemi reboot etmelisiniz. 
    Örneğin bu dosyanın içeriğini "kaan-bbb" olarak değiştirdiğimizi varsayalım:

    $ hostname
    kaan-bbb

    Host isminiz eğer çözülemiyorsa "/etc/hosts" dosyasını kontrol etmelisiniz. Bu dosyada aşağıdaki gibi bir satırın bulunması 
    gerekir:

    127.0.0.1 <belirlediğiniz_host_ismi>

    Örneğin test ettiğimiz BBB'deki kök dosya sisteminde bu satırı ekledikten sonra "/etc/hosts" dosyasının içeriği şöyle olacaktır:

    127.0.0.1	kaan-bbb
    127.0.0.1	localhost
    ::1			localhost ip6-localhost ip6-loopback
    ff02::1		ip6-allnodes
    ff02::2		ip6-allrouters
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												78. Ders 04/02/2025 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux sistemine ssh server kurmak oldukça basittir. apt paket yöneticiniz varsa kurulum şöyle yapılabilir:

    $ sudo apt-get install openssh-server

    ssh server programının çalışıp çalışmadığına şöyle bakabilirsiniz:

    $ systemctl status ssh

    Sistem açıldığında otomatik çalışmanın sağlanması için systemctl enable işlemi de yapılabilir:

    $ systemctl enable ssh
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												78. Ders 06/02/2025 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Gömülü Linux sisteminizin host makinenin internetini kullanmasını da sağlayabilirsiniz. Bu işlem için hem gömülü Linux 
    sistemminde hem de host sistemde birtakım ayarların yapılması gerekmektedir. Konu aslında ağ yapılandırılmasının bazı ayrıntıları
    ile ilgilidir. Biz burada ayrıntıya girmeden bunun nasıl yapılabileceğini açıklayacağız. Bu işlem biraz sıkıcıdır. İşlemler
    çeşitli biçimlerde otomatize de edilebilir. Bu işlem için ilk yapılacak şey gömülü sistemde (Burada BBB üzerinde örnek veriyoruz)
    "USB ethernet gadget" aygıt sürücüsünün çekirdeğe dahil edilmesidir. BBB için oluşturulmuş orijinal Debian imajında bütün
    bu işlemler yapılmış durumdadır. Dolayısıyla orijinal imajdaki konfigürasyon dosyasını temel alıp "make oldconfig" uygularsanız 
    bu aygıt sürücü zaten dahil edilmiş olacaktır. Bu aygıt sürücüyü çekirdeğe dahil etmek için "make menuconfig" menüsünde 
    "Device Drivers / USB support / USB gadget support / USB Gadget precomposed configurations / Ethernet Gadget (with CDC 
    Ethernet support)" seçeneği <M> ya da <*> yapılabilir. Ancak burada bu aygıt ile ilgili bazı seçimlerin de yapılması 
    gerekebilmektedir. Ya da bunun yerine konfigürasyon dosyasında satırlarda aşağıdaki değişiklikleri manuel yapabilirsiniz:

    CONFIG_USB_GADGET=y
    CONFIG_USB_LIBCOMPOSITE=y

    CONFIG_USB_GADGETFS=y
    CONFIG_USB_ETH=y
    CONFIG_USB_ETH_RNDIS=y
    CONFIG_USB_CONFIGFS=y
    CONFIG_USB_CONFIGFS_ETH=y

    CONFIG_USB_GADGET_DEBUG
    CONFIG_USB_GADGET_DEBUG_FS

    Çekirde yukarıdaki seçenek <M> yapılarak derlendiğinde g_ether aygıt sürücüsünü yüklemek için modprobe komutundan 
    faydalanabilirsiniz:

    $ sudo modprobe g_ether

    Tabii eğer g_ether aygıt sürücüsü <*> ile çekirdeğe dahil edilmişse böyle bir yükleme yapmaya gerek yoktur. Sisteminizde 
    o anda "g_ether (ethernet gadget)" aygıt sürücüsünün yüklü olup olmadığını BBB'de "ip a" komutuyla anlayabilirsiniz. Bu 
    komut verildiğinde USB ağ arayüzünün gözükmesi gerekir. Örneğin:

    # ip a
    1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
        inet 127.0.0.1/8 scope host lo
        valid_lft forever preferred_lft forever
        inet6 ::1/128 scope host
        valid_lft forever preferred_lft forever
    2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
        link/ether 6c:30:2a:c4:5c:78 brd ff:ff:ff:ff:ff:ff
        inet 192.168.1.134/24 brd 192.168.1.255 scope global dynamic eth0
        valid_lft 84342sec preferred_lft 84342sec
        inet6 2a02:4e0:2d80:660:6e30:2aff:fec4:5c78/64 scope global dynamic mngtmpaddr noprefixroute
        valid_lft 230sec preferred_lft 50sec
        inet6 fe80::6e30:2aff:fec4:5c78/64 scope link
        valid_lft forever preferred_lft forever
    3: usb0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000
        link/ether 26:55:91:b6:b6:d2 brd ff:ff:ff:ff:ff:ff

    Eğer burada "usb0" görmezseniz bu durumda bu aygıt sürücü çekirdek derlemesine dahil edilmemiş ise "modprobe g_ether" 
    yapılmamış olabilir.

    "g_ether" aygıt sürücüsü yüklenirken kendisi için (BBB tarafı için) ve host tarafı için (yani desktop Linux tarafı için)
    rastgele MAC adresleri oluşturmaktadır. Aygıt sürücü USB yoluyla host ile iletişim kurduğunda host için üretttiğim MAC 
    adresini host'a göndermektedir. Eğer g_ether aygıt sürücüsünün rastgele MAC adresi üretmesini istemiyorsanız bunu siz de 
    aşağıdaki gibi aygıt sürücüye parametre geçirerek sağlayabilirsiniz:

    $ sudo modprobe g_ether host_addr=02:34:56:78:9A:BC dev_addr=02:34:56:78:9A:BD

    Ancak biz buradaki örneklerimizde MAC adreslerini kendimiz belirlemeyeceğiz. Burada host_addr host tarafın USB ağ arayüzünün 
    MAC adresini, dev_addr ise BBB'deki USB ağ arayüzünün MAC adresini belirtmektedir.

    Bu aygıt sürücünün yüklendiğinden emin olduktan sonra host sistemde ve BBB'de yapılacaklar aşağıda belirtilmektedir.

    Host sistemde yapılacaklar şunlardır:

    1) Önce "ip a" komutu ile host sistemdeki USB ağ arayüzü kontrol edilmelidir. Tabii bu komutu uygulamadan önce BBB'nin 
    host makineye bağlı olması ve BBB'de "g_ether" aygıt sürücüsünün yüklü olması gerekir. Default durumda host taraftaki ağ 
    arayüzünün ismi "usb0" olarak değil "enxHHHHHHHHHHHH" biçiminde oluşturulmaktadır. Örneğin:

    $ ip a
    1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
        inet 127.0.0.1/8 scope host lo
        valid_lft forever preferred_lft forever
        inet6 ::1/128 scope host noprefixroute
        valid_lft forever preferred_lft forever
    2: wlp0s20f3: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc noqueue state UP group default qlen 1000
        link/ether d4:f3:2d:2f:eb:1c brd ff:ff:ff:ff:ff:ff
        inet 192.168.1.18/24 brd 192.168.1.255 scope global dynamic noprefixroute wlp0s20f3
        valid_lft 83155sec preferred_lft 83155sec
        inet6 2001:930:154:9a8d:a6ef:7cf6:697:3ec2/64 scope global temporary dynamic
        valid_lft 601490sec preferred_lft 83083sec
        inet6 2001:930:154:9a8d:8d37:c87a:d603:d813/64 scope global dynamic mngtmpaddr noprefixroute
        valid_lft 2591996sec preferred_lft 604796sec
        inet6 fe80::b00e:ac17:b957:ade1/64 scope link noprefixroute
        valid_lft forever preferred_lft forever
    4: enxca0e96288af0: <NO-CARRIER,BROADCAST,MULTICAST,UP> mtu 1500 qdisc pfifo_fast state DOWN group default qlen 1000
        link/ether ca:0e:96:28:8a:f0 brd ff:ff:ff:ff:ff:ff
        inet6 fe80::9593:b8c:978b:bd63/64 scope link noprefixroute
        valid_lft forever preferred_lft forever

    Burada host makinenin wireless ile internete bağlandığı anlaşılmaktadır. USB arayüzüne ise enxca0e96288af0 ismi verilmiştir. 
    (Bu isimdeki "enx" harflerinin yanındaki sayılar bu arayüze atanmış olan MAC adresinin hex digit'leridir.) Host makinede USB 
    ağ arayüzünün MAC adresi her bağlantıda değişebildiği için buradaki isim de her bağlantıda değişecektir. Bu isim UDEV kuralı 
    oluşturularak kalıcı hale getirilebilir.

    2) Host makinenin internet bağlantısını BBB ile paylaşmak için IP forwarding'i etkinleştir:

    $ echo 1 | sudo tee /proc/sys/net/ipv4/ip_forward

    3) NAT (Network Address Translation) ayarının yapılması için aşağıdaki komutlar kullanılabilir:

    $ sudo iptables -t nat -A POSTROUTING -o wlp0s20f3 -j MASQUERADE

    Buradaki "wlp0s20f3" host makinedeki wireless arayüzünün ismidir. Eğer host makinede internete ethernet arayüzü ile çıkıyorsanız
    buradaki ismi "eth0" yapabilirsiniz.

    4) Yönlendirmede sorun çıkmaması için firewall ayarlarının yapılması gerekir:

    $ sudo iptables -A FORWARD -i wlp0s20f3 -o enxHHHHHHHHHHHH -m state --state RELATED,ESTABLISHED -j ACCEPT
    $ sudo iptables -A FORWARD -i enxHHHHHHHHHHHH -o wlp0s20f3 -j ACCEPT

    5) USB ağ arayüzüne statik IP atamak için aşağıdaki komut çalıştırılır:

    $ sudo ip addr add 192.168.7.1/24 dev enxHHHHHHHHHHHH
    $ sudo ip link set enxHHHHHHHHHHHH up

    BBB'de de sırasıyla şu işlemlerin yapılması gerekir:

    1) BBB'de ağ arayüzlerinin isimleri "ip a" komutuyla elde edilip incelenir. Örneğin:

    # ip a
    1: lo: <LOOPBACK,UP,LOWER_UP> mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
        inet 127.0.0.1/8 scope host lo
        valid_lft forever preferred_lft forever
        inet6 ::1/128 scope host
        valid_lft forever preferred_lft forever
    2: eth0: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP group default qlen 1000
        link/ether 6c:30:2a:c4:5c:78 brd ff:ff:ff:ff:ff:ff
        inet 192.168.1.134/24 brd 192.168.1.255 scope global dynamic eth0
        valid_lft 84167sec preferred_lft 84167sec
        inet6 2a02:4e0:2d80:660:6e30:2aff:fec4:5c78/64 scope global dynamic mngtmpaddr noprefixroute
        valid_lft 292sec preferred_lft 112sec
        inet6 fe80::6e30:2aff:fec4:5c78/64 scope link
        valid_lft forever preferred_lft forever
    3: usb0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop state DOWN group default qlen 1000
        link/ether 22:3c:15:e5:cc:bd brd ff:ff:ff:ff:ff:ff

    Genellikle gömülü sistemlerde burada USB ağ arayüzü için "usb0" ismini göreceksiniz.

    2) USB ağ arayüzüne IP adresinin atanması gerekir. Bu işlem şu komutlarla yapılabilir:

    $ sudo ip addr add 192.168.7.2/24 dev usb0
    $ sudo ip link set usb0 up

    3) İnternete çıkış yapabilmesi için varsayılan gateway olarak host makine aşağıdaki gibi ayarlanabilir:

    $ sudo ip route add default via 192.168.7.1

    Bu işlemden sonra "ip route show" komutunu uyguladığınızda aşağıdaki gibi bir satır görmeniz gerekir:

    default via 192.168.7.1 dev usb0

    Eğer default gateway doğru atanmamışsa ve "ip route add default" komutundan "ip: RTNETLINK answers: File exists"
    biçiminde bir hata mesajı alırsanız yanlış gateway adresini aşağıdaki gibi düzeltebilirsiniz:

    $ sudo ip route replace default via 192.168.7.1 dev usb0

    Burada artık BBB'de host makinenın IP adresi 192.168.7.1 biçiminde BBB'deki USB arayüzünün IP adresi ise 192.168.7.2 
    biçiminde ayarlanmıştır. Yukarıdaki iki maddenin otomatik yapılması için "/etc/network/interfaces" dosyası aşağıdaki 
    gibi de düzenlenebilir:

    auto usb0
    iface usb0 inet static
        address 192.168.7.2
        netmask 255.255.255.0
        gateway 192.168.7.1

    4) BBB'de DNS sunucusunun IP adresi belirtilmelidir. Bunun için "/etc/resolv.conf" dosyasına aşağıdaki satırı ekleyebilirsiniz:

    nameserver 8.8.8.8
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												79. Ders 11/02/2025 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi bu süreçleri host tarafında ve BBB tarafında nasıl otomatik hale getirebiliriz? Host tarafındaki temel sorun USB 
    ağ arayüzünün isminin BBB'de "g_ether" aygıt sürücüsünün her yüklenmesinde değişiyor olmasıdır. Bunun host tarafında otomatize 
    edilebilmesi için BBB'de g_ether aygıt sürücüsü install edildiğinde bir script'in stabil bir isimle çalıştırılması gerekir. 
    İşte bunun için host tarafta "/etc/udev/rules.d/" dizininde "99-bbb-connect.rules" gibi bir isimle (isim farklı olabilir) bir 
    kural dosyasının oluşturulması gerekir. Ancak bu kural dosyasını "idVedor" ve "idProduct" değerlerine göre ayarlamak için 
    öncelikle USB ağ arayüzüne ilişkin "idVendor" ve "idProduct" değerlerinin elde edilmesi gerekir. Bu değerler aşağıdaki gibi 
    elde edilebilir.

    $ udevadm info -p /sys/class/net/enx* | grep -E 'ID_MODEL|ID_SERIAL|ID_VENDOR_ID|ID_MODEL_ID'

    Komut uygulandığında aşağıdakine benzer çıktı göreceksiniz:

    : ID_MODEL=RNDIS_Ethernet_Gadget
    E: ID_MODEL_ENC=RNDIS\x2fEthernet\x20Gadget
    E: ID_MODEL_ID=a4a2
    E: ID_SERIAL=Linux_6.6.32-custom_with_musb-hdrc_RNDIS_Ethernet_Gadget
    E: ID_VENDOR_ID=0525
    E: ID_MODEL_FROM_DATABASE=Linux-USB Ethernet/RNDIS Gadget

    Burada "idVendor" değeri "0525", "idProduct" değeri ise "a4a2" biçimindedir. Bu değerler "lsusb" komutuyla da elde edilebilir. 
    Bu komut bütün USB aygıtlarını listelemektedir. Örneğin:

    $ lsusb
    Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub
    Bus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub
    Bus 003 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub
    Bus 003 Device 002: ID 10c4:ea60 Silicon Labs CP210x UART Bridge
    Bus 003 Device 003: ID 0408:1061 Quanta Computer, Inc. FHD Camera
    Bus 003 Device 004: ID 8087:0033 Intel Corp. AX211 Bluetooth
    Bus 003 Device 007: ID 0525:a4a2 Netchip Technology, Inc. Linux-USB Ethernet/RNDIS Gadget
    Bus 004 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub

    Burada "Linux-USB Ethernet/RNDIS Gadget" satırındaki 0525:a4a2 sırasıyla "idVendor" ve "idProduct" değerleridir. İşte bu değerler 
    elde edildikten sonra "/etc/udev/rules.d/99-bbb-connect.rules" dosyasına aşağıdaki giriş eklenebilir:

    ACTION=="add", SUBSYSTEM=="net", ATTRS{idVendor}=="0525", ATTRS{idProduct}=="a4a2", RUN+="/bin/sh -c '/usr/local/bin/usb-script'" NAME="usb0"

    Artık USB ağ arayüzümüz her zaman "usb0" ismiyle görüntülenecektir. Buradaki "/usr/local/bin/usb-script" yol ifadesi BBB tarafında 
    "g_ether" sürücüsü yüklendiğinde çalıştırılacak script'i belirtmektedir. Bu script dosyasına host tarafında çalıştırılması gereken 
    komutları yerleştirebiliriz:

    #!/bin/bash
    echo 1 | sudo tee /proc/sys/net/ipv4/ip_forward
    sudo iptables -t nat -A POSTROUTING -o wlp0s20f3 -j MASQUERADE
    sudo iptables -A FORWARD -i wlp0s20f3 -o usb0 -m state --state RELATED,ESTABLISHED -j ACCEPT
    sudo iptables -A FORWARD -i usb0 -o wlp0s20f3 -j ACCEPT
    sudo ip addr add 192.168.7.1/24 dev usb0
    sudo ip link set usb0 up

    Makineyi reboot etmek istemiyorsanız aşağıdaki komutları çalıştırmalısınız:

    $ sudo udevadm control --reload-rules
    $ sudo udevadm trigger
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												80. Ders 13/02/2025 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de BBB'de yapılması gerekenleri otomatize edelim. BBB'deki sistemde "systemd" kullanılıyorsa (örneğin biz "debootstrap" 
    ile Debian sistemi kurmuşsak) otomatize etmek için bir "servis birim (service unit)" dosyası oluşturabiliriz. Bu dosya şöyle 
    olabilir:

    [Unit]
    Description=USB connection
    After=network.target
    Wants=network-online.target

    [Service]
    Type=oneshot
    RemainAfterExit=yes
    ExecStart=/bin/bash -c "modprobe g_ether;ip addr add 192.168.7.2/24 dev usb0;ip link set usb0 up;
    ip route add default via 192.168.7.1;"
    ExecStop=/bin/bash -c "ip link set usb0 down"

    [Install]
    WantedBy=multi-user.target

    Buradaki birim dosyasını "/etc/systemd/system" dizini içerisine herhangi bir isimle save edebilirsiniz. Örneğin bu ismi 
    "usb-internet.service" biçiminde vermiş olalım. Artık BBB reboot edildiğinde otomatik olarak yukarıdaki işlemler yapılacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de interneti BusyBox ile oluşturduğumuz minimal kök dosya sistemindeki Linux'a bağlamaya çalışalım. Ancak öncelikle
    BusyBox'ta oluşturduğunuz kök dosya sisteminin ağ komutlarını içerip içermediğinden emin olmalısınız. Eğer bu kök dosya 
    sisteminde bu komutlar yoksa kök dosya sistemi bu komutları içerecek biçimde yeniden derlenmelidir. Bu seçenekler BusyBox'ın
    menuconfig menüsünde "Network Utilities" girişinde bulunmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Önce BusyBox ile oluşturduğumuz kök dosya sisteminde Ethernet girişi ile internet bağlantısını yapalım. BBB'de zaten Ethernet
    girişinin olduğunu anımsayınız. Aygıt ağacından hareketle işletim sistemi zaten otomatik bu arayüzü görecektir. Dolayısıyla
    biz "ip a" komutunu uyguladığımızda "eth0" biçiminde bir ağ arayüzünü görmemiz gerekir. Örneğin:

    # ip a
    1: lo: <LOOPBACK> mtu 65536 qdisc noop qlen 1000
        link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00
    2: eth0: <BROADCAST,MULTICAST> mtu 1500 qdisc noop qlen 1000
        link/ether 6c:30:2a:c4:5c:78 brd ff:ff:ff:ff:ff:ff

    Bu arayüze aşağıdaki gibi bir statik ip atayabiliriz:

    $ ip addr add 192.168.1.100/24 dev eth0
    $ ip link set eth0 up

    Şimdi default gateway ataması yapalım:

    $ ip route add default via 192.168.1.1

    Tabii en az bir tane DNS server adresinin "/etc/resolv.conf" dosyasına girilmesi gerekir:

    nameserver      8.8.8.8
    nameserver      8.8.4.4

    Bu iki DNS Server da Google firmasının server'larıdır.

    Artık Ethernet yoluyla internet bağlantısı sağlanmıştır.

    Pekiyi bu işlemi nasıl otomatize edebiliriz? Anımsanacağı gibi BusyBox içerisinde klasik "sysvinit" sistemine benzer bir 
    "init" sistemi bulunuyordu.Bu "init" sisteminin "/etc/inittab" dosyasına başvurup oradaki script'leri çalıştırdığını anımsayınız. 
    Biz daha önce oluşturduğumuz BusyBox kök dosya sistemindeki "/etc/inittab" dosyasını şöyle düzenlemiştik:

    ::sysinit:/etc/init.d/rcS
    ::sysinit:/bin/mount -a
    ::sysinit:/bin/hostname -F /etc/hostname
    ttyS0::respawn:/sbin/getty -L ttyS0 115200 vt100

    Buradaki "/etc/init.d/rcS" dosyasını bir yer tutucu olarak içi boş biçimde bırakmıştık. İşte biz yukarıdaki işlemleri bu 
    dosyanın içerisine bir script olarak yazabiliriz. Örneğin:

    #!/bin/sh
    ip link set eth0 up
    ip addr add 192.168.1.100/24 dev eth0
    ip route add default via 192.168.1.1

    İkinci yol da "/etc/inittab" dosyasına yeni bir giriş eklemek olabilir. Örneğin:

    ::sysinit:/etc/init.d/network

    Bu giriş eklendiğinde artık açılış sırasında rcS script'inin yanı sıra "network" script'i de çalıştırılacaktır. Bu dosyaların 
    "x" hakkına sahip olması gerektiğini anımsayınız. Yukarıdaki script içeriğini "network" isimli script dosyasına yazabiliriz:
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												82. Ders 20/02/2025 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bu bölümde geçici olarak Gömülü Linux sistemlerinin organize edilmesine yönelik konulardan uzaklaşıp kernel mod aygıt 
    sürücülerin yazılması ve kullanılması üzerinde duracağız. Sonra yeniden Linux sistemlerinin organize edilmesine ilişkin 
    "buildroot" ve "yocto" gibi araçları inceleyeceğiz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Giriş derslerinden de anımsayacağınız gibi modern Linux sistemleri işlemcilerin "korumalı mod" özelliklerini kullanıyordu. 
    Bu sistemlerde çalışan programların (yani proseslerin) "kullanıcı modu (user mode)" ya da "çekirdek modu (kernel mode)" biçiminde
    çalışma modları vardır. Normal bütün programlar kullanıcı modunda (user mode'da) çalışmaktadır. Ancak çekirdek kodları 
    "çekirdek modunda (kernel mode)" çalışır. Kullanıcı modunda koruma mekanizması aktiftir. Dolayısıyla kullanıcı modunda çalışan 
    programlar bellekte her yere erişemezler ve her makine komutunu kullanamazlar. Halbuki çekirdek kodları koruma mekanizmasına 
    takılmamaktadır. Yani çekirdek kodları bellekte her yere erişebilmekte ve her makine komutunu kullanabilmektedir. Daha önceden 
    de gördüğümüz gibi kullanıcı modundaki sıradan programlar işletim sisteminin içerisindeki ismine "sistem fonksiyonları ya da 
    sistem çağrıları" denilen özel fonksiyonları çağırabilmektedir. Kullanıcı modundaki programlar bir sistem fonksiyonunu çağırdığında
    programın akışı sistem fonksiyonu çağrıldığı anda çekirdek moduna geçer, sistem fonksiyonu çekirdek modunda çalıştırılır, 
    sonra sistem fonksiyonu bittiğinde programın akışı yeniden kullanıcı modune döner. Bunu şekilsel olarak şöyle gösterebiliriz:

    kullanıcı modunda çalışan sıradan program -----> sistem fonksiyonunu çağırıyor -----> programın akışı kullanıcı modundan 
    çekirdek moduna geçiliyor -----> ilgili sistem fonksiyonun kodları çalıştırılıyor -----> sistem fonksiyonun çalışması bitiyor
    -----> programın akışı çekirdek modundan yeniden kullanıcı moduna geçiyor.

    Kullanıcı modunda çalışan sıradan programlar sistem fonksiyonlarını genellikle doğrudan değil POSIX kütüphanesindeki POSIX
    fonksiyonları yoluyla dolaylı bir biçimde çağırmaktadır. Yani programcı bir POSIX fonksiyonunu çağırdığında o POSIX fonksiyonu 
    da bir sistem fonksiyonunu çağırabilmektedir. Tabii her POSIX fonksiyonun bir sistem fonksiyonunu çağırdığını söylemiyoruz. 
    Önceki konularda çekirdeğe yeni sistem fonksiyonu eklerken de gördüğümüz gibi programcı isterse syscall isimli "libc" kütüphane
    fonksiyonu ile numarasını belirterek de sistem fonksiyonlarını doğrudan çağırabilir. Tabii Linux'ta sistem fonksiyonlarının 
    çağrılmasının belli bir yöntemi vardır. Bunun için makine dilinde bazı komutların kullanılması gerekmektedir. syscall fonksiyonu
    bunu bizim için yapmaktadır.

    Linux çekirdeğinin içerisinde sistem fonksiyonlarının dışında binlerce fonksiyon vardır. Kullanıcı modunda çalışan normal 
    programlar yalnızca sistem fonksiyonlarını çağırabilmektedir.

    Biz bir programı etkin kullanıcı id'si 0 olacak biçimde "sudo" ile çalıştırdığımızda program yine kullanıcı modunda çalışmaktadır. 
    Bu "sudo" mekanizmasının bu konuyla bir ilgisi yoktur. Linux sistemlerinde kullanıcı id'leri bir kullanıcının bir programının 
    başka bir kullanıcının bir dosyasına erişip erişememesi konusunda etki göstermektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    İşte çekirdeğin bir parçası biçiminde işlev gören çekirdek modunda çalışan özel programlara "çekirdek modülleri (kernel modules)
    ve "aygıt sürücüler (device drivers)" denilmektedir. Çekirdek modülleri ya da aygıt sürücülerin en önemli özelliği özelliği 
    bunların bellek ve komut koruma mekanizmasına takılmamalarıdır. Böylece biz kullanıcı modunda yapamayacağımız birtakım işlemleri 
    çekirdek modülleri ve aygıt sürücüler oluşturarak yapabilmekteyiz. Aslında aygıt sürücülerin çekirdek modu yerine kullanıcı 
    modunda çalıştığı işletim sistemleri de vardır. Bu tür çekirdek mimarilerine genel olarak "mikro çekirdek (micro kernel)" 
    mimarileri denilmektedir. Ancak Linux ve Windows sistemleri büyük ölçüde "monolitik" bir yapıdadır. Fakat bu işletim sistemlerine 
    de yavaş yavaş "kullanıcı modunda çalışan aygıt sürücüler" sokulmaktadır.

    Linux sistemlerinde "çekirdek modülü (kernel module)" ve "aygıt sürücü (device driver)" kavramları arasında bir fark vardır. 
    Çekirdeğe yüklenen bütün kodlara "çekirdek modülü" denilmektedir. Eğer bir çekirdek modülü kullanıcı modu ile ilişki kuruyorsa
    ya da birtakım kesme gibi olaylara yanıt verecek biçimde yazılmışsa bunlara aygıt sürücü denilmektedir. Yani her aygıt sürücü 
    bir çekirdek modülüdür ancak her çekirdek modülü bir aygıt sürücü değildir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdek modüllerinde ve aygıt sürücülerde her türlü fonksiyon kullanılamaz. Bunları yazabilmek için özel başlık dosyalarına 
    ve ve amaç dosyalara gereksinim duyulmaktadır. Bu nedenle ilk yapılacak şey bu başlık dosyalarının ve kütüphanelerin ilgili 
    sisteme yüklenmesidir.

    Genellikle bir Linux sistemini yüklediğimizde zaten çekirdek modüllerini ve aygıt sürücüleri oluşturabilmek için gereken 
    başlık dosyaları ve diğer gerekli öğeler zaten "/usr/src" dizini içerisindeki "linux-headers-$(uname -r)" dizininde yüklü 
    biçimde bulunmaktadır. Ancak bunlar yüklü değilse Debian tabanlı sistemlerde bunları şöyle yükleyebilirsiniz:

    $ sudo apt install linux-headers-$(uname -r)

    Tabii programcı o anda çalışılan çekirdeğin kodlarının hepsini de kendi makinesine indirmek isteyebilir. Bunun için aşağıdaki 
    komut kullanılabilir:

    $ sudo apt-get install linux-source

    Bu indirmeler "/usr/src" dizinine yapılmaktadır.

    Ayrıca "/lib/modules/$(uname -r)" isimli dizindeki "build" isimli dizin de çekirdek kaynak kodlarının bulunduğu dizine ya 
    da aygıt sürücülerin derlenmesi için gereken öğelerin bulunduğu dizine (tipik olarak "linux-headers-$(uname -r)" dizinine) 
    sembolik link yapılmış durumdadır.

    Biz daha önce çekirdeği derlerken "make modules_install" yaptığımızda çekirdek modüllerinin install edildiği yerde "build" 
    isimli biri dizinin de oluşturulduğunu görmüştük. Bu "build" dizini aslında çekirdek kaynak kodlarına bir sembolik link 
    oluşturmaktaydı. Yani "make modules_install" yapıldığında aslında aynı zamanda çekirdek modüllerinin ve aygıt sürücülerin 
    derlenmesi ve link edilmesi için gerekli olan dosyalar da hedefe çekilmiş olmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bir çekirdek modülünde biz user mod için yazılmış kodları kullanamayız. Çünkü orası ayrı bir dünyadır. Ayrıca biz çekirdek 
    modüllerinde çekirdek içerisindeki her fonksiyonu da kullanamayız. Yalnızca bazı fonksiyonları kullanabiliriz. Bunlara 
    "çekirdek tarafından export edilmiş fonksiyonlar" denilmektedir. "Çekirdek tarafından export edilmiş fonksiyon" kavramıyla 
    "sistem fonksiyonu" kavramının bir ilgisi yoktur. Sistem fonksiyonları kullanıcı modundan (user mode) çağrılmak üzere tasarlanmış 
    ayrı bir grup fonksiyondur. Oysa çekirdek tarafından export edilmiş fonksiyonlar kullanıcı modundan çağrılamazlar. Yalnızca 
    çekirdek modüllerinden çağrılabilirler. Buradan çıkan sonuç şudur: Bir çekirdek modülü yazılırken ancak çekirdeğim export 
    ettiği fonksiyonlar ve nesneler kullanılabilmektedir. Tabii çekirdeğin kaynak kodları çok büyüktür ancak buradaki kısıtlı 
    sayıda fonksiyon export edilmiştir. Benzer biçimde programcının oluşturduğu bir çekirdek modül içerisindeki belli fonksiyonları 
    da programcı export edebilir. Bu durumda bu fonksiyonlar da başka çekirdek modüllerinden kullanılabilirler. O halde özetle:

    1) Çekirdek modülleri yalnızca çekirdek içerisindeki export edilmiş fonksiyonları kullanabilir.
    2) Kendi çekirdek modülümüzde biz de istediğimiz fonksiyonu export edebiliriz. Bu durumda bizim çekirdek modülümüz çekirdeğin
    bir parçası haline geldiğine göre başka çekirdek modülleri de bizim export ettiğimiz bu fonksiyonları kullanabilir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Mademki çekirdek modülleri işletim sisteminin çekirdek kodlarındaki fonksiyonları ve nesneleri kullanabiliyor o zaman çekirdek 
    modülleri o anda çalışılan çekirdeğin yapısına da bağlı durumdadır. Bu nedenle işletim sistemlerinde "çekirdek modülü yazmak" 
    ya da "aygıt sürücü yazmak" biçiminde genel bir konu yoktur. Her işletim sisteminin çekirdek modül ve aygıt sürücü mimarisi 
    diğerlerinden farklıdır. Dolayısıyla çekirdek modüllerinin ve aygıt sürücülerinin yazılması spesifik bir işletim sistemi için 
    geçerli olabilecek platform oldukça bağımlı bir konudur. Hatta işletim sistemlerinde bazı versiyonlarda genel aygıt sürücü 
    mimarisi bile değiştirilebilmektedir. Dolayısıyla bu tür durumlarda eski aygıt sürücüler yeni versiyonlarda, yenileri de eski 
    versiyonlarda çalışamamaktadır. Örneğin Linux'ta çekirdek versiyonları arasında çekirdekteki export edilmiş bazı fonksiyonlar 
    isim ya da parametrik yapı olarak değiştirilmiş durumdadır. Bu nedenle Linux çekirdeğinin belli bir versiyonu için yazılmış 
    olan aygıt sürücüler başka bir versiyonunda geçersiz hale gelebilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdek modüllerinin ve aygıt sürücülerin yazımı için programcının çekirdek yapısını ana hatlarıyla bilmesi gerekmektedir. 
    Çünkü bunları yazarken çekirdeğin içerisindeki çeşitli veri yapıları ve export edilmiş fonksiyonlar kullanılmaktadır.

    Linux çekirdek modülleri ve aygıt sürücüleri hakkında yazılmış birkaç kitap vardır. Bunların en klasik olanı "Linux Device 
    Drivers (3. Edition)" kitabıdır. Ancak bu kitaptaki bazı içerikler güncel çekirdeklerle uyumsuz hale gelmiştir. Bu konudaki 
    resmi dokümanlar ise "kernel.org" sitesindeki "documentation" kısmında bulunmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bir çekirdek modülünü derlemek ve link etmek maalesef sanıldığından daha zordur. Her ne kadar çekirdek modülleri ELF object 
    dosyaları biçimindeyse de bunlarda özel bazı "bölümler (sections)" bulunmaktadır. Dolayısıyla bu modüllerin derlenmesinde 
    özel gcc seçenekleri devreye sokulmaktadır. Çekirdek modüllerinin link edilmeleri de bazı kütüphane dosyalarının devreye 
    sokulmasıyla yapılmaktadır. Dolayısıyla bir çekirdek modülünün manuel biçimde "build edilmesi" için bazı ayrıntılı bilgilere 
    gereksinim duyulmaktadır. İşte çekirdek modüllerinin build edilmesinde çekirdeğin KBuild sistemi devreye sokulmaktadır. Bu 
    nedenle çekirdek modüllerinin build edilmesi için çekirdek kaynak kodlarındaki birtakım başlık dosyalarının ve Make dosyalarının 
    build işleminin yapılacağı makinede bulunması gerekir. Biz yukarıda bu dosyalara "/lib/modules/$(uname -r)/build" dizini 
    yoluyla erişilebileceğini belirtmiştik. Bu dizin aslında Linux kaynak kod ağacının bulunduğu dizini belirtmektedir. Ancak
    yukarıda da belirttiğimiz gibi çekirdek modüllerinin ve aygıt sürücülerin derlenmesi için Linux'ın tüm kaynak kodlarına
    gerek yoktur. Yalnızca başlık dosyaları ve make dosyalarının bulunması yeterlidir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdek modülleri o anda çalışılan host sistem için derlenebileceği gibi gömülü bir sistem için de derlenebilir. Eğer derleme
    gömülü sistem için yapılacaksa süphesiz çapraz derleyicilerin de ilgili sistemde kurulu olması gerekir. Yukarıda da belirttiğimiz 
    gibi çekirdek modüllerinin derlenmesi için ilgili çekirdeğe yönelik başlık dosyaları ve çeşitli make dosyaları gibi 
    bazı öğelerin de bulunuyor olması gerekir. Eğer derleme bir gömülü sistem için yapılacaksa o gömülü sistemdeki çekirdeğe 
    ilişkin bu dosyalar da host makinede bulunuyor olmalıdır. Örneğin biz masaüstü bilgisayardaki Mint dağıtımında çalışıyor 
    olalım. Bu sistemin kendisi için çekirdek modülü derleyeceksek zaten tüm gerekli öğeler hazır bulunuyor olacaktır. Ancak biz 
    bu makinede BBB için çekirdek modülü ve aygıt sürücü derlemesi yapacaksak çapraz derleyicimizin ve BBB'deki çekirdeğe yönelik 
    temel başlık dosyalarının ve Make dosyalarının bulunuyor olması gerekecektir. Tabii BBB'deki çekirdek sürümüne kaynak kodları 
    bu makineye çekerek bu gereksinimi karşılayabiliriz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Masaüstü bir sistem için çekirdek modül derlemesinde kullanılabilecek minimal bir "Makefile" dosyası aşağıdaki gibi olabilir:

    obj-m += generic.o

    all:
        make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
    clean:
        make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

    Burada önce "/lib/modules/$(uname -r)/build" dizinindeki "Makefile" dosyası çalıştırılmış ondan sonra çalışma bu yazdığımız 
    make dosyasından devam ettirilmiştir. Özetle bu make dosyası aslında çekirdeğin build sistemini kullanarak "generic.c" isimli 
    dosyanın derlenmesini ve çekirdek modülü biçiminde link edilmesini sağlamaktadır. Tabii bu make dosyasını şöyle de düzenleyebiliriz:

    obj-m += generic.o

    KDIR := /lib/modules/$(shell uname -r)/build
    PWD := $(shell pwd)

    all:
        make -C ${KDIR} M=${PWD} modules
    clean:
        make -C ${KDIR} M=${PWD} clean

    Çekirdek modülü birden fazla kaynak dosya kullanılarak oluşturulabilir. Bu durumda ilk satır şöyle oluşturulabilir:

	obj-m += a.o b.o c.o...

    Eğer bu dosyaları birden fazla satırda ayrı ayrı belirtirsek bu durumda birden fazla modül dosyası oluşturulur:

    obj-m += a.o
    obj-m += b.o
    obj-m += c.o
    ...

    Eğer derlenecek dosyayı komut satırından girmek istiyorsanız Makefile dosyasını aşağıdaki gibi de düzenleyebilirsiniz:

    obj-m += ${file}.o

    all:
        make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
    clean:
        make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

    Bizim oluşturduğumuz Makefile dosyasındaki "all" hedefine dikkat ediniz:

    $ make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules

    make programının -C seçeneği Makefile dosyasını aramadan önce bu seçeneğin argümanında belirtilen dizine geçiş yapmaktadır.
    Dolayısıyla aslında yukarıdaki satırla "/lib/modules/$(shell uname -r)/build" dizinindeki Makefile dosyası çalıştırılacaktır.
    Buradaki M=${PWD} derlenecek kaynak dosyaların o anda çalışılan dizinde aranacağını belirtmektedir. Böylece çekirdeğin KBuild
    sistemi yalnızca bizim dosyalarımızı derleyecektir.

    Makefile oluştururken bir noktaya dikkat ediniz. Make dilinde hedeflerin aşağısındaki yapılacak işlemler bir tab içeriden 
    yazılmaktadır. Bazı text editörler TAB tuşuna basıldığında dosyaya TAB karakter yerine belli miktar (tipik olarak 4) SPACE
    karakteri basmaktadır. TAB yerine n tane SPACE karakterinin basılması make dosyalarında bir derleme sorununa yol açacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												83. Ders 25/02/2025 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdek modüllerini va aygıt sürücüleri derlerken iki noktaya dikkat etmelisiniz:

    1) Kullandığınız çekirdek kodları hedef makinenin çekirdek sürümüne uygun olmalıdır. Eğer bu koşul sağlanmazsa çekirdekler
    arasında farklılıklar söz konusu olabileceği için derlenmiş olan çekirdek modül dosyası hedef sisteme başarılı bir biçimde
    yüklenemeyebilir. Tabii Linux çekirdeğindeki değişiklikler daha önce yazılmış olan her çekirdek modülünü ve aygıt sürücüyü
    geçersiz hale getirmemektedir. Örneğin minör numara değişikliklerinde genellikle bir sorun oluşmamaktadır. Ancak ne olursa 
    olsun derleme yapılırken hedef sistemdeki çekirdeğe uygun kaynak dosyaların kullanılması şiddetle tavsiye edilmektedir. 
    Örneğin biz 6.9.2 çekirdeğinde çalışan makine için aygıt sürücüsü yazacaksak derleme yaptığımız makinede kullanacağımız 
    çekirdek kaynak kodlarının da bu 6.9.2 çekirdeğine ilişkin olması gerekir. Biz eski bir çekirdeğin kaynak kodlarıyla yeni 
    bir çekirdek için aygıt sürücü derlemeye çalışmamalıyız. Tabii eski bir veriyon kullanılarak derleme yapılırsa çoğu 
    durumda bir sorun ortaya çıkmayabilecektir. Ancak sorunun ortaya çıkma olasılığı da vardır.

    2) Kullanılan araç zincirinin de (yani derleyici, linker gibi programların da) çekirdeğin derlenmiş olduğu sistemle uyumlu
    olmasına dikkat ediniz. Eğer bu temel araçların versiyonlarında geçmişe doğru uyumu bozabilecek değişiklikler söz konusuysa
    yine derleme işlemi başarısız olabilir ya da çekirdek modülü yüklenirken sorun oluşabilir. Aslında çekirdeğin KBuild sistemi 
    çekirdek konfigürasyon dosyası yoluyla bu kontrolü yapabilmektedir. Ancak bu kontrol bypass da edilebilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi bir çekirdek modülünü ya da aygıt sürücüyü gömülü bir Linux sistemi için derlerken yukarıdaki iki madde dışında nelere 
    dikkat etmemiz gerekir? Host makine genellikle Intel tabanlı hedef makine de ARM tabanlı olacaktır. O halde yine bir çapraz 
    derleme işleminin yapılması gerekir. Çapraz derleme yaparken make işleminde yine CROSS_COMPILE çevre değişkeni set edilmelidir. 
    Derlemenin yapıldığı kabukta yine çağıran derleyicinin "bin" dizini için PATH çevre değişkeninin ayarlanmış olması gerekir. 
    Ayrıca make işleminde ARCH çevre değişkeninin "arm" biçiminde ya da "arm64" biçiminde belirtilmiş olması gerekir. O halde 
    çapraz derleme yapacak tipik bir Makefile dosyası şöyle olabilir:

    CROSS_COMPILE = arm-none-linux-gnueabihf-
    ARCH = arm

    KDIR := /home/kaan/Study/EmbeddedLinux/KernelBuild/linux-6.6.32-ti-arm32-r4
    PWD := $(shell pwd)

    obj-m += $(file).o

    all:
        make -C $(KDIR) M=$(PWD) ARCH=$(ARCH) CROSS_COMPILE=$(CROSS_COMPILE) modules
    clean:
        make -C $(KDIR) M=$(PWD) ARCH=$(ARCH) CROSS_COMPILE=$(CROSS_COMPILE) clean
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdek modüllerinin ve aygıt sürücülerin derlenmesi için hedef çekirdeğe ilişkin başlık dosyalarının ve birtakım diğer 
    dosyaların derlemenin yapılacağı makinede hazır olarak bulundurulması gerektiğini belirtmiştik. Host sistemin kendisi 
    üzerinde geliştirme yapıyorsak genellikle bunlar zaten host sistemde bulunacaktır. Ancak başka bir çekirdeğe yönelik geliştirme
    yapılacaksa o çekirdeğe ilişkin kaynak kodların geliştirmenin yapılacağı makineye indirilmesi gerekir. Fakat yalnızca kaynak 
    kodların indirilmesi yeterli değildir. Kaynak kodlar indirildikten sonra en azından aşağıdaki iki işlemin yapılması gerekir:

    1) Modül derlemesi için "make modules_prepare" işleminin yapılması gerekir. Örneğin:

    $ make modules_prepare

    2) Modüllerin derlenmesi için "make modules" işleminin yapılması gerekir. Örneğin:

    $ make modules

    Tabii modüllerin derlenmesi uzun zaman almaktadır. Aslında uygulamacı kendi çekirdek modülü ya da aygıt sürücüsü içerisinde
    kullanacağı az sayıda modülü de derleyebilir. Ancak bunun kestirilmesi o kadar kolay değildir. Tabii çekirdek modüllerinin 
    ya da aygıt sürücülerin derlenmesi için sisteminde hazır olan dizin için zaten bunlar yapılmış durumdadır. Çekirdeğin hepsini 
    yeniden derlerken zaten yukarıdaki işlemlerin de yapılmış olacağına dikkat ediniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi en basit bir kernel modülü oluşturup bunu bir başlangıç noktası olarak kullanalım. Bu modülümüze "helloworld" ismini
    verelim:

    /* helloworld.c */

    #include <linux/module.h>
    #include <linux/kernel.h>

    MODULE_LICENSE("GPL");

    int init_module(void)
    {
        printk(KERN_INFO "Hello World...\n");

        return 0;
    }

    void cleanup_module(void)
    {
        printk(KERN_INFO "Goodbye World...\n");
    }

    Bu kernel modül aşağıdaki gibi build edilebilir:

    $ make file=helloworld"

    Build işlemi bittiğinde kernel modül "helloworld.ko" dosyası biçiminde oluşturulacaktır. Burada "ko" uzantısı "kernel 
    object" sözcüklerinden kısaltılmıştır.
-----------------------------------------------------------------------------------------------------------------------------*/

/* helloworld.c */

#include <linux/module.h>
#include <linux/kernel.h>

MODULE_LICENSE("GPL");

int init_module(void)
{
	printk(KERN_INFO "Hello World...\n");

	return 0;
}

void cleanup_module(void)
{
	printk(KERN_INFO "Goodbye World...\n");
}

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/*-----------------------------------------------------------------------------------------------------------------------------
    Modüller "modprobe" isimli programla da yüklenebilir. Ancak modprobe programı yüklenecek modülleri "/lib/modules/$(uname -r)"
    dizininde aramaktadır. Dolayısıyla biz kendi derlediğimiz modülleri bu dizine yerleştirmemişsek yüklemeyi modprobe ile 
    yapamayız. Ancak çekirdek derlenirken oluşturulmuş olan modüller bu dizinde olduğu için bunları modprobe ile yükleyebiliriz. 
    modprobe programı yüklenecek aygıt sürücünün yalnızca ismini almaktadır. Çünkü zaten arama işlemini kendisi yapmaktadır. 
    Örneğin:

    $ modprobe g_ether

    insmod programının yüklenecek aygıt sürücü dosyasının tüm yol ifadesini aldığına dikkat ediniz. modprobe programında dosyanın 
    ".ko" uzantısı da belirtilmemektedir. Halbuki insmod programında bu uzantının da belirtilmesi gerekmektedir. modprobe aslında 
    "modules.dep" isimi bir dosyaya başvurmaktadır. Bu dosya çekirdek kaynak kodlarının kök dizininde çekirdek modülleri derlenirken 
    oluşturulmaktadır. Bu dosya içerisinde bağımlılık bilgileri vardır. Bir çekirdek modülü yazılırken başka bir çekirdek modülünün 
    içerisindeki fonksiyonlar kullanılmış olabilir. Bu durumda kullanan modülün yüklenmesi için önce onun kullandığı modülün 
    yüklenmesi gerekir. İşte bu biçimde durum karmaşık bir hal alabilmektedir. "modules.dep" dosyası içerisinde bir modülün 
    yüklenebilmesi için hangi modüllerin de yüklenmesi gerektiği bilgileri bulunmaktadır. Eğer biz kendi çekirdek modülümüzün de 
    modprobe ile yüklenmesini istiyorsak önce onu "/lib/modules/$(uname -r)/kernel" dizininin içerisindeki dizinlerden birine yerleştirip 
    sonra bu "modules.dep" dosyasının güncellenmesini sağlamamız gerekir. Bu işlem "depmod" programıyla "-a" seçeneği kullanılarak 
    yapılmaktadır:

    $ sudo depmod -a

    Kendi çekirdek modülünüzü ya da aygıt sürücünüzü örneğin "/lib/modules/$(uname -r)/kernel/drivers/misc" dizinine yerleştirebilirsiniz.
    Tabii aygıt sürücü geliştirirken ikide bir modülü buraya yerleştirmenin bir anlamı yoktur. Bu nedenle geliştirme aşamasında 
    genellikle "insmod" programı kullanılmaktadır.

    modprobe ile yüklenen aygıt sürücü "modeprobe -r" ile boşaltılabilir. Örneğin:

    $ modprobe -r g_ether

    Tabii boşaltım sırasında yine eğer aygıt sürünün bağımlı olduğu çekirdek modülleri başka modüller tarafından kullanılmıyorsa
    onlar da çekirdekten çıkartılacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												84. Ders 27/02/2025 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Sistem açılır açılmaz otomatik olarak bir çekirdek modülünün ya da aygıt sürücünün yüklenmesi için birka. yöntem kullanılabilmektedir. 
    "/etc/modules" dosyası "klasik sysvinit" ve "systemd" init tarafından işletilmektedir. Dolayısıyla bu dosyanın içerisine bir 
    satıra çekirdek modülünüzün ismini (yalnızca ismini) yazarsanız sistem açıldığında çekirdek modülü de otomatik yüklenmiş olur. 
    Ancak init programları bu dosyada belirtilen çekirdek modüllerini modprobe ile yüklemektedir. Dolayısıyla sizin de çekirdek 
    modülünüzü "/lib/modules/$(uname -r)/kernel" içerisindeki bir dizine (örneğin "/lib/modules/$(uname -r)/kernel/drivers/misc"
    dizinine) yerleştirip "sudo depmod -a" komutunu uygulamanız gerekir. Eğer systemd init sistemi ile çalışıyorsanız yüklemeyi 
    yapacak bir "servis birim dosyası" oluşturabilirsiniz. Örneğin.

    [Unit]
    Description=Modül Yükleme Servisi
    After=network.target

    [Service]
    Type=oneshot
    ExecStart=/sbin/modprobe <modül_adı>
    RemainAfterExit=true

    [Install]
    WantedBy=multi-user.target

    Diğer bir yöntem de klasik systemvinit ve systemd tarafından bakılan "/etc/rc.local" dosyasının içerisine yükleme komutunu 
    yazmaktır. Örneğin:

    "sudo insmod /path/helloworld.ko"

    Tabii burada modprobe da kullanılabilir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    En basit bir çekirdek modülünde aşağıdaki iki temel dosya include edilmelidir:

    #include <linux/module.h>
    #include <linux/kernel.h>

    Bu iki dosya "/lib/modules/$(uname -r)/build/include" dizini içerisindedir. (Bu dizinin çekirdek kaynak kodlarındaki "include"
    dizini olduğuna dikkat ediniz. Bu iki başlık dosyası "libc" ve POSIX kütüphanelerinin başlık dosyalarının bulunduğu "/usr/include" 
    içerisinde değildir.) Yukarıda kullandığımız make dosyası include dosyalarının bu dizinde aranmasını sağlamaktadır.

    Eskiden çekirdek modüllerine modül lisansının eklenmesi zorunlu değildi. Ancak belli bir zamandan sonra bu zorunlu hale
    getirilmiştir. Modül lisansı MODULE_LICENSE isimli makro ile belirtilmektedir. Bu makro <linux/module.h> dosyası içerisinde
    bildirilmiştir. Tipik modül lisansı aşağıdaki gibi "GPL" biçiminde oluşturulabilir:

    MODULE_LICENSE("GPL");

    Bir çekirdek modülü yüklendiğinde çekirdek modülü içerisinde belirlenmiş olan bir fonksiyon çağrılır (bu fonksiyon C++'taki 
    "constructor" gibi düşünülebilir.) Default çağrılacak fonksiyonun ismi init_module biçimindedir. Bu fonksiyonun geri 
    dönüş değeri int türdendir ve parametresi yoktur. Fonksiyon başarı durumunda 0 değerine, başarısızlık durumunda negatif 
    hata koduna (negatif errno değerine) geri dönmelidir. Bu fonksiyon başarısızlıkla geri dönerse modülün yüklenmesinden 
    vazgeçilmektedir. Benzer biçimde bir modül çekirdek alanından boşaltılırken de yine bir fonksiyon çağrılmaktadır. (Bu 
    fonksiyon da C++'taki "destructor" gibi düşünülebilir.) Default çağrılacak fonksiyonun ismi cleanup_module biçimindedir. 
    Bu fonksiyonun geri dönüş değeri ve parametresi void biçimdedir.

    Çekirdek modülleri ekrana değil log dosyalarına yazarlar. Bunun için çekirdek içindeki printk isimli fonksiyon kullanılmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    helloworld modülünde kullanmış olduğumuz printk fonksiyonu "çekirdeğin printf fonksiyonu" gibi düşünülebilir. printk fonksiyonunun 
    genel kullanımı printf fonksiyonu gibidir. Default durumda bu fonksiyon mesajların "/var/log/syslog" dosyasına yazdırılmasını 
    sağlamaktadır. printk fonksiyonunun prototipi <linux/kernel.h> dosyası içerisindedir. printk fonksiyonunun örnek kullanımı şöyledir:

    printk(KERN_INFO "This is test\n");

    Mesajın solundaki KERN_XXX biçimindeki makrolar aslında bir string açımı yapmaktadır. Dolayısıyla yan yana iki string 
    birleştirildiği için mesaj yazısının başında küçük bir önek bulunur. Bu önek (yani bu makro) mesajın türünü ve aciliyetini 
    belirtmektedir. Tipik KERN_XXX makroları şunlardır:

    KERN_EMERG
    KERN ALERT
    KERN_CRIT
    KERN_ERR
    KERN_WARN
    KERN_NOTICE
    KERN_INFO
    KERN_DEBUG

    Bu makroların tipik yazım biçimi şöyledir:

    #define KERN_SOH	    "\001"		/* ASCII Start Of Header */
    #define KERN_SOH_ASCII	'\001'

    #define KERN_EMERG	    KERN_SOH "0"	    /* system is unusable */
    #define KERN_ALERT	    KERN_SOH "1"	    /* action must be taken immediately */
    #define KERN_CRIT	    KERN_SOH "2"	    /* critical conditions */
    #define KERN_ERR	    KERN_SOH "3"	    /* error conditions */
    #define KERN_WARNING	KERN_SOH "4"	    /* warning conditions */
    #define KERN_NOTICE	    KERN_SOH "5"	    /* normal but significant condition */
    #define KERN_INFO	    KERN_SOH "6"	    /* informational */
    #define KERN_DEBUG	    KERN_SOH "7"	    /* debug-level messages */

    Ancak bu makrolarda çeşitli çekirdek versiyonlarında değişiklikler yapılabilmektedir. C'de aralarında hiçbir operatör bulunmayan
    iki string'in derleyici tarafından birleştirildiğini anımsayınız. Bu durumda aslında örneğin:

    printk(KERN_INFO "Hello World...\n");

    ile aşağıdaki çağrı eşdeğerdir:

    printk("\0017Hello World...\n");

    Ancak yukarıda da belirttiğimiz gibi bu makrolar üzerinde değişiklikler yapılabilmektedir. Dolayısıyla makroların kendisinin 
    kullanılması gerekir.

    Aslında KERN_XXX makroları ile printk fonksiyonunu kullanmak yerine pr_xxx makroları da kullanılabilir. Şöyle ki:

    printk(KERN_INFO "Hello World...\n");

    ile

    pr_info("Hello World...\n");

    tamamen eşdeğerdir. Diğer pr_xxx makroları şunlardır:

    pr_emerg
    pr_alert
    pr_crit
    pr_err
    pr_warning
    pr_notice
    pr_info
    pr_debug

    printk fonksiyonunun yazdıklarını "/var/log/syslog" dosyasına bakarak görebiliriz. Örneğin:

    $ tail /var/log/syslog

    Ya da "dmesg" programı ile de aynı bilgi elde edilebilir.

    En çok kullanılan log düzeyini belirten makrolar KERN_INFO, KERN_ERR ve KERN_WARNING makrolarıdır. Çekirdek modülü ya da 
    aygıt sürücü içerisinde bazı durumlara yönelik bilgi vermek için KERN_INFO, hatalı bir durumlar karşılaştığında KERN_ERR 
    ve bir uyarı oluşturulacağı zaman KERN_WARNING kullanılmaktadır. Diğer makrolar geliştiriciler tarafından çok seyrek 
    kullanılmaktadır.

    Çekirdek modülleri çekirdeğin içerisine yerleştirildiği için çekirdek modüllerinde biz kullanıcı modundaki (user mode'daki) 
    kütüphaneleri kullanamayız. (Örneğin çekirdek modunda standart C fonksiyonlarını ve POSIX fonksiyonlarını kullanamayız.) 
    Çünkü standart C fonksiyonları ve POSIX fonksiyonları "kullanıcı modunda (user mode)" programlar için oluşturulmuş kütüphanelerin 
    içerisindedir. Biz çekirdek modüllerinin içerisinde yalnızca "export edilmiş çekirdek fonksiyonlarını" kullanabiliriz.

    Çekirdek modülleri içerisinde kullanılabilecek export edilmiş çekirdek fonksiyonları "Linux Kernel API" ismi altında "kernel.org"
    tarafından dokümante edilmiştir. Örneğin bu fonksiyonların dokümantasyonuna aşağıdaki bağlantıdan erişebilirsiniz:

    https://docs.kernel.org/core-api/kernel-api.html

    Ancak maalesef bu export edilmiş fonksiyonlar hakkında ayrıntılı açıklamalar bulmak zordur. Bu nedenle bazen çekirdek kaynak 
    kodlarına başvurmak da gerekebilir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Belli bir anda yüklenmiş olan çekirdek modülleri "/proc/modules" dosyasından elde edilebilir. "/proc/modules" "bir text 
    dosyadır. Dosyanın her satırında bir çekirdek modülünün bilgisi vardır. Örneğin:

    $ cat /proc/modules
    helloworld 16384 0 - Live 0x0000000000000000 (OE)
    vmw_vsock_vmci_transport 32768 2 - Live 0x0000000000000000
    vsock 40960 3 vmw_vsock_vmci_transport, Live 0x0000000000000000
    snd_ens1371 28672 2 - Live 0x0000000000000000
    snd_ac97_codec 131072 1 snd_ens1371, Live 0x0000000000000000
    gameport 20480 1 snd_ens1371, Live 0x0000000000000000
    ac97_bus 16384 1 snd_ac97_codec, Live 0x0000000000000000
    binfmt_misc 24576 1 - Live 0x0000000000000000
    intel_rapl_msr 20480 0 - Live 0x0000000000000000
    ...

    Yüklü modüllerin bilgileri "lsmod" isimli bir yardımcı programla da görüntülenebilmektedir. Tabii aslında "lsmod" 
    "/proc/modules" dosyasını okuyup onu daha anlaşılır biçimde görüntülemektedir. Örneğin:

    $ lsmod
    Module                  Size  Used by
    helloworld             16384  0
    btrfs                1564672  0
    blake2b_generic        20480  0
    xor                    24576  1 btrfs
    zstd_compress         229376  1 btrfs
    raid6_pq              122880  1 btrfs
    ufs                   106496  0
    qnx4                   16384  0
    hfsplus               118784  0
    hfs                    65536  0
    ...
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												85. Ders 04/03/2025 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aslında init_module ve cleanup_module fonksiyonlarının ismi değiştirilebilir. Fakat bunun için bildirimde bulunmak gerekir. 
    Bildirimde bulunmak için ise module_init(...) ve module_exit(...) makroları kullanılmaktadır. Bu makrolar kaynak kodun 
    herhangi bir yerinde bulundurulabilir. Ancak makro içerisinde belirtilen fonksiyonların daha yukarıda bildirilmiş olması 
    gerekmektedir. Bu makrolar tipik olarak kaynak kodun sonuna yerleştirilmektedir. Örneğin:

    #include <linux/module.h>
    #include <linux/kernel.h>

    int helloworld_init(void)
    {
        printk(KERN_INFO "Hello World...\n");

        return 0;
    }

    void helloworld_exit(void)
    {
        printk(KERN_INFO "Goodbye World...\n");
    }

    module_init(helloworld_init);
    module_exit(helloworld_exit);

    Aşağıda örnek bütünsel olarak verilmiştir. make işlemi şöyle yapılabilir:

    $ make file=helloworld
-----------------------------------------------------------------------------------------------------------------------------*/

/* helloworld.c */

#include <linux/module.h>
#include <linux/kernel.h>

int helloworld_init(void)
{
	printk(KERN_INFO "Hello World...\n");

	return 0;
}

void helloworld_exit(void)
{
	printk(KERN_INFO "Goodbye World...\n");
}

module_init(helloworld_init);
module_exit(helloworld_exit);

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/*-----------------------------------------------------------------------------------------------------------------------------
    Genellikle çekirdek modülü içerisindeki global değişkenlerin ve fonksiyonların "içsel bağlamaya (internal linkage)" sahip 
    olması tercih edilmektedir. Bu durum birtakım isim çakışmalarını da engelleyecektir. Biz de genel olarak örneklerimizde 
    zorunlu olmadıkça fonksiyonları hep static biçimde tanımlayacağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/* helloworld.c */

#include <linux/module.h>
#include <linux/kernel.h>

static int helloworld_init(void)
{
	printk(KERN_INFO "Hello World...\n");

	return 0;
}

static void helloworld_exit(void)
{
	printk(KERN_INFO "Goodbye World...\n");
}

module_init(helloworld_init);
module_exit(helloworld_exit);

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdek modüllerinin init ve cleanup fonksiyonlarında fonksiyon isimlerinin soluna __init ve __exit makroları getirilebilmektedir. 
    Bu makrolar <linux/init.h> dosyası içerisindedir. Bu dosya da <linux/module.h> dosyası içerisinde include edilmiştir. 
    __init makrosu ilgili fonksiyonu ELF dosyasının özel bir bölümüne (section) yerleştirir. Modül yüklendikten sonra bu bölüm 
    çekirdek alanından atılmaktadır. __exit makrosu ise çekirdeğin içine gömülmüş modüllerde fonksiyonun dikkate alınmayacağını 
    (dolayısıyla da fonksiyonun yerleştirildiği bölümün çekirdekle birlikte belleğe hiç yüklenmeyeceğini) belirtir. Ancak 
    sonradan yüklemelerde bu makronun bir etkisi yoktur. Bir çekirdek modülü çekirdeğin içerisine gömülürse modülün cleanup 
    fonksiyonu zaten çağrılmamaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/* helloworld.c */

#include <linux/module.h>
#include <linux/kernel.h>

static int __init helloworld_init(void)
{
	printk(KERN_INFO "Hello World...\n");

	return 0;
}

static void __exit helloworld_exit(void)
{
	printk(KERN_INFO "Goodbye World...\n");
}

module_init(helloworld_init);
module_exit(helloworld_exit);

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux sistemlerine 2003 yılında 2.6 çekirdekleriyle birlikte "sysfs (kısaca sys)" isimli bellek tabanlı yeni bir dosya sistemi
    daha eklenmiştir. Bu dosya sistemi de tıpkı proc dosya sistemi gibi çekirdeğin içinde bulunduğu durumu dış dünyaya bildirmek 
    ve çekirdek davranışının dışarıdan değiştirilmesine olanak sağlamak amacıyla oluşturulmuştur. Ancak "sysfs" dosya sistemi 
    daha "nesne yönelimli" bir tasarıma sahiptir. Yani birtakım olgular dizinlerle onların özellikleri de o dizinler içerisindeki 
    dosyalarla temsil edilmektedir. Bu bakımdan "sysfs" dosya sistemi "proc" dosya sisteminin bazı eksikliklerini tamamlamaktadır. 
    sysfs dosya sistemine "/sys" dizini yoluyla erişilmektedir.

    insmod ile yüklediğimiz her modül için "/sys/module" dizinin içerisinde ismi modül ismiyle aynı olan bir dizin yaratılmaktadır. 
    "/proc/modules" dosyası ile bu dizini karıştırmayınız. "/proc/modules" dosyasının satırları yüklü olan modüllerin isimlerini 
    ve bazı temel bilgilerini tutmaktadır. Modüllere ilişkin asıl önemli bilgiler ise çekirdek tarafından "/sys/module" dizininde 
    tutulmaktadır. sysfs dosya sistemi de proc dosya sistemi gibi çekirdek tarafından bellek üzerinde oluşturulan ve içeriği çekirdek
    tarafından güncellenen bir dosya sistemidir. Örneğin "helloworld.ko" modülünü yükledikten sonra bu dizin aşağıdaki gibi bir 
    içeriğe sahip olacaktır:

    $ ls /sys/module/helloworld -l
    toplam 0
    -r--r--r-- 1 root root 4096 Mar 22 21:25 coresize
    drwxr-xr-x 2 root root    0 Mar 22 21:25 holders
    -r--r--r-- 1 root root 4096 Mar 22 21:25 initsize
    -r--r--r-- 1 root root 4096 Mar 22 21:25 initstate
    drwxr-xr-x 2 root root    0 Mar 22 21:25 notes
    -r--r--r-- 1 root root 4096 Mar 22 21:25 refcnt
    drwxr-xr-x 2 root root    0 Mar 22 21:25 sections
    -r--r--r-- 1 root root 4096 Mar 22 21:25 srcversion
    -r--r--r-- 1 root root 4096 Mar 22 21:25 taint
    --w------- 1 root root 4096 Mar 22 21:22 uevent
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Nasıl kullanıcı modu programlarında main fonksiyonuna komut satırı argümanları geçirilebiliyorsa benzer biçimde çekirdek 
    modüllerine de argüman (ya da parametre diyebiliriz) geçirilebilmektedir. Bu konuya genel olarak "çekirdek modül parametreleri" 
    denilmektedir.

    Çekirdek modüllerine parametre geçirme işlemi insmod komutu ile modül yüklenirken komut satırında modül isminden sonra 
    "değişken=değer" çiftleriyle yapılmaktadır. Örneğin:

    $ sudo insmod helloworld.ko number=10 msg="\"This is a test\"" values=10,20,30,40,50

    Bu örnekte number parametresi int bir değerden, msg parametresi bir yazıdan values parametresi ise birden fazla int değerden 
    oluşmaktadır. Bu tür parametrelere modülün dizi parametreleri denilmektedir.

    Çekirdek modüllerine geçirilen parametreleri modül içerisinde almak için module_param ve module_param_array isimli makrolar 
    kullanılır. module_param makrosunun üç parametresi vardır:

    module_param(name, type, perm);

    name parametresi ilgili değişkenin ismini belirtmektedir. Biz makroyu çağırmadan önce bu isimde bir global değişkeni tanımlamalıyız. 
    Ancak buradaki değişken isminin komut satırında verilen parametre (argüman da diyebiliriz) ismi ile aynı olması gerekmektedir. 
    type ilgili parametrenin türünü belirtir. Bu tür şunlardan biri olabilir:

    int
    long
    short
    uint
    ulong
    ushort
    charp
    bool
    invbool

    Buradaki charp char türden adresi, invbool ise geçirilen argümanın bool bakımdan tersini temsil etmektedir. module_param
    makrosunun perm parametresi "/sys/modules/<modül ismi>" dizininde yaratılacak olan "parameters" dizininin erişim haklarını 
    belirtir. Bu makrolar global alanda herhangi bir yere yerleştirilebilir.

    Örneğin kernel modülümüzde count ve msg isimli iki parametre olsun. Bunlara ilişkin module_param makroları şöyle oluşturulmalıdır:

    int count = 0;
    char *msg = "Ok";

    module_param(count, int, S_IRUSR|S_IWUSR|S_IRGRP|S_IROTH);
    module_param(msg, charp, S_IRUSR|S_IWUSR|S_IRGRP|S_IROTH);

    char * türünden modül parametresi için makrodaki türün "charp" biçiminde olduğuna dikkat ediniz. Buradaki gösterici const 
    olamamaktadır. Bizim bir parametre için module_param makrosunu kullanmış olmamız modül yüklenirken bu parametrenin belirtilmesini 
    zorunlu hale getirmemektedir. Bu durumda bu parametreler default değerlerde kalacaktır. Yukarıdaki parametreleri helloworld 
    modülüne aşağıdaki gibi geçirebiliriz:

    $ sudo insmod helloworld.ko count=100 msg="\"this is a test\""

    Burada neden iç içe tırnakların kullanıldığını merak edebilirsiniz. Kabuk üzerinde tırnaklar "boşluklarla ayrılmış olan yazıların 
    tek bir komut satırı argümanı olarak ele alınacağını belirtmektedir. Ancak bizim ayrıca yazısal argümanları modüllere parametre 
    yoluyla aktarırken onları tırnaklamamız gerekir. Bu nedenle iç içe iki tırnak kullanılmıştır.

    Modül parametreleri kernel tarafından "/sys/module" içerisindeki modül ismine ilişkin dizinin altındaki parameters dizininde 
    dosyalar biçiminde dış dünyaya sunulmaktadır. İşte makrodaki erişim hakları buradaki parametre dosyalarının erişim haklarını 
    belirtmektedir. Kernel modül root kullanıcısı tarafından yüklendiğine göre bu dosyaların da kullanıcı ve grup id'leri root 
    olacaktır. Örneğin helloworld modülü için bu dosyalar "/sys/module/helloworld/parameters" dizini içerisindedir:

    $ ls -l /sys/module/helloworld/parameters
    toplam 0
    -rw-r--r-- 1 root root 4096 Mar 22 22:24 count
    -rw-r--r-- 1 root root 4096 Mar 22 22:24 msg

    Bu dosyalar doğrudan kernel modüldeki parametre değişkenlerini temsil etmektedir. Yani örneğin biz buradaki count dosyasına
    başka bir değer yazdığımızda kernel modülümüzdeki count değeri de değişmiş olacaktır. Tabii yukarıdaki erişim haklarıyla biz
    dosyaya yazma yapamayız. Bu erişim haklarıyla yazma yapabilmemiz için yazmayı yapan programın root olması gerekir. Terminalden 
    bu işlem aşağıdaki gibi yapılabilir:

    $ sudo bash -c "echo 200 > /sys/module/helloworld/parameters/count"

    yada

    $ echo 200 | sudo tee /sys/module/helloworld/parameters/count

    Burada işlemi aşağıdaki gibi yapamayacağımıza dikkat ediniz:

    $ sudo echo 200 > /sys/module/helloworld/parameters/count

    Çünkü burada her ne kadar echo programı root önceliğinde çalıştırılıyorsa da dosyayı açan kullanıcı root değildir. Çünkü 
    > işareti ve onun sağının sudo ile bir ilgisi yoktur.

    Bu denemeyi aşağıdaki modülle yapabilirsiniz. Modülü önce insmod ile aşağıdaki gibi yükleyiniz:

    $ sudo insmod helloworld.ko count=200 msg="\"this is a generic module\""

    Sonra "/sys/module/helloworld/parameters" dizinine geçip aşağıdaki komutları uygulayınız:

    $ echo 500 | sudo tee count
    $ echo "this is a new message" | sudo tee msg

    Modülü "rmmod" ile çekirdek alanından çıkarttıktan sonra yeniden "dmesg" yapınız. Artık modül içerisindeki parametrelerin
    aşağıdaki gibi değiştiğini göreceksiniz:

    [ 7668.582978] count = 500, msg=this is a new message
-----------------------------------------------------------------------------------------------------------------------------*/

/* helloworld.c */

#include <linux/module.h>
#include <linux/kernel.h>

MODULE_LICENSE("GPL");

static int count = 0;
static char *msg = "Ok";

module_param(count, int, S_IRUSR|S_IWUSR|S_IRGRP|S_IROTH);
module_param(msg, charp, S_IRUSR|S_IWUSR|S_IRGRP|S_IROTH);

static int __init helloworld_init(void)
{
	printk(KERN_INFO "Hello World...\n");

	return 0;
}

static void __exit helloworld_exit(void)
{
	printk(KERN_INFO "Goodbye World...\n");
	printk(KERN_INFO "count = %d, msg=%s\n", count, msg);
}

module_init(helloworld_init);
module_exit(helloworld_exit);

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdek modülene birden fazla değer de bir dizi gibi aktarılabilir. Bunun için module_param_array makrosu kullanılmaktadır. 
    module_param_array makrosu da şöyledir:

    module_param_array(name, type, nump, perm)

    Makronun birinci ve ikinci parametreleri yine değişken ismi ve türünü belirtir. Tabii buradaki değişken isminin bir dizi 
    ismi olarak, türün de bu dizinin eleman türü olarak girilmesi gerekmektedir. Üçüncü parametre toplam kaç değerin modüle dizi 
    biçiminde aktarıldığını belirten int bir nesnenin adresini (ismini değil) alır. Son parametre yine oluşturulacak dosyanın 
    erişim haklarını belirtmektedir. Örneğin:

    static int values[5];
    static int size;

    module_param_array(values, int, &size, S_IRUSR|S_IWUSR|S_IRGRP|S_IROTH);

    module_param_array makrosuyla bir diziye değer aktarırken değerlerin virgüllerle ayrılmış bir biçimde girilmesi gerekmektedir.
    Örneğin:

    $ sudo insmod helloworld.ko values=1,2,3,4,5

    Burada eğer verilen değerler dizinin uzunluğundan fazla olursa zaten modül yüklemesi başarısız olmaktadır. Yani "insmod" 
    bir hata mesajı ile işlemini sonlandıracaktır. Tabii verilen değerlerin dizinin uzunluğundan daha az olabilir. Girilen değerlerin
    sayısı zaten örneğimizde size nesnesine yerleştirilecektir.

    Aşağıdaki örnekte üç parametre komut satırından çekirdek modülüne geçirilmiştir. Komut satırındaki isimlerle programın içerisindeki 
    değişken isimlerinin aynı olması gerektiğini anımsayınız. Dizi elemanlarını virgüllerle belirtirken yanlışlıkla virgüllerin 
    arasına boşluk karakterleri yerleştirmeyiniz. Programı şöyle make yapabilirsiniz:

    $ make file=helloworld

    Yüklemeyi şöyle yapabilirsiniz:

    $ sudo insmod helloworld.ko count=200 msg="\"this is a generic module\"" values=10,20,30,40,50
-----------------------------------------------------------------------------------------------------------------------------*/

/* helloworld.c */

#include <linux/module.h>
#include <linux/kernel.h>

MODULE_LICENSE("GPL");

static int count = 0;
static char *msg = "Ok";
static int values[5];
static int size;

module_param(count, int, S_IRUSR|S_IWUSR|S_IRGRP|S_IROTH);
module_param(msg, charp, S_IRUSR|S_IWUSR|S_IRGRP|S_IROTH);
module_param_array(values, int, &size, S_IRUSR|S_IWUSR|S_IRGRP|S_IROTH);

static int __init helloworld_init(void)
{
	int i;

	printk(KERN_INFO "Hello World...\n");

	printk(KERN_INFO "count = %d\n", count);
	printk(KERN_INFO "msg = %s\n", msg);
	printk(KERN_INFO "Values:\n");
	for (i = 0; i < size; ++i)
		printk(KERN_INFO "%d ", values[i]);
	printk(KERN_INFO "\n");

	return 0;
}

static void __exit helloworld_exit(void)
{
	printk(KERN_INFO "Goodbye World...\n");
}

module_init(helloworld_init);
module_exit(helloworld_exit);

/*-----------------------------------------------------------------------------------------------------------------------------
												86. Ders 06/03/2025 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    errno değişkeni aslında "libc" kütüphanesinin (libc standart C ve POSIX kütüphanesidir) içerisinde tanımlanmış bir değişkendir. 
    Çekirdek modunda yani çekirdeğin içerisinde errno isimli bir değişken yoktur. Bu nedenle çekirdekteki fonksiyonlar pek çok 
    POSIX fonksiyonunda olduğu gibi başarısızlık durumunda -1 ile geri dönüp errno değişkenini set etmezler. Çekirdek içerisindeki 
    fonksiyonlar başarısızlık durumunda negatif errno değeri ile geri dönerler. Örneğin "open" POSIX fonksiyonu "sys_open" isimli 
    çekirdek içerisinde bulunan sistem fonksiyonunu çağırdığında onun negatif bir değerle geri dönüp dönmediğine bakar. Eğer "sys_open" 
    fonksiyonu negatif değerle geri dönerse bu durumda bu değerin pozitiflisini errno değişkenine yerleştirip -1 ile geri dönmektedir. 
    Başka bir deyişle aslında bizim çağırdığımız int geri dönüş değerine sahip POSIX fonksiyonları sistem fonksiyonlarını çağırıp 
    o fonksiyonlar negatif bir değerle geri dönmüş ise bir hata oluştuğunu düşünerek o negatif değerin pozitiflisini errno değişkenine 
    yerleştirip -1 ile geri dönmektedir.

    Çekirdek modül yazan programcıların da bu biçime uyması iyi bir tekniktir. Örneğin:

    if (some_control_failed)		/* burada kontrol yapılıyor */
        return -EXXX;				/* fonksiyon başarısız ise negatif errno değeriyle geri döndürülüyor */

    Özetle biz çekirdek içerisindeki geri dönüş değeri int olan bir fonksiyonu çağırdığımızda onun başarılı olup olmadığını geri dönüş 
    değerinin negatif olup olmadığı ile kontrol ederiz. Eğer çağırdığımız fonksiyonun geri dönüş değeri negatif ise onun pozitif hali
    başarısızlığa ilişkin errno numarasını vermektedir.

    POSIX arayüzünde adrese geri dönen fonksiyonlar genel olarak başarısızlık durumunda NULL adrese geri dönmektedir. Oysa çekirdek 
    kodlarında adrese geri dönen fonksiyonlar başarısız olduklarında yine sanki bir adresmiş gibi negatif errno değerine geri 
    dönerler. Örneğin şöyle bir çekirdek fonksiyonu olsun:

    void *foo(void);

    Biz bu fonksiyonu çekirdek modülümüz içerisinde çağırdığımızda eğer fonksiyon başarısızsa negatif errno değerini bir adres gibi
    geri döndürmektedir. Negatif küçük değerlerin 2'ye tümleyen aritmetiğinde başı 1'lerle dolu olan bir sayı olacağına dikkat 
    ediniz. Örneğin bu foo fonksiyonu -EPERM değeri ile geri dönüyor olsun. EPERM değeri 1'dir. 64 bit sistemdeki -1 değeri 
    ise şöyledir:

    FF FF FF FF FF FF FF FF

    Bu değer ise çok yüksek bir adres gibidir. O zaman eğer fonksiyon çok yüksek bir adres geri döndürdüyse başarısız olduğu 
    sonucunu çıkartabiliriz. Örneğin yukarıdaki fonksiyon -ENOENT değeri ile geri dönüyor olsun. ENOENT 2 değerindedir. -2 
    ise 64 bit sistemde 2'ye tümleyen aritmetiğinde aşağıdaki gibidir:

    FF FF FF FF FF FF FF FE

    Görüldüğü gibi bu adres bilgisi de aslında bellek alanının sonlarındaki bir adrese belirtmektedir. İşte Linux çekirdeğindeki 
    son 4095 adres zaten çekirdek tarafından kullanılmamaktadır. Bunlar negatif errno değerlerini belirtirler. O halde biz adrese 
    geri dönen bir Linux çekirdek fonksiyonunu çağırdığımızda bu fonksiyon eğer belleğin sonundaki 4095 adresten biriyle geri 
    dönüyorsa aslında negatif bir errno değeriyle geri dönmektedir.

    Pekiyi bir adres değerinin aslında negatif bir errno değeri içerdiğini yani geçerli olmadığını nasıl anlayabiliriz? 
    İşte yukarıda da belirttiğimiz gibi negatif errno değerleri bir adres gibi ele alındığında adeta adres alanının sonundaki 
    adresler gibi bir görünümde olacaktır. errno değerleri için toplamda ayrılan sayılar da sınırlı olduğu için kontrol kolaylıkla
    yapılabilir. Ancak bu kontrol için IS_ERR isimli inline fonksiyon da bulundurulmuştur. IS_ERR inline fonksiyonu şöyle 
    yazılmıştır:

    static inline long IS_ERR(const void *ptr)
    {
        return (unsigned long)ptr > (unsigned long)-4095;
    }

    Burada fonksiyon adresin "adres alanının son 4095 adresinden biri içerisinde mi" kontrolünü yapmaktadır. Negatif errno 
    değerlerinin hepsi bu aralıktadır. Tabii 4095 errno değeri yoktur. Burada geleceğe uyumu korumak için 4095'lik bir 
    alan ayrılmıştır. Bu durumda çekirdek kodlarında adrese geri dönen fonksiyonların başarısızlığı aşağıdaki gibi kontrol 
    edilebilmektedir.

    void *ptr;

    ptr = foo();
    if (IS_ERR(ptr)) {
        ...
    }

    Linux çekirdeğindeki EXXX sembolik sabitleri POSIX arayüzündeki EXXX sabitleriyle aynı değerdedir.

    Çekirdek kodlarındaki ERR_PTR isimli inline fonksiyon bir tamsayı değeri alıp onu adres türüne dönüştürmektedir. Bu nedenle 
    adrese geri dönen fonksiyonlarda aşağıdaki gibi kodlar görebilirsiniz:

    void *foo(void)
    {
        ...
        if (expression)
            return ERR_PTR(-EXXX);
        ...
    }

    ERR_PTR aşağıdaki gibi tanımlanmıştır:

    static inline void *ERR_PTR(long error)
    {
        return (void *) error;
    }

    Bu işlemin tersi de PTR_ERR inline fonksiyonu ile yapılmaktadır. Yani PTR_ERR bir adresi alıp onu negatif errno değerine 
    dönüştürmektedir. Bu fonksiyon da şöyle tanımlanmıştır:

    static inline long PTR_ERR(const void *ptr)
    {
        return (long) ptr;
    }

    Yani PTR_ERR makrosu bize aslında adres olarak kodlanmış olan negatif errno değerini geri döndürmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Yukarıda ele aldığımız konuyu şöyle özetleyebiliriz:

    1) Bir çekirdek fonksiyonu tamsayı türlerine ilişkin bir değere geri dönüyorsa geri dönüş değerinin negatif olması 
    fonksiyonun başarısı olduğunu gösterir. Bu negatif değerin pozitiflisi errno değerini vermektedir.

    2) Bir çekirdek fonksiyonu bir adrese geri dönüyorsa fonksiyonun başarısı verilen adresin değerine bağlıdır. Eğer verilen 
    adres çok bir büyük bir adresse fonksiyon başarısız olmuştur. Bu kontrol IS_ERR inline fonksiyonuyla yapılmaktadır.

    3) Adrese geri dönen çekirdek fonksiyonu eğer başarısızsa negatif errno değeri PTR_ERR inline fonksiyonuyla elde edilir.

    4) Biz negatif bir errno değerini bir adres gibi geri döndireceksek bunun için ERR_PTR inline fonksiyonunu kullanmalıyız.

    5) Biz de çekirdek modüllerini ve aygıt sürücülerini yazarken çekirdekte uygulanan bu biçime (convention) uymalıyız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bir çekirdek modülünü yazarken o modül ile ilgili önemli bazı belirlemeler "modül makroları" denilen MODULE_XXX biçimindeki 
    makrolarla yapılmaktadır. Her ne kadar bu modül makrolarının bulundurulması zorunlu değilse de şiddetle tavsiye edilmektedir. 
    En önemli üç makronun tipik kullanımı şöyledir:

    MODULE_LICENSE("GPL");
    MODULE_AUTHOR("Kaan Aslan");
    MODULE_DESCRIPTION("General Kernel Module");

    Modül lisansı herhangi bir açık kaynak kod lisansı olabilir. Tipik olarak "GPL" tercih edilmektedir. MODULE_AUTHOR makrosu 
    ile modülün yazarı belirtilir. MODULE_DESCRIPTION modülün ne iş yapacağına yönelik kısa bir başlık yazısı içermektedir.

    Bu makrolar global alanda herhangi bir yere yerleştirilebilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Daha önceden de belirttiğimiz gibi kullanıcı modundaki programlar aygıt sürücülerle dosya sistemi yoluyla iletişim kurmaktadır. 
    Aygıt sürücüler sanki birer dosyaymış gibi açılırlar ve birer dosyaymış gibi işleme sokulurlar. Pekiyi aygıt sürücüleri açmak 
    için yol ifadesi olarak (yani dosya ismi olarak) ne kullanılmaktadır? İşte aygıt sürücüler dosya sisteminde bir dizin girişiyle 
    temsil edilmektedir. O dizin girişi open fonksiyonuyla ile açıldığında aslında o dizin girişinin temsil ettiği aygıt sürücü 
    açılmış olur. Bu biçimdeki aygıt sürücüleri temsil eden dizin girişlerine "aygıt dosyaları (device files)" denilmektedir. 
    Aygıt dosyaları diskte bir dosya belirtmemektedir. Çekirdek içerisindeki aygıt sürücüyü temsil eden bir dizin girişi belirtmektedir. 
    Aygıt dosyalarının i-node tablosunda bir i-node elemanı vardır ancak bu i-node elemanı diskte bir yer değil çekirdekte bir 
    aygıt sürücü belirtmektedir.

    Pekiyi bir aygıt dosyası nasıl yaratılmaktadır ve nasıl bir aygıt sürücüyü temsil eder hale getirilmektedir? İşte her aygıt 
    sürücünün majör ve minör numarası vardır. Bu majör ve minör numarayı aygıt sürücüye erişmek için kullanılan bir adres gibi 
    düşünebilirsiniz. Aynı zamanda aygıt dosyalarının da majör ve minör numaraları vardır. Bir aygıt sürücünün majör ve minör 
    numarası bir aygıt dosyasının majör ve minör numarasıyla aynıysa bu durumda o aygıt dosyası o aygıt sürücüyü temsil eder.
    Yani o aygıt dosyası açıldığında o aygıt sürücüyle iletişim kurulacaktır.

    Aygıt dosyaları özel dosyalardır. Bir dosyanın aygıt dosyası olup olmadığı "ls -l" komutunda dosya türü olarak 'c' (karakter 
    aygıt sürücüsü) ya da 'b' (blok aygıt sürücüsü) ile temsil edilmektedir. Anımsanacağı gibi dosya bilgileri stat, fstat, lstat 
    POSIX fonksiyonlarıyla elde ediliyordu. İşte struct stat yapısının dev_t türünden st_rdev elemanı eğer dosya bir aygıt dosyasıysa 
    dosyanın majör ve minör numaralarını belirtir. Biz de <sys/stat.h> dosyasındaki S_ISCHR ve S_ISBLK makrolarıyla ilgili dosyanın 
    bir aygıt dosyası olup olmadığını öğrenebiliriz.

    Yukarıda da belirttiğimiz gibi aygıt sürücüler "karakter aygıt sürücüleri (character device driver)" ve "blok aygıt sürücüleri
    (block device driver)" olmak üzere ikiye ayrılmaktadır. Karakter aygıt sürücüleri daha yaygın kullanılmaktadır. Biz kursumuzda
    önce karakter aygıt sürücülerini sonra blok aygıt sürücülerini ele alacağız. Blok aygıt sürücüleri tipik olarak disk gibi 
    medyalara erişmek amacıyla kullanılan aygıt sürücülerdir. Bunlar aktarım işlemini blok blok yaparlar. Bu işlemlerin daha 
    etkin gerçekleştirilmesi için çekirdeğin "buffer cache" (ya da yeni ismiyle "page cache") alt sistemleri devreye sokulmaktadır. 
    Karakter aygıt sürücüleri blok blok aktarım yapmayan aygıtlarla iletişim kuran aygıt sürücülerdir. Örneğin seri porttan bilgi 
    okuyan seri porta bilgi yazan aygıt sürücüler karakter aygıt sürücüleridir. Fakat RAM Disk oluşturan aygıt sürücüleri blok
    aygıt sürücüleridir. Karakter aygıt sürücülerinin yazımı blok aygıt sürücülerinden daha kolaydır.

    O halde şimdi bizim bir aygıt dosyasını nasıl oluşturacağımızı ve aygıt sürücüye nasıl majör ve minör numara atayacağımızı 
    bilmemiz gerekir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aygıt dosyaları mknod isimli POSIX fonksiyonuyla (bu fonksiyon Linux'ta doğrudan sys_node isimli sistem fonksiyonunu 
    çağırmaktadır) ya da komut satırından mknod komutuyla (bu komut da mknod fonksiyonu ile işlemini yapmaktadır) yaratılabilir. 
    mknod fonksiyonunun prototipi şöyledir:

    #include <sys/stat.h>

    int mknod(const char *pathname, mode_t mode, dev_t dev);

    Fonksiyonun birinci parametresi yaratılacak aygıt dosyasının yol ifadesini, ikinci parametresi erişim haklarını ve üçüncü 
    parametresi de aygıt dosyasının majör ve minör numaralarını belirtmektedir. Aygıt dosyasının majör ve minör numaraları dev_t 
    türünden tek bir değer ile belirtilmektedir. dev_t türü POSIX standartlarına göre herhangi bir tamsayı türü olabilmektedir. 
    Biz majör ve minör numaraları user mod programlarda makedev isimli makroyla oluştururuz. Bir dev_t türünden değerin içerisinden 
    major numarayı almak için major makrosu, minor numarayı almak için ise minor makrosu bulunmaktadır:

    #include <sys/sysmacros.h>

    dev_t makedev(unsigned int maj, unsigned int min);
    unsigned int major(dev_t dev);
    unsigned int minor(dev_t dev);

    Yani aslında majör ve minör numaralar dev_t türünden bir değerin belli bitlerinde bulunmaktadır. Ancak bu numaraların dev_t 
    türünden değerin hangi bitlerinde bulunduğu sistemden sisteme değişebileceği için bu makrolar kullanılmaktadır.

    Ancak çekirdek dev_t nesnesini oluşturmak için büyük harflerle isimlendirilmiş aşağıdaki makrolar kullanılmaktadır:

    #include <linux/fs.h>

    MKDEV(major, minor)
    MAJOR(dev)
    MINOR(dev)

    Linux'ta son versiyonlar da dikkate alındığında dev_t 32 bitlik işaretsiz bir tamsayı türündendir. Bu 32 bitin yüksek anlamlı 
    12 biti majör numarayı, düşük anlamlı 20 biti ise minör numarayı temsil etmektedir. Ancak programcı bu varsayımlarla 
    kodunu düzenlememeli yukarıda belirtilen makroları kullanmalıdır.

    mknod fonksiyonunun ikinci parametresindeki erişim haklarına aygıt dosyasının türünü belirten aşağıdaki sembolik sabitlerden 
    biri de bit OR operatörü ile eklenmelidir:

    S_IFCHR (Karakter Aygıt Sürücüsü)
    S_IFBLK (Blok Aygıt Sürücüsü)

    Aslında mknod fonksiyonu ile Linux sistemlerinde isimli boru dosyaları, UNIX domain soket dosyaları ve hatta normal dosyalar 
    da yaratılabilmektedir. Bu durumda fonksiyonun aygıt numarasını belirten üçüncü parametresi fonksiyon tarafından dikkate 
    alınmamaktadır. Bu özel dosyalar için erişim haklarına eklenecek makrolar da şunlardır:

    S_IFREG (Disk dosyası yaratmak için)
    S_IFIFO (İsimli boru dosyası yaratmak için)
    S_IFSOCK (UNIX domain soket dosyası yaratmak için)

    Aslında mknod fonksiyonu aygıt dosyaları yaratmak için kullanılıyor olsa da yukarıda belirttiğimiz özel dosyaları da 
    yaratabilmektedir. Tabii zaten isimli boru dosyasını yaratmak için mkfifo fonksiyonu, normal dosyaları yaratmak için 
    open fonksiyonu kullanılabilmektedir.

    mknod fonksiyonu başarı durumunda 0 değerine, başarısızlık durumunda -1 değerine geri dönmektedir.

    Ayrıca mknod POSIX fonksiyonunun mknodat isimli at'li bir versiyonu da bulunmaktadır:

    #include <fcntl.h>

    int mknodat(int fd, const char *path, mode_t mode, dev_t dev);

    Bu at'li versiyon daha önce görmüş olduğumuz at'li fonksiyonlar gibi çalışmaktadır. Yani fonksiyon ilgili dizine ilişkin 
    dosya betimleyicisini ve göreli yol ifadesini parametre olarak alır. O dizinden göreli biçimde yol ifadesini oluşturur. 
    Yine fonksiyonun birinci parametresine AT_FDCWD özel değeri geçilebilir. Bu durumda fonksiyon at'siz versiyondaki gibi 
    çalışır. Diğer at'li fonksiyonlarda olduğu gibi bu fonksiyonun da ikinci parametresindeki yol ifadesi mutlak ise birinci 
    parametresindeki dizin hiç kullanılmamaktadır.

    mknod ve mknodat fonksiyonları prosesin umask değerini dikkate almaktadır. Bu fonksiyonlarla aygıt dosyası yaratabilmek için
    (diğer özel dosyalar için gerekmemektedir) prosesin uygun önceliğe sahip olması gerekmektedir.

    Aşağıdaki aygıt dosyası yaratan mymknode isimli bir fonksiyon yazılmıştır. Fonksiyonun genel kullanımı şöyledir:

    ./mymknod [-m ya da --mode <erişim hakları>] <path> <c ya da b> <majör numara> <minör numara>

    Örnek bir çalıştırma şöyle olabilir:

    $ sudo ./mymknode -m 666 mydriver c 25 0

    Programı sudo ile çalıştırmayı unutmayınız.
-----------------------------------------------------------------------------------------------------------------------------*/

/* mymknod.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdbool.h>
#include <sys/stat.h>
#include <getopt.h>
#include <sys/sysmacros.h>

bool ismode_correct(const char *mode);
void exit_sys(const char *msg);

int main(int argc, char *argv[])		/* ./mymknod [-m <mode>] <path> <type> <major> <minor> */
{
	int m_flag;
	int err_flag;
	char *m_arg;
	int result;
	int mode;
	dev_t dev;

	struct option options[] = {
		{"mode", required_argument, NULL, 'm'},
		{0, 0, 0, 0}
	};

	m_flag = err_flag = 0;

	opterr = 0;
	while ((result = getopt_long(argc, argv, "m:", options, NULL)) != -1) {
		switch (result) {
		case 'm':
			m_flag = 1;
			m_arg = optarg;
			break;
		case '?':
			if (optopt == 'm')
				fprintf(stderr, "option -m or --mode without argument!...\n");
			else if (optopt != 0)
				fprintf(stderr, "invalid option: -%c\n", optopt);
			else
				fprintf(stderr, "invalid long option!...\n");

			err_flag = 1;
			break;
		}
	}
	if (err_flag)
		exit(EXIT_FAILURE);

	if (argc - optind != 4) {
		fprintf(stderr, "wrong number of arguments!...\n");
		exit(EXIT_FAILURE);
	}

	if (m_flag) {
		if (!ismode_correct(m_arg)) {
			fprintf(stderr, "incorrect mode argument!...\n");
			exit(EXIT_FAILURE);
		}
		sscanf(m_arg, "%o", &mode);
	}
	else
		mode = 0644;

	if (argv[optind + 1][1] != '\0') {
		fprintf(stderr, "invalid type argument: %s\n", argv[optind + 1]);
		exit(EXIT_FAILURE);
	}
	if (argv[optind + 1][0] == 'c')
		mode |= S_IFCHR;
	else if (argv[optind + 1][0] == 'b')
		mode |= S_IFBLK;
	else {
		fprintf(stderr, "invalid type argument: %s\n", argv[optind + 1]);
		exit(EXIT_FAILURE);
	}

	dev = makedev(atoi(argv[optind + 2]), atoi(argv[optind + 3]));

	umask(0);
	if (mknod(argv[optind + 0], mode, dev) == -1)
		exit_sys("mknod");

	return 0;
}

bool ismode_correct(const char *mode)
{
	if (strlen(mode) > 3)
		return false;

		while (*mode != '\0') {
		if (*mode < '0' || *mode > '7')
			return false;
		++mode;
	}

	return true;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
    Aslında yukarıda yazdığımız mymknod programının aynısı zaten mknod isimli kabuk komutu biçiminde bulunmaktadır. Bu komutun
    genel biçimi şöyledir:

    sudo mknod [-m ya da --mode <erişim hakları>] <dosya ismi> <c ya da b> <majör numara> <minör numara>

    Örneğin:

    $ sudo mknod mydriver c 25 0

    mknod komutunu sudo ile çalıştırmayı unutmayınız. Yukarıdaki komut uygulandığında oluşturulan dosya şöyle olacaktır:

    crw-rw-rw- 1 root root 25, 0 Mar 29 22:05 mydriver
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												87. Ders 11/03/2025 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bir çekirdek modülünün karakter aygıt sürücüsü haline getirilebilmesi için öncelikle bir aygıt numarasıyla (majör ve minör 
    numara ile) temsil edilip çekirdeğe kaydettirilmesi (register ettirilmesi) gerekmektedir. Bu işlem tipik olarak 
    register_chrdev_region isimli çekirdek fonksiyonuyla yapılır. Fonksiyonun prototipi şöyledir:

    #include <linux/fs.h>

    int register_chrdev_region(dev_t from, unsigned count, const char *name);

    Fonksiyonun birinci parametresi aygıt sürücünün majör ve minör numaralarına ilişkin dev_t türünden değeri almaktadır. Bu 
    parametre için argüman genellikle MKDEV makrosuyla oluşturulmaktadır. MKDEV makrosu majör ve minör numarayı argüman olarak alıp 
    bunlardan dev_t türünden aygıt numarası oluşturmaktadır. Fonksiyonun ikinci parametresi ilk parametrede belirtilen minör numaradan 
    itibaren kaç minör numaranın kaydettirileceğini belirtmektedir. Örneğin biz majör = 20, minör = 0'dan itibaren 5 minör numarayı 
    kaydettirebiliriz. Fonksiyonun son parametresi proc ve sys dosya sistemlerinde görüntülenecek olan aygıt sürücünün ismini 
    belirtmektedir. Çekirdek modüllerinin isimleri çekirdek modül dosyasından gelmektedir. Ancak karakter aygıt sürücülerinin isimlerini 
    biz istediğimiz gibi verebiliriz. Tabii her aygıt sürücü bir çekirdek modülü biçiminde yazılmak zorundadır.

    register_chrdev_region fonksiyonu başarı durumunda 0 değerine, başarısızlık durumunda negatif errno değerine geri dönmektedir. 
    Fonksiyon tipik olarak çekirdek modülünün "init" fonksiyonunda çağrılır. Eğer fonksiyon başarısız olursa init fonksiyonu da 
    bu fonksiyonun geri döndürdüğü değerle geri döndürülür. Örneğin:

    static int __init generic_init(void)
    {
        int result;

        printk(KERN_INFO "generic-char-driver module initialization...\n");

        if ((result = register_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1, "generic-char-driver")) < 0) {
            printk(KERN_ERR "cannot register device!...\n");
            return result;
        }

        return 0;
    }

    Sistemde zaten yüklü olan aynı majör numaraya ilişkin bir aygıt sürücü varsa ya da fonksiyona girilen aygıt numarası geçersiz
    ise fonksiyon başarısız olabilir.

    register_chrdev_region fonksiyonu ile register ettirilmiş olan majör ve minör numaralar unregister_chrdev_region fonksiyonuyla 
    geri bırakılmalıdır. Aksi halde modül çekirdek alanından "rmmod" komutuyla atılsa bile bu aygıt numaraları tahsis edilmiş bir 
    biçimde kalmaya devam edecektir. Bu da önemli sorunlar doğurabilir. unregister_chrdev_region fonksiyonunun prototipi şöyledir:

    #include <linux/fs.h>

    void unregister_chrdev_region (dev_t from, unsigned count);

    Fonksiyonun birinci parametresi aygıt sürücünün register ettirilmiş olan majör ve minör numarasını, ikinci parametresi ise yine 
    o noktadan başlayan kaç minör numaranın unregister ettirileceğini belirtmektedir. Bu fonksiyon da tipik olarak aygıt sürücünün
    cleanup fonksiyonunda (exit fonksiyonunda) çağrılmalıdır. Örneğin:

    static void __exit helloworld_exit(void)
    {
        printk(KERN_INFO "generic-char-driver exit...\n");

        unregister_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1);
    }

    Bir aygıt sürücü register_chrdev_region fonksiyonuyla majör ve minör numarayı register ettirdiğinde artık "/proc/devices" 
    dosyasında bu aygıt sürücü için bir satır yaratılır. Aygıt sürücü unregister_chrdev_region fonksiyonuyla yok edildiğinde 
    "/proc/devices" dosyasındaki satır silinir. Örneğin aygıt sürücümüzü yükledikten sonra "/proc/devices" dosyasının içeriği 
    aşağıdakine benzer görüntülenecektir:

    Character devices:
    1 mem
    4 /dev/vc/0
    4 tty
    4 ttyS
    5 /dev/tty
    5 /dev/console
    5 /dev/ptmx
    5 ttyprintk
    6 lp
    7 vcs
    10 misc
    13 input
    14 sound/midi
    14 sound/dmmidi
    21 sg
    29 fb
    89 i2c
    99 ppdev
    108 ppp
    116 alsa
    128 ptm
    130 generic-char-driver
    136 pts
    ...

    Buradan da görüldüğü gibi aygıt sürücümüz "generic-char-driver" ismiyle 130 majör numaraya sahip olacak biçimde yüklenmiştir.

    Aşağıdaki örnekte çekirdek modülünün init fonksiyonunda register_chrdev_region fonksiyonu Majör = 139, Minor = 1 olacak 
    biçimde bir aygıt numarası çekirdeğe kaydettirilmiştir. Bu kayıt modülün exit fonksiyonunda unregister_chrdev_region fonksiyonu 
    ile silinmiştir. çekirdek modülünü aşağıdaki gibi derleyebilirsiniz:

    $ make file=generic-char-driver

    Modülü install ettikten sonra "/proc/modules" ve "/proc/devices" dosyalarına bakınız. "proc/devices" dosyasında aygıt
    sürücünün belirlediğimiz isimle ve majör numarayla kaydettirildiğini göreceksiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/* generic-char-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>

#define DEV_MAJOR		130
#define DEV_MINOR		0

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("General Character Device Driver");

static int __init generic_init(void)
{
	int result;

	printk(KERN_INFO "generic-char-driver init...\n");

	if ((result = register_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1, "generic-char-driver")) < 0) {
		printk(KERN_ERR "Cannot load generic-char-driver!...\n");
		return result;
	}

	return 0;
}

static void __exit generic_exit(void)
{
	printk(KERN_INFO "generic-char-driver exit...\n");

	unregister_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1);
}

module_init(generic_init);
module_exit(generic_exit);

# Makefile

 obj-m += ${file}.o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi aygıt sürücümüzü belli bir majör ve minör numarayla sisteme register ettirdikten sonra ne yapacağız? İşte aygıt 
    sürücüleri kabaca bir grup fonksiyondan oluşan modüller biçiminde düşünebiliriz. Aygıt sürücü içerisindeki fonksiyonlar 
    kullanıcı modunda bazı işlemler sonucunda çekirdek tarafından çağrılmaktadır. Örneğin:

    - Programcı aygıt sürücüye ilişkin aygıt dosyasını open fonksiyonu ile açtığı zaman aygıt sürücü içerisindeki "open" 
    fonksiyonu çağrılır.

    - Programcı aygıt dosyasından elde ettiği dosya betimleyicisi ile read işlemi yaptığında aygıt sürücü içerisindeki "read" 
    fonksiyonu çağrılır.

    - Programcı aygıt dosyasından elde ettiği dosya betimleyicisi ile write işlemi yaptığında aygıt sürücü içerisindeki "write" 
    fonksiyonu çağrılır.

    - Programcı aygıt dosyasından elde ettiği dosya betimleyicisi ile close işlemi yaptığında aygıt sürücü içerisindeki "close" 
    fonksiyonu çağrılır.

    Buradaki aygıt sürücü içerisindeki open, read, write, close fonksiyonlarına aygıt sürücüyü yazanlar istedikleri ismi verebilmektedir.
    Tabii yukarıda belirtmediğimiz ancak konular içerisinde göreceğimiz başka işlemler sonucunda yine aygıt sürücünün o işlemlere
    ilişkin fonksiyonları çağrılmaktadır. Aynı zamanda aygıt sürücüleri yazanlar dosya işlemleriyle doğrudan ilgili olmayan 
    aygıt sürücü fonksiyonlarına numaralar atayarak onların kullanıcı modundan ioctl isimli POSIX fonksiyonuyla (tabii bu POSIX 
    fonksiyonu da sys_ioctl isimli sistem fonksiyonunu çağırmaktadır) çağrılmasını sağlayabilmektedir. Tabii şüphesiz aygıt sürücü 
    içerisindeki bu fonksiyonlar çekirdek modunda çalıştırılmaktadır. Zaten aygı sürücü yazmanın ana nedenlerinden biri kullanıcı
    modunda yapılamayan işlemlerin çekirdek modunda yapılmasını sağlamak içindir.

    Ancak aygıt sürücüleri yalnızca kullanıcı modundan çekirdek modunda çalışacak fonksiyon çağırma mekanizması olarak düşünmemek 
    gerekir. Aygıt sürücüler birtakım kesmelere o anda yanıt verebilmektedir. Dolayısıyla aynı zamanda onları çekirdek modunda 
    çalışan birer program gibi de düşünebiliriz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bir çekirdek modülü bir aygıt numarasıyla ilişkilendirdikten sonra artık ona gerçek anlamda bir karakter aygıt sürücü kimliğinin 
    kazandırılması gerekir. Bu işlem struct cdev isimli bir yapının içinin doldurularak sisteme eklenmesi (yerleştirilmesi) 
    ile yapılmaktadır. Linux çekirdeği tüm çekirdek modüllerini ve aygıt sürücülerini çeşitli veri yapılarıyla tutmaktadır. Aygıt 
    sürücü yazan programcılar çekirdeğin bu organizasyonunu bilmek zorunda değillerdir. Ancak bazı işlemleri tam gerektiği gibi yapmak 
    zorundadırlar. (Linux çekirdeğinin aygıt sürücü mimarisi oldukça karmaşıktır. Bu konu "Linux Kernel" kursunda ele alınmaktadır.)

    cdev aşağıdaki gibi bir yapıdır:

    #include <linux/fs.h>

    struct cdev {
        struct kobject kobj;
        struct module *owner;
        const struct file_operations *ops;
        struct list_head list;
        dev_t dev;
        unsigned int count;
    };

    Bu türden bir yapı nesnesi programcı tarafından global olarak (statik ömürlü olarak) tanımlanabilir ya da alloc_cdev isimli 
    çekirdek fonksiyonuyla çekirdeğin heap sistemi (slab allocator) kullanılarak dinamik bir biçimde tahsis edilebilir. (İşletim 
    sistemlerinin çekirdeklerinin ayrı bir heap sistemi vardır. Linux çekirdeğinde spesifik türden nesnelerin hızlı tahsis edilmesi 
    için "slab allocator" denilen bir heap sistemi kullanılmaktadır.) Bu yapı nesnesini yerel bir nesne biçiminde oluşturmayınız. 
    Çünkü yerel değişkenler fonksiyon sonlandığında yok edilirler. Halbuki bu yapı nesnesinin aygıt sürücü yüklü olduğu sürece 
    bellekte bulunuyor olması gerekir.

    Eğer cdev türünden bu yapı nesnesi programcı tarafından global bir biçimde tanımlanacaksa yapının elemanlarına ilk değer vermek 
    için cdev_init fonksiyonu çağrılmalıdır. Eğer cdev yapısı cdev_alloc fonksiyonuyla dinamik bir biçimde tahsis edilecekse artık 
    yapı elemanlarına ilkdeğerlerin verilmesi işlemi cdev_init fonksiyonuyla yapılmaz. Çünkü zaten cdev_alloc bu işlemi kendi 
    içerisinde yapmaktadır. Fakat yine de programcının bu durumda manuel olarak yapının bazı elemanlarına değer ataması da 
    gerekmektedir. Bu iki yoldan biriyle oluşturulmuş olan cdev yapı nesnesi cdev_add isimli fonksiyonla çekirdeğin veri yapılarına 
    yerleştirilmelidir. Tabii aygıt sürücü boşaltılırken bu yerleştirme işlemi cdev_del fonksiyonuyla geri alınmalıdır. cdev_del 
    fonksiyonu, struct cdev yapısı cdev_alloc ile tahsis edilmişse aynı zamanda onu free hale de getirmektedir. Özetle çekirdek 
    modülümüzün tam bir karakter aygıt sürücüsü haline getirilmesi için şunlar yapılmalıdır:

    1) struct cdev isimli bir yapı türünden nesne global olarak (statik ömürlü olarak) tanımlanmalı ya da cdev_alloc fonksiyonu ile
    çekirdeğin heap sistemi içerisinde tahsis edilmelidir. Eğer bu nesne global olarak tanımlanacaksa nesneye cdev_init fonksiyonu 
    ile ilkdeğerleri verilmelidir. Eğer nesne cdev_alloc fonksiyonu ile çekirdeğin heap alanında tahsis edilecekse bu durumda ilkdeğer 
    verme işlemi bu fonksiyon tarafından yapılmaktadır. Ancak programcının yine yapının bazı elemanlarını manuel olarak doldurması 
    gerekmektedir.

    2) Oluşturulan bu struct cdev nesnesi cdev_add çekirdek fonksiyonu ile çekirdeğe eklenmelidir.

    3) Çekirdek modülü çekirdek alanından atılırken modülün exit fonksiyonunda cdev_add işleminin geri alınması için cdev_del 
    fonksiyonunun çağrılması gerekmektedir.

    cdev_init fonksiyonunun parametrik yapısı şöyledir:

    #include <linux/cdev.h>

    void cdev_init(struct cdev *cdev, const struct file_operations *fops);

    Fonksiyonun birinci parametresi ilk değer verilecek global cdev nesnesinin adresini alır. İkinci parametre ise file_operations 
    türünden bir yapı nesnesinin adresi almaktadır. file_operations isimli yapı birtakım fonksiyon adreslerinden oluşmaktadır. 
    Yani yapının tüm elemanları birer fonksiyon göstericisidir. Bu yapı kullanıcı modundaki program tarafından ilgili aygıt dosyası 
    açılıp çeşitli işlemler yapıldığında çağrılacak fonksiyonların adreslerini tutmaktadır. Örneğin kullanıcı modundaki program open, 
    close, read, write yaptığında çağrılacak fonksiyonlarımızı burada belirtiriz. file_operations büyük bir yapıdır:

    struct file_operations {
        struct module *owner;
        loff_t (*llseek) (struct file *, loff_t, int);
        ssize_t (*read) (struct file *, char __user *, size_t, loff_t *);
        ssize_t (*write) (struct file *, const char __user *, size_t, loff_t *);
        ssize_t (*read_iter) (struct kiocb *, struct iov_iter *);
        ssize_t (*write_iter) (struct kiocb *, struct iov_iter *);
        int (*iopoll)(struct kiocb *kiocb, bool spin);
        int (*iterate) (struct file *, struct dir_context *);
        int (*iterate_shared) (struct file *, struct dir_context *);
        __poll_t (*poll) (struct file *, struct poll_table_struct *);
        long (*unlocked_ioctl) (struct file *, unsigned int, unsigned long);
        long (*compat_ioctl) (struct file *, unsigned int, unsigned long);
        int (*mmap) (struct file *, struct vm_area_struct *);
        unsigned long mmap_supported_flags;
        int (*open) (struct inode *, struct file *);
        int (*flush) (struct file *, fl_owner_t id);
        int (*release) (struct inode *, struct file *);
        int (*fsync) (struct file *, loff_t, loff_t, int datasync);
        int (*fasync) (int, struct file *, int);
        int (*lock) (struct file *, int, struct file_lock *);
        ssize_t (*sendpage) (struct file *, struct page *, int, size_t, loff_t *, int);
        unsigned long (*get_unmapped_area)(struct file *, unsigned long, unsigned long, unsigned long, unsigned long);
        int (*check_flags)(int);
        int (*flock) (struct file *, int, struct file_lock *);
        ssize_t (*splice_write)(struct pipe_inode_info *, struct file *, loff_t *, size_t, unsigned int);
        ssize_t (*splice_read)(struct file *, loff_t *, struct pipe_inode_info *, size_t, unsigned int);
        int (*setlease)(struct file *, long, struct file_lock **, void **);
        long (*fallocate)(struct file *file, int mode, loff_t offset, loff_t len);
        void (*show_fdinfo)(struct seq_file *m, struct file *f);
    #ifndef CONFIG_MMU
        unsigned (*mmap_capabilities)(struct file *);
    #endif
        ssize_t (*copy_file_range)(struct file *, loff_t, struct file *, loff_t, size_t, unsigned int);
        loff_t (*remap_file_range)(struct file *file_in, loff_t pos_in, struct file *file_out, loff_t pos_out,
                    loff_t len, unsigned int remap_flags);
        int (*fadvise)(struct file *, loff_t, loff_t, int);
    };

    Bu yapının yalnızca bazı elemanlarına atama yapabiliriz. Bunun için gcc eklentilerinden faydalanılabilir. (Bu eklentiler C99 
    ile birlikte C'ye eklenmiştir.) Örneğin:

    static int generic_open(struct inode *inodep, struct file *filp);
    static int generic_release(struct inode *inodep, struct file *filp);

    struct file_operations g_file_ops = {
        .owner = THIS_MODULE,
        .open = generic_open,
        .release = generic_release
    };

    Yapının owner elemanına THIS_MODULE makrosunun atanması iyi bir tekniktir. Biz burada "aygıt sürücümüz open fonksiyonuyla 
    açıldığında generic_open isimli fonksiyon çağrılsın", aygıt sürücümüz close fonksiyonu ile kapatıldığında "generic_release 
    isimli fonksiyonumuz çağrılsın" demiş olmaktayız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												88. Ders 13/03/2025 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirttiğimiz gibi cdev yapısı cdev_alloc fonksiyonuyla dinamik bir biçimde de tahsis edilebilir. cdev_alloc 
    fonksiyonunun prototipi şöyledir:

    #include <linux/cdev.h>

    struct cdev *cdev_alloc(void);

    Fonksiyon başarı durumunda cdev yapısının adresine, başarısızlık durumunda NULL adrese geri dönmektedir. Yukarıda da belirttiğimiz
    gibi cdev yapısı cdev_alloc fonksiyonu ile tahsis edilmişse cdev_init yapılmasına gerek yoktur. Ancak bu durumda programcının 
    manuel olarak yapının owner ve ops elemanlarına değer ataması gerekir. Örneğin:

    struct cdev *g_cdev;
    ...
    if ((gcdev = cdev_alloc()) == NULL) {
        printk(KERN_ERROR "cannot allocate cdev!...\n");
        return -ENOMEM;
    }
    g_cdev->owner = THIS_MODULE;
    g_cdev->ops = &g_file_ops;

    cdev_alloc fonksiyonu başarısız olduğunda bunu çağıran fonksiyonun -ENOMEM değeri ile geri döndürülmesi uygun olur. ENOMEM 
    errno değeri bellek yetersizliği nedeniyle başarısızlık oluştuğunu belirtmektedir. cdev yapı nesnesi başarılı bir biçimde 
    oluşturulduktan sonra artık bu yapının çekirdek modülü içerisine yerleştirilmesi gerekir. Bu da cdev_add fonksiyonuyla 
    yapılmaktadır. cdev_add fonksiyonunun prototipi de şöyledir:

    #include <linux/cdev.h>

    int cdev_add(struct cdev *devp, dev_t dev, unsigned count);

    Fonksiyonun birinci parametresi cdev türünden yapı nesnesinin adresini almaktadır. Fonksiyonun ikinci parametresi aygıt sürücünün 
    majör ve minör numaralarını, üçüncü parametresi ise ilgili minör numaradan itibaren kaç minör numaranın kullanılacağı belirtmektedir.
    Fonksiyon başarı durumunda sıfır değerine, başarısızlık durumunda negatif errno değerine geri döner. Örneğin:

    if ((result = cdev_add(&g_cdev, MKDEV(DEV_MAJOR, DEV_MINOR), 1)) < 0) {
        ...
        return result;
    }

    Aygıt sürücü boşaltılırken cdev_add ile yapılan işlemin geri alınması gerekir. Bu da cdev_del fonksiyonuyla yapılmaktadır. 
    (cdev_alloc işlemi için bunu free hale getiren ayrı bir fonksiyon yoktur. cdev_alloc ile tahsis edilen alan cdev_del fonksiyonu 
    tarafından otomatik olarak free hale getirilmektedir.)

    #include <linux/cdev.h>

    void cdev_del(struct cdev *devp);

    Fonksiyon parametre olarak cdev yapısının adresini almaktadır.

    Buradaki önemli bir nokta şudur: cdev_add fonksiyonu cdev nesnesinin içini çekirdekteki uygun veri yapısına kopyalamamaktadır. 
    Bizzat bu nesnenin adresini kullanmaktadır. Yani çekirdek modülü var olduğu sürece bu cdev nesnesinin de yaşıyor olması gerekir.
    Bu da cdev nesnesinin ve file_operations nesnesinin global biçimde (ya da statik ömürlü biçimde) tanımlanmasını gerektirmektedir.

    Aşağıda bu işlemlerin yapıldığı örnek bir karakter aygıt sürücüsü verilmiştir. Bu aygıt sürücü majör=130, minör=0 aygıtını 
    kullanmaktadır. Dolayısıyla aşağıdaki programın testi için şöyle bir aygıt dosyasının yaratılmış olması gerekir. Yaratımı
    aşağıdaki gibi yapabilirsiniz:

    $ sudo mknod mydriver -m 666 c 130 0

    Bu aygıt sürücü insmod ile yüklendiğinde artık biz kullanıcı modunda "mydriver" dosyasını açıp kapattığımızda file_operations
    yapısına yerleştirdiğimiz generic_open ve generic_release fonksiyonları çağrılacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/* generic-char-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>

#define DEV_MAJOR		130
#define DEV_MINOR		0

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("General Character Device Driver");

static int generic_open(struct inode *inodep, struct file *filp);
static int generic_release(struct inode *inodep, struct file *filp);

static struct cdev g_cdev;
struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = generic_open,
	.release = generic_release
};

static int __init generic_init(void)
{
	int result;

	printk(KERN_INFO "generic-char-driver init...\n");

	if ((result = register_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1, "generic-char-driver")) < 0) {
		printk(KERN_ERR "Cannot load generic-char-driver!...\n");
		return result;
	}

	cdev_init(&g_cdev, &g_fops);
	if ((result = cdev_add(&g_cdev, MKDEV(DEV_MAJOR, DEV_MINOR), 1)) < 0) {
		printk(KERN_ERR "Cannot add device...\n");
		unregister_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1);
		return result;
	}

	return 0;
}

static void __exit generic_exit(void)
{
	printk(KERN_INFO "generic-char-driver exit...\n");

	cdev_del(&g_cdev);
	unregister_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1);
}

static int generic_open(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic_open called...\n");

	return 0;
}

static int generic_release(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic_release called...\n");

	return 0;
}

module_init(generic_init);
module_exit(generic_exit);

# Makefile

 obj-m += ${file}.o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* app.c */

#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <unistd.h>

void exit_sys(const char *msg);

int main(void)
{
	int fd;

	if ((fd = open("mydriver", O_RDONLY)) == -1)
		exit_sys("open");

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
    Yukarıdaki programda biz cdev nesnesini global olarak tanımladık. Aşağıda ise cdev nesnesinin cdev_alloc fonksiyonu ile 
    dinamik biçimde tahsis edilmesine bir örnek veriyoruz. cdev_alloc fonksiyonu ile tahsis edilmiş alanların zaten cdev_del
    fonksiyonu ile geri bırakıldığını belirtmiştik. Ancak cdev_add fonksiyonu başarısız olursa cdev_del fonksiyonunun çağrılması
    anlamsız olacağı için cdev_alloc fonksiyonu ile tahsis edilmiş olan alan kfree fonksiyonuyla serbest bırakılmıştır. kfree
    fonksiyonu çekirdek heap sistemine ilişkin genel bir bir fonksiyondur. Çekirdek heap sistemine "dilimli tahsisat sistemi 
    (slab allocator)" denilmektedir. Bu konu ileride ele alınacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/* generic-char-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>
#include <linux/slab.h>

#define DEV_MAJOR		130
#define DEV_MINOR		0

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("General Character Device Driver");

static int generic_open(struct inode *inodep, struct file *filp);
static int generic_release(struct inode *inodep, struct file *filp);

static struct cdev *g_cdev;
struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = generic_open,
	.release = generic_release
};

static int __init generic_init(void)
{
	int result;

	printk(KERN_INFO "generic-char-driver init...\n");

	if ((result = register_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1, "generic-char-driver")) < 0) {
		printk(KERN_ERR "Cannot load generic-char-driver!..\n");
		return result;
	}

	if ((g_cdev = cdev_alloc()) == NULL) {
		printk(KERN_ERR "cannot allocate cdev!...\n");
		unregister_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1);
		return -ENOMEM;
	}
	g_cdev->owner = THIS_MODULE;
	g_cdev->ops = &g_fops;

	if ((result = cdev_add(g_cdev, MKDEV(DEV_MAJOR, DEV_MINOR), 1)) < 0) {
		printk(KERN_ERR "Cannot add device...\n");
		kfree(g_cdev);
		unregister_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1);
		return result;
	}

	return 0;
}

static void __exit generic_exit(void)
{
	printk(KERN_INFO "generic-char-driver exit...\n");

	cdev_del(g_cdev);
	unregister_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1);
}

static int generic_open(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic_open called...\n");

	return 0;
}

static int generic_release(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic_release called...\n");

	return 0;
}

module_init(generic_init);
module_exit(generic_exit);

# Makefile

 obj-m += ${file}.o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* app.c */

#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <unistd.h>

void exit_sys(const char *msg);

int main(void)
{
	int fd;

	if ((fd = open("mydriver", O_RDONLY)) == -1)
		exit_sys("open");

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdek kodlarının ve aygıt sürücü kodlarının çekirdek modunda (kernel mode) çalıştığını belirtmiştik. Çekirdeğin bulunduğu
    bellek alanı ile kullanıcı proseslerinin bulunduğu bellek alanı birbirlerinden izole edilmiştir. Daha önceden de belirttiğimiz 
    gibi kullanıcı modunda çalışan prosesler çekirdek alanına erişemezler. Çünkü çekirdek kendisini sayfa tabanlı koruma mekanizması 
    yoluyla sıradan proseslerden korumaktadır. Fakat bazı durumlarda çekirdek alanı alanı kullanıcı proseslerinin bulunduğu kullanıcı 
    alanı arasında veri transferlerinin yapılması gerekebilmektedir. Örneğin sys_read sistem fonksiyonu çekirdek tarafından okunan 
    bilgileri kendisini çağıran prosesin kullanıcı alanına aktarmaktadır. sys_write fonksiyonu ise bunun tersini yapmaktadır. 

    Çekirdek alanı ile kullanıcı alanı arasında memcpy fonksiyonu ile transfer yapmaya çalışmak uygun değildir. Bunun birkaç nedeni 
    vardır. Bu tür transferlerde çekirdek modunda çalışan kodların kullanıcı alanındaki adresin geçerliliğini kontrol etmesi gerekir.
    Aksi takdirde çekirdek modunda geçersiz bir alana kopyalama yapmak sistemin çökmesine yol açabilmektedir. Örneğin biz sys_read 
    sistem fonksiyonu ile dosyadan belirttiğimiz adrese aktarım yapmak isteyelim. Eğer biz kendi prosesimize ilişkin bir adres vermek 
    yerine çekirdeğin çalıştığı alana ilişkin bir adres verirsek tüm sistem çökebilir. İşte sys_read fonksiyonu aktarımı yapmadan önce 
    verilen adresin gerçekten prosesin adres alanı içerisindeki bir adres olup olmadığını kontrol etmektedir. Ayrıca kullanıcı alanına 
    ilişkin prosesin sayfa tablosunun bazı bölümleri o anda RAM'de olmayabilir (yani swap out yapılmış olabilir). Böyle bir durumda 
    işleme devam etmek çekirdek tasarımı bakımından sorun oluşturmaktadır. Eğer böyle bir durum varsa çekirdek kodlarının önce sayfa 
    tablosunu RAM'e geri yükleyip işlemine devam etmesi gerekmektedir.

    İşte yukarıda açıklanan bazı nedenlerden dolayı çekirdek alanı ile kullanıcı alanı arasında aktarım işlemi için özel çekirdek 
    fonksiyonları kullanılmaktadır. Yani biz kullanıcı modunda çalışan programlar ile çekirdek modülümüz arasında aktarımları özel 
    bazı çekirdek fonksiyonlarıyla yapmalıyız. Bu amaçla kullanılan çeşitli çekirdek fonksiyonları ve makroları bulunmaktadır. En temel 
    iki fonksiyon copy_to_user ve copy_from_user fonksiyonlarıdır. Bu fonksiyonların prototipleri şöyledir:

    #include <linux/uaccess.h>

    unsigned long copy_to_user(void *to, const void *from, unsigned len);
    unsigned long copy_from_user(void *to, const void *from, unsigned len);

    Fonksiyonların birinci parametreleri kopyalamanın yapılacağı hedef adresi belirtmektedir. Yani copy_to_user için birinci 
    parametre user alanındaki adres, copy_from_user için birinci parametre çekirdek alanındaki adrestir. İkinci parametre kaynak 
    adresi belirtmektedir. Bu kaynak adres copy_to_user için çekirdek alanındaki adres, copy_from_user için kullanıcı alanındaki 
    adrestir. Son parametre aktarılacak byte sayısını belirtmektedir. Fonksiyonlar başarı durumunda 0 değerine, başarısızlık 
    durumunda aktarılamayan byte sayısına geri dönerler. Çekirdek mod programcılarının bu fonksiyonlar başarısız olursa kendi
    fonksiyonlarını -EFAULT (Bad address) ile geri döndürmesi uygun olur. (Örneğin sys_read ve sys_write fonksiyonlarına 
    biz geçersiz bir user mode adresi verirsek bu sistem fonksiyonları da -EFAULT değeri ile geri dönmektedir. Bu hata kodunun 
    yazısal karşılığı "Bad address" biçimindedir.) Örneğin:

    if (copy_to_user(...) != 0)
        return -EFAULT;

    Bazen kullanıcı alanındaki adresin geçerliliği zaten daha önceden sınanmıştır. Bu durumda yeniden geçerlilik sınaması yapmadan 
    yukarıdaki işlemleri yapan __copy_to_user ve __copy_from_user fonksiyonları kullanılabilir. Bu fonksiyonların parametrik yapıları 
    copy_to_user ve copy_from_user fonksiyonları ile aynıdır. Aralarındaki tek fark ise bu fonksiyonların adres geçerliliğine ilişkin 
    sınama yapmamalarıdır:

    #include <linux/uaccess.h>

    unsigned long __copy_to_user(void *to, const void *from, unsigned len);
    unsigned long __copy_from_user(void *to, const void *from, unsigned len);

    Bazı durumlarda programcı 1 byte, 2 byte, 4 byte, 8 byte'lık verileri transfer etmek isteyebilir. Bu küçük miktardaki verilerin 
    transfer edilmesi için daha hızlı çalışan özel iki makro bulundurulmuştur: put_user ve get_user. Bu makroların parametrik 
    yapısı şöyledir:

    #include <linux/uaccess.h>

    put_user(x, ptr);
    get_user(x, ptr);

    Burada x aktarılacak nesneyi belirtir. (Bu nesnenin adresini programcı almaz, makro içinde bu işlem yapılmaktadır.) ptr 
    ise aktarım adresini belirtmektedir. Aktarım ikinci parametrede belirtilen adresin türünün uzunluğu kadar yapılmaktadır. 
    Başka bir deyişle biz makroya hangi türden nesne verirsek zaten makro o uzunlukta aktarım yapmaktadır.

    Makrolar başarı durumunda 0, başarısızlık durumunda negatif hata koduna geri dönerler. Kullanımları şöyle olabilir:

    if (put_user(...) != 0)
        return -EFAULT;

    Bu makroların da geçerlilik kontrolü yapmayan __put_user ve __get_user isimli versiyonları vardır:

    #include <linux/uaccess.h>

    __put_user(x, ptr);
    __get_user(x, ptr);

    Örneğin biz çekirdek modülümüzdeki 4 byte'lık int bir x nesnesinin içerisindeki bilgiyi puser ile temsil edilen kullanıcı 
    alanındaki adrese kopyalamak isteyelim. Bu işlemi şöyle yaparız:

    int x;
    int *puser;
    ...
    if (put_user(x, puser) != 0)
        return -EFAULT;

    Nihayet kullanıcı alanındaki adresin geçerliliği de access_ok isimli makroyla sorgulanabilmektedir. Makro şöyledir:

    #include <linux/uaccess.h>

    access_ok(type, addr, size);

    Buradaki type sınama geçerliliğinin türünü belirtmektedir. Okuma geçerliliği için bu parametre VERIFY_READ, yazma geçerliliği 
    için VERIFY_WRITE ve hem okuma hem de yazma geçerliliği için VERIFY_READ|VERIFY_WRITE biçiminde girilmelidir. İkinci parametre
    geçerliliği sınanacak adresi ve üçüncü parametre de o adresten başlayan alanın uzunluğunu belirtmektedir. Fonksiyon başarı 
    durumunda sıfır dışı bir değere, başarısızlık durumunda sıfır değerine geri dönmektedir. Örneğin biz kullanıcı alanında puser
    adresiyle başlayan 100 byte'lık alanın yazma bakımından geçerli bir alan olup olmadığını sınamak isteyelim. Bu sınamayı
    çekirdek modülümüzde şöyle yapabiliriz:

    if (access_ok(VERIFY_WRITE, puser, 100)) {		// adres geçerli
        ...
    }
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												89. Ders 18/03/2025 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz şimdiye kadar aygıt dosyası open ile açıldığında ve close ile kapatıldığında aygıt sürücümüz içerisindeki fopen ve release 
    fonksiyonlarımızın çağrılmasını sağladık. Şimdi de aygıt dosyası üzerinde read ve write fonksiyonları uygulandığında aygıt 
    sürücümüzdeki read ve write fonksiyonlarının çağrılması üzerinde duracağız.

    Aygıt dosyası open POSIX ile açılıp read POSIX fonksiyonu ile okunduğunda aygıt sürücümüz içerisinde belirlediğimiz "read" 
    fonksiyonumuz, write POSIX fonksiyonu çağrıldığında da aygıt sürücümüz içerisinde belirlediğimiz write fonksiyonumuz çağrılmaktadır. 
    Bunu sağlamak için file_operations yapısının read ve write elemanlarına çağrılacak fonksiyonların adreslerini girmeliyiz. 
    Karakter aygıt sürücülerinin read ve write fonksiyonlarının prototipleri aşağıdaki gibi olmak zorundadır:

    static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off);
    static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off);

    Aygıt sürücüsü için read ve write fonksiyonları yukarıdaki prototipe uygun bir biçimde tanımlandıktan sonra bunların adresleri 
    aşağıdaki gibi file_operations türünden yapı nesnesinin read ve write elemanlarına atanmalıdır:

    static struct file_operations g_file_ops = {
        .owner = THIS_MODULE,
        .open = generic_open,
        .release = generic_release,
        .read = generic_read,
        .write = generic_write,
    };

    Artık aygıt dosyası üzerinde read POSIX fonksiyonu çağrıldığında aygıt sürücümüzdeki generic_read fonksiyonu, write POSIX 
    fonksiyonu çağrıldığında da aygıt sürücümüzdeki generic_write POSIX fonksiyonu çağrılacaktır.

    Aygıt sürücümüzdeki read ve write fonksiyonlarının birinci parametresi açılmış dosyaya ilişkin struct file nesnesinin adresini 
    belirtir. Bu nesneye "dosya nesnesi (file object)" de denilmektedir.

    Anımsanacağı gibi bir dosya açıldığında çekirdek sys_open fonksiyonunda bir dosya nesnesi (struct file) tahsis edip bu dosya 
    nesnesinin adresini dosya betimleyici tablosundaki bir slota yerleştirip onun indeksini dosya betimleyicisi olarak geri 
    döndürüyordu. İşte bu read ve write fonksiyonlarının birinci parametreleri bu dosya nesnesinin adresini belirtmektedir. 
    Çekirdek açık dosya ilgili her türlü işlemi bu dosya nesnesindeki bilgilerden hareketle yapmaktadır.

    Dosya Betimleyici Tablosu

    0 ---------> Dosya Nesnesi
    1 ---------> Dosya Nesnesi
    2 ---------> Dosya Nesnesi
    3 ---------> Dosya Nesnesi
    4 ---------> Dosya Nesnesi
    5 ---------> Dosya Nesnesi
    ...

    Yukarıda da belirttiğimiz gibi file yapısı içerisinde dosya göstericisinin konumu, dosyanın erişim hakları, referans sayacının 
    değeri, dosyanın açış modu ve açış bayrakları ve başka birtakım bilgiler bulunmaktadır. Linux çekirdeğinin 2.4.30 sürümündeki 
    file yapısı şöyledir:

    struct file {
        struct list_head		f_list;
        struct dentry			*f_dentry;
        struct vfsmount			*f_vfsmnt;
        struct file_operations	*f_op;
        atomic_t				f_count;
        unsigned int			f_flags;
        mode_t					f_mode;
        loff_t					f_pos;
        unsigned long			f_reada, f_ramax, f_raend, f_ralen, f_rawin;
        struct fown_struct		f_owner;
        unsigned int			f_uid, f_gid;
        int						f_error;

        size_t					f_maxcount;
        unsigned long			f_version;

        // needed for tty driver, and maybe others
        void					*private_data;

        // preallocated helper kiobuf to speedup O_DIRECT
        struct kiobuf			*f_iobuf;
        long					f_iobuf_lock;
    };

    Biz burada bilerek sadelik sağlamak için eski bir çekirdeğin file yapısını verdik. Yeni çekirdeklerde buna birkaç eleman daha 
    eklenmiştir. Ancak temel elemanlar yine aynıdır. Biz aygıt sürücümüzün read ve write fonksiyonlarında söz konusu aygıt 
    dosyasının birtakım özelliklerine erişmek istediğimizde bu yapıyı kullanırız.

    Aygıt sürücüdeki read ve write fonksiyonlarının ikinci parametresi kullanıcı alanındaki transfer adresini belirtir. Kullanıcı 
    modunda read POSIX fonksiyonu çağrıldığında aygıt sürücüdeki read fonksiyonunun copy_to_user gibi bir fonksiyonla bu adrese
    transfer yapması gerekir. Benzer biçimde kullanıcı modunda write POSIX fonksiyonu çağrıldığında da aygıt sürücü içerisindeki 
    write fonksiyonunun kullanıcı modundaki bu adresten copy_from_user gibi bir fonksiyonla transfer yapması gerekir. Aygıt 
    sürücüdeki read ve write fonksiyonlarının üçüncü parametreleri okunacak ya da yazılacak byte miktarını belirtmektedir. Son 
    parametre ise dosya göstericisinin konumunu belirtir. Ancak bu parametre file yapısı içerisindeki f_pos elemanının adresi 
    değildir. Çekirdek tarafından aygıt sürücünün read ve write fonksiyonları çağrılmadan önce file yapısı içerisindeki f_pos 
    elemanının değeri başka bir nesneye atanıp o nesnenin adresi read ve write fonksiyonlarına geçirilmektedir. read ve write 
    fonksiyonları sonlandığında çekirdek adresini geçirdiği nesnenin değerini file yapısının f_pos elemanına kendisi yerleştirmektedir.
    Yani aygıt sürücümüzdeki read ve write fonksiyonları içerisinde biz her zaman dosya göstericisinin konumunu bu parametrenin
    gösterdiği nesneden alıp bu parametrenin gösterdiği yerdeki nesneyi güncellemeliyiz.

    Aygıt sürücü içerisindeki read ve write fonksiyonları başarı durumunda transfer edilen byte sayısına, başarısızlık durumunda 
    negatif errno değerine geri dönmelidir.

    Biz aygıt sürücümüz için read ve write fonksiyonlarını yazarken read ve write fonksiyonları içerisinde transfer edilen byte 
    miktarı kadar dosya göstericisini ilerletmemiz gerekir. Bu işlem yukarıda da belirttiğimiz gibi fonksiyonların son parametresi 
    olan off göstericisinin gösterdiği yerin güncellenmesi ile yapılmalıdır. Örneğin n byte transfer edilmiş olsun. Bu durumda 
    dosya göstericisinin konumu aşağıdaki gibi güncellenebilir:

    static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
    {
        ...
        *off += n;
        ...

        return n;
    }

    Yukarıda da belirttiğimiz gibi aygıt sürücünüzün read ve write fonksiyonlarında dosya göstericisini konumlandırmak için 
    file yapısının f_pos elemanını güncellemeyiniz. Dosya göstericisinin konumlandırılması her zaman read ve write fonksiyonlarının 
    son parametresi yoluyla yapılmaktadır. Çekirdeğin dosya göstericisini nasıl güncellediğine ilişkin aşağıdaki gibi bir 
    temsili kod örneği verebiliriz:

    loff_t off;
    ...
    off = filp->f_pos;
    read(filp, buf, size, &off);
    filp->f_pos = off;

    Aşağıdaki örnekte aygıt sürücü için read fonksiyonu yazılmıştır. Bu fonksiyon aslında g_buf isimli dizinin içini dosya 
    gibi vermektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/* generic-char-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>

#define DEV_MAJOR		25
#define DEV_MINOR		0

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("General Character Device Driver");

static int generic_open(struct inode *inodep, struct file *filp);
static int generic_release(struct inode *inodep, struct file *filp);
static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off);
static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off);

static struct cdev g_cdev;
static struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = generic_open,
	.read = generic_read,
	.write = generic_write,
	.release = generic_release
};

static int __init generic_init(void)
{
	int result;

	printk(KERN_INFO "generic-char-driver init...\n");

	if ((result = register_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1, "generic-char-driver")) < 0) {
		printk(KERN_ERR "cannot register device!...\n");
		return result;
	}

	cdev_init(&g_cdev, &g_fops);
	if ((result = cdev_add(&g_cdev, MKDEV(DEV_MAJOR, DEV_MINOR), 1)) < 0) {
		unregister_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1);
		printk(KERN_ERR "cannot add device!...\n");
		return result;
	}

	return 0;
}

static void __exit generic_exit(void)
{
	cdev_del(&g_cdev);
	unregister_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1);

	printk(KERN_INFO "generic-char-driver module exit...\n");
}

static int generic_open(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver opened...\n");

	return 0;
}

static int generic_release(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver closed...\n");

	return 0;
}

static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
{
	printk(KERN_INFO "generic_read called...\n");

	return size;
}

static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off)
{
	printk(KERN_INFO "generic_write called...\n");

	return size;
}

module_init(generic_init);
module_exit(generic_exit);

# Makefile

obj-m += ${file}.o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* app.c */

#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <unistd.h>

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[100];

	if ((fd = open("mydriver", O_RDWR)) == -1)
		exit_sys("open");

	read(fd, buf, 100);
	write(fd, buf, 100);

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de aygıt sürücümüzün read fonksiyonunun gerçekten bir dosyadan okuma yapıyormuş gibi davranmasını sağlayalım. Bunun 
    için dosyamızı temsil eden aşağıdaki gibi global bir dizi kullanacağız:

    static char g_file_buf[] = "01234567890ABCDEFGH";

    Buradaki diziyi sanki bir dosya gibi ele alacağız. Aygıt sürücümüzün read fonksiyonu aşağıdaki gibi olacaktır:

    static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
    {
        size_t esize;
        size_t slen;

        slen = strlen(g_buf);
        esize = *off + size > slen ? slen - *off : size;

        if (copy_to_user(buf, g_buf + *off, esize) != 0)
            return -EFAULT;
        *off += esize;

        return esize;
    }

    Burada önce dosya göstericisinin gösterdiği yerden itibaren size kadar byte'ın gerçekten dizi içerisinde olup olmadığına 
    bakılmıştır. Eğer *off + size değeri bu dizinin uzunluğundan fazlaysa size kadar değer değil slen - *off kadar değer okunmuştur. 
    Aygıt sürücülerin read ve write fonksiyonlarında dosya göstericisinin ilerletilmesi programcının sorumluluğundadır. Bu nedenle 
    okuma işlemi yapıldığında dosya göstericisinin konumu aşağıdaki gibi artırılmıştır:

    *off += esize;

    read fonksiyonunun okunabilen byte sayısına geri döndürüldüğüne dikkat ediniz. copy_to_user fonksiyonu ile tüm byte'lar
    kullanıcı alanına kopyalanamamışsa fonksiyon -EFAULT değeri ile geri döndürülmüştür.
-----------------------------------------------------------------------------------------------------------------------------*/

/* generic-char-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>

#define DEV_MAJOR		130
#define DEV_MINOR		0

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("General Character Device Driver");

static int generic_open(struct inode *inodep, struct file *filp);
static int generic_release(struct inode *inodep, struct file *filp);
static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off);
static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off);

static struct cdev g_cdev;
static struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = generic_open,
	.read = generic_read,
	.write = generic_write,
	.release = generic_release
};
static char g_file_buf[] = "01234567890ABCDEFGH";

static int __init generic_init(void)
{
	int result;

	printk(KERN_INFO "generic-char-driver init...\n");

	if ((result = register_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1, "generic-char-driver")) < 0) {
		printk(KERN_ERR "cannot register device!...\n");
		return result;
	}

	cdev_init(&g_cdev, &g_fops);
	if ((result = cdev_add(&g_cdev, MKDEV(DEV_MAJOR, DEV_MINOR), 1)) < 0) {
		unregister_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1);
		printk(KERN_ERR "cannot add device!...\n");

		return result;
	}

	return 0;
}

static void __exit generic_exit(void)
{
	cdev_del(&g_cdev);
	unregister_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1);

	printk(KERN_INFO "generic-char-driver exit...\n");
}

static int generic_open(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver opened...\n");

	return 0;
}

static int generic_release(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver closed...\n");

	return 0;
}

static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
{
	size_t esize;
	size_t slen;

	slen = strlen(g_file_buf);
	esize = size > slen - *off ? slen - *off : size;

	if (copy_to_user(buf, g_file_buf + *off, esize) != 0)
		return -EFAULT;

	*off += esize;

	return esize;
}

static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off)
{
	printk(KERN_INFO "generic_write called...\n");

	return size;
}

module_init(generic_init);
module_exit(generic_exit);

# Makefile

 obj-m += ${file}.o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* app.c */

#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <unistd.h>

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[4096 + 1];
	ssize_t result;
	unsigned n;

	if ((fd = open("mydriver", O_RDONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("number of bytes to read? ");
		scanf("%u", &n);

		if ((result = read(fd, buf, n)) == -1)
			exit_sys("read");
		if (result == 0)
			break;
		buf[result] = '\0';
		puts(buf);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
    Aygıt sürücü için write fonksiyonu da tamamen read fonksiyonuna benzer biçimde yazılmaktadır. write fonksiyonu içerisinde
    biz kullanıcı modundaki bilgiyi copy_from_user ya da get_user fonksiyonlarıyla alırız. Yine write fonksiyonu da istenilen 
    kadar byte'ın transfer edilememesi durumunda -EFAULT değeri ile, başarılı sonlanmada ise yazılan (çekirdek alanına yazılan) 
    byte miktarı ile geri dönmelidir.

    Aşağıdaki örnekte aygıt sürücü bellekte oluşturulmuş bir dosya gibi davranmaktadır. Aygıt sürücünün taklit ettiği dosya
    en fazla 4096 byte olabilmektedir:

    #define FILE_BUF_SIZE		4096
    ...
    static char g_file_buf[FILE_BUF_SIZE];

    Ancak buradaki FILE_BUF_SIZE bellek dosyasının maksimum uzunluğunu belirtmektedir. Bellek dosyasının gerçek uzunluğu f_fsize 
    nesnesinde tutulmaktadır. Aygıt sürücünün write fonksiyonu aşağıdaki gibi yazılmıştır:

    static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off)
    {
        size_t esize;

        esize = size > FILE_BUF_SIZE - *off ? FILE_BUF_SIZE - *off : size;

        if (esize > 0) {
            if (copy_from_user(g_file_buf + *off, buf, esize) != 0)
                return -EFAULT;
            *off += esize;

            if (*off > g_fsize)
                g_fsize = *off;
        }

        return esize;
    }

    Burada yine dosya göstericisinin gösterdiği yerden itibaren yazılmak istenen byte sayısı FILE_BUF_SIZE değerini aşıyorsa 
    geri kalan miktar kadar yazma yapılmıştır. Dosya göstericisinin yine ilerletildiğine dikkat ediniz. Dosya göstericisinin 
    ilerletilmesi her zaman programcının sorumluluğundadır. Aygıt sürücümüzün read fonksiyonu da şöyledir:

    static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
    {
        size_t esize;

        esize = size > g_fsize - *off ? g_fsize - *off : size;

        if (esize > 0) {
            if (copy_to_user(buf, g_file_buf + *off, esize) != 0)
                return -EFAULT;
            *off += esize;
        }

        return esize;
    }

    Burada da dosya göstericisinin gösterdiği yerden itibaren okunmak istenen byte sayısının g_fsize değerinden büyük olup 
    olmadığına bakılmıştır. Yine dosya göstericisi fonksiyon tarafından güncellenmiştir.

    Programın testi için önce aygıt sürücüye aşağıdaki gibi birtakım byte'ları aktarabilirsiniz:

    $ echo -n "0123456789" | sudo tee mydriver

    Burada -n parametresi '\n' karakterinin dosyaya yazılmasını engellemektedir. Bundan sonra artık yukarıdaki "app.c" programı
    ile testi yapabilirsiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/* generic-char-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>

#define DEV_MAJOR		130
#define DEV_MINOR		0

#define FILE_BUF_SIZE		4096

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("General Character Device Driver");

static int generic_open(struct inode *inodep, struct file *filp);
static int generic_release(struct inode *inodep, struct file *filp);
static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off);
static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off);

static struct cdev g_cdev;
static struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = generic_open,
	.read = generic_read,
	.write = generic_write,
	.release = generic_release
};
static char g_file_buf[FILE_BUF_SIZE];
static size_t g_fsize = 0;

static int __init generic_init(void)
{
	int result;

	printk(KERN_INFO "generic-char-driver init...\n");

	if ((result = register_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1, "generic-char-driver")) < 0) {
		printk(KERN_ERR "cannot register device!...\n");
		return result;
	}

	cdev_init(&g_cdev, &g_fops);
	if ((result = cdev_add(&g_cdev, MKDEV(DEV_MAJOR, DEV_MINOR), 1)) < 0) {
		unregister_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1);
		printk(KERN_ERR "cannot add device!...\n");

		return result;
	}

	return 0;
}

static void __exit generic_exit(void)
{
	cdev_del(&g_cdev);
	unregister_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1);

	printk(KERN_INFO "generic-char-driver exit...\n");
}

static int generic_open(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver opened...\n");

	return 0;
}

static int generic_release(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver closed...\n");

	return 0;
}

static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
{
	size_t esize;

	esize = size > g_fsize - *off ? g_fsize - *off : size;

	if (esize > 0) {
		if (copy_to_user(buf, g_file_buf + *off, esize) != 0)
			return -EFAULT;
		*off += esize;
	}

	return esize;
}

static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off)
{
	size_t esize;

	esize = size > FILE_BUF_SIZE - *off ? FILE_BUF_SIZE - *off : size;

	if (esize > 0) {
		if (copy_from_user(g_file_buf + *off, buf, esize) != 0)
			return -EFAULT;
		*off += esize;

		if (*off > g_fsize)
			g_fsize = *off;
	}

	return esize;
}

module_init(generic_init);
module_exit(generic_exit);

# Makefile

 obj-m += ${file}.o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* app.c */

#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <unistd.h>

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[4096 + 1];
	ssize_t result;
	unsigned n;

	if ((fd = open("mydriver", O_RDONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("number of bytes to read? ");
		scanf("%u", &n);

		if ((result = read(fd, buf, n)) == -1)
			exit_sys("read");
		if (result == 0)
			break;
		buf[result] = '\0';
		puts(buf);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
												90. Ders 20/03/2025 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Kullanıcı modundan aygıt dosyası betimleyicisi ile lseek POSIX fonksiyonu çağrıldığında (bu fonksiyon da sys_lseek sistem 
    fonksiyonu çağırmaktadır) karakter aygıt sürücüsünün file_operations yapısı içerisine yerleştirilen llseek fonksiyonu 
    çağrılmaktadır. llseek fonksiyonun parametrik yapısı şöyledir:

    static loff_t generic_llseek(struct file *filp, loff_t off, int whence);

    Fonksiyonun birinci parametresi dosya nesnesini, ikinci parametresi konumlandırılmak istenen offset'i, üçüncü parametresi 
    ise konumlandırmanın nereye göre yapılacağını belirtmektedir. Bu fonksiyonu gerçekleştirirken programcı file yapısı 
    içerisindeki f_pos elemanını güncellemelidir. whence parametresi lseek fonksiyonundaki (ya da C'nin fseek fonksiyonundaki)
    orijinin belirten parametreyle aynı anlamdadır. Tipik olarak programcı whence parametresini switch içerisine alır. Hedeflenen 
    offset'i hesaplar ve en sonunda file yapısının f_pos elemanına bu hedeflenen offset'i yerleştirir. Hedeflenen offset uygun 
    değilse fonksiyon tipik olarak -EINVAL değeriyle geri döndürülür. Eğer konumlandırma offset'i başarılı ise fonksiyon 
    dosya göstericisinin yeni değerine geri dönmelidir.

    Aşağıda daha önce yapmış olduğumuz bellek dosyası örneğine llseek fonksiyonu da eklenmiştir. Fonksiyon aşağıdaki gibi 
    yazılmıştır:

    static loff_t generic_llseek(struct file *filp, loff_t off, int whence)
    {
        loff_t newpos;

        switch (whence) {
            case 0:
                newpos = off;
                break;
            case 1:
                newpos = filp->f_pos + off;
                break;
            case 2:
                newpos = g_fmem_size + off;
                break;
            default:
                return -EINVAL;
        }

        if (newpos < 0 || newpos > g_fmem_size)
            return -EINVAL;

        filp->f_pos = newpos;

        return newpos;
    }

    Burada önce whence parametresine bakılarak dosya göstericisinin konumlandırılacağı offset belirlenmiştir. Sonra dosya 
    nesnesinin f_pos elemanı güncellenmiştir. Çekirdek kodlarında da kullanıcı modunda kullandığımız SEEK_SET (0), SEEK_CUR (1)
    ve SEEK_END (2) sembolik sabitleri tanımlanmış durumdadır.

    Aşağıdaki örnekte aygıt sürücüyü yükledikten sonra yine onun içerisinde oluşturduğumuz dosyaya komut satırından birşeyler
    yazabilirsiniz:

    $ echo -n "0123456789" | sudo tee mydriver

    Test programında lseek ile konumlandırma yapıp sonra okuma yaptık. Test kodunu değiştirerek lseek fonksiyonunun 
    çalışıp çalışmadığını kontrol edebilirsiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/* generic-char-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>

#define DEV_MAJOR		130
#define DEV_MINOR		0

#define FILE_BUF_SIZE		4096

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("General Character Device Driver");

static int generic_open(struct inode *inodep, struct file *filp);
static int generic_release(struct inode *inodep, struct file *filp);
static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off);
static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off);
static loff_t generic_llseek(struct file *filp, loff_t off, int whence);

static struct cdev g_cdev;
static struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = generic_open,
	.read = generic_read,
	.write = generic_write,
	.llseek = generic_llseek,
	.release = generic_release
};
static char g_file_buf[FILE_BUF_SIZE];
static size_t g_fsize = 0;

static int __init generic_init(void)
{
	int result;

	printk(KERN_INFO "generic-char-driver init...\n");

	if ((result = register_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1, "generic-char-driver")) < 0) {
		printk(KERN_ERR "cannot register device!...\n");
		return result;
	}

	cdev_init(&g_cdev, &g_fops);
	if ((result = cdev_add(&g_cdev, MKDEV(DEV_MAJOR, DEV_MINOR), 1)) < 0) {
		unregister_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1);
		printk(KERN_ERR "cannot add device!...\n");

		return result;
	}

	return 0;
}

static void __exit generic_exit(void)
{
	cdev_del(&g_cdev);
	unregister_chrdev_region(MKDEV(DEV_MAJOR, DEV_MINOR), 1);

	printk(KERN_INFO "generic-char-driver exit...\n");
}

static int generic_open(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver opened...\n");

	return 0;
}

static int generic_release(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver closed...\n");

	return 0;
}

static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
{
	size_t esize;

	esize = size > g_fsize - *off ? g_fsize - *off : size;

	if (esize > 0) {
		if (copy_to_user(buf, g_file_buf + *off, esize) != 0)
			return -EFAULT;
		*off += esize;
	}

	return esize;
}

static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off)
{
	size_t esize;

	esize = size > FILE_BUF_SIZE - *off ? FILE_BUF_SIZE - *off : size;

	if (esize > 0) {
		if (copy_from_user(g_file_buf + *off, buf, esize) != 0)
			return -EFAULT;
		*off += esize;

		if (*off > g_fsize)
			g_fsize = *off;
	}

	return esize;
}

static loff_t generic_llseek(struct file *filp, loff_t off, int whence)
{
	loff_t newpos;

	switch (whence) {
		case 0:
			newpos = off;
			break;
		case 1:
			newpos = filp->f_pos + off;
			break;
		case 2:
			newpos = g_fsize + off;
			break;
		default:
			return -EINVAL;
	}
	if (newpos < 0 || newpos >= g_fsize)
		return -EINVAL;

	filp->f_pos = newpos;

	return newpos;
}

module_init(generic_init);
module_exit(generic_exit);

# Makefile

 obj-m += ${file}.o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* app.c */

#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <unistd.h>

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[4096 + 1];
	ssize_t result;
	unsigned n;

	if ((fd = open("mydriver", O_RDONLY)) == -1)
		exit_sys("open");

	if (lseek(fd, 5, 0) == -1)
		exit_sys("lseek");

	for (;;) {
		printf("number of bytes to read? ");
		scanf("%u", &n);

		if ((result = read(fd, buf, n)) == -1)
			exit_sys("read");
		if (result == 0)
			break;
		buf[result] = '\0';
		puts(buf);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz şimdiye kadarki örneklerimizde aygıt sürücümüzün majör ve minör numarasını baştan belirledik. Bunun en önemli sakıncası 
    belirlediğimiz majör numaralı bir aygıt sürücünün zaten yüklü olarak bulunuyor olmasıdır. Bu durumda aygıt sürücümüz yüklenemeyecektir. 
    Aslında daha doğru bir strateji tersten gitmektir. Yani önce aygıt sürücümüz içerisinde biz boş bir majör numara bulup onu 
    kullanabiliriz. Tabii sonra kullanıcı modundan bu aygıt numarasına ilişkin bir aygıt dosyasını da yaratmamız gerekir.

    Boş bir aygıt numarasını bize veren alloc_chrdev_region isimli bir çekirdek fonksiyonu vardır. Fonksiyonun parametrik yapısı 
    şöyledir:

    int alloc_chrdev_region(dev_t *dev, unsigned baseminor, unsigned count, const char *name);

    Fonksiyonun birinci parametresi aygıt numarasının yerleştirileceği dev_t nesnesinin adresini alır. İkinci ve üçüncü 
    parametreler başlangıç minör numarası ve onun sayısını belirtir. Son parametre ise aygıt sürücüsünün "/proc/devices" dosyasında 
    ve "/sys/module" dizininde görüntülenecek olan ismini belirtmektedir. alloc_chrdev_region fonksiyonu zaten register_chrdev_region 
    fonksiyonunun yaptığını da yapmaktadır. Dolayısıyla bu iki fonksiyondan yalnızca biri kullanılmalıdır. Fonksiyon başarı durumunda 
    0 değerine, başarısızlık durumunda negatif errno değerine geri döner. Örneğin:

    dev_t g_dev;
    ...

    if ((result = alloc_chrdev_region(&g_dev, 0, 1, "generic-char-driver")) != 0) {
        printk(KERN_ERR "cannot register device!...\n");
        return result;
    }

    Aygıt sürücülerin majör numaraları birbirinden farklı olmak zorundadır. Biz kullanılan bir majör numaraya ilişkin kullanılmayan 
    bir numara eşliğinde aygıt sürücümüzü register ettiremeyiz.

    Aygıt sürücümüzde alloc_chrdev_region fonksiyonu ile boş bir majör numara numaranın bulunup aygıt sürücümüzün register 
    ettirildiğini düşünelim. Pekiyi biz bu numarayı nasıl bilip de komut satırından bu numaraya uygun aygıt dosyası yaratacağız? 
    İşte bunun için genellikle izlenen yöntem "/proc/devices" dosyasına bakıp oradan majör numarayı alıp aygıt dosyasını yaratmaktır. 
    Tabii bu manuel olarak yapılabilir ancak bir "shell script" ile otomatize de edilebilir. Aşağıdaki bu işlemi yapan "load" 
    isimli bir "shell script" verilmiştir:

    #!/bin/bash

    module=$1
    mode=666

    /sbin/insmod ./${module}.ko ${@:2} || exit 1
    major=$(awk "\$2 == \"$module\" {print \$1}" /proc/devices)
    rm -f $module
    mknod -m $mode $module c $major 0

    Artık biz bu "load" script'i ile aygıt sürücümüzü yükleyip aygıt dosyamızı yaratabileceğiz. Bu script'i "load" ismiyle yazıp 
    aşağıdaki gibi dosyaya "x" hakkı vermelisiniz:

    $ chmod +x load

    Çalıştırmayı komut satırı argümanı vererek aşağıdaki gibi yapmalısınız:

    $ sudo ./load generic-char-driver

    Burada "load" script'i çalıştırıldığında hem aygıt sürücü çekirdek alanına yüklenmekte hem de yüklenen aygıt sürücünün 
    majör numarasıyla (minör numarası da 0 olacak biçimde) "generic-char-driver" isimli aygıt dosyası yaratılmaktadır. Aygıt 
    sürücünün çekirdek alanından atılması manuel bir biçimde "rmmod" komutuyla yapılabilir. Tabii aynı zamanda bu aygıt sürücü 
    için yaratılan aygıt dosyasının da silinmesi uygun olabilir. Yukarıdaki script'te aygıt dosyası zaten varsa aynı zamanda o 
    dosya silinmektedir. Tabii aygıt dosyasını çekirdek alanından atarak silen ayrı bir "unload" isimli script'i de aşağıdaki 
    gibi yazabiliriz:

    #!/bin/bash

    module=$1

    /sbin/rmmod ./$module.ko || exit 1
    rm -f $module

    Tabii yine bu script dosyasının da "x" hakkına sahip olması gerekmektedir:

    $ chmod +x unload

    "unload" script'ini aşağıdaki gibi çalıştırabilirsiniz:

    $ sudo ./unload generic-char-driver

    Aşağıdaki örnekte alloc_chrdev_region fonksiyonuyla hem boş bir aygıt numarası elde edilip hem de bu aygıt numarası register 
    ettirilmiştir. Yükleme işlemi yukarıdaki "load" script'i ile yapılmalıdır. çekirdek modülünün boşaltılması işlemi manuel 
    olarak ya da "unload" script'i ile yapılabilir. Örneğin:

    $ sudo ./load generic-char-driver
    ...
    $ sudo ./unload generic-char-driver
-----------------------------------------------------------------------------------------------------------------------------*/

/* generic-char-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>

#define FILE_BUF_SIZE		4096

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("General Character Device Driver");

static int generic_open(struct inode *inodep, struct file *filp);
static int generic_release(struct inode *inodep, struct file *filp);
static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off);
static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off);
static loff_t generic_llseek(struct file *filp, loff_t off, int whence);

static dev_t g_dev;
static struct cdev g_cdev;
static struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = generic_open,
	.read = generic_read,
	.write = generic_write,
	.llseek = generic_llseek,
	.release = generic_release
};

static char g_file_buf[FILE_BUF_SIZE];
static size_t g_fsize = 0;

static int __init generic_init(void)
{
	int result;

	printk(KERN_INFO "generic-char-driver init...\n");

	if ((result = alloc_chrdev_region(&g_dev, 0, 1, "generic-char-driver")) < 0) {
		printk(KERN_ERR "cannot register device!...\n");
		return result;
	}

	cdev_init(&g_cdev, &g_fops);
	if ((result = cdev_add(&g_cdev, g_dev, 1)) < 0) {
		unregister_chrdev_region(g_dev, 1);
		printk(KERN_ERR "cannot add device!...\n");

		return result;
	}

	return 0;
}

static void __exit generic_exit(void)
{
	cdev_del(&g_cdev);
	unregister_chrdev_region(g_dev, 1);

	printk(KERN_INFO "generic-char-driver exit...\n");
}

static int generic_open(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver opened...\n");

	return 0;
}

static int generic_release(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver closed...\n");

	return 0;
}

static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
{
	size_t esize;

	esize = size > g_fsize - *off ? g_fsize - *off : size;

	if (esize > 0) {
		if (copy_to_user(buf, g_file_buf + *off, esize) != 0)
			return -EFAULT;
		*off += esize;
	}

	return esize;
}

static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off)
{
	size_t esize;

	esize = size > FILE_BUF_SIZE - *off ? FILE_BUF_SIZE - *off : size;

	if (esize > 0) {
		if (copy_from_user(g_file_buf + *off, buf, esize) != 0)
			return -EFAULT;
		*off += esize;

		if (*off > g_fsize)
			g_fsize = *off;
	}

	return esize;
}

static loff_t generic_llseek(struct file *filp, loff_t off, int whence)
{
	loff_t newpos;

	switch (whence) {
		case 0:
			newpos = off;
			break;
		case 1:
			newpos = filp->f_pos + off;
			break;
		case 2:
			newpos = g_fsize + off;
			break;
		default:
			return -EINVAL;
	}
	if (newpos < 0 || newpos >= g_fsize)
		return -EINVAL;

	filp->f_pos = newpos;

	return newpos;
}

module_init(generic_init);
module_exit(generic_exit);

# Makefile

 obj-m += ${file}.o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* load (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1
mode=666

/sbin/insmod ./${module}.ko ${@:2} || exit 1
major=$(awk "\$2 == \"$module\" {print \$1}" /proc/devices)
rm -f $module
mknod -m $mode $module c $major 0

/* unload (bu satırı dosyaya kopyalamayınız ) */

#!/bin/bash

module=$1

/sbin/rmmod ./${module}.ko || exit 1
rm -f $module

/* app.c */

#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <unistd.h>

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[4096 + 1];
	ssize_t result;
	unsigned n;

	if ((fd = open("generic-char-driver", O_RDONLY)) == -1)
		exit_sys("open");

	if (lseek(fd, 5, 0) == -1)
		exit_sys("lseek");

	for (;;) {
		printf("number of bytes to read? ");
		scanf("%u", &n);

		if ((result = read(fd, buf, n)) == -1)
			exit_sys("read");
		if (result == 0)
			break;
		buf[result] = '\0';
		puts(buf);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
												91. Ders 25/03/2025 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi gelinen noktaya kadar görülmüş olan konular kullanılarak basit bir "boru (pipe)" örneği yapalım. Borular pek çok 
    işletim sisteminde bulunan ve en çok kullanılan "prosesler arası haberleşme (interprocess communication)" yöntemlerinden 
    biridir. Bir proses boruya birtakım byte'ları yazar. Diğeri de o byte'ları yazıldığı sırada okur. Bu yönüyle borular
    çekirdek tarafından organize edilen FIFO kuyruk sistemi gibidir.

    Bizim boru örneğimizde bir proses boruyu yazma modunda açtığında prosesin write fonksiyonuyla yazdıkları aygıt sürücü 
    içerisindeki bir FIFO kuyruk sistemine yazılmaktadır. Diğer proses de read fonksiyonuyla okuma yaptığında aslında bu bu 
    FIFO kuyruk sisteminden okuma yapılmaktadır. Burada yapacağımız gerçekleştirim UNIX/Linux sistemlerindeki "isimli borulara 
    (named pipes)" benzemektedir. Biz bu örneği çeşitli konuları gördükçe geliştireceğiz. Anımsayacağınız gibi UNIX/linux 
    sistemlerindeki boruları kullanırken eğer boru tamamen boşsa karşı taraf boruya en az 1 byte yazana kadar bloke oluşmaktadır. 
    Boru tamamen doluysa yazma sırasında karşı taraf okuma yapıp boruda yazılacak miktar kadar alan açana kadar bloke oluşmaktadır. 
    Ayrıca isimli borularda boruyu bir taraf okuma modunda açmaya çalıştığında diğer taraf boruyu yazma modunda açana kadar, 
    yazma modunda açmaya çalıştığında diğer taraf boruyu okuma modunda açana kadar da bloke oluşmaktadır. Biz bu gerçekleştirimde 
    henüz bloke oluşturmayı görmediğimizden dolayı bu özellikleri sağlamayacağız.

    Boruya ilişkin bir FIFO kuysuk sistemini oluşturabilmek için aşağıdaki nesnelerin tanımlanması gerekmektedir:

    #define PIPE_BUFFER_SIZE		8192

    static unsigned char g_pipebuf[PIPE_BUFFER_SIZE];
    static size_t g_head;
    static size_t g_tail;
    static size_t g_count;

    Burada g_pipebuf FIFO kuyruk sistemi için kullanılacak olan tamponu belirtmektedir. Bu tamponun PIPE_BUFFER_SIZE kadar 
    olduğuna dikkat ediniz. g_head kuyruğun başını, g_tail ise sonunu göstermektedir. Kuyruğa yazan taraf g_tail indeksinden 
    itibaren yazmayı yapar, kuyruktan okuma yapan taraf ise g_head indeksinden itibaren okuma yapar. Tabii bu indeksler dizinin
    sonuna geldiğinde yeniden başa geçirilmelidir. g_count ise kuyrukta kaç byte'ın bulunduğunu belirtmektedir. Başlangıçta 
    g_head, g_tail ve g_count 0 değerindedir. Yani kuyruk boştur.

    Aygıt sürücünün write fonksiyonu şöyle yazılmıştır:

    static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off)
    {
        size_t esize, size1, size2;

        if (g_count == PIPE_BUFFER_SIZE)
            return 0;

        esize = MIN(size, PIPE_BUFFER_SIZE - g_count);
        if (g_tail >= g_head)
            size1 = MIN(esize, PIPE_BUFFER_SIZE - g_tail);
        else
            size1 = esize;
        size2 = esize - size1;

        if (copy_from_user(g_pipebuf + g_tail, buf, size1) != 0)
            return -EFAULT;
        if (size2 != 0)
            if (copy_from_user(g_pipebuf, buf + size1, size2) != 0)
                return -EFAULT;

        g_tail = (g_tail + esize ) % PIPE_BUFFER_SIZE;
        g_count += esize;

        return esize;
    }

    Burada kullanıcı modundaki proses write işlemi yaptığında bizim yazılmak istenen byte'ları copy_from_user fonksiyonu ile 
    alarak g_pipebuf içerisine g_tail indeksinden itibaren yazmamız gerekir. Ancak burada iki durum söz konusudur. Eğer g_tail 
    indeksi g_head indeksinden büyük ya da ona eşitse iki parçalı bir yazım gerekebilir. Ancak eğer g_tail indeksi g_head indeksinden 
    küçükse yazım tek seferde yapılabilir. Biz kodumuzda önce boru tamponunun dolu olup olmadığına baktık:

    if (g_count == PIPE_BUFFER_SIZE)
        return 0;

    Boru tamponu tamamen dolu ise fonksiyonu 0 ile geri döndürdük. Kullanıcı modunda write fonksiyonun geri dönüş değerini 0 
    olarak gören programcı borunun dolu olduğunu anlayacaktır. Biz kodumuzda, yazma işlemi sanki iki parça halinde yapılacakmış 
    gibi bu iki parçanın uzunluklarını elde ettik:

    esize = MIN(size, PIPE_BUFFER_SIZE - g_count);
    if (g_tail >= g_head)
        size1 = MIN(esize, PIPE_BUFFER_SIZE - g_tail);
    else
        size1 = esize;
    size2 = esize - size1;

    Tabii eğer g_tail indeksi g_head indeksinin gerisindeyse burada size2 zaten 0 olacaktır. Ayrıca g_tail indeksi g_head indeksinin
    ilerisinde olduğu halde yazılacak miktar PIPE_BUFFER_SIZE - g_tail miktarından küçük ya da ona eşit ise yine size2 0 olacaktır.
    Kopyalama şöyle yapılmıştır:

    if (copy_from_user(g_pipebuf + g_tail, buf, size1) != 0)
        return -EFAULT;
    if (size2 != 0)
        if (copy_from_user(g_pipebuf, buf + size1, size2) != 0)
            return -EFAULT;

    Tabii bu işlemlerden sonra g_tail artık yeni pozisyonuna çekilmeli ve g_count da yazılan miktar kadar artırılmalıdır:

    g_tail = (g_tail + esize ) % PIPE_BUFFER_SIZE;
    g_count += esize;

    write fonksiyonun başarılı biçimde yazılan byte sayısıyla geri döndüğünü anımsayınız. İsimli borularda aslında yazılmak istenen 
    miktar kadar boruda boş yer yoksa ve blokeli mod söz konusuysa bloke oluştuğunu ancak blokesiz mod söz konusuysa write fonksiyonun 
    başarısız olduğunu ve errno değerinin EAGAIN ile set edildiğini anımsayınız. Bizim buradaki tasarımımız blokesiz mod gibi de 
    değildir. Biz burada eğer boruda yazmak istenilen miktar kadar yer yoksa yazılabilecek kadar bilgiyi boruya yazmayı tercih ettik.

    Aygıt sürücümüzün read fonksiyonu da benzer biçimde yazılabilir:

    static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off)
    {
        size_t esize, size1, size2;

        if (g_count == PIPE_BUFFER_SIZE)
            return 0;

        esize = MIN(size, PIPE_BUFFER_SIZE - g_count);
        if (g_tail >= g_head)
            size1 = MIN(esize, PIPE_BUFFER_SIZE - g_tail);
        else
            size1 = esize;
        size2 = esize - size1;

        if (copy_from_user(g_pipebuf + g_tail, buf, size1) != 0)
            return -EFAULT;
        if (size2 != 0)
            if (copy_from_user(g_pipebuf, buf + size1, size2) != 0)
                return -EFAULT;

        g_tail = (g_tail + esize ) % PIPE_BUFFER_SIZE;
        g_count += esize;

        return esize;
    }

    Buradaki aygıt sürücümüzde şu kusurlar vardır:

    - Aygıt sürücümüzde read/write fonksiyonlarında hiçbir senkronizasyon uygulamadık. Dolayısıyla eş zamanlı işlemlerde boru 
    mekanizması birbirine girebilir. Örneğin iki farklı proses bu boruya aynı anda yazma yaparsa senkronizasyondan kaynaklanan 
    sorunlar oluşabilir.

    - Bu gerçekleştirimimizde ayrıca iki proses de boruyu kapatsa bile borunun içerisindekiler silinmemektedir. Halbuki orijinal 
    isimli borularda prosesler boruyu kapatınca boru içerisindeki tüm bilgiler silinmektedir.

    - Bu gerçekleştirimimizde sistem genelinde tek bir boru yaratılmaktadır. Yani bizim boru aygıt sürücümüz tek bir boru üzerinde 
    işlemler yapmaktadır. Halbuki orijinal isimli borularda programcılar birbirinden bağımsız istedikleri kadar çok isimli 
    boru yaratabilmektedir.

    Aygıt sürücümüzü önce build edip sonra aşağıdaki gibi yüklemelisiniz:

    $ make file=pipe-driver
    $ sudo ./load pipe-driver

    Buradaki boru aygıt sürücüsünü test etmek için "pwriter" ve "preader" isimli iki program yazılmıştır. "pwriter" programı 
    klavyeden (stdin dosyasından) alınan yazıları boruya yazmakta, "preader" ise klavyeden (stdin dosyasından) alınan uzunlukta 
    byte'ı borudan okumaktadır. Test işlemini yaparken boru uzunluğunu azaltabilirsiniz. Biz örneğimizde boru uzunluğunu 
    8192 aldık.
-----------------------------------------------------------------------------------------------------------------------------*/

/* pipe-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>

#define PIPE_BUFFER_SIZE		8192
#define MIN(a, b)	((a) < (b) ? (a) : (b))

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("Pipe Device Driver");

static int generic_open(struct inode *inodep, struct file *filp);
static int generic_release(struct inode *inodep, struct file *filp);
static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off);
static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off);

static dev_t g_dev;
static struct cdev g_cdev;
static struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = generic_open,
	.read = generic_read,
	.write = generic_write,
	.release = generic_release
};

static unsigned char g_pipebuf[PIPE_BUFFER_SIZE];
static size_t g_head;
static size_t g_tail;
static size_t g_count;

static int __init generic_init(void)
{
	int result;

	printk(KERN_INFO "generic-char-driver init...\n");

	if ((result = alloc_chrdev_region(&g_dev, 0, 1, "pipe-driver")) < 0) {
		printk(KERN_ERR "cannot register device!...\n");
		return result;
	}

	cdev_init(&g_cdev, &g_fops);
	if ((result = cdev_add(&g_cdev, g_dev, 1)) < 0) {
		unregister_chrdev_region(g_dev, 1);
		printk(KERN_ERR "cannot add device!...\n");

		return result;
	}

	return 0;
}

static void __exit generic_exit(void)
{
	cdev_del(&g_cdev);
	unregister_chrdev_region(g_dev, 1);

	printk(KERN_INFO "generic-char-driver exit...\n");
}

static int generic_open(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver opened...\n");

	return 0;
}

static int generic_release(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver closed...\n");

	return 0;
}

static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;

	if (g_count == 0)
		return 0;

	esize = MIN(size, g_count);
	if (g_head >= g_tail)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_head);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_to_user(buf, g_pipebuf + g_head, size1) != 0)
		return -EFAULT;
	if (size2 != 0)
		if (copy_to_user(buf + size1, g_pipebuf, size2) != 0)
			return -EFAULT;

	g_head = (g_head + esize) % PIPE_BUFFER_SIZE;
	g_count -= esize;

	return esize;
}

static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;

	if (g_count == PIPE_BUFFER_SIZE)
		return 0;

	esize = MIN(size, PIPE_BUFFER_SIZE - g_count);
	if (g_tail >= g_head)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_tail);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_from_user(g_pipebuf + g_tail, buf, size1) != 0)
		return -EFAULT;
	if (size2 != 0)
		if (copy_from_user(g_pipebuf, buf + size1, size2) != 0)
			return -EFAULT;

	g_tail = (g_tail + esize ) % PIPE_BUFFER_SIZE;
	g_count += esize;

	return esize;
}

module_init(generic_init);
module_exit(generic_exit);

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* load (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1
mode=666

/sbin/insmod ./$module.ko ${@:2} || exit 1
major=$(awk "\$2 == \"$module\" {print \$1}" /proc/devices)
rm -f $module
mknod -m $mode $module c $major 0

/* unload (bu satırı dosyaya kopyalamayınız ) */

#!/bin/bash

module=$1

/sbin/rmmod ./$module.ko || exit 1
rm -f $module

/* pwriter.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	char *str;
	ssize_t result;

	if ((fd = open("pipe-driver", O_WRONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Enter text:");
		fflush(stdout);
		if (fgets(buf, BUFFER_SIZE, stdin) == NULL)
			continue;
		if ((str = strchr(buf, '\n')) != NULL)
			*str = '\0';
		if (!strcmp(buf, "quit"))
			break;
		if ((result = write(fd, buf, strlen(buf))) == -1)
			exit_sys("write");

		if (result > 0)
			printf("%jd bytes written...\n", (intmax_t)result);
		else
			printf("pipe full, try again...\n");
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/* preader.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	int n;
	ssize_t result;

	if ((fd = open("pipe-driver", O_RDONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Number of bytes to read? ");
		scanf("%d", &n);
		if (n == 0)
			break;
		if ((result = read(fd, buf, n)) == -1)
			exit_sys("read");
		if (result == 0) {
			printf("pipe is empty, try again...\n");
			continue;
		}
		buf[result] = '\0';
		printf("%jd bytes read: %s\n", (intmax_t)result, buf);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
												92. Ders 27/03/2025 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aygıt sürücülerimiz içerisindeki fonksiyonlar kullanıcı modundaki proseslerin thread'leri tarafında çalıştırılabilmektedir. 
    Örneğin yukarıdaki boru örneğinde bir prosesteki bir thread write POSIX fonksiyonuyla bu aygıt sürücümüzün write fonksiyonunun 
    çalıştırılmasına yol açabilir. Tam o sırada tesadüfen başka bir prosesin başka bir thread'i de yine write POSIX fonksiyonuyla 
    aygıt sürücümüzün write fonksiyonun çalıştırılmasına yol açabilir. Böylece aygıt sürücümüzün write fonksiyonun kodları birden 
    fazla akış tarafından iç içe çalıştırılmış olacaktır. İşte bu tür durumlarda eğer birden fazla akış tarafından çalıştırılan 
    kod parçası global birtakım veri yapılarını ve nesneleri kullanıyorsa onların karalı durumunu bozabilir. Bu da aygıt sürücünün
    hatalı çalışmasına ya da tüm sistemin çökmesine yol açabilir. Örneğin aygıt sürücümüz içerisindeki bir kodun bir diziye 
    insert işlemi yaptığını düşünelim:

    xxxxxxxxxxxxxxxxxxxx
          ^

    Burada aygıt sürücümüz içerisindeki kod dizinin işaretlenmiş noktasına bir insert işlemi yapacak olsun. Bu insert işlemi 
    için bizim bu diziye o noktadan sağa doğru açmamız (expand işlemi) gerekir:

    xxxxxx xxxxxxxxxxxxxx
          ^

    Bu açım da bir döngü içerisinde yapılacaktır. İşte bu açım iki farklı prosesin akışları tarafından tesadüfen aynı zaman 
    dilimi içerisinde yapılırsa bu dizi bozulacaktır. Bunun sonucu olarak da ya kod istenildiği gibi çalışmayacak ya da çökmeler
    oluşacaktır. Aslında bu akışların iç içe geçme durumu bir global değişkenin değerinin artırılması gibi basit bir işlemde 
    bile sorunlara yol açabilmektedir. Örneğin:

    int g_count;

    ...
    ...
    ++g_count;
    ...
    ...

    Burada aygıt sürücümüz içerisindeki bir fonksiyon (örneğin aygıt sürücümüzün read ya da write fonksiyonu) bu g_count değerini 
    1 artırmaktadır. Normal olarak bu kod parçası iki farklı akış tarafından işletildiğinde toplamda bu g_count değeri 2 artmış 
    olmalıdır. Ancak burada bir sorun vardır. Derleyiciler bu tür artırımları tek bir makine komutu ile yapmak zorunda değildir. 
    Örneğin 32 bit Intel işlemcileri bu artırımı tipik olarak 3 makine komutuyla yaparlar:

    MOV EAX, g_count
    INC EAX
    MOC g_count, EAX

    İşte iki akış iç içe geçtiğinde burada bile sorun oluşabilir. Örneğin:

    MOV EAX, g_count
    ----> ikinci akış
    INC EAX
    ----> birinci akış
    MOC g_count, EAX

    Burada aslında g_count iki kez artırılmak yerine iç içe geçmeden dolayı bir kez artırılacaktır. Buradaki g_count nesnesinin
    kuyruktaki eleman sayısını belirttiğini düşünelim. Bu kodda kuyruğa eleman ekleyen kısım olsun. Bu durumda aslında kuyruğa 
    iki eleman eklendiği halde g_count 1 artırılmış olacaktır. Dolayısıyla bütün kuyruk mekanizması bozulacak belki de bundan 
    tüm sistem etkilenecektir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi aygıt sürücümüz içerisindeki hangi kod parçaları iç içe çalışma bakımından potansiyel bir tehlike oluşturmaktadır?
    Bir fonksiyon hiçbir paylaşılan kaynağa erişmiyorsa yalnızca kendi yerel değişkenlerini kullanıyorsa bu fonksiyonun bir
    sorun yaratma olasılığı yoktur. Çünkü aygıt sürücü içerisindeki fonksiyonlar çağrılırken kullanıcı modundaki prosesler 
    farklı stack kullanmaktadır. Dolayısıyla yerel değişkenler de stack'te yaratıldığı için aslında bu akışlar yerel değişkenlerin
    farklı kopyalarını kullanıyor durumdadır. Örneğin:

    void foo(void)
    {
        int i = 0;

        ...
        ++i;
        ...
        ++i;
        ...
        ++i;
        ...
    }

    Buradaki foo fonksiyonunun birden fazla akış tarafından işletilmesi bir soruna yol açmaz. Çünkü aslında her akış buradaki 
    yerel i değişkeninin farklı bir kopyasını kullanıyor durumdadır. Fakat örneğin:

    int g_i = 0;

    void foo(void)
    {
        ...
        ++g_i;
        ...
        ++g_i;
        ...
        ++g_i;
        ...
    }

    Burada g_i değişkeni global olduğu için ve global değişkenlerin toplamda tek bir kopyası olduğu için farklı akışlar 
    bu fonksiyonu çalıştırdığında sorunlar ortaya çıkabilir. İşte genel olarak "paylaşılan (sharable)" bir kaynağa erişim 
    bir senkronizasyon problemi oluşturma potansiyeline sahiptir. Örneğin global nesneler, static yerel nesneler, global veri 
    yapıları, birtakım donanım aygıtları paylaşılan kaynaklara örnek olarak verilebilir. Aslında genellikle (fakat her zaman 
    değil) birden fazla akışın paylaşılan bir kaynağa okuma yapma amaçlı erişimi bir soruna yol açmamaktadır. İki akış üzerinde
    bu durumu şöyle açıklayabiliriz:

    Akış-1          Akış-2          Paylaşılan Kaynağın Durumu
    Okuma           Okuma           Bozulma Olmaz
    Okuma           Yazma           Bozulma Olabilir
    Yazma           Okuma           Bozulma Olabilir
    Yazma           Yazma           Bozulma Olabilir

    Özetle n tane akışın paylaşılan bir kaynağa eş zamanlı erişmesi durumunda eğer bu n tane kaynağın hepsi bu paylaşılan kaynağa 
    okuma amaçlı erişiyorsa bir sorun oluşmamaktadır. Ancak bu n akışın en az biri yazma amaçlı erişiyorsa burada sorun oluşma
    potansiyeli vardır.

    İşte aygıt sürücüleri yazanlar bu durumu dikkate alıp kendi kodlarının içerisinde gerekli önlemleri almalıdırlar.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    İşletim sistemleri dünyasında ve çok akışlı programlamada başından sonuna kadar tek bir akış tarafından işletilmesi gereken
    kodlara "kritik kodlar (critical sections)" denilmektedir. Bir akış kritik koda girdiğinde başka bir bakış kritik koda 
    girmemeli ancak diğer akış kritik kodda çıkınca girmelidir. Örneğin:

    ...
    ...
    ...    KRİTİK KOD
    ...
    ...

    Burada kritik koda bir akış girdiğinde başka akışlar kritik koda girmemelidir. Ta ki girmiş olan akış kritik koddan çıkana
    kadar.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Pekiyi kritik kodlar nasıl oluşturulabilir? Kritik kodların oluşturulması için özel makine komutları kullanılmaktadır. 
    Intel ve ARM gibi yaygın işlemciler kritik kod oluşturmayı sağlayan özel makine komutlarına sahiptir. Kritik kodlar aşağıdaki
    gibi bir flag mekanizmasıyla oluşturulamazlar:

    int g_flag = 0;
    ...

    while (g_flag == 1)
        ;
    g_flag = 1;
    ...
    ...    KRİTİK KOD
    ...
    g_flag = 0;

    Koddaki mantık şöyledir: Eğer g_flag değişkeni 0 ise kaynak boştadır. Bu durumda döngüden çıkılır ancak kritik koda girmeden 
    g_flag değişkeni 1 yapılarak diğer akışların bekletilmesi sağlanır. Kritik koddan çıkılırken de g_flag değişkeni 0 yapılmıştır. 
    Böylece kritik koddan çıkan akış kilidi açmış olacaktır. Ancak bu mekanizmanın bariz üç problemi vardır:

    1) g_flag = 1 iken kritik koda girmeye çalışan akış bir döngü içerisinde sürekli biçimde kontrol yapacak ve gereksiz bir biçimde 
    CPU zamanı harcayacaktır. Bu tür döngülere işletim sistemleri terminolojisinde "meşgul döngüler (busy loops)" denilmektedir.

    2) Koddaki ikinci sorun farklı işlemcilerde ya da çekirdeklerde çalışan iki farklı kodun aynı anda döngüden çıkabilmesidir. 
    Tabii bu çok işlemcili ya da çok çekirdekli sistemlerde söz konusu olabilir.

    while (g_flag == 1)
        ;
    ----> Farklı çekirdeklerdeki kodlar burayı tesadüfen birlikte geçebilirler
    g_flag = 1;
    ...
    ...    KRİTİK KOD
    ...
    g_flag = 0;

    3) Linux çekirdekleri 2.6 versiyonuyla birlikte preemptive hale getirilmiştir. Dolayısıyla kullanıcı modundaki bir thread 
    çekirdek moduna geçip çalışırken quanta süresini bitirdiğinde thread'ler arası geçiş olabilir. Bu geçiş eğer tesadüfen 
    döngüden çıkıldığında gerçekleşirse tek bir işlemci ya da çekirdeğin olduğu ortamda bile kritik koda birden fazla akış 
    girebilir. Örneğin:

    while (g_flag == 1)
        ;
    ----> Tam bu noktada thread'ler arası geçiş olursa başka bir akış da kritik koda girebilir
    g_flag = 1;
    ...
    ...    KRİTİK KOD
    ...
    g_flag = 0;
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux gibi, Windows gibi, macOS gibi preemptive işletim sistemleri zaman paylaşımlı biçimde çalışmaktadır. İşletim sisteminin
    çekirdeği tarafından oluşturulan ismine "çalışma kuyruğu (run queue)" denilen bir kuyruk sistemi vardır. Çalışan thread'ler 
    bu kuyruk sisteminde tutulmaktadır. İşletim sistemi de kuyrukta sırada bekleyen thread'i CPU'ya atar onu belli bir süre çalıştırıp 
    çalışmasına ara vererek kuyruktaki diğer thread'e geçer. Böylece çalışma kuyruğundaki thread'ler aslında kesikli bir biçimde 
    "biraz çalıştırılıp biraz bekletilerek" çalıştırılmaktadır. Bu biçimdeki çalışma sistemine işletim sistemleri dünyasında 
    "zaman paylaşımlı (time sharing)" çalışma denilmektedir. Zaman paylaşımlı çalışma 1950'li yılların sonlarına doğru işletim 
    sistemlerine sokulmuştur. Günümüzde çok prosesli ve çok thread'li işletim sistemlerinin hemen hepsi bu biçimde çalışmaktadır. 
    Çalışma kuyruğu işletim sistemi tarafından bir "bağlı liste (linked list)" biçiminde oluşturulmaktadır. Bunu görsel biçimde 
    şöyle temsil edebiliriz:

    thread-1 ---> thread-2 ---> thread-3 ---> thread-4 ---> [İlk düğümü gösteriyor (thread-1)]

    Tabii bu kuyruk sistemi döngüseldir. İşletim sistemi de buradan thread'leri alarak onu belli sürelerde çalıştırıp kalınan 
    yeri not alarak diğer thread'e geçmektedir. Kullanıcılar sanki programlarını kesiksiz çalışıyor sanabilirler. Ancak aslında 
    programları parçalı bir biçimde çalıştırılmaktadır. Örneğin:

    for (;;) {
        ...
    }

    Programcılar bu kodun CPU verilip sürekli olarak CPU'nun bu for döngüsünü çalıştırdığını sanabilmektedir. Aslında bu kod
    sürekli çalıştırılmamakta durdurulup kalınan yerden devam ettirilip kesikli kesikli çalıştırılmaktadır.

    İşletim sistemleri terminolojisinde bir thread'in parçalı çalışma süresine "quanta süresi (time quantum)" denilmektedir. 
    Bir thread'in çalışmasına ara verilip durumunun kaydedilmesi ve diğer thread'in kaldığı yerden CPU'ya atanmasına "bağlamsal
    geçiş" ya da İngilizcesiyle "context switch" denilmektedir. Eğer ilgili sistemde quanta süresi çok yüksek tutulursa bu 
    durumda interaktivite azalır. Eğer quanta süresi çok düşük tutulursa bu durumda bağlamsal geçiş (context switch) için harcanan 
    zaman thread'lerin harcadığı zaman oranla büyür, birim zamanda yapılan iş miktarı (throughput) düşer. Linux sistemlerinde 
    thread'e ayrılan quanta süresi thread önceliğine göre, "nice değerine" göre değişebilmektedir. Günümüz bilgisayarlarında 
    ortalama 60 ms gibi bir quanta süresi pek çok genel amaçlı sistem için uygun bir süredir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												93. Ders 08/04/2025 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çok prosesli ve çok thread'li preemptive işletim sistemlerinde en önemli kavramlardan biri de "thread'in bloke olması 
    (blocking)" denilen kavramdır. Bir thread'in bloke olması onun geçici olarak çalışma kuyruğundan (run queue) çıkartılıp 
    "bekleme kuyruğu (wait queue)" denilen bir kuyrukta bekletilmesi anlamına gelmektedir. İşletim sistemi bir thread'i CPU'ya 
    atadığı zaman o thread kendisine ayrılan quanta süresini sonuna kadar kullanmak zorunda değildir. Thread'ler uzun zaman 
    alabilecek dışsal bir olayı beklemeye başladığında işletim sistemi tarafından geçici olarak çalışma kuyruğundan çıkartılıp 
    bekleme kuyruğu denilen bir kuyruk sisteminde bekletilmektedir. İlgili olay gerçekleştiğinde yine işletim sistemi tarafından 
    thread bekleme kuyruğundan çıkartarak yeniden çalışma kuyruğuna yerleştirmektedir. Örneğin bir thread klavyeden (stdin dosyasından) 
    bir okuma yapacak olsun. Bu durumda işletim sistemi thread'i çalışma kuyruğundan çıkartıp bekleme kuyruğuna yerleştirir. 
    Böylece thread olayın gerçekleşmesini CPU zamanı harcamadan pasif bir biçimde bekler. Kullanıcı klavyeden tuşa bastığında 
    işletim sistemi bunu fark eder, bekleme kuyruğundaki thread'i yeniden çalışma kuyruğuna yerleştirir. Burada kullanıcı açısından 
    değişen hiçbir şey olmamaktadır. Kullanıcı klavyeden tuşa bastığında programın devam ettiğini düşünür. Buradaki bütün mesele 
    beklemenin CPU zamanı harcamadan yapılmasıdır. Örneğin işletim sistemlerindeki akışı belli bir süre bekletmek için kullanılan 
    sleep fonksiyonları da blokeye yol açmaktadır. Programın akışı sleep fonksiyonuna girdiğinde işletim sistemi thread'i çalışma 
    kuyruğundan çıkartıp bekleme kuyruğuna alır. sleep ile belirlenen süre dolduğunda da thread'i yeniden bekleme kuyruğundan 
    çıkartıp çalışma kuyruğuna yerleştirir. Yani bekleme pasif bir biçimde CPU zamanı harcanmadan sağlanmaktadır.

    Bir thread kendisine verilen quanta süresini büyük ölçüde kullanıyorsa bu tür thread'lere "CPU yoğun (CPU bound)" thread'ler 
    denilmektedir. Örneğin bir döngü içerisinde hiç IO işlemi yapmadan yalnızca matematiksel hesap yapan bir thread kendisine 
    verilen quanta süresini sonuna kadar kullanacaktır. CPU yoğun thread'ler sistemi yavaşlatma potansiyeline sahiptir. Ancak bir 
    thread kendisine verilen quanta süresinin çok azını kullanıp hemen bloke oluyorsa bu tür thread'lere de "IO yoğun (IO bound)"
    thread'ler denilmektedir. Örneğin:

    for (;;) {
        scanf("%d", val);
        printf("%d\n", val * val);
    }

    Bu for döngüsü IO yoğun bir thread'e ilişkindir. Bu thread çok az CPU zamanı kullanacaktır. Bu biçimde yüzlerce thread'in 
    olması bile sistemi yormayacaktır. Aslında programların büyük çoğunluğu IO yoğun biçimdedir. Bu nedenle sistemi yormamaktadır.

    Pekiyi işletim sisteminde toplamda bir tane mi bekleme kuyruğu vardır? İşte aslında işletim sistemleri her olay için 
    o olaya özgü ayrı bir bekleme kuyruğu oluşturmaktadır. Dolayısıyla sistemde pek çok farklı bekleme kuyrukları vardır. 
    Her kuyruk belli bir olayı bekleyen thread'leri barındırır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çok işlemcili ya da çok çekirdekli sistemlerde zaman paylaşımlı çalışma benzer biçimde yürütülür. Genellikle işletim sistemleri 
    her CPU ya da çekirdek için ayrı bir çalışma kuyruğu oluşturmaktadır. Örneğin sistemimizde 4 çekirdek varsa 4 farklı çalışma 
    kuyruğu vardır. Bizim thread'imiz de bu çalışma kuyruklarının herhangi birinde bulunabilir. Ancak yine o kuyrukta sırası 
    geldiğinde çalışacaktır. Bu durumu bir süpermarkette tek kasa yerine 4 kasanın olduğu duruma benzetebiliriz. Yine müşteri
    bekler ancak kuyruklar tek kasa durumuna göre daha kısa olduğundan daha az beklemiş olur. Tabii süpermarketlerde de şöylesi 
    durumlarla hepimiz karşılaşmışızdır: Biz en az müşterinin olduğu kuyruğa girdiğimiz halde süreç umduğumuz gibi ilerlememiş 
    ve diğer kuyruklar bizimkinden daha hızla işlem görerek kısalmış olabilir. Bu tür durumlarda biz kendi kuyruğumuzu bırakıp 
    diğer kısalmış olan diğer kuyruğa geçmeyi tercih ederiz. İşte aynı durum çok işlemcili ya da çok çekirdekli sistemlerde de 
    benzer biçimdedir. İşletim sistemi bir thread'i bir kuyruğa atadığında diğer kuyruklar azalmışsa onu oradan kopartıp diğer 
    kuyruğa transfer edebilmektedir. İşletim sistemlerinin bu işlemleri yapan alt sistemlerine "çizelgeleyici (scheduler)" 
    denilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bizim aygıt sürücüleri yazan kişiler olarak bekleme kuyrukları ile ilgili şu işlemleri yapabilmemiz gerekir:

    1) Yeni bir bekleme kuyruğunun yaratılması ve yok edilmesi
    2) Çalışma kuyruğundan bekleme kuyruğuna thread'in aktarılması
    3) Bekleme kuyruğundan çalışma kuyruğuna thread'in aktarılması

    Örneğin gömülü sistemimize bir düğme (button) yerleştirmiş olalım. İlgili thread'in de kullanıcı düğmeye basılana kadar
    bekletilmesini sağlamak isteyelim. Burada iki yöntem kullanılabilir. Birinci yönteme "yoklama (polling)" yöntemi denilmektedir. 
    Bu yöntemde biz bir döngü içerisinde sürekli bir biçimde "düğmeye basılmış mı" diye bakarız. Ancak bu iyi bir yöntem değildir. 
    Çünkü CPU yoğun bir biçimde meşgul bir döngüde gereksiz CPU zamanının harcanmasına yol açmaktadır. Özellikle gömülü sistemlerde
    böylesi meşgul döngüler önemli bir güç harcanmasına da yol açmaktadır. İkinci yöntemde biz thread'i bloke ederek çalışma 
    kuyruğundan çıkartıp bekleme kuyruğuna yerleştiririz. Düğmeye basıldığında da bir donanım kesmesinin oluşturulmasını sağlarız. 
    Bu kesme oluştuğunda aygıt sürücümüz kesmeye yanıt verir ve bekleme kuyruğundaki thread'i yeniden çalışma kuyruğuna yerleştirir.
    Bu yönteme "kesme (interrupt) yöntemi" de denilmektedir. Tabii bu yöntemi uygulayabilmemiz için bizim bekleme bekleme kuyruklarıyla 
    işlem yapmayı bilmemiz gerekir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdek modunda aygıt sürücü kodları daha önce user mode'da gördüğümüz senkronizasyon nesnelerini kullanamaz. Çünkü daha 
    önce gördüğümüz senkronizasyon nesneleri user mode'dan kullanılsın diye oluşturulmuştur. Çekirdeğin içerisinde kernel 
    mode'dan kullanılabilecek ayrı senkronizasyon nesneleri bulunmaktadır. Bu bölümde aygıt sürücülerin kernel mode'da 
    kullanabileceği senkronizasyon nesnelerini göreceğiz.

    Çekirdek modu için user mode'dakine benzer senkronizasyon nesneleri kullanılmaktadır. Bunların genel çalışma biçimi user 
    mode'dakilere benzemektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Kritik kod oluşturmak için en çok kullanılan nesnelerden biri "mutex (mutual exclusion)" denilen nesnelerdir. UNIX/Linux 
    sistemlerinde kullanıcı modundan kullanılabilecek mutex nesneleri de vardır. Ancak biz burada çekirdeğin içerisinde bulunan 
    aygıt sürücülerimizde kullanabileceğimiz mutex nesneleri üzerinde duracağız.

    Mutex nesneleri Linux çekirdeğine 2.6 versiyonu ile eklenmiştir. Bundan önce mutex işlemleri binary semaphore'larla yapılıyordu. 
    Çekirdeğin mutex mekanizması kullanıcı modundaki mutex mekanizmasına çok benzemektedir. Çekirdek mutex nesnelerinin yine 
    thread temelinde sahipliği vardır. Çekirdek mutex nesneleri thread'i bloke edip onu bekleme kuyruklarında bekletebilmektedir. 

    Mutex mekanizması şöyle işletilmektedir: Önce bir mutex nesnesi yaratılır. Kritik koda girişte bu mutex nesnesinin sahipliği
    ele geçirilmeye çalışılır. Mutex'in sahipliğinin ele geçirilmesine "mutex'in kilitlenmesi (mutex lock)" de denilmektedir. Eğer 
    mutex'in sahipliği ele geçirilirse (yani mutex kilitlenirse) sahiplik bırakılana kadar (yani kilit bırakılana kadar) başka bir 
    thread kritik koda giremez. Mutex'in sahipliğini almaya çalışan thread mutex kilitli ise bloke olarak mutex kilidi açılana kadar 
    bekler. Mutex'in sahipliğini almış olan thread kritik koddan çıkarken mutex'in sahipliğini bırakır (yani mutex'in kilidini açar). 
    Böylece blokede bekleyen thread'lerden biri mutex'in sahipliğini alarak kritik koda girer. Kritik kod tipik olarak şöyle 
    oluşturulmaktadır:

    mutex_lock(...)
    ...
    ...    KRİTİK KOD
    ...
    mutex_unlock(...)

    Thread'lerden biri mutex_lock fonksiyonuna geldiğinde eğer mutex kilitlenmemişse mutex'i kilitler ve kritik koda giriş yapar. 
    Eğer mutex zaten kilitlenmişse mutex_lock fonksiyonunda thread bloke edilir ve bekleme kuyruğuna alınır. Kritik koda girmiş
    olan thread mutex_unlock fonksiyonu ile mutex nesnesinin kilidini bırakır. Böylece nesneyi bekleyen thread'lerden biri nesnenin 
    sahipliğini alarak mutex'i kilitler. Birden fazla thread'in mutex_lock fonksiyonunda bloke edilmesi durumunda mutex'in kilidi 
    açıldığında bunlardan hangisinin mutex kilidini alarak kritik koda gireceği konusunda bir garanti verilmemektedir. (İlk bloke 
    olan thread'in mutex kilidini alarak kritik koda gireceğini düşünebilirsiniz, ancak bunun bir garantisi yoktur.)

    Çekirdekteki mutex mekanizmasının tipik gerçekleştirimi şöyledir:

    1) mutex_lock işlemi sırasında işlemcinin maliyetsiz compare/set (compare/exchange) komutlarıyla mutex'in kilitli olup olmadığına 
    bakılır.
    2) Diğer bir işlemcideki thread mutex'i kilitlemişse boşuna bloke olmamak için yine compare/set komutlarıyla biraz spin 
    işlemi yapılır. Spin işleminin be olduğu izleyen paragraflarda açıklanacaktır.
    3) Spin işleminden sonuç elde edilemezse bloke oluşturulur.

    Çekirdeğin mutex nesneleri tipik olarak şöyle kullanılmaktadır:

    1) Mutex nesnesi mutex isimli bir yapıyla temsil edilmektedir. Sistem programcısı bu yapı türünden global bir nesne yaratır 
    ve ona ilk değerini verir. DEFINE_MUTEX(name) makrosu hem struct mutex türünden nesneyi tanımlamakta hem de ona ilk değerini 
    vermektedir. Örneğin:

    #include <linux/mutex.h>

    static DEFINE_MUTEX(g_mutex);

    Burada biz hem g_mutex isminde bir global nesne tanımlamış olduk hem de ona ilk değer vermiş olduk. Aynı işlem önce nesneyi 
    tanımlayıp sonra mutex_init fonksiyonunun çağrılmasıyla da yapılabilmektedir. Örneğin:

    static struct mutex g_mutex;
    ...
    mutex_init(&g_mutex);

    DEFINE_MUTEX makrosuna nesnenin adresinin verilmediğine dikkat ediniz. Bu makro ve mutex_init fonksiyonunun prototipleri
    <linux/mutex.h> başlık dosyasında bulunmaktadır.

    Her ne kadar mutex_init bir fonksiyon görünümündeyse de aslında çekirdek kodlarında hem bir makro olarak hem de bir fonksiyon 
    olarak bulunmaktadır. Mevcut Linux çekirdeklerinde fonksiyonların makro gerçekleştirimleri aşağıdaki gibidir:

    #define DEFINE_MUTEX(mutexname)						    \
        struct mutex mutexname = __MUTEX_INITIALIZER(mutexname)

    #define mutex_init(mutex)				\
    do {							\
        static struct lock_class_key __key;		\
                                \
        __mutex_init((mutex), #mutex, &__key);		\
    } while (0)

    2) Mutex nesnesini kilitlemek için mutex_lock fonksiyonu kullanılır:

    #include <linux/mutex.h>

    void mutex_lock(struct mutex *lock);

    Mutex'in kilitli olup olmadığı ise mutex_trylock fonksiyonuyla kontrol edilebilir:

    #include <linux/mutex.h>

    int mutex_trylock(struct mutex *lock);

    Eğer mutex kilitliyse fonksiyon bloke olmadan 0 değeriyle geri döner. Eğer mutex kilitli değilse mutex kilitlenir ve fonksiyon
    1 değeri ile geri döner.

    Mutex nesnesi mutex_lock ile kilitlenmek istendiğinde bloke oluşursa bu blokeden sinyal yoluyla çıkılamamaktadır. Örneğin mutex_lock 
    ile çekirdek modunda biz mutex kilidini alamadığımızdan dolayı bloke oluştuğunu düşünelim. Bu durumda ilgili prosese bir sinyal 
    gelirse ve eğer o sinyal için sinyal fonksiyonu set edilmişse thread uyandırılıp sinyal fonksiyonu çalıştırılmamaktadır. Ayrıca 
    bu durumda biz ilgili prosese SIGINT gibi SIGKILL gibi sinyaller göndererek de prosesi sonlandıramayız. İşte eğer mutex'in kilitli 
    olması nedeniyle bloke oluştuğunda sinyal yoluyla thread'in uyandırılıp sinyal fonksiyonunun çalıştırması ya da sinyal fonksiyonu 
    set edilmemişse prosesin sonlandırılması isteniyorsa mutex nesnesi mutex_lock ile değil, mutex_lock_interrupible fonksiyonu 
    ile kilitlenmeye çalışılmalıdır. mutex_lock_interruptible fonksiyonunun prototipi şöyledir:

    #include <linux/mutex.h>

    int mutex_lock_interruptible(struct mutex *lock);

    Fonksiyon eğer mutex kilidini alarak sonlanırsa 0 değerine, bloke olup sinyal dolayısıyla sonlanırsa -EINTR değerine geri dönmektedir. 
    Programcı bu fonksiyonun 0 ile geri dönmediğini ya da -EINTR ile geri döndüğünü tespit ettiğinde ilgili sistem fonksiyonunun yeniden 
    çalıştırılabilirliğini sağlamak için -ERESTARTSYS ile geri dönebilir. Örneğin:

    if (mutex_lock_interruptible(&g_mutex) != 0)
        return -ERESTARTSYS;

    3) Mutex nesnesinin kilidini bırakmak için (nesneyi unlock etmek için) mutex_unlock fonksiyonu kullanılmaktadır:

    void mutex_unlock(struct mutex *lock);

    Bu durumda örneğin tipik olarak aygıt sürücü içerisinde belli bir bölgeyi mutex yoluyla koruma şöyle yapılmaktadır:

    DEFINE_MUTEX(g_mutex);
    ...

    if (mutex_lock_interruptible(&g_mutex) != 0)
        return -ERESTARTSYS;

    ...
    ...    KRİTİK KOD
    ...

    mutex_unlock(&g_mutex);

    Mutex nesnesini kilitledikten sonra fonksiyonlarınızı geri döndürürken kilidi açmayı unutmayınız.

    Aşağıdaki örnekte yukarıdaki boru aygıt sürücüsü daha güvenli olacak biçimde mutex nesneleriyle senkronize edilmiştir.
-----------------------------------------------------------------------------------------------------------------------------*/

/* pipe-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>
#include <linux/mutex.h>

#define PIPE_BUFFER_SIZE		8192
#define MIN(a, b)	((a) < (b) ? (a) : (b))

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("Pipe Device Driver");

static int generic_open(struct inode *inodep, struct file *filp);
static int generic_release(struct inode *inodep, struct file *filp);
static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off);
static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off);

static dev_t g_dev;
static struct cdev g_cdev;
static struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = generic_open,
	.read = generic_read,
	.write = generic_write,
	.release = generic_release
};

static unsigned char g_pipebuf[PIPE_BUFFER_SIZE];
static size_t g_head;
static size_t g_tail;
static size_t g_count;

static DEFINE_MUTEX(g_mutex);

static int __init generic_init(void)
{
	int result;

	printk(KERN_INFO "generic-char-driver init...\n");

	if ((result = alloc_chrdev_region(&g_dev, 0, 1, "pipe-driver")) < 0) {
		printk(KERN_ERR "cannot register device!...\n");
		return result;
	}

	cdev_init(&g_cdev, &g_fops);
	if ((result = cdev_add(&g_cdev, g_dev, 1)) < 0) {
		unregister_chrdev_region(g_dev, 1);
		printk(KERN_ERR "cannot add device!...\n");

		return result;
	}

	return 0;
}

static void __exit generic_exit(void)
{
	cdev_del(&g_cdev);
	unregister_chrdev_region(g_dev, 1);

	printk(KERN_INFO "generic-char-driver exit...\n");
}

static int generic_open(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver opened...\n");

	return 0;
}

static int generic_release(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver closed...\n");

	return 0;
}

static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;
	ssize_t result = -EFAULT;

	if (mutex_lock_interruptible(&g_mutex) != 0)
		return -ERESTARTSYS;

	if (g_count == 0) {
		result = 0;
		goto EXIT;
	}

	esize = MIN(size, g_count);
	if (g_head >= g_tail)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_head);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_to_user(buf, g_pipebuf + g_head, size1) != 0)
		goto EXIT;

	if (size2 != 0)
		if (copy_to_user(buf + size1, g_pipebuf, size2) != 0)
			goto EXIT;

	g_head = (g_head + esize) % PIPE_BUFFER_SIZE;
	g_count -= esize;

	result = esize;
EXIT:
	mutex_unlock(&g_mutex);

	return result;
}

static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;
	ssize_t result = -EFAULT;

	if (mutex_lock_interruptible(&g_mutex) != 0)
		return -ERESTARTSYS;

	if (g_count == PIPE_BUFFER_SIZE) {
		result = 0;
		goto EXIT;
	}

	esize = MIN(size, PIPE_BUFFER_SIZE - g_count);
	if (g_tail >= g_head)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_tail);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_from_user(g_pipebuf + g_tail, buf, size1) != 0)
		goto EXIT;
	if (size2 != 0)
		if (copy_from_user(g_pipebuf, buf + size1, size2) != 0)
			goto EXIT;

	g_tail = (g_tail + esize ) % PIPE_BUFFER_SIZE;
	g_count += esize;

	result = esize;

EXIT:
	mutex_unlock(&g_mutex);

	return esize;
}

module_init(generic_init);
module_exit(generic_exit);

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* load (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1
mode=666

/sbin/insmod ./$module.ko ${@:2} || exit 1
major=$(awk "\$2 == \"$module\" {print \$1}" /proc/devices)
rm -f $module
mknod -m $mode $module c $major 0

/* unload (bu satırı dosyaya kopyalamayınız ) */

#!/bin/bash

module=$1

/sbin/rmmod ./$module.ko || exit 1
rm -f $module

/* pwriter.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	char *str;
	ssize_t result;

	if ((fd = open("pipe-driver", O_WRONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Enter text:");
		fflush(stdout);
		if (fgets(buf, BUFFER_SIZE, stdin) == NULL)
			continue;
		if ((str = strchr(buf, '\n')) != NULL)
			*str = '\0';
		if (!strcmp(buf, "quit"))
			break;
		if ((result = write(fd, buf, strlen(buf))) == -1)
			exit_sys("write");
		if (result > 0)
			printf("%jd bytes written...\n", (intmax_t)result);
		else
			printf("pipe full, try again...\n");
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/* preader.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	int n;
	ssize_t result;

	if ((fd = open("pipe-driver", O_RDONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Number of bytes to read? ");
		scanf("%d", &n);
		if (n == 0)
			break;
		if ((result = read(fd, buf, n)) == -1)
			exit_sys("read");
		if (result == 0) {
			printf("pipe is empty, try again...\n");
			continue;
		}
		buf[result] = '\0';
		printf("%jd bytes read: %s\n", (intmax_t)result, buf);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
												94. Ders 10/04/2025 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çok kullanılan diğer bir senkronizasyon nesnesi de "semaphore" denilen nesnedir. Semaphore'lar sayaçlı senkronizasyon
    nesneleridir. Semaphore'lar ilk kez Edsger Dijkstra tarafından bulunmuştur. Bugün neredeyse tüm işletim sistemlerinde 
    kullanıcı modunda ve çekirdek modunda kullanılmaktadır. UNIX/Linux sistemlerinde de kullanıcı modunda kullanılabilen 
    semaphore nesneleri vardır. Ancak biz burada aygıt sürücülerde de kullanılan çekirdeğin içerisindeki semaphore nesneleri 
    üzerinde duracağız.

    Semaphore'lar bir kritik koda en fazla n tane akışın girmesine olanak sağlamaktadır. Örneğin buradaki n değerinin 3 olduğunu
    düşünelim. Bu durumda birinci thread semaphore'dan geçer ve kritik koda girer. İkinci thread da semaphore'dan geçip geçip 
    kritik koda girer. Şimdi kritik kodda iki thread bulunmaktadır. Üçüncü thread de semaphore'dan geçerek kritik koda girebilir. 
    Şimdi kritik kodda üç thread bulunmaktadır. Artık dördüncü bir thread kritik koda girmek isterse bloke oluşur ve bu thread
    bekleme kuyruklarına alınarak bekletilir. Beşinci thread de benzer biçimde semaphore'dan geçemeyecek ve bloke olacaktır. 
    Şimdi kritik koda girmiş olan thread'lerden birinin kritik koddan çıktığını düşünelim. Şimdi kritik iki thread bulunmaktadır. 
    İşte bloke edilmiş olan thread'lerden biri kritik koda girebilir. Böylece kritik kod içerisinde yine en fazla 3 thread 
    bulunmaktadır. Tıpkı mutex nesnelerinde olduğu gibi bu durumda blokede bekleyen hangi thread'in kritik koda gireceği 
    hakkında bir garanti verilmemektedir. (Yani ilk bloke thread'in kritik koda gireceğinin bir garantisi yoktur.)

    Semaphore'larda N sayısı 1 ise bu durumda kritik koda en fazla tek bir thread girebilir. Böyle semaphore'lara "ikili semaphore'lar
    (binary semaphores)" denilmektedir. İkili semaphore'lar kullanım amacı bakımından mutex nesnelerine oldukçe benzemektedir. 
    (Ancak ikili semaphore'lar mutex nesneleriyle tamamen aynı işlevselliği sunmazlar.)

    Yukarıda da belirttiğimiz gibi bir kritik koda iki akışın bile girmesi paylaşılan kaynağı bozabilir. O halde kritik koda
    N tane akışın girmesinin ne anlamı olabilir? İşte semaphore'lar tipik olarak N tane kaynağı thread'lere paylaştırmak 
    için kullanılmaktadır. Örneğin elimizde 3 tane makine olsun. Bir thread makine istediğinde biz ona bu üç makineden birini 
    veririz. Başka bir thread de makine istediğinde biz ona geri kalan iki makineden birini veririz. Başka bir thread de makine 
    istediğinde biz ona boşta olan tek makineyi veririz. Artık elimizde hiç makine kalmamıştır. Şimdi başka bir thread bizden 
    makine istediğinde biz artık o thread'e elimizde makine kalmadığı için makine veremeyiz. Ancak o thread'in işlemine devam 
    etmesi için makineye gereksinimi vardır. İşte bu durumda o thread'in bir makine boşalana kadar CPU zamanı harcamadan beklemesi 
    gerekir. Semaphore'lar tipik olarak bu biçimde senaryolarda kullanılmaktadır.

    <semaphore girişi>
    ...
    ...    Buradaki kritik kod boştaki bir makineyi gelen thread'e veriyor
    ...
    <semaphore çıkışı>

    Yukarıdaki örnekte makineyi elde eden thread'lerden biri kritik koddan çıktığında artık onun kullandığı makine boşaltılmış 
    olur. Bu durumda bloke olmuş olan bir thread uyanıp kritik koda girer. Artık elimizde boşta bir makine olduğuna göre onu
    gelen thread'e atayabiliriz.

    Semaphore'lar üretici-tüketici problemi (producer-consumer problem) senkronizasyon problemini çözmek için de kullanılmaktadır. 
    Zaten Edsger Dijkstra semaphore nesnelerini üretici-tüketici problemlerinin çözmek amacıyla bulmuştur. Örneğin UNIX/Linux
    sistemlerinde kullanıcı modunda kullanılan "mesaj kuyrukları (message queues)" tipik olarak semaphore nesneleriyle 
    gerçekleştirilmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Semaphore nesnelerinini bir sayıcının bulunduğunu belirtmiştik. Bu sayaç bir thread kritik koda girerken kontrol edilir. 
    Eğer sayaç 0'dan büyükse kritik koda giriş izni verilir. Ancak sayaç thread kritik koda girerken 1 eksiltilir. Eğer 
    sayaç 0 değerine düşerse artık semaphore nesnesi kapalı durumda olur. Bu durumda thread semaphore sayacı 0'dan büyük 
    duruma gelene kadar blokede bekletilir. Semaphore'larla kritik kod tipik olarak aşağıdaki gibi oluşturulmaktadır:

    down(...);
    ...
    ... KRİTİK KOD
    ...
    up(...);

    down fonksiyonu semaphore sayacı 0 ise bloke oluşturur, böylece thread kritik koda giremez. up fonksiyonu da semaphore sayacını 
    1 artırmaktadır. Burada semaphore sayacının 3 olduğunu düşünelim. Bir thread down fonksiyonuna geldiğinde down fonksiyonu 
    semaphore sayacı 0'dan büyük olduğu için bloke oluşturmaz ancak semaphore sayacını 1 eksiltir. Şimdi semaphore sayacı 2'dir. 
    Bir thread daha kritik koda girmek istediğinde semaphore sayacı 1'e düşecektir. Şimdi kritik kodda iki thread bulunacaktır.
    Bir thread daha kritik koda girmek istediğinde semaphore sayacı 0 olur ve artık kritik kodda üç thread bulunmaktadır. 
    Artık yeni bir thread down fonksiyonuna geldiğinde semaphore sayacı 0 olduğu için blokede bekleyecektir. Kritik koddaki 
    bir thread kritik koddan çıkarken up fonksiyonunu çağırır. Bu fonksiyon da semaphore 1 artırır. Şimdi semaphore sayacı 
    yeniden 1 olmuştur. Artık blokede bekleyen bir thread kritik koda girebilir. Tabii bu thread kritik koda girdiğinde semaphore
    sayacı yeniden 0 olacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdek semaphore nesnelerini şöyle kullanılmaktadır:

    1) Semaphore nesnesi struct semaphore isimli bir yapıyla temsil edilmiştir. Bir semaphore nesnesi DEFINE_SEMAPHORE(name) 
    makrosuyla aşağıdaki gibi oluşturulabilir.

    #include <linux/semaphore.h>

    static DEFINE_SEMAPHORE(g_sem);

    Bu biçimde yaratılan semaphore nesnesinin başlangıçta sayaç değeri 1'dir. Yeni çekirdeklerde (v6.4-rc1 ve sonrası) bu makro iki 
    parametreli olarak da kullanılabilmektedir:

    static DEFINE_SEMAPHORE(g_sem);

    Buradaki ikinci parametre semaphore sayacının başlangıçtaki değerini belirtmektedir.

    Semaphore nesneleri sema_init fonksiyonuyla da yaratılabilmektedir:

    static struct semaphore g_sem;
    ...
    sema_init(&g_sem, 1);

    Fonksiyonun ikinci parametresi başlangıç sayaç numarasıdır.

    2) Kritik kod "down" ve "up" fonksiyonları arasına alınır. "down" fonksiyonları sayacı bir eksilterek kritik koda giriş yapar. 
    "up" fonksiyonu ise sayacı bir artırmaktadır. Fonksiyonların prototipleri şöyledir:

    #define <linux/semaphore.h>

    void down(struct semaphore *sem);
    int down_interruptible(struct semaphore *sem);
    int down_killable(struct semaphore *sem);
    int down_trylock(struct semaphore *sem);
    int down_timeout(struct semaphore *sem, long jiffies);
    void up(struct semaphore *sem);

    Kritik kod "down" fonksiyonu ile oluşturulduğunda thread bloke olursa sinyal yoluyla uyandırılamamaktadır. Ancak kritik kod 
    "down_interruptible" fonksiyonu ile oluşturulduğunda thread bloke olursa sinyal yoluyla uyandırılabilmektedir. down_killable
    bloke olmuş thread'in yalnızca SIGKILL sinyalini kabul edip sonlandırılabilmesini sağlamaktadır. down_killable fonksiyonunda 
    eğer thread bloke olursa diğer sinyaller yine blokeyi sonlandıramamaktadır. down_trylock yine nesnenin açık olup olmadığına 
    bakmak için kullanılır. Eğer nesne açıksa yine sayaç 1 eksiltilir ve kritik koda girilir. Bu durumda fonksiyon 0 dışı bir 
    değerle geri döner. Nesne kapalıysa (yani semaphore sayacı 0 ise) fonksiyon bloke olmadan 0 değerine geri döner. down_timeout 
    ise en kötü olasılıkla belli miktar "jiffy" zamanı kadar blokeye yol açmaktadır. ("jiffy" kavramı ileride ele alınacaktır.) 
    Fonksiyon zaman aşımı dolduğundan dolayı sonlanmışsa negatif hata koduna, normal bir biçimde sonlanmışsa 0 değerine geri 
    dönmektedir. down_interruptible fonksiyonu normal sonlanmada 0 değerine, sinyal yoluyla sonlanmada -ERESTARTSYS değeri ile 
    geri döner. Normal uygulama eğer bu fonksiyonlar -ERESTARTSYS ile geri dönerse aygıt sürücüdeki fonksiyonun da aynı değerle 
    geri döndürülmesidir. Zaten çekirdek bu -ERESTARTSYS geri dönüş değerini aldığında asıl sistem fonksiyonunu eğer sinyal için 
    otomatik restart mekanizması aktif değilse -EINTR değeri ile geri döndürmektedir. Bu da tabii POSIX fonksiyonlarının başarısız 
    olup errno değerini EINTR biçiminde set edilmesine yol açmaktadır. up fonksiyonu yukarıda da belirttiğimiz gibi semaphore 
    sayacını 1 artırmaktadır.

    Kernel semaphore nesneleriyle kritik kod aşağıdaki gibi oluşturulmaktadır:

    DEFINE_SEMAPHORE(g_sem, 3);
    ...

    down_interruptible(&g_sem);
    ...
    ... <KRİTİK KOD>
    ...
    up(&g_sem);

    Yukarıdaki boru örneğinde biz mutex nesnesi yerine binary semaphore nesnesi de kullanabilirdik. Aşağıda aynı örneğin 
    binary semaphore ile gerçekleştirimi görülmektedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/* pipe-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>
#include <linux/semaphore.h>

#define PIPE_BUFFER_SIZE		8192
#define MIN(a, b)	((a) < (b) ? (a) : (b))

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("Pipe Device Driver");

static int generic_open(struct inode *inodep, struct file *filp);
static int generic_release(struct inode *inodep, struct file *filp);
static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off);
static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off);

static dev_t g_dev;
static struct cdev g_cdev;
static struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = generic_open,
	.read = generic_read,
	.write = generic_write,
	.release = generic_release
};

static unsigned char g_pipebuf[PIPE_BUFFER_SIZE];
static size_t g_head;
static size_t g_tail;
static size_t g_count;

static DEFINE_SEMAPHORE(g_sem);

static int __init generic_init(void)
{
	int result;

	printk(KERN_INFO "generic-char-driver init...\n");

	if ((result = alloc_chrdev_region(&g_dev, 0, 1, "pipe-driver")) < 0) {
		printk(KERN_ERR "cannot register device!...\n");
		return result;
	}

	cdev_init(&g_cdev, &g_fops);
	if ((result = cdev_add(&g_cdev, g_dev, 1)) < 0) {
		unregister_chrdev_region(g_dev, 1);
		printk(KERN_ERR "cannot add device!...\n");

		return result;
	}

	return 0;
}

static void __exit generic_exit(void)
{
	cdev_del(&g_cdev);
	unregister_chrdev_region(g_dev, 1);

	printk(KERN_INFO "generic-char-driver exit...\n");
}

static int generic_open(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver opened...\n");

	return 0;
}

static int generic_release(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver closed...\n");

	return 0;
}

static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;
	ssize_t result = -EFAULT;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	if (g_count == 0) {
		result = 0;
		goto EXIT;
	}

	esize = MIN(size, g_count);
	if (g_head >= g_tail)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_head);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_to_user(buf, g_pipebuf + g_head, size1) != 0)
		goto EXIT;

	if (size2 != 0)
		if (copy_to_user(buf + size1, g_pipebuf, size2) != 0)
			goto EXIT;

	g_head = (g_head + esize) % PIPE_BUFFER_SIZE;
	g_count -= esize;

	result = esize;
EXIT:
	up(&g_sem);

	return result;
}

static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;
	ssize_t result = -EFAULT;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	if (g_count == PIPE_BUFFER_SIZE) {
		result = 0;
		goto EXIT;
	}

	esize = MIN(size, PIPE_BUFFER_SIZE - g_count);
	if (g_tail >= g_head)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_tail);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_from_user(g_pipebuf + g_tail, buf, size1) != 0)
		goto EXIT;
	if (size2 != 0)
		if (copy_from_user(g_pipebuf, buf + size1, size2) != 0)
			goto EXIT;

	g_tail = (g_tail + esize ) % PIPE_BUFFER_SIZE;
	g_count += esize;

	result = esize;

EXIT:
	up(&g_sem);

	return esize;
}

module_init(generic_init);
module_exit(generic_exit);

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* load (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1
mode=666

/sbin/insmod ./$module.ko ${@:2} || exit 1
major=$(awk "\$2 == \"$module\" {print \$1}" /proc/devices)
rm -f $module
mknod -m $mode $module c $major 0

/* unload (bu satırı dosyaya kopyalamayınız ) */

#!/bin/bash

module=$1

/sbin/rmmod ./$module.ko || exit 1
rm -f $module

/* pwriter.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	char *str;
	ssize_t result;

	if ((fd = open("pipe-driver", O_WRONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Enter text:");
		fflush(stdout);
		if (fgets(buf, BUFFER_SIZE, stdin) == NULL)
			continue;
		if ((str = strchr(buf, '\n')) != NULL)
			*str = '\0';
		if (!strcmp(buf, "quit"))
			break;
		if ((result = write(fd, buf, strlen(buf))) == -1)
			exit_sys("write");
		if (result > 0)
			printf("%jd bytes written...\n", (intmax_t)result);
		else
			printf("pipe full, try again...\n");
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/* preader.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	int n;
	ssize_t result;

	if ((fd = open("pipe-driver", O_RDONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Number of bytes to read? ");
		scanf("%d", &n);
		if (n == 0)
			break;
		if ((result = read(fd, buf, n)) == -1)
			exit_sys("read");
		if (result == 0) {
			printf("pipe is empty, try again...\n");
			continue;
		}
		buf[result] = '\0';
		printf("%jd bytes read: %s\n", (intmax_t)result, buf);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdek kodlarında ve aygıt sürücülerde çok kullanılan diğer bir senkronizasyon nesnesi de "spinlock" denilen nesnelerdir. 
    Buradaki "spin" sözcüğü "meşgul bir döngü oluşturarak kontrol etmek" anlamına gelmektedir. Spinlock mekanizması oldukça 
    basittir. Kritik koda girerken eğer spinlock açık ise giriş gerçekleşir. Ancak spinlock kilitli ise bloke oluşmaz bir döngü
    içerisinde kilit açılana kadar sürekli kilit kontrol edilir. Biz kritik kod kilidinin bu biçimde kontrol edilmesinin sürekli 
    CPU'yu meşgul ettiğinden dolayı uygun olmadığını belirtmiştik. Ancak bazı durumlarda aslında bloke olmadan sürekli döngü 
    içerisinde kontrol etme daha verimli sonuçlara yol açabilmektedir.

    Eğer kritik kod kısa ise bu durumda kritik koda girmek isteyen thread'in bloke olup bekleme kuyruğuna alınması yerine 
    meşgul bir döngüde biraz beklemesi daha etkin bir çözüm oluşturmaktadır. Çünkü kritik kod kısa olduğuna göre zaten bekleyen 
    thread çok fazla spin yapmadan kritik koda girebilecektir. Tabii kritik koda girmiş olan thread'in kritik kod içerisinde 
    bloke olmaması gerekir. Eğer kritik koda girmiş olan thread kritik kod içerisinde bloke olursa bu durumda kritik koda 
    girmek isteyen thread'ler tüm quanta sürelerini spin yaparak geçirirler. Bu da çok verimsiz durum oluşturur. Spinlock 
    nesneleri özellikle çok işlemcili ya da çekirdekli sistemlerde fayda sağlamaktadır. Çünkü işlemcilerin ya da çekirdeklerin
    birinde çalışan bir thread kritik koda girdiğinde başka bir işlemcide ya da çekirdekte çalışan thread spin yaparak diğerinin
    kritik koddan çıkmasını beklemektedir. Tek bir işlemcili ya da çekirdekli sistemlerde spinlock kullanımının bir anlamı yoktur.

    Pekiyi bir thread spinlock'tan geçerek kritik koda girdiğinde o sırada quanta süresi bittiği için bağlamsal geçiş oluşursa
    ne olur? Thread bir sonraki quanta süresine kadar artık CPU'ya atanmayacaktır. Bu durumda spinlock kilitli kalacaktır. 
    Başka bir thread kritik koda girmek istediğinde tüm quanta süresini spin ile geçirecektir. Bu da sistemin etkinliğini 
    düşürecektir. İşte bunun için spinlock fonksiyonları kritik koda girişte kesme mekanizmasını kapatarak kritik kodda 
    çıkılana kadar bağlamsal geçişin oluşmasını engelleyebilmektedir. Yani spinlock'tan geçerek kritik koda giren thread'ler 
    kritik koddan çıkana kadar hiç kesilmemektedir.

    İşletim sistemi kodları ve aygıt sürücü kodları genel yazılmaktadır. Yani örneğin işletim sistemleri ve aygıt sürücüler 100 
    işlemcili ya da çekirdekli sistemde de 1 işlemcili ya da çekirdekli sistemde de çalışacak biçimde yazılırlar. Pekiyi spinlock 
    kullanıldığında eğer sistemimizde bir işlemci ya da çekirdek varsa bu durum bir olumsuzluğa yol açar mı? Bunun yanıtı hayır'dır.
    Tek işlemcili ya da çekirdekli sistemlerde bir thread kritik koda girdiğinde zaten çıkana kadar CPU bağlamsal geçişe kapatılır.
    Böylece kritik kod içerisinde bloke de oluşmayacağı için sistem sanki spinlock yokmuş gibi çalışacaktır.

    Burada bir kez daha spinlock kullanımı için dikkat edilmesi gereken durumları belirtmek istiyoruz:

    - Spinlock ile kritik koda giren thread spinlock kilidini uzun süre kapalı tutmamalıdır. Yani spinlock kısa kodlar için 
    uygulanmalıdır
    - Spinlock ile kritik koda giren thread bloke olmamalıdır.
    - Spinlock ile kritik koda giren thread CPU'yu IRQ'lara açma konusunda dikkatli olmalıdır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdekteki spinlock nesneleri tipik olarak şöyle kullanılmaktadır:

    1) Spinlock nesnesi spinlock_t türü ile temsil edilmektedir. Spinlock nesnesini aşağıdaki gibi tanımlayabilirsiniz:

    static spinlock_t g_spinlock;

    inux'un 2.6.9 çekirdeği ile birlikte spinlock nesnesini tanımlayıp ona ilkdeğer vermek için DEFINE_SPINLOCK makrosu da 
    çekirdeğe eklenmiştir. Bu makro kullanılarak spinlock nesnesi açık bir biçimde şöyle oluşturulabilir:

    #include <linux/spinlock.h>

    static DEFINE_SPINLOCK(g_spinlock);

    spinlock_t nesnesine ilkdeğer verme işlemi spin_lock_init fonksiyonuyla da yapılabilmektedir. spin_lock_init fonksiyonu 
    spinlock_t nesnesine açık olacak biçimde (unlocked) ilkdeğerlerini vermektedir:

    #include <linux/spinlock.h>

    void spin_lock_init(spinlock_t *lock);

    Örneğin:

    spinlock_init(&g_spinlock);S

    2) Kritik koda giriş için aşağıdaki fonksiyonlar kullanılmaktadır:

    #include <linux/spinlock.h>

    void spin_lock(spinlock_t *lock);
    void spin_lock_irq(spinlock_t *lock);
    void spin_lock_irqsave(spinlock_t *lock, unsigned long flags);
    void spin_lock_bh(spinlock_t *lock);

    spin_lock fonksiyonu klasik spin yapan fonksiyondur. spin_lock_irq fonksiyonu o anda çalışılan işlemci ya da çekirdekteki 
    IRQ'ları (yani donanım kesmelerini) kapatarak kilidi almaktadır. Yani biz bu fonksiyonla kilidi almışsak kilidi bırakana 
    kadar donanım kesmeleri oluşmayacaktır. spin_lock_irqsave fonksiyonu kritik koda girerken donanım kesmelerini kapatmakla 
    birlikte önceki bir durumu geri yükleme yeteneğine sahiptir. Aslında bu fonksiyonların bazıları makro olarak yazılmıştır. 
    Örneğin spin_lock_irqsave aslında bir makrodur. Biz bu fonksiyonun ikinci parametresine nesne adresini geçmemiş olsak da 
    bu bir makro olduğu için aslında ikinci parametrede verdiğimiz nesnenin içerisine IRQ durumları yazılmaktadır. spin_lock_bh
    fonksiyonu yalnızca yazılım kesmelerini kapatmaktadır.

    3) Kilidin geri bırakılması için spin_unlock fonksiyonları kullanılmaktadır:

    #include <linux/spinlock.h>

    void spin_unlock(spinlock_t *lock);
    void spin_unlock_irqrestore(spinlock_t *lock, unsigned long flags);
    void spin_unlock_irq(spinlock_t *lock);
    void spin_unlock_bh(spinlock_t *lock);

    Yukarıdaki lock fonksiyonlarının hepsinin bir unlock karşılığının olduğunu görüyorsunuz. Biz kilidi hangi lock fonksiyonu 
    ile almışsa o unlock fonksiyonu ile bırakmalıyız. Örneğin:

    spin_lock(&g_spinlock);
    ...
    ... <KRİTİK KOD>
    ...
    spin_unlock(&g_spinlock);

    Ya da örneğin:

    ...
    unsigned long irqstate;
    ...

    spin_lock_irqsave(&g_spinlock, irqstate);
    ...
    ... <KRİTİK KOD>
    ...
    spin_unlock_irqrestore(&g_spinlock, irqstate);

    Yine kernel spinlock nesnelerinde de try'lı lock fonksiyonları bulunmaktadır:

    #include <linux/spinlock.h>

    int spin_trylock(spinlock_t *lock);
    int spin_trylock_bh(spinlock_t *lock);

    Bu fonksiyonlar eğer spinlock kilitliyse spin yapmazlar ve 0 ile geri dönerler. Eğer kilidi alırlarsa sıfır dışı bir değerle
    geri dönerler.

    Her ne kadar yukarıdaki boru sürücüsündeki read ve write fonksiyonlarında kuyruğu korumak için spinlock kullanımı uygun değilse 
    de biz yine kullanım biçimini göstermek için aşağıdaki örneği veriyoruz.
-----------------------------------------------------------------------------------------------------------------------------*/

/* pipe-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>
#include <linux/spinlock.h>

#define PIPE_BUFFER_SIZE		8192
#define MIN(a, b)	((a) < (b) ? (a) : (b))

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("Pipe Device Driver");

static int generic_open(struct inode *inodep, struct file *filp);
static int generic_release(struct inode *inodep, struct file *filp);
static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off);
static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off);

static dev_t g_dev;
static struct cdev g_cdev;
static struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = generic_open,
	.read = generic_read,
	.write = generic_write,
	.release = generic_release
};

static unsigned char g_pipebuf[PIPE_BUFFER_SIZE];
static size_t g_head;
static size_t g_tail;
static size_t g_count;

static DEFINE_SPINLOCK(g_spinlock);

static int __init generic_init(void)
{
	int result;

	printk(KERN_INFO "generic-char-driver init...\n");

	if ((result = alloc_chrdev_region(&g_dev, 0, 1, "pipe-driver")) < 0) {
		printk(KERN_ERR "cannot register device!...\n");
		return result;
	}

	cdev_init(&g_cdev, &g_fops);
	if ((result = cdev_add(&g_cdev, g_dev, 1)) < 0) {
		unregister_chrdev_region(g_dev, 1);
		printk(KERN_ERR "cannot add device!...\n");

		return result;
	}

	return 0;
}

static void __exit generic_exit(void)
{
	cdev_del(&g_cdev);
	unregister_chrdev_region(g_dev, 1);

	printk(KERN_INFO "generic-char-driver exit...\n");
}

static int generic_open(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver opened...\n");

	return 0;
}

static int generic_release(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "generic-char-driver closed...\n");

	return 0;
}

static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;
	ssize_t result = -EFAULT;

	spin_lock(&g_spinlock);

	if (g_count == 0) {
		result = 0;
		goto EXIT;
	}

	esize = MIN(size, g_count);
	if (g_head >= g_tail)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_head);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_to_user(buf, g_pipebuf + g_head, size1) != 0)
		goto EXIT;

	if (size2 != 0)
		if (copy_to_user(buf + size1, g_pipebuf, size2) != 0)
			goto EXIT;

	g_head = (g_head + esize) % PIPE_BUFFER_SIZE;
	g_count -= esize;

	result = esize;
EXIT:
	spin_unlock(&g_spinlock);

	return result;
}

static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;
	ssize_t result = -EFAULT;

	spin_lock(&g_spinlock);

	if (g_count == PIPE_BUFFER_SIZE) {
		result = 0;
		goto EXIT;
	}

	esize = MIN(size, PIPE_BUFFER_SIZE - g_count);
	if (g_tail >= g_head)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_tail);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_from_user(g_pipebuf + g_tail, buf, size1) != 0)
		goto EXIT;
	if (size2 != 0)
		if (copy_from_user(g_pipebuf, buf + size1, size2) != 0)
			goto EXIT;

	g_tail = (g_tail + esize ) % PIPE_BUFFER_SIZE;
	g_count += esize;

	result = esize;

EXIT:
	spin_unlock(&g_spinlock);

	return esize;
}

module_init(generic_init);
module_exit(generic_exit);

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* load (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1
mode=666

/sbin/insmod ./$module.ko ${@:2} || exit 1
major=$(awk "\$2 == \"$module\" {print \$1}" /proc/devices)
rm -f $module
mknod -m $mode $module c $major 0

/* unload (bu satırı dosyaya kopyalamayınız ) */

#!/bin/bash

module=$1

/sbin/rmmod ./$module.ko || exit 1
rm -f $module

/* pwriter.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	char *str;
	ssize_t result;

	if ((fd = open("pipe-driver", O_WRONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Enter text:");
		fflush(stdout);
		if (fgets(buf, BUFFER_SIZE, stdin) == NULL)
			continue;
		if ((str = strchr(buf, '\n')) != NULL)
			*str = '\0';
		if (!strcmp(buf, "quit"))
			break;
		if ((result = write(fd, buf, strlen(buf))) == -1)
			exit_sys("write");
		if (result > 0)
			printf("%jd bytes written...\n", (intmax_t)result);
		else
			printf("pipe full, try again...\n");
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/* preader.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	int n;
	ssize_t result;

	if ((fd = open("pipe-driver", O_RDONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Number of bytes to read? ");
		scanf("%d", &n);
		if (n == 0)
			break;
		if ((result = read(fd, buf, n)) == -1)
			exit_sys("read");
		if (result == 0) {
			printf("pipe is empty, try again...\n");
			continue;
		}
		buf[result] = '\0';
		printf("%jd bytes read: %s\n", (intmax_t)result, buf);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
												95. Ders 15/04/2025 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Diğer çok kullanılan bir senkronizasyon nesnesi de "okuma yazma kilitleri (readers-writer locks)" denilen nesnelerdir. 
    Önce bu nesnelere neden gereksinim duyulduğunu bir örnekle açıklamak istiyoruz. Aygıt sürücümüzde paylaşılan bir kaynak 
    bulunuyor olsun. Örneğin bunun global bir liste (linked lists) olduğunu düşünelim. Bu bağlı listeye bir grup thread eleman
    (node) ekliyor olsun, bir grup thread de bu bağlı listeyi dolaşarak eleman arıyor olsun. Tabii burada thread demekle aslında
    aygıt sürücümüzdeki fonksiyonu çağıran kullanıcı modundaki herhangi bir prosesin herhangi bir thread'ini kastediyoruz. Burada
    bağlı listede arama yapmak "okuma (read)" işlemi gibi düşünülebilir. Çünkü bu işlem paylaşılan kaynakta (burada bağlı liste)
    bir durum değişikliğine yol açmadığı için farklı thread'lerden aynı anda yürütülebilir. Ancak bağlı listeye eleman ekleyen 
    thread bu işlem sırasında bağlı listenin düğümlerini değiştirdiği için tam o sırada başka bir thread de ekleme yaparsa ya 
    da arama yaparsa bir çökme oluşturabilir. Burada bağlı listeye eleman eklemek bir yazma (write) işlemi olarak düşünülebilir. 
    O halde bizim öyle bir kritik kod oluşturmamız gerekir ki birden fazla okuma yapan thread bu kritik koda girebilsin ancak 
    bir thread okuma yaparken yazma yapan bir thread kritik koda girmeden okuma yapan thread çıkana kadar beklesin. Benzer biçimde
    eğer yazma yapan bir thread kritik koda girmişse bu işlem bitene kadar okuma yapan bir thread de yazma yazma yapan bir thread 
    de kritik koda giremez. Aşağıda Thread-1 kritik koda girmişse Thread-2'nin durumu açıklanmaktadır:

    Thread-1            Thread-2        Bloke Oluşmalı Mı?
    -------------------------------------------------------
    Okuma               Okuma           Hayır
    Okuma               Yazma           Evet
    Yazma               Okuma           Evet
    Yazma               Yazma           Evet

    Görüldüğü gibi bu mekanizma yalnızca eş zamanlı okumalara izin vermektedir.

    Bu mekanizma tek başına mutex ya da semaphore nesneleriyle sağlanamaz. Aşağıdaki temsili koda (pseudo code) dikkat 
    ediniz:

    static DEFINE_MUTEX(g_mutex);

    read()
    {
        mutex_lock(&g_mutex);
        <okuma işlemi yapılıyor>
        mutex_unlock(&g_mutex);
    }

    write()
    {
        mutex_lock(&g_mutex);
        <yazma işlemi yapılıyor>
        mutex_unlock(&g_mutex);
    }

    Burada birden fazla okuma işlemi de blokeye yol açacaktır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Okuma yazma kilitleri Linux'ta spinlock oluşturarak çalışmaktadır. Bu nedenle bu nesnelere Linux'ta "spinlock'lu okuma yazma
    kilitleri" reader/writer spinlock de denilmektedir.

    Spinlock'lu okuma yazma kilitleri rwlock_t türüyle temsil edilmektedir. Bu nesnelerin tanımlanması yine iki biçimde yapılabilmektedir. 
    Birinci biçimde DEFINE_RWLOCK(x) makrosu kullanılır. Örneğin:

    #include <linux/rwlock.h>

    static DEFINE_RWLOCK(g_rwlock);

    Bu makro eski çekirdeklerde bulunmamaktadır. Dolayısıyla kullanırken hata oluşursa diğer yöntemi deneyebilirsiniz. Spinlock'lu 
    okuma yazma kilit nesneleri global düzeyde tanımlanıp bunlara rwlock_init fonksiyonuyla da ilkdeğer verilebillmektedir.

    #include <linux/rwlock.h>

    void rwlock_init(rwlock_t *lock);

    Spinlock'lu okuma yazma kilitleri ile kritik kod oluşturmak için aşağıdaki fonksiyonlar kullanılmaktadır:

    #include <linux/rwlock.h>

    void read_lock(rwlock_t *lock);
    void read_lock_irqsave(rwlock_t *lock, unsigned long flags);
    void read_lock_irq(rwlock_t *lock);
    void read_lock_bh(rwlock_t *lock);

    void read_unlock(rwlock_t *lock);
    void read_unlock_irqrestore(rwlock_t *lock, unsigned long flags);
    void read_unlock_irq(rwlock_t *lock);
    void read_unlock_bh(rwlock_t *lock);

    void write_lock(rwlock_t *lock);
    void write_lock_irqsave(rwlock_t *lock, unsigned long flags);
    void write_lock_irq(rwlock_t *lock);
    void write_lock_bh(rwlock_t *lock);
    int write_trylock(rwlock_t *lock);

    void write_unlock(rwlock_t *lock);
    void write_unlock_irqrestore(rwlock_t *lock, unsigned long flags);
    void write_unlock_irq(rwlock_t *lock);
    void write_unlock_bh(rwlock_t *lock);

    Nesne read amaçlı lock edilmişse read amaçlı unlock işlemi, write amaçlı lock edilmişse write amaçlı unlock işlemi 
    uygulanmalıdır. Fonksiyonların diğer işlevleri normal spinlock nesnelerinde olduğu gibidir.

    Örneğin biz bu fonksiyonlarla okuma yazma işlemlerini aşağıdaki gibi senkronize edebiliriz:

     static DEFINE_RWLOCK(g_rwlock);

    read()
    {
        read_lock(&g_rwlock);
        <okuma işlemi yapılıyor>
        read_unlock(&g_rwlock);
    }

    write()
    {
        write_lock(&g_rwlock);
        <yazma işlemi yapılıyor>
        write_unlock(&g_rwlock);
    }

    Burada artık okuma yapmak isteyen thread read fonksiyonunu çağırdığında read_lock fonksiyonu ile spinlock kilidi alınır, 
    başka bir thread bu kilidi write_lock ile alamaz ve spin yapmaya başlar. Ancak başka bir thread kilidi yine read_lock 
    ile alabilir. Eğer bir thread kilidi write_lock ile almışsa başka bir thread kilidi read_lock ile de write_lock ile de 
    alamaz ve spin yaparak bekler.

    read_lock ve write_lock fonksiyonlarının irq sonekli versiyonları yine akış kritik kodda girdiğinde ilgili CPU ya da 
    çekirdeğin yerel kesmelerini kapatmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çok işlemcili ya da çok çekirdekli sistemlerde RAM ortak bir biçimde kullanılmaktadır. Bu konuda yaygın iki mimari bulunmaktadır. 
    Bunlardan birine SMP (Symmetric Multiprocessors), diğerine ise NUMA (Non-Uniform Memory Access) denilmektedir. Masaüstü ve 
    taşınabilir bilgisayarlarımızda hemen her zaman SMP mimarisini kullanan çok çekirdekli işlemciler bulunmaktadır. NUMA mimarisi 
    daha çok güçlü sunucularda ve iş istasyonlarında tercih edilmektedir. SMP mimarisinde bir işlemci ya da çekirdek RAM'e erişirken 
    diğerlerini durdurmaktadır. Böylece belli bir anda tek bir işlemci ya da çekirdek RAM'e erişmekte ve bus çakışması bu yolla 
    ortadan kaldırılmaktadır. Ancak bu sistem Intel gibi bazı işlemcilerde bazı özel durumlarda yetersiz kalabilmektedir. Örneğin 
    Intel işlemcileri özellikle hizalanmamış adreslerden bilgi çekerken ya da hizalanmamış adreslere bilgi yazarken bus'ı tüm 
    işlem boyunca tutmamaktadır. Hizalanmamış verileri bellekten okurken işlemci (ya da işlemcideki bir çekirdek) verinin bir 
    kısmını okuyup bus'ı bırakıp sonra diğer kısmını okuyabilmektedir. Aynı durum yazma sırasında da yapılmaktadır. İşte tam 
    bu sırada büyük bir tesadüfle diğer işlemci ya da çekirdek de aynı bellek bölgesinden okuma yazma yapıyorsa oradaki bilgi 
    yanlış okunabilmekte ya da oraya yanlış bilgi yazılabilmektedir. Bunu engellemek için Intel LOCK isimli bir önek makine 
    komutu oluşturmuştur. Belleğe erişirken bu LOCK öneki kullanıldığında tüm işlem bitene kadar bus tutulmaktadır. Örneğin 
    iki farklı işlemci ya da çekirdekteki kod aynı global değişkene tesadüfen aynı anda atama yapıyor olsun:

    Çekirdek-1             Çekirdek-2
    ...                    ...
    g_x = 1000;            g_x = 2000;
    ...                    ...

    Burada g_x hizalanmamışsa çok düşük bir olasılıkla g_x'in içerisinde 10000 de 20000 de yerleştirilmemiş olabilir. Bu da 
    tüm programın yanlış çalışmasına yol açacaktır. Tabii aynı sorun bir işlemci ya da çekirdeğin bir değişkene bir şey yazarken 
    tesadüfen aynı anda diğerinin okuması durumunda da oluşmaktadır. Tabii eğer bu işlemler için derleyici aşağıdaki makine 
    komutları üretseydi bir sorun olmayacaktır:

    Çekirdek-1             Çekirdek-2
    ...                    ...
    LOCK MOV g_x, 1000     LOCK MOV g_x, 2000
    ...                    ...

    Ancak derleyiciler yavaşlatacağı gerekçesiyle bu biçimde kod üretmemektedir. Pekiyi bu durumda ne yapılabilir? İlk akla 
    gelen bu tür erişimleri kritik kod oluşturarak muhtemelen spinlock nesneleriyle yapmaktır. Ancak onun da maliyeti vardır. 
    İşte kullanıcı modunda olduğu gibi aygıt sürücülerde de basit atama, artırma, eksiltme gibi işlemlerin atomic yapılmasını 
    sağlayan özel fonksiyonlar vardır. Bu fonksiyonların hepsi nesneyi atomic_t türü biçiminde istemektedir. atomic_t türü 
    içerisinde yalnızca int bir nesne olan bir yapı türüdür. Bu yapı nesnesinin içerisindeki değeri alan atomic_read isimli 
    inline bir fonksiyon da vardır. Atomic inline fonksiyonların bazıları şunlardır:

    #include <asm/atomic.h>

    int atomic_read(const atomic_t *v);
    void atomic_set(atomic_t *v, int i);
    void atomic_add(int i, atomic_t *v);
    void atomic_sub(int i, atomic_t *v);
    void atomic_inc(atomic_t *v);
    void atomic_dec(atomic_t *v)
    ...

    Bu fonksiyonların hepsinin atomic_t türünden nesnenin adresini alan bir parametresi vardır. atomic_set fonksiyonunun ikinci 
    parametresi set edilecek değeri almaktadır.

    Yukarıda da belirttiğimiz gibi atomic_t türü aslında int bir elemana sahip bir yapı biçimindedir. atomic_t türünden 
    bir değişkene ilkdeğer vermek için ATOMIC_INIT makrosu da kullanılabilir. Örneğin:

    atomic_t g_count = ATOMIC_INIT(0);

    Yukarıda da belirttiğimiz gibi atomic_t nesnesi içerisindeki değeri atomic_read makrosuyla elde edebiliriz. Örneğin:

    val = atomic_read(&g_count);

    Pekiyi mademki atomic_t türü içerisinde bir int değerin bulunduğu bir yapı belirtiyor bu durumda neden doğrudan int nesne
    kullanılmıyor da içerisinde iny bir eleman olan yapı kullanılıyor? İşte bunun amacı bu atomik nesnenin ++, -- += gibi 
    operatörlerle kullanımı konusunda cesareti kırmaktır.

    Bit işlemlerine yönelik atomik işlemler de yapılabilmektedir:

    void set_bit(nr, void *addr);
    void clear_bit(nr, void *addr);
    void change_bit(nr, void *addr);
    test_bit(nr, void *addr);
    int test_and_set_bit(nr, void *addr);
    int test_and_clear_bit(nr, void *addr);
    int test_and_change_bit(nr, void *addr);

    RISC işlemcilerinde aritmetik işlem yapan, karşılaştırma ve bit işlemleri yapan makine komutları bellek ile çalışmamaktadır. 
    Bu işlemcilerdeki bu tarz komutlar hep yazmaç üzerinden çalışmaktadır. Dolayısıyla da bu işlemlemcilerde bu işlemler 
    tek bir makine komutuyla yapılamamaktadır. İşte yukarıdaki inline fonksiyonlar bu işlemcilerde daha özel olarak yazılmıştır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												96. Ders 17/04/2025 - Persembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz kullanıcı modunda çeşitli fonksiyonların çeşitli koşullar altında blokeye yol açtığını belirtmiştik. Bir thread bloke 
    olduğunda thread belli bir koşul sağlanana kadar ilgili CPU'nun "çalışma kuyruğundan (run queue)" çıkartılır, ismine 
    "bekleme kuyruğu (wait queue)" denilen bir kuyruğa yerleştirilir. Blokeye yol açan koşul ortadan kalktığında ise thread 
    yeniden bekleme kuyruğundan alınarak ilgili CPU'nun çalışma kuyruğuna yerleştirilir.

    Aygıt sürücülerde blokeyi aygıt sürücünün kendisi oluşturmaktadır. Örneğin biz boru aygıt sürücümüzde read işlemi yapıldığında 
    eğer boruda okunacak hiç bilgi yoksa read işlemini yapan kullanıcı modundaki thread'i bloke edebiliriz. Boruya bilgi geldiğinde 
    de thread'i yeniden çalışma kuyruğuna yerleştirip blokeyi çözebiliriz. İşte bu bölümde aygıt sürücüde thread'lerin nasıl 
    bloke edileceği ve blokenin nasıl çözüleceği üzerinde duracağız.

    Daha önceden de belirttiğimiz gibi mevcut Linux sistemlerinde her CPU ya da çekirdeğin ayrı bir "çalışma kuyruğu (run queue)" 
    bulunmaktadır. Ancak bir ara O(1) çizelgelemesi ismiyle Linux'ta bu konuda bir değişikliğe gidilmişti ((2.6.0 ile 2.6.22
    arasındaki çekirdekler)O(1) çizelgelemesi tekniğinde toplam tek bir çalışma kuyruğu bulunuyordu. Hangi CPU ya da çekirdeğe 
    atama yapılacaksa bu tek olan çalışma kuyruğundan thread alınıyordu. O(1) çizelgelemesi Linux'ta kısa bir süre kullanılmıştır. 
    Bunun yerine "CFS (Completely Fair Scheduling)" çizelgeleme sistemine geçilmiştir. Bugün ağırlıklı olarak CFS çizelgeleme 
    algoritmasının iyileştirilmiş biçimleri kullanılmaktadır.

    Daha önceden de belirttiğimiz gibi Çalışmakta olan bir thread'in bloke olması sırasında thread'in yerleştirileceği tek bir 
    "bekleme kuyruğu (wait queue)" yoktur. Her CPU ya da çekirdek için de ayrı bir bekleme kuyruğu bulundurulmamaktadır. Bekleme 
    kuyrukları ilgili olay temelinde oluşturulmaktadır. Örneğin sleep fonksiyonu dolayısıyla bloke olan thread'ler ayrı bir bekleme 
    kuyruğuna, boru dolayısıyla bloke olan thread'ler ayrı bir bekleme kuyruğuna yerleştirilmektedir. Aygıt sürücüleri yazanlar 
    da kendi olayları için kendi bekleme kuyruklarını yaratırlar. Tabii çekirdekteki mutex ve semaphore fonksiyonları da aslında 
    kendi içerisinde bir bekleme kuyruğu kullanmaktadır. Çünkü bu fonksiyonlar da blokeye yol açmaktadır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirttiğimiz gibi her aygıt sürücü kendi bloke olayları için kendinin kullanacağı bekleme kuyrukları 
    yaratabilmektedir. Çekirdek içerisinde bekleme kuyruklarını yaratan ve yok eden çekirdek fonksiyonları bulunmaktadır. Yine 
    çekirdek içerisinde bir thread'i çalışma kuyruğundan çıkartıp bekleme kuyruğuna yerleştiren, bekleme kuyruğundan çıkartıp 
    çalışma kuyruğuna yerleştiren fonksiyonlar bulunmaktadır.

    Linux'ta bekleme kuyrukları wait_queue_head_t isimli bir yapıyla temsil edilmektedir. Bir bekleme kuyruğu DECLARE_WAIT_QUEUE_HEAD(name) 
    makrosuyla oluşturulabilir. Örneğin:

    #include <linux/wait.h>

    static DECLARE_WAIT_QUEUE_HEAD(g_wq);

    Bu makro hem wait_queue_head_t nesnesini tanımlayıp hem de ona küme parantezleriyle ilkdeğerlerini vermektedir. Alternatif 
    olarak önce nesne tanımlanıp sonra init_waitqueue_head fonksiyonuyla da ilk değer verilebilir. Bu fonksiyon aslında bir 
    makro biçiminde yazılmıştır. Örneğin:

    #include <linux/wait.h>

    static wait_queue_head_t g_wq;
    ...
    init_waitqueue_head(&g_wq);

    Bir thread'i (yani task_struct nesnesini) çalışma kuyruğundan çıkartıp istenilen bekleme kuyruğuna yerleştirme işlemi wait_event 
    makrolarıyla gerçekleştirilmektedir. Temel wait_event makroları şunlardır:

    wait_event(wq_head, condition);
    wait_event_interruptible(wq_head, condition);
    wait_event_killable(wq_head, condition);
    wait_event_timeout(wq_head, condition, timeout);
    wait_event_interruptible_timeout(wq_head, condition, timeout);
    wait_event_interruptible_exclusive(wq_head, condition);

    wait_event makrosu thread'i "uninterruptible" biçimde bekleme kuyruğuna yerleştirir. Bu biçimde bloke olmuş thread'lerin
    blokeleri sinyal dolayısıyla çözülememektedir. wait_event_interruptible makrosu ise aynı işlemi "interruptible" olarak 
    yapmaktadır. Yani sinyal geldiğinde thread bekleme kuyruğundan uyandırılır. wait_event_killable makrosu yalnızca SIGKILL 
    sinyali için thread'i uyandırmaktadır. Yani bu biçimde bekleme kuyruğuna yerleştirilmiş bir thread'in blokesi sinyal geldiğinde 
    çözülmez, ancak SIGKILL sinyali ile thread yok edilebilir. wait_event_timeout ve wait_event_interruptible_timeout makrolarının 
    wait_event makrolarından farkı thread'i en kötü olasılıkla belli bir jiffy zaman aşımı ile uyandırabilmesidir. Jiffy kavramı 
    izleyen bölümlerde ele alınacaktır. Makrolardaki ilk parametre bekleme kuyruğunu belirtmektedir. Bu parametreye argüman hiç 
    adresi alınmadan geçirilmelidir.

    Makrolardaki "condition (koşul)" parametresi bool bir ifade biçiminde oluşturulmalıdır. Bu ifade ya sıfır olur ya da sıfır 
    dışı bir değer olur. Bu koşul ifadesi "uyanık kalmak için bir koşul" belirtmektedir. Yani bu koşul uyandırma koşulu değildir, 
    uyanık kalma koşuludur. Çünkü bu makrolarda koşula bakılması uyumadan önce ve uyandırılma işleminden sonra yapılmaktadır. 
    Yani önce koşula bakılır. Koşul sağlanmıyorsa thread uyutulur. Thread uyandırıldığında yeniden koşula bakılır. Koşul sağlanmıyorsa 
    yeniden uyutulur. Dolayısıyla uyanma işlemi çekirdek kodlarında tıpkı koşul değişkenlerinde (condition variable) olduğu gibi 
    döngü içerisinde yapılmaktadır. Örneğin:

    DECLARE_WAIT_QUEUE_HEAD(g_wq);
    int g_flag = 0;
    ...

    wait_event(g_wq, g_flag != 0);

    Burada koşul g_flag != 0 biçimindedir. wait_event makroları fonksiyon değil makro biçiminde yazıldığı için bu koşul bu haliyle 
    makronun içinde kullanılmaktadır. (Yani koşul ifadesinin sonucu değil, kendisi makroda kullanılmaktadır.) Makronun içerisinde 
    önce koşula bakılmakta, bu koşul sağlanıyorsa thread zaten uyutulmamaktadır. Eğer koşul sağlanmıyorsa thread uyutulmaktadır. 
    Thread uykudan uyandırıldığında tıpkı koşul değişkenlerinde olduğu gibi yeniden koşula bakılmakta eğer koşul sağlanmıyorsa 
    thread yeniden uyutulmaktadır. wait_event makrosunun geri döndürdüğü bir değer yoktur. wait_event makrosu şöyle çalışmaktadır:

    1) Makro önce koşula bakar, koşul zaten sağlanıyorsa hemen işlemini sonlandırır.
    2) Eğer koşul sağlanmıyorsa thread çalışma kuyruğundan çıkartılıp bekleme kuyruğuna yerleştirilir.
    3) Thread uyandırıldığında aslında çalışma yine wait_event makrosunun içerisinden devam edecektir. Bu noktada makro yeniden 
    koşula bakar, koşulu sağlamayan thread'leri yeniden uyutur.

    Burada en çok tereddüt edilen nokta koşulun ne işe yaradığıdır. wake_up makroları izleyen paragraflarda da göreceğimiz gibi 
    yalnızca koşulu sağlayan thread'leri uyandıramamaktadır. Böyle bir mekanizmanın etkin bir biçimde oluşturulması da mümkün 
    değildir. Bu nedenle wake_up makroları koşula bakmaksızın bekleme kuyruğundaki birden fazla thread'i uyandırır. Uyanan 
    thread'lerin kendileri koşula bakmaktadır.

    wait_event_interruptible makrosunun wait_event makrosundan farkı eğer thread uyutulmuşsa uykudan bir sinyalle uyandırılabilmesidir. 
    Halbuki wait_event ile uykuya dalmış olan thread sinyal oluşsa bile uykudan uyandırılmamaktadır. wait_event_killable ile thread 
    uykuya dalındığında ise yalnızca SIGKILL sinyali ile thread uykudan uyandırılabilmektedir. Tabii programcı wait_event_interruptible
    makrosunun geri dönüş değerine bakmalı, eğer thread sinyal dolayısıyla uykudan uyandırılmışsa -ERESTARTSYS değeriyle kendi 
    fonksiyonundan geri dönmelidir. wait_event_interruptible makrosu eğer sinyal dolayısıyla uyanmışsa -ERESTARTSYS değeri ile, 
    koşul sağlandığından dolayı uyanmışsa 0 değeri ile geri dönmektedir. Örneğin:

    DECLARE_WAIT_QUEUE_HEAD(g_wq);
    int g_flag = 0;
    ...

    if (wait_event_interruptible(g_wq, g_flag != 0) != 0)
        return -ERESTARTSYS;

    Bu tür durumlarda koşulda kullanılan değişkenleri atomic olarak tanımlama iyi bir tekniktir. Örneğin:

    DECLARE_WAIT_QUEUE_HEAD(g_wq);
    static atomic_t g_flag = ATOMIC_INIT(0);
    ...

    if (wait_event_interruptible(g_wq, atomic_read(&g_flag) != 0) != 0)
        return -ERESTARTSYS;

    wait_event_interruptible_exclusive (bunun interruptible olmayan biçimi yoktur) makrosu Linux çekirdeklerine 2.6'nın belli 
    sürümünden sonra sokulmuştur. Yine bu makroyla birlikte aşağıda ele alınan wake_up_xxx_nr makroları da eklenmiştir. Bir 
    prosesin exclusive olarak wait kuyruğuna yerleştirilmesi onlardan belli sayıda olanların uyandırılabilmesini sağlamaktadır.

    Tabii wait_event makroları o andaki thread'i çizelgeden (yani run kuyruğundan) çıkartıp wait kuyruğuna yerleştirdikten sonra 
    "bağlamsal geçiş (context switch)" işlemini de yapmaktadır. Bağlamsal geçiş işlemi sonrasında artık çalışma kuyruğundaki yeni 
    bir thread CPU'ya atanarak çalıştırılır.

    wait_event makrolarının temsili kodunu şöyle düşünebilirsiniz:

    while (koşul_sağlanmadığı_sürece) {
        <thread'i bekleme kuyruğuna ekle>
        ---> <thread uyandırıldığında buradan çalışmaya devam eder>
    }

    Eski çekirdeklerde (yenilerinde de önemli değişiklik yoktur) wait_event makrosu şöyle yazılmıştır:

    #define __wait_event(wq, condition) 				\
    do {									        \
        wait_queue_t __wait;						\
        init_waitqueue_entry(&__wait, current);		\
                                                    \
        add_wait_queue(&wq, &__wait);				\
        for (;;) {							        \
            set_current_state(TASK_UNINTERRUPTIBLE);		\
            if (condition)						    \
                break;						        \
            schedule();						        \
        }								            \
        current->state = TASK_RUNNING;				\
        remove_wait_queue(&wq, &__wait);			\
    } while (0)

    #define wait_event(wq, condition) 				\
    do {									        \
        if (condition)	 						    \
            break;							        \
        __wait_event(wq, condition);				\
    } while (0)

    Burada uyandırılan thread aslında schedule fonksiyonun içerisinde çalışmaya devam edecektir. Koddan da gördüğünüz gibi akış
    schedule fonksiyonundan çıktığında döngü başa saracak ve yeniden koşul kontrol edilecektir.

    Bekleme kuyruğunda blokede bekletilen thread'ler wake_up makrolarıyla uyandırılmaktadır. Uyandırılmaktan kastedilen şey thread'in 
    bekleme kuyruğundan çıkartılıp yeniden çalışma kuyruğuna (run queue) yerleştirilmesidir. wait_event makrolarındaki koşula 
    wake_up bakmamaktadır. wake_up makroları yalnızca thread'i bekleme kuyruğundan çıkartıp çalışma kuyruğuna taşımaktadır. Koşula 
    uyandırılmış thread'in kendisi bakmaktadır. Eğer koşul sağlanmıyorsa thread yeniden uyutulmaktadır. Yani biz koşulu sağlanır 
    duruma getirmeden wake_up işlemi yaparsak thread yeniden uykuya dalacaktır. (Zaten yukarıda da belirttiğimiz gibi yalnızca 
    "koşulu sağlayan thread'i uyandırması" mümkün değildir.)

    En çok kullanılan wake_up makroları şunlardır:

    wake_up(wq_head);
    wake_up_nr(wq_head, nr);
    wake_up_all(wq_head);
    wake_up_interruptible(wq_head);
    wake_up_interruptible_nr(wq_head, nr);
    wake_up_interruptible_all(wq_head);

    Bu makroların hepsi birinci parametre olarak bekleme kuyruğunun adresini almaktadır. Makroların çalışmasının anlaşılması 
    için bekleme kuyrukları hakkında biraz ayrıntıya girmek gerekir. Bekleme kuyruğunu temsil eden wait_queue_head_t yapısı şöyle 
    bildirilmiştir:

    struct wait_queue_head {
        spinlock_t lock;
        struct list_head head;
    };

    typedef struct wait_queue_head wait_queue_head_t;

    Görüldüğü gibi bu bir bağlı listedir. Bağlı liste spinlock ile korunmaktadır. Bu bağlı listenin düğümleri wait_queue_entry
    yapılarından oluşmaktadır.

    struct wait_queue_entry {
        unsigned int flags;
        void *private;
        wait_queue_func_t func;
        struct list_head entry;
    };

    Bu yapının ayrıntısına girmeyeceğiz. Ancak yapıdaki flags elemanına dikkat ediniz. Bekleme kuyruğuna yerleştirilen bir 
    thread'in exclusive bekleme yapıp yapmadığı (yani wait_event_intrerruptible_exclusive ile bekleme yapıp yapmadığı)
    bu flags elemanında saklanmaktadır. Bu wait kuyruğunun bekleyen thread'leri (onların task_struct adreslerini) tutan
    bir bağlı liste olduğunu varsayabilirsiniz. (Yapının private elemanı thread'leri temsil eden task_struct yapı nesnelerinin 
    adreslerini tutmaktadır.) Yani bekleme kuyrukları aşağıdaki gibi düşünülebilir:

    T1 ---> T2 ---> T3 ---> T4 ---> T5 ---> T6 ---> T7 ---> T8 ---> NULL

    Bu thread'lerden bazıları exclusive bekleme yapmış olabilir. Bunları (E) ile belirtelim:

    T1 ---> T2 ---> T3 ---> T4(E) ---> T5 ---> T6(E) ---> T7 ---> T8(E) ---> NULL

    Artık wake_up makrolarını açıklayabiliriz. wake_up makrosu kuyruğun başından itibaren ilk exclusive bekleme yapan thread'e 
    kadar bu thread de dahil olmak üzere tüm thread'leri uyandırmaktadır. Tabii bu thread'lerin hepsi uyandırıldıktan sonra 
    ayrıca koşula da bakacaktır. Örneğimizde wake_up makrosu çağrıldığında T1, T2, T3 ve T4 thread'leri uyandırılacaktır. Görüldüğü 
    gibi wake_up makrosu aslında 1 tane exclusive thread uyandırmaya çalışmaktadır. Ancak onu uyandırırken kuyruğun önündeki 
    exclusive olmayanları da uyandırmaktadır. Tabii bu anlatımdan anlaşılacağı gibi wake_up makrosu eğer kuyrukta hiç exclusive 
    bekleme yapan thread yoksa thread'lerin hepsini uyandırmaktadır.

    wake_up_nr makrosu, wake_up makrosu gibi davranır ancak 1 tane değil en fazla nr parametresiyle belirtilen sayıda exclusive 
    thread'i uyandırmaya çalışır. Başka bir deyişle wake_up(g_wq) çağrısı ile wake_up_nr(g_qw, 1) çağrısı aynı anlamdadır.
    Eğer yukarıdaki örnekte wake_up_nr(g_wq, 2) çağrısını yapmış olsaydık T1, T2, T2, T4, T5, T6 thread'leri uyandırılırdı. 
    Tabii yukarıda da belirttiğimiz gibi bu thread'lerin uyandırılmış olması wait_event makrolarından çıkılacağı anlamına gelmemektedir. 
    Uyandırma işleminden sonra koşula yeniden bakılmaktadır.

    wake_up_all makrosu bekleme kuyruğundaki tüm exclusive thread'leri ve exclusive olmayan thread'leri yani kısaca tüm thread'leri 
    uyandırmaktadır. Tabii yine uyanan thread'ler koşula bakacaktır.

    wake_up_interruptible, wake_up_interruptible_nr ve wake_up_interruptible_all makroları interruptible olmayan makrolar 
    gibi çalışmaktadır. Ancak bu makrolar bekleme kuyruğunda yalnızca "interruptible" wait_event fonksiyonlarıyla bekletilmiş 
    thread'lerle ilgilenmektedir. Diğer thread'ler kuyrukta yokmuş gibi davranmaktadır.

    wake_up makroları birden fazla thread'i uyandırabildiğine göre uyanan thread'lerin yeniden uykuya dalması gerekebilir. Çünkü 
    programcı yalnızca bir thread'in çalışmaya devam etmesini isteyebilir. Bu durumda tıpkı kullanıcı modundaki koşul değişkenlerindeki 
    gibi bir kalıp kullanılabilir:

    if (mutex_lock_interruptible(&g_mutex) < 0)
        return -ERESTARTSYS;

    while (koşul_sağlanmadığı_sürece) {
        mutex_unlock(&g_mutex);
        if (wait_event_interruptible(g_wq, uyanık_kalma_koşulu) != 0)
            return -ERESTARTSYS;
        if (mutex_lock_interruptible(&g_mutex) < 0)
            return -ERESTARTSYS;
    }

    /* KRİTİK KOD, bu noktaya koşulu sağlayan ve uyandırılan tek bir thread gelir */

    mutex_unlock(&g_mutex);

    Burada birden fazla thread uyandırıldığında bunlardan yalnızca biri mutex kilidini alarak kritik koda girmektedir. Eğer 
    kritik kod içerisinde koşul sağlanmaz hale getirilirse bu durumda diğer thread'ler while döngüsü nedeniyle yeniden uykuya 
    dalacaktır.

    Örneğin boru aygıt sürücüsünde okuma yapan thread'ler eğer boruda hiç byte yoksa bloke olmalıdır. O halde buradaki koşul 
    g_count > 0 olmalıdır. Boruya yazan thread g_count değerini güncelledikten sonra eğer g_count önceden sıfırsa wake_up 
    makrolarıyla bekleyen thread'leri uyandırır. Thread'ler uyandıktan sonra yukarıdaki while döngüsünde bunlardan yalnızca 
    biri mutex kilidini alır. Nutex kilidini alan thread'de borudan okuma yapar. Eğer okuma sonucunda g_count hala > 0 durumunda
    ise başka bir thread daha okuma yapacaktır. Taki g_count değeri 0 olana kadar. Bu durumda diğer thread'ler boruya yeni 
    bir yazma yapılana kadar blokede bekleyeceklerdir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												97. Ders 22/04/2025 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aygıt sürücümüzün read ve write fonksiyonları aşağıdaki gibi olsun:

    wait_queue_head_t g_wq;
    atomic_t g_flag;
    ...

    static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
    {
        printk(KERN_INFO "wait-driver read...\n");

        atomic_set(&g_flag, 0);
        if (wait_event_interruptible(g_wq, atomic_read(&g_flag) != 0) != 0) {
            printk(KERN_INFO "Signal occurred...");
            return -ERESTARTSYS;
        }

        return 0;
    }

    static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off)
    {
        printk(KERN_INFO "wait-driver write...\n");

        atomic_set(&g_flag, 1);
        wake_up_interruptible(&g_wq);

        return 0;
    }

    Burada eğer birden fazla thread read yaparsa exclusive olmayan bir biçimde bekleme kuyruğunda bekleyecektir. write işleminde
    wake_up_interruptible makrosu ile uyandırma yapıldığına dikkat ediniz. Bekleme kuyruğunda exclusive bekleyen thread olmadığına 
    göre burada tüm read yapan thread'ler uyandırılacaktır. Onların koşulları sağlandığı için hepsi read fonksiyonundan çıkacaktır. 
    Şimdi bu read fonksiyonunda exclusive bekleme yapmış olalım:

    static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
    {
        printk(KERN_INFO "wait-driver read...\n");

        atomic_set(&g_flag, 0);
        if (wait_event_interruptible_exclusive(g_wq, atomic_read(&g_flag) != 0) != 0) {
            printk(KERN_INFO "Signal occurred...");
            return -ERESTARTSYS;
        }

        return 0;
    }

    Artık write fonksiyonunda wake_up makrosu çağrıldığında yalnızca bir tane exclusive bekleme yapan thread uyandırılacağı 
    için read fonksiyonundan yalnızca bir thread çıkacaktır. Test için aşağıdaki kodları kullanabilirsiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/* wait-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>
#include <asm/atomic.h>
#include <linux/wait.h>

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("Wait-Driver");

static int generic_open(struct inode *inodep, struct file *filp);
static int generic_release(struct inode *inodep, struct file *filp);
static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off);
static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off);

static dev_t g_dev;
static struct cdev *g_cdev;
static struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = generic_open,
	.read = generic_read,
	.write = generic_write,
	.release = generic_release
};

static wait_queue_head_t g_wq;
static atomic_t g_flag;

static int __init generic_init(void)
{
	int result;

	printk(KERN_INFO "wait-driver module initialization...\n");

	if ((result = alloc_chrdev_region(&g_dev, 0, 1, "wait-driver")) < 0) {
		printk(KERN_INFO "cannot alloc char driver!...\n");
		return result;
	}

	if ((g_cdev = cdev_alloc()) == NULL) {
		printk(KERN_INFO "cannot allocate cdev!...\n");
		return -ENOMEM;
	}

	g_cdev->owner = THIS_MODULE;
	g_cdev->ops = &g_fops;

	if ((result = cdev_add(g_cdev, g_dev, 1)) < 0) {
		unregister_chrdev_region(g_dev, 1);
		printk(KERN_ERR "cannot add device!...\n");
		return result;
	}

	init_waitqueue_head(&g_wq);

	return 0;
}

static void __exit generic_exit(void)
{
	cdev_del(g_cdev);
	unregister_chrdev_region(g_dev, 1);

	printk(KERN_INFO "wait-driver module exit...\n");
}

static int generic_open(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "wait-driver opened...\n");

	return 0;
}

static int generic_release(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "wait-driver closed...\n");

	return 0;
}

static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
{
	printk(KERN_INFO "wait-driver read...\n");

	atomic_set(&g_flag, 0);
	if (wait_event_interruptible_exclusive(g_wq, atomic_read(&g_flag) != 0) != 0) {
		printk(KERN_INFO "Signal occurred...");
		return -ERESTARTSYS;
	}

	return 0;
}

static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off)
{
	printk(KERN_INFO "wait-driver write...\n");

	atomic_set(&g_flag, 1);
	wake_up_interruptible(&g_wq);

	return 0;
}

module_init(generic_init);
module_exit(generic_exit);

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* load (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1
mode=666

/sbin/insmod ./$module.ko ${@:2} || exit 1
major=$(awk "\$2 == \"$module\" {print \$1}" /proc/devices)
rm -f $module
mknod -m $mode $module c $major 0

/* unload (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1

/sbin/rmmod ./$module.ko || exit 1
rm -f $module

/* wait-test-read.c */

#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <unistd.h>

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[32];
	ssize_t result;

	if ((fd = open("wait-driver", O_RDONLY)) == -1)
		exit_sys("open");

	printf("reading begins...\n");
	if ((result = read(fd, buf, 32)) == -1)
		exit_sys("result");

	printf("Ok\n");

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/* wait-test-write.c */

#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <unistd.h>

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[32] = {0};

	if ((fd = open("wait-driver", O_WRONLY)) == -1)
		exit_sys("open");

	if (write(fd, buf, 32) == -1)
		exit_sys("write");

	printf("Ok\n");

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
    Birden fazla thread'in uyandırıldığı durumda bunların yalnızca bir tanesinin kritik koda girmesini sağlayan kalıbı 
    anımsayınız:

    if (mutex_lock_interruptible(&g_mutex) < 0)
        return -ERESTARTSYS;

    while (koşul_sağlanmadığı_sürece) {
        mutex_unlock(&g_mutex);
        if (wait_event_interruptible(g_wq, uyanık_kalma_koşulu) != 0)
            return -ERESTARTSYS;
        if (mutex_lock_interruptible(&g_mutex) < 0)
            return -ERESTARTSYS;
    }

    /* KRİTİK KOD, bu noktaya koşulu sağlayan ve uyandırılan tek bir thread gelir */

    mutex_unlock(&g_mutex);

    Aşağıdaki kodda bu kalıp uygulanmıştır. Böylece her write işlemi yapıldığında yalnızca tek bir thread gerçek anlamda uyanıp
    kritik koda girecektir. Aygıt sürücünün read ve write fonksiyonları aşağıda verilmiştir:
-----------------------------------------------------------------------------------------------------------------------------*/

/* blocking-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>
#include <asm/atomic.h>
#include <linux/wait.h>

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("General Character Device Driver");

static int generic_open(struct inode *inodep, struct file *filp);
static int generic_release(struct inode *inodep, struct file *filp);
static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off);
static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off);

static dev_t g_dev;
static struct cdev g_cdev;
static struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = generic_open,
	.read = generic_read,
	.write = generic_write,
	.release = generic_release
};
static int g_flag;
static wait_queue_head_t g_wq;
static DEFINE_MUTEX(g_mutex);

static int __init generic_init(void)
{
	int result;

	printk(KERN_INFO "blocking-driver init...\n");

	if ((result = alloc_chrdev_region(&g_dev, 0, 1, "blocking-driver")) < 0) {
		printk(KERN_ERR "cannot #include <asm/atomic.h> register device!...\n");
		return result;
	}

	cdev_init(&g_cdev, &g_fops);
	if ((result = cdev_add(&g_cdev, g_dev, 1)) < 0) {
		unregister_chrdev_region(g_dev, 1);
		printk(KERN_ERR "cannot add device!...\n");

		return result;
	}

	init_waitqueue_head(&g_wq);

	return 0;
}

static void __exit generic_exit(void)
{
	cdev_del(&g_cdev);
	unregister_chrdev_region(g_dev, 1);
	printk(KERN_INFO "blocking-driver exit...\n");
}

static int generic_open(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "blocking-driver opened...\n");

	return 0;
}

static int generic_release(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "blocking-driver closed...\n");

	return 0;
}

static ssize_t generic_read(struct file *filp, char *buf, size_t size, loff_t *off)
{
	printk(KERN_INFO "blocking...\n");

	g_flag = 0;

	if (mutex_lock_interruptible(&g_mutex) < 0)
		return -ERESTARTSYS;

	while (g_flag == 0) {
		mutex_unlock(&g_mutex);
		if (wait_event_interruptible(g_wq, g_flag != 0) < 0)
			return -ERESTARTSYS;
		if (mutex_lock_interruptible(&g_mutex) < 0)
			return -ERESTARTSYS;
		printk(KERN_INFO "waking up...\n");
	}
	g_flag = 0;
	printk(KERN_INFO "enters critical section...\n");

	mutex_unlock(&g_mutex);

	return 0;
}

static ssize_t generic_write(struct file *filp, const char *buf, size_t size, loff_t *off)
{
	printk(KERN_INFO "wake up...\n");
	g_flag = 1;
	wake_up_interruptible(&g_wq);

	return 0;
}

module_init(generic_init);
module_exit(generic_exit);

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* load (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1
mode=666

/sbin/insmod ./$module.ko ${@:2} || exit 1
major=$(awk "\$2 == \"$module\" {print \$1}" /proc/devices)
rm -f $module
mknod -m $mode $module c $major 0

/* unload (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1

/sbin/rmmod ./$module.ko || exit 1
rm -f $module

/* wait-test-read.c */

#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <unistd.h>

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[32];
	ssize_t result;

	if ((fd = open("wait-driver", O_RDONLY)) == -1)
		exit_sys("open");

	printf("reading begins...\n");
	if ((result = read(fd, buf, 32)) == -1)
		exit_sys("result");

	printf("Ok\n");

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/* wait-test-write.c */

#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <unistd.h>

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[32] = {0};

	if ((fd = open("wait-driver", O_WRONLY)) == -1)
		exit_sys("open");

	if (write(fd, buf, 32) == -1)
		exit_sys("write");

	printf("Ok\n");

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
    Burada bir noktaya dikkatinizi çekmek istiyoruz. Daha önce görmüş olduğumuz mutex, semaphore, read/write kilitleri gibi 
    senkronizasyon nesnelerinin kendilerinin oluşturduğu bekleme kuyrukları vardır. Bu senkronizasyon nesneleri bloke oluşturmak
    için kendi bekleme kuyruklarını kullanmaktadır. Çekirdek kodları içerisinde bu senkronizasyon nesneleri için oluşturulmuş 
    bekleme kuyruklarını görebilirsiniz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												98. Ders 24/04/2025 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de daha önce yapmış olduğumuz boru örneğimizi gerçek bir boru haline getirelim. Yani eğer boruda en az 1 byte boş 
    alan kalmadıysa read fonksiyonu blokede en az 1 byte okuyana kadar beklesin. Eğer boruda tüm bilgileri yazacak kadar boş 
    yer kalmadıysa bu kez de yazan taraf blokede beklesin. Okuyan thread kuyruktaki byte sayısını belirten g_count == 0 olduğu 
    sürece bekleme kuyruğunda beklemelidir. Tabii bizim kuyruk üzerinde işlem yaptığımız kısımları senkronize etmemiz gerekir. 
    Bunu da bir binary semaphore nesnesi ya da mutex nesnesi iel sağlayabiliriz. Semaphore nesnesini ve bekleme kuyruğunu aşağıdaki 
    gibi yaratabiliriz:

    static wait_queue_head_t g_wq;
    DEFINE_SEMAPHORE(g_sem);

    Okuyan taraf önce semaphore kilidini eline almalı ancak eğer uykuya dalacaksa onu serbest bırakıp uykuya dalmalıdır. Kuyruk 
    üzerinde aynı anda işlemler yapılabileceği için tüm işlemlerin kritik kod içerisinde ele alınması uygun olur. O halde read 
    işlemindeki bloke olmanın tipik çatısı şöyle oluşturulabilir:

    ...
    if (down_interruptible(&g_sem) != 0)
        return -ERESTARTSYS;

    while (g_count == 0) {
        up(&g_sem);
        if (wait_event_interruptible(g_wqread, g_count > 0) != 0)
            return -ERESTARTSYS;
        if (down_interruptible(&g_sem) != 0)
            return -ERESTARTSYS;
    }

    // kuyruktan okuma işlemleri

    up(&g_sem);

    Burada önce down_interruptible fonksiyonu ile semaphore kilitlenmeye çalışılmıştır. Eğer semaphore zaten kilitliyse semaphore'un 
    kendi bekleme kuyruğunda thread uykuya dalacaktır. Daha sonra g_count değerine bakılmıştır. Eğer g_count değeri 0 ise önce 
    semaphore serbest bırakılıp sonra thread bekleme kuyruğunda uyutulmuştur. Thread bekleme kuyruğundan uyandırıldığında yeniden 
    semaphore kontrolünü ele almaktadır. Tabii eğer birden fazla thread bekleme kuyruğundan uyandırılırsa yalnızca bunlardan biri 
    semaphore kontrolünü ele alacaktır. Semaphore kilidini alan thread bundan sonra kuyruktan bilgiler okunacak ve semaphore kilidini 
    serbest bırakılacaktır. Eğer birden fazla thread bekleme kuyruğundan uyanmışsa bu kez diğer bir thread semaphore kontrolünü ele 
    alacak ve g_count değerine bakacaktır.

    Benzer biçimde write işleminin de çatısı aşağıdaki gibidir:

    if (down_interruptible(&g_sem) != 0)
        return -ERESTARTSYS;

    while (PIPE_BUFFER_SIZE - g_count < size) {
        up(&g_sem);
        if (wait_event_interruptible(g_wqwrite, PIPE_BUFFER_SIZE - g_count >= size) != 0)
            return -ERESTARTSYS;
        if (down_interruptible(&g_sem) != 0)
            return -ERESTARTSYS;
    }

    // kuyruğa yazma işlemleri

    up(&g_sem);

    Burada benzer işlemler uygulanmıştır. Eğer kuyrukta yazma yapılmak istenen kadar boş alan varsa akış while döngüsünün içerisine 
    girmeyecektir. (Buradaki while koşulunun "PIPE_BUFFER_SIZE - g_count < size" biçiminde olduğuna dikkat ediniz.) Dolayısıyla yazma 
    işlemi kritik kod içerisinde yapılabilecektir. Ancak kuyrukta yeteri kadar yer yoksa semaphore kilidi serbest bırakılıp thread 
    bekleme kuyruğunda bekletilecektir. Çıkışta benzer işlemler yapılmaktadır.

    Aslında burada spinlock nesneleri de kullanılabilir. Ancak zaten mutex, semaphore ve read/write lock nesneleri kendi içerisinde 
    bir miktar spin yapmaktadır. Spinlock için şu durumları gözden geçirmelisiniz:

    - Spinlock nesnesinde bekleme CPU zamanı harcanarak meşgul bir döngü içerisinde yapılmaktadır. Dolayısıyla spinlock nesneleri 
    kilidin kısa süreli bırakılacağından emin olunabiliyorsa kullanılmalıdır.

    - Spinlock içerisinde bağlamsal geçiş kapatılmakta ve sinyal işlemleri de bekletilmektedir. Yani spinlock beklemelerinin 
    "interruptible" bir biçimi yoktur.

    Örneğimizde kilitli kalınan kod miktarı dikkate alındığında semaphore ya da mutex nesnelerinin kullanılmasının daha uygun 
    olacağı söylenebilir.

    Burada yazma işlemleri için "yazma bekleme kuyruğu" ve okuma işlemleri için "okuma bekleme kuyruğu" biçiminde iki bekleme
    kuyruğu olduğuna dikkat ediniz. Çünkü yazan taraf okuma bekleme kuyruğundaki thread'leri okuyan taraf ise yazma bekleme 
    kuyruğundaki thread'leri uyandırmak isteyecektir.
-----------------------------------------------------------------------------------------------------------------------------*/

/* pipe-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>
#include <linux/semaphore.h>
#include <linux/wait.h>

#define PIPE_BUFFER_SIZE		10
#define MIN(a, b)	((a) < (b) ? (a) : (b))

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("Pipe Device Driver");

static int pipe_driver_open(struct inode *inodep, struct file *filp);
static int pipe_driver_release(struct inode *inodep, struct file *filp);
static ssize_t pipe_driver_read(struct file *filp, char *buf, size_t size, loff_t *off);
static ssize_t pipe_driver_write(struct file *filp, const char *buf, size_t size, loff_t *off);

static dev_t g_dev;
static struct cdev g_cdev;
static struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = pipe_driver_open,
	.read = pipe_driver_read,
	.write = pipe_driver_write,
	.release = pipe_driver_release
};

static unsigned char g_pipebuf[PIPE_BUFFER_SIZE];
static size_t g_head;
static size_t g_tail;
static size_t g_count;
static wait_queue_head_t g_wqread;
static wait_queue_head_t g_wqwrite;
static int n_readers;
static int n_writers;

static DEFINE_SEMAPHORE(g_sem);

static int __init pipe_driver_init(void)
{
	int result;

	printk(KERN_INFO "pipe-driver init...\n");

	if ((result = alloc_chrdev_region(&g_dev, 0, 1, "pipe-driver")) < 0) {
		printk(KERN_ERR "cannot register device!...\n");
		return result;
	}

	cdev_init(&g_cdev, &g_fops);
	if ((result = cdev_add(&g_cdev, g_dev, 1)) < 0) {
		unregister_chrdev_region(g_dev, 1);
		printk(KERN_ERR "cannot add device!...\n");

		return result;
	}

	init_waitqueue_head(&g_wqread);
	init_waitqueue_head(&g_wqwrite);

	return 0;
}

static void __exit pipe_driver_exit(void)
{
	cdev_del(&g_cdev);
	unregister_chrdev_region(g_dev, 1);

	printk(KERN_INFO "pipe-driver exit...\n");
}

static int pipe_driver_open(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "pipe-driver opened...\n");

	return 0;
}

static int pipe_driver_release(struct inode *inodep, struct file *filp)
{
	printk(KERN_INFO "pipe-driver closed...\n");

	return 0;
}

static ssize_t pipe_driver_read(struct file *filp, char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;
	ssize_t result = -EFAULT;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	while (g_count == 0) {
		up(&g_sem);
		if (wait_event_interruptible(g_wqread, g_count > 0) != 0)
			return -ERESTARTSYS;
		if (down_interruptible(&g_sem) != 0)
			return -ERESTARTSYS;
	}

	esize = MIN(size, g_count);
	if (g_head >= g_tail)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_head);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_to_user(buf, g_pipebuf + g_head, size1) != 0)
		goto EXIT;

	if (size2 != 0)
		if (copy_to_user(buf + size1, g_pipebuf, size2) != 0)
			goto EXIT;

	g_head = (g_head + esize) % PIPE_BUFFER_SIZE;
	g_count -= esize;

	result = esize;
EXIT:
	wake_up_interruptible(&g_wqwrite);
	up(&g_sem);

	return result;
}

static ssize_t pipe_driver_write(struct file *filp, const char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;
	ssize_t result = -EFAULT;

	if (size > PIPE_BUFFER_SIZE)
		size = PIPE_BUFFER_SIZE;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	while (PIPE_BUFFER_SIZE - g_count < size) {
		up(&g_sem);
		if (wait_event_interruptible(g_wqwrite, PIPE_BUFFER_SIZE - g_count >= size) != 0)
			return -ERESTARTSYS;
		if (down_interruptible(&g_sem) != 0)
			return -ERESTARTSYS;
	}

	esize = MIN(size, PIPE_BUFFER_SIZE - g_count);

	if (g_tail >= g_head)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_tail);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_from_user(g_pipebuf + g_tail, buf, size1) != 0)
		goto EXIT;
	if (size2 != 0)
		if (copy_from_user(g_pipebuf, buf + size1, size2) != 0)
			goto EXIT;

	g_tail = (g_tail + esize ) % PIPE_BUFFER_SIZE;
	g_count += esize;

	result = esize;

EXIT:
	wake_up_interruptible(&g_wqread);
	up(&g_sem);

	return esize;
}

module_init(pipe_driver_init);
module_exit(pipe_driver_exit);

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* load (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1
mode=666

/sbin/insmod ./$module.ko ${@:2} || exit 1
major=$(awk "\$2 == \"$module\" {print \$1}" /proc/devices)
rm -f $module
mknod -m $mode $module c $major 0

/* unload (bu satırı dosyaya kopyalamayınız ) */

#!/bin/bash

module=$1

/sbin/rmmod ./$module.ko || exit 1
rm -f $module

/* pwriter.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	char *str;
	ssize_t result;

	if ((fd = open("pipe-driver", O_WRONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Enter text:");
		fflush(stdout);
		if (fgets(buf, BUFFER_SIZE, stdin) == NULL)
			continue;
		if ((str = strchr(buf, '\n')) != NULL)
			*str = '\0';
		if (!strcmp(buf, "quit"))
			break;
		if ((result = write(fd, buf, strlen(buf))) == -1)
			exit_sys("write");

		printf("%jd bytes written...\n", (intmax_t)result);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/* preader.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	int n;
	ssize_t result;

	if ((fd = open("pipe-driver", O_RDONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Number of bytes to read? ");
		scanf("%d", &n);
		if (n == 0)
			break;
		if ((result = read(fd, buf, n)) == -1)
			exit_sys("read");
		buf[result] = '\0';
		printf("%jd bytes read: %s\n", (intmax_t)result, buf);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
    Yukarıda vermiş olduğumuz blokeli boru aygıt sürücüsü örneği UNIX/Linux sistemlerinde bulunan isimli borulara oldukça 
    benzemektedir. Ancak UNIX/Linux sistemlerindeki isimli boruların yukarıdaki aygıt sürücümüzde olmayan şu ek özellikleri 
    vardır:

    - Anımsanacağı gibi isimli boruyu bir bir prosesin thread'i O_RDONLY bayrağı ile okuma amaçlı açmak istediğinde eğer bu 
    boruyu herhangi bir prosesin thread'i O_WRONLY bayrağı ile yazma amaçlı açmamışsa okuma amaçlı açmaya çalışan thread boru 
    yazma amaçlı açılana kadar open fonksiyonunda bloke olmaktadır. Benzer biçimde bir thread isimli boruyu O_WRONLY bayrağı 
    ile yazma amaçlı açmak istediğinde bu boruyu herhangi bir prosesin thread'i O_RONLY bayrağı ile okuma modunda açmamışsa yazma
    amaçlı açmaya çalışan thread boru okuma amaçlı açılana kadar open fonksiyonunda bloke olmaktadır. Bizim aygıt sürücümüzde 
    böyle bir özellik yoktur.

    - İsimli borularda boru boşken okuma yapılmak istendiğinde eğer boruya yazma yapma potansiyelinde hiçbir thread kalmamışsa
    read fonksiyonu blokeye yol açmamakta 0 ile geri dönmektedir. Zaten boru haberleşmesi bu biçimde sonlandırılır. Yani boruya 
    yazan taraf önce boruyu kapatır. Borudan okuyan taraf borudakileri okur. Eğer boruda hiçbir şey kalmazsa read fonksiyonu 
    0 ile geri döner. Okuyan taraf da döngüden çıkarak işlemini sonlandırır. Bizim yukarıdaki boru aygıt sürücümüzde bu özellik 
    yoktur.

    - İsimli borularda borudan okuma yapma potansiyelinde olan hiçbir thread yoksa boruya yazma yapıldığında SIGPIPE sinyali 
    oluşturulmaktadır. Bu sinyal de ele alınmadıysa yazma yapan prosesin sonlanmasına yol açar. Bizim boru aygıt sürücümüzde
    de bu özellik yoktur.

    Pekiyi bu özellikler nasıl sağlanabilir? Bizim open fonksiyonunda bloke oluşturabilmemiz için boruya yazma potansiyelinde 
    olan ve borudan okuma yapma potansiyelinde olan kaç thread'in bulunduğunu tutmamız gerekir. Tüm prosesler aygıt sürücüyü 
    açtığına göre bu işlem aygıt sürücünün open fonksiyonunda ve release fonksiyonunda yapılabilir. Dosya open fonksiyonu 
    ile açıldığında filp parametresinin gösterdiği yerdeki file nesnesinin f_flags elemanı open fonksiyonunda kullanılan açma
    bayrağını belirtmektedir. Biz de iki sayaç alıp kaç thread'in okuma amaçlı kaç thread'in yazma amaçlı olarak boruyu açtığını
    tutabiliriz.

    Aşağıdaki örnekte boru aygıt sürücümüzün yukarıdaki belirtilen eksiklikleri giderilmiştir. Burada aygıt sürücünün open 
    fonksiyonunda bloke işlemi şöyle sağlanmıştır:

    static int pipe_driver_open(struct inode *inodep, struct file *filp)
    {
        int accmode = filp->f_flags & O_ACCMODE;

        if (down_interruptible(&g_sem) != 0)
            return -ERESTARTSYS;

        if (accmode == O_RDONLY) {
            ++g_nreaders;
            wake_up_interruptible(&g_writeopen);
            while (g_nwriters == 0) {
                up(&g_sem);
                if (wait_event_interruptible(g_readopen, g_nwriters > 0))
                    return -ERESTARTSYS;
                if (down_interruptible(&g_sem))
                    return -ERESTARTSYS;
            }
        }
        else if (accmode == O_WRONLY) {
            ++g_nwriters;
            wake_up_interruptible(&g_readopen);
            while (g_nreaders == 0) {
                up(&g_sem);
                if (wait_event_interruptible(g_writeopen, g_nreaders > 0))
                    return -ERESTARTSYS;
                if (down_interruptible(&g_sem))
                    return -ERESTARTSYS;
            }
        }

        else if (accmode == O_RDWR) {
            ++g_nreaders;
            ++g_nwriters;
            wake_up_interruptible(&g_readopen);
            wake_up_interruptible(&g_writeopen);
        }
        up(&g_sem);

        return 0;
    }

    Aygıt dosyasının hangi bayrakla açıldığının belirlenmesi için filp göstericisinin gösterdiği yerdeki file nesnesinin f_ops
    elemanına bakılmıştır. Bu elemanın ilk 2 biti dışındaki bitleri başka bayraklarla ilgili olduğu için önce ilk 2 bit 
    maskelenmiştir:

    int accmode = filp->f_flags & O_ACCMODE;

    Sonra eğer aygıt dosyası yazma amaçlı açılmışsa okuma amaçlı açış yapılmış mı diye, okuma amaçlı açılmışsa yazma amaçlı açış 
    var mı diye bakılmıştır. Kodumuzda open fonksiyonunda bloke oluşturmak için iki ayrı bekleme kuyruğunun daha yaratıldığını 
    görüyorsunuz. Aygıt sürücümüzün release fonksiyonunda bu sayaçlar aşağıdaki gibi eksiltilmiştir:

    static int pipe_driver_release(struct inode *inodep, struct file *filp)
    {
        int accmode = filp->f_flags & O_ACCMODE;

        if (down_interruptible(&g_sem) != 0)
            return -ERESTARTSYS;

        if (accmode == O_RDONLY)
            --g_nreaders;
        else if (accmode == O_WRONLY)
            --g_nwriters;
        else if (accmode == O_RDWR) {
            --g_nreaders;
            --g_nwriters;

        }
        up(&g_sem);

        return 0;
    }

    Aygıt sürücümüzün read fonksiyonunda eğer boruya yazma potansiyelinde olan hiçbir thread kalmamışsa read fonksiyonu 0 ile 
    geri döndürülmüştür:

    ...
    if (down_interruptible(&g_sem) != 0)
        return -ERESTARTSYS;

    while (g_count == 0) {
        if (g_nwriters == 0) {
            result = 0;
            goto EXIT;
        }
        up(&g_sem);
        if (wait_event_interruptible(g_wqread, g_count > 0 || g_nwriters == 0) != 0)
            return -ERESTARTSYS;
        if (down_interruptible(&g_sem) != 0)
            return -ERESTARTSYS;
    }
    ...

    Benzer biçimde aygıt sürücümüzün write fonksiyonunda eğer borudan okuma yapma potansiyelinde hiçbir thread kalmamışsa 
    SIGPIPE sinyali oluşturulmuştur:

    ...
    if (g_nreaders == 0) {
        up(&g_sem);
        send_sig(SIGPIPE, current, 0);
        return -EPIPE;
    }
    while (PIPE_BUFFER_SIZE - g_count < size) {
        up(&g_sem);
        if (wait_event_interruptible(g_wqwrite, PIPE_BUFFER_SIZE - g_count >= size || g_nreaders == 0) != 0)
            return -ERESTARTSYS;
        if (down_interruptible(&g_sem) != 0)
            return -ERESTARTSYS;
        if (g_nreaders == 0) {
            up(&g_sem);
            send_sig(SIGPIPE, current, 0);
            return -EPIPE;
        }
    }
    ...

    Aygıt sürücümüzün release fonksiyonunda da sayaçlar eksiltilmiştir:

    int accmode = filp->f_flags & O_ACCMODE;

    if (down_interruptible(&g_sem) != 0)
        return -ERESTARTSYS;

    if (accmode == O_RDONLY)
        --g_nreaders;
    else if (accmode == O_WRONLY)
        --g_nwriters;
    else if (accmode == O_RDWR) {
        --g_nreaders;
        --g_nwriters;

    }
    up(&g_sem);

    Aşağıda örnek bir bütün olarak verilmiştir.
-----------------------------------------------------------------------------------------------------------------------------*/

/* pipe-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>
#include <linux/semaphore.h>
#include <linux/wait.h>

#define PIPE_BUFFER_SIZE		10
#define MIN(a, b)	((a) < (b) ? (a) : (b))

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("Pipe Device Driver");

static int pipe_driver_open(struct inode *inodep, struct file *filp);
static int pipe_driver_release(struct inode *inodep, struct file *filp);
static ssize_t pipe_driver_read(struct file *filp, char *buf, size_t size, loff_t *off);
static ssize_t pipe_driver_write(struct file *filp, const char *buf, size_t size, loff_t *off);

static dev_t g_dev;
static struct cdev g_cdev;
static struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = pipe_driver_open,
	.read = pipe_driver_read,
	.write = pipe_driver_write,
	.release = pipe_driver_release
};

static unsigned char g_pipebuf[PIPE_BUFFER_SIZE];
static size_t g_head;
static size_t g_tail;
static size_t g_count;
static wait_queue_head_t g_wqwriteopen;
static wait_queue_head_t g_wqreadopen;
static wait_queue_head_t g_wqread;
static wait_queue_head_t g_wqwrite;
static int g_nreaders;
static int g_nwriters;

static DEFINE_SEMAPHORE(g_sem);

static int __init pipe_driver_init(void)
{
	int result;

	printk(KERN_INFO "pipe-driver init...\n");

	if ((result = alloc_chrdev_region(&g_dev, 0, 1, "pipe-driver")) < 0) {
		printk(KERN_ERR "cannot register device!...\n");
		return result;
	}

	cdev_init(&g_cdev, &g_fops);
	if ((result = cdev_add(&g_cdev, g_dev, 1)) < 0) {
		unregister_chrdev_region(g_dev, 1);
		printk(KERN_ERR "cannot add device!...\n");

		return result;
	}

	init_waitqueue_head(&g_wqreadopen);
	init_waitqueue_head(&g_wqwriteopen);
	init_waitqueue_head(&g_wqread);
	init_waitqueue_head(&g_wqwrite);

	return 0;
}

static void __exit pipe_driver_exit(void)
{
	cdev_del(&g_cdev);
	unregister_chrdev_region(g_dev, 1);

	printk(KERN_INFO "pipe-driver exit...\n");
}

static int pipe_driver_open(struct inode *inodep, struct file *filp)
{
	int accmode = filp->f_flags & O_ACCMODE;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	if (accmode == O_RDONLY) {
		++g_nreaders;
		wake_up_interruptible(&g_wqwriteopen);
		while (g_nwriters == 0) {
			up(&g_sem);
			if (wait_event_interruptible(g_wqreadopen, g_nwriters > 0))
				return -ERESTARTSYS;
			if (down_interruptible(&g_sem))
				return -ERESTARTSYS;
		}
	}
	else if (accmode == O_WRONLY) {
		++g_nwriters;
		wake_up_interruptible(&g_wqreadopen);
		while (g_nreaders == 0) {
			up(&g_sem);
			if (wait_event_interruptible(g_wqwriteopen, g_nreaders > 0))
				return -ERESTARTSYS;
			if (down_interruptible(&g_sem))
				return -ERESTARTSYS;
		}
	}

	else if (accmode == O_RDWR) {
		++g_nreaders;
		++g_nwriters;
		wake_up_interruptible(&g_wqreadopen);
		wake_up_interruptible(&g_wqwriteopen);
	}
	up(&g_sem);

	return 0;
}

static int pipe_driver_release(struct inode *inodep, struct file *filp)
{
	int accmode = filp->f_flags & O_ACCMODE;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	if (accmode == O_RDONLY)
		--g_nreaders;
	else if (accmode == O_WRONLY)
		--g_nwriters;
	else if (accmode == O_RDWR) {
		--g_nreaders;
		--g_nwriters;
	}
	if (g_nreaders == 0)
		wake_up_interruptible(&g_wqwrite);
	if (g_nwriters == 0)
		wake_up_interruptible(&g_wqread);

	up(&g_sem);

	return 0;
}

static ssize_t pipe_driver_read(struct file *filp, char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;
	ssize_t result = -EFAULT;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	while (g_count == 0) {
		if (g_nwriters == 0) {
			result = 0;
			goto EXIT;
		}
		up(&g_sem);
		if (wait_event_interruptible(g_wqread, g_count > 0 || g_nwriters == 0) != 0)
			return -ERESTARTSYS;
		if (down_interruptible(&g_sem) != 0)
			return -ERESTARTSYS;
	}

	esize = MIN(size, g_count);
	if (g_head >= g_tail)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_head);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_to_user(buf, g_pipebuf + g_head, size1) != 0)
		goto EXIT;

	if (size2 != 0)
		if (copy_to_user(buf + size1, g_pipebuf, size2) != 0)
			goto EXIT;

	g_head = (g_head + esize) % PIPE_BUFFER_SIZE;
	g_count -= esize;

	result = esize;
EXIT:
	wake_up_interruptible(&g_wqwrite);
	up(&g_sem);

	return result;
}

static ssize_t pipe_driver_write(struct file *filp, const char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;
	ssize_t result = -EFAULT;

	if (size > PIPE_BUFFER_SIZE)
		size = PIPE_BUFFER_SIZE;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	if (g_nreaders == 0) {
		up(&g_sem);
		send_sig(SIGPIPE, current, 0);
		return -EPIPE;
	}
	while (PIPE_BUFFER_SIZE - g_count < size) {
		up(&g_sem);
		if (wait_event_interruptible(g_wqwrite, PIPE_BUFFER_SIZE - g_count >= size || g_nreaders == 0) != 0)
			return -ERESTARTSYS;
		if (down_interruptible(&g_sem) != 0)
			return -ERESTARTSYS;
		if (g_nreaders == 0) {
			up(&g_sem);
			send_sig(SIGPIPE, current, 0);
			return -EPIPE;
		}
	}

	esize = MIN(size, PIPE_BUFFER_SIZE - g_count);

	if (g_tail >= g_head)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_tail);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_from_user(g_pipebuf + g_tail, buf, size1) != 0)
		goto EXIT;
	if (size2 != 0)
		if (copy_from_user(g_pipebuf, buf + size1, size2) != 0)
			goto EXIT;

	g_tail = (g_tail + esize ) % PIPE_BUFFER_SIZE;
	g_count += esize;

	result = esize;

EXIT:
	wake_up_interruptible(&g_wqread);
	up(&g_sem);

	return esize;
}

module_init(pipe_driver_init);
module_exit(pipe_driver_exit);

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* load (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1
mode=666

/sbin/insmod ./$module.ko ${@:2} || exit 1
major=$(awk "\$2 == \"$module\" {print \$1}" /proc/devices)
rm -f $module
mknod -m $mode $module c $major 0

/* unload (bu satırı dosyaya kopyalamayınız ) */

#!/bin/bash

module=$1

/sbin/rmmod ./$module.ko || exit 1
rm -f $module

/* pwriter.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	char *str;
	ssize_t result;

	if ((fd = open("pipe-driver", O_WRONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Enter text:");
		fflush(stdout);
		if (fgets(buf, BUFFER_SIZE, stdin) == NULL)
			continue;
		if ((str = strchr(buf, '\n')) != NULL)
			*str = '\0';
		if (!strcmp(buf, "quit"))
			break;
		if ((result = write(fd, buf, strlen(buf))) == -1)
			exit_sys("write");

		printf("%jd bytes written...\n", (intmax_t)result);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/* preader.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	int n;
	ssize_t result;

	if ((fd = open("pipe-driver", O_RDONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Number of bytes to read? ");
		scanf("%d", &n);
		if (n == 0)
			break;
		if ((result = read(fd, buf, n)) == -1)
			exit_sys("read");
		if (result == 0)
			break;
		buf[result] = '\0';
		printf("%jd bytes read: %s\n", (intmax_t)result, buf);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
												99. Ders 06/05/2025 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aslında bekleme kuyrukları wait_queue_entry isimli yapı nesnelerinden oluşan bir çift bağlı listedir. wait_queue_head_t 
    yapısı da bağlı listenin ilk ve son elemanlarının adresini tutmaktadır:

    wait_queue_head_t <-----> wait_queue_entry <-----> wait_queue_entry <-----> wait_queue_entry <-----> wait_queue_entry ...

    Çekirdek kodlarında bu yapılar "include/linux/wait.h" dosyası içerisinde aşağıdaki gibi bildirilmiştir:

    struct wait_queue_head {
        spinlock_t	lock;
        struct list_head head;
    };

    typedef struct wait_queue_head wait_queue_head_t;

    struct wait_queue_entry {
        unsigned int flags;
        void *private;
        wait_queue_func_t func;
        struct list_head entry;
    };

    wait_queue_head yapısının içerisindeki list_head elemanı bağlı listenin ilk ve son elemanlarının adreslerini tutmaktadır. 
    Yapının lock elemanı ise bekleme kuyruğuna erişirken kullanılacak olan spinlock nesnesini belirtmektedir. Biz burada 
    wait_queue_entry yapısının ayrıntılarına girmeyeceğiz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz aygıt sürücü kodumuzda o anda quanta süresini bırakıp çizelgeleyicinin kendi algortimasına göre sıradaki thread'i 
    çizelgelemesini sağlayabiliriz. Bunun için schedule isimli çekirdek fonksiyonu kullanılmaktadır. Bu fonksiyon bloke 
    oluşturmamaktadır. Yalnızca thread'ler arası geçiş (context switch) oluşturmaktadır. schedule fonksiyonu herhangi bir 
    parametre almamaktadır:

    #include <linux/kernel.h>

    void schedule(void);

    Tabii koşullara bağlı olarak biz schedule fonksiyonunu çağırmış olsak bile işletim sistemi başka bir thread olmadığı için 
    ya da thread önceliklerinden dolayı yine bizim thread'imizi çizelgeleyebilir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aslında wait_event fonksiyonları export edilmiş birkaç fonksiyon çağrılarak yazılmıştır. Dolayısıyla wait_event fonksiyonlarını 
    çağırmak yerine programcı daha aşağı seviyeli (zaten wait_event fonksiyonlarının çağırmış olduğu) fonksiyonları çağırabilir. 
    Yani bu işlemi daha aşağı seviyede manuel de yapabilir. Prosesin manuel olarak wait kuyruğuna alınması prepare_to_wait ve 
    prepare_to_wait_exclusive isimli fonksiyonlar tarafından yapılmaktadır:

    #include <linux/wait.h>

    void prepare_to_wait(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state);
    void prepare_to_wait_exclusive(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry, int state);

    Bu fonksiyonların birinci parametreleri bekleme kuyruğu nesnesinin adresini, ikinci parametreleri bu kuyruğa yerleştirilecek 
    wait_queue_entry nesnesinin adresini almaktadır. Fonksiyonların üçüncü parametreleri TASK_UNINTERRUPTIBLE ya da TASK_INTERRUPTIBLE 
    biçiminde geçilebilir. Bir wait_queue_entry nesnesi şöyle oluşturulabilir:

    DEFINE_WAIT(wqentry);

    Ya da açıkça tanımlanıp init_wait makrosuyla ilk değerlenebilir. Örneğin:

    struct wait_queue_entry wqentry;
    ...
    init_wait(&wqentry);

    DEFINE_WAIT makrosu global tanımlamalarda kullanılamamaktadır. Çünkü bu makro küme parantezleri içerisinde sabit ifadesi olmayan 
    ifadeler barındırmaktadır. Ancak makro yerel tanımlamalarda kullanılabilir.

    Aslında prepare_to_wait ve prepare_to_wait_exclusive fonksiyonları bekleme kuyruğuna bir wait_queue_entry nesnesi eklemektedir. 
    Yani programcının bunun için yeni bir wait_queue_entry nesnesi oluşturması gerekmektedir. prepare_to_wait_exclusive fonksiyonu 
    exclusive uyuma için kullanılmaktadır.

    prepare_to_wait ve prepare_to_wait_exclusive fonksiyonları şunları yapmaktadır:

    1) Thread'i çalışma kuyruğundan çıkartıp bekleme kuyruğuna yerleştirir. (Çalışma kuyruğunun organizasyonu ve bu işlemin gerçek 
    ayrıntıları biraz karmaşıktır. Biz burada çalışma kuyruğunun organizasyonu üzerinde durmayacağız.)
    2) Thread'in durum bilgisini (task state) state parametresiyle belirtilen duruma çeker.
    3) prepare_to_wait fonksiyonu kuyruk elemanını exclusive olmaktan çıkartırken, prepare_to_wait_exclusive onu exclusive yapar.

    Thread'in çalışma kuyruğundan bekleme kuyruğuna aktarılması onun uykuya dalması anlamına gelmemektedir. Programcı artık thread 
    çalışma kuyruğunda olmadığına göre schedule fonksiyonu ile thread'ler arası geçiş (context switch) uygulamalı ve akış kontrolünü 
    başka bir thread'e bırakmalıdır. Zaten thread'in çalışma kuyruğundan çıkartılması artık yeniden çalışma kuyruğuna alınmadıktan 
    sonra uykuda bekletilmesi anlamına gelmektedir.

    Tabii biz prepare_to_wait ya da prepare_to_wait_exclusive fonksiyonlarını çağırdıktan sonra bir biçimde koşul durumuna bakmalıyız. 
    Eğer koşul sağlanmışsa hiç prosesi uykuya daldırmadan hemen bekleme kuyruğundan çıkarmalıyız. Eğer koşul sağlanmamışsa gerçekten 
    artık schedule fonksiyonuyla "thread'ler arası geçiş" uygulamalıyız. Thread'imiz schedule fonksiyonunu çağırdıktan sonra artık 
    uyandırılana kadar bir daha çizelgelenmeyecektir. Bu da bizim uykuya dalmamız anlamına gelmektedir.

    Pekiyi thread'imiz uyandırıldığında nereden çalışmaya devam edecektir? İşte schedule fonksiyonu thread'ler arası geçiş yaparken 
    kalınan yeri thread'e ilişkin task_struct yapısının içerisine kaydetmektedir. Kalınan yer schedule fonksiyonunun içerisinde 
    bir yerdir. O halde thread'imiz uyandırıldığında schedule fonksiyonunun içerisinden çalışmaya devam edecektir. Sonra schedule 
    fonksiyonu geri dönecek ve thread akışı devam edecektir.

    wake_up fonksiyonları thread'i bekleme kuyruklarından çıkartıp çalışma kuyruğuna eklemektedir. Ancak prepare_to_wait ve 
    prepare_to_wait_exclusive fonksiyonları çağrıldıktan sonra eğer koşulun zaten sağlandığı görülürse bu durumda uyandırma 
    wake_up fonksiyonlarıyla yapılmadığı için bekleme kuyruğundan thread'in geri çıkartılması da programcının sorumluluğundadır. 
    Bu işlem finish_wait fonksiyonu ile yapılmaktadır.

    #include <linux/wait.h>

    void finish_wait(struct wait_queue_head *wq_head, struct wait_queue_entry *wq_entry);

    Bu fonksiyon zaten thread wake_up fonksiyonları tarafından bekleme kuyruğundan çıkartılmışsa herhangi bir işlem yapmaz. 
    Bu durumda manuel uyuma şöyle yapılabilir.

    DEFINE_WAIT(wqentry);

    prepare_to_wait(&g_wq, &wqentry, TASK_UNINTERRUPTIBLE);
    if (!condition)
        schedule();
    finish_wait(&wqentry);

    Tabii eğer thread INTERRUPTIBLE olarak uyuyorsa schedule fonksiyonundan çıkıldığında sinyal dolayısıyla da çıkılmış olabilir. 
    Bunu anlamak için signal_pending isimli fonksiyon çağrılır. Bu fonksiyon sıfır dışı bir değerle geri dönmüşse uyandırma 
    işleminin sinyal yoluyla yapıldığı anlaşılır. Bu durumda tabii aygıt sürücüdeki fonksiyon -ERESTARTSYS ile geri döndürülmelidir. 
    signal_pending fonksiyonunun prototipi şöyledir:

    #include <linux/kernel.h>

    int signal_pending(struct task_struct *p);

    Fonksiyon parametre olarak thread'e ilişkin task_struct yapısının adresini almaktadır. Bu durumda INTERRUPTIBLE uyuma aşağıdaki 
    gibi yapılabilir:

    DEFINE_WAIT(wqentry);

    prepare_to_wait(&g_wq, &wqentry, TASK_INTERRUPTIBLE);
    if (!condition)
        schedule();
    if (signal_pending(current))
        return -ERESTARTSYS;
    finish_wait(&wqentry);

    wake_up makrolarının şunları yaptığını anımsayınız:

    1) Wait kuyruğundaki prosesleri çıkartarak run kuyruğuna yerleştirir.
    2) Prosesin durumunu TASK_RUNNING haline getirir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aslında wait_event fonksiyonları yukarıda açıkladığımız daha aşağı seviyeli fonksiyonlar kullanılarak gerçekleştirilmiştir. 
    Mevcut son Linux çekirdeğinde wait_event_interruptible makrosu şöyle yazılmıştır:

    #define wait_event_interruptible(wq_head, condition)		        \
    ({										                            \
        int __ret = 0;								                    \
        might_sleep();								                    \
        if (!(condition))							                    \
            __ret = __wait_event_interruptible(wq_head, condition);		\
        __ret;									                        \
    })

    Burada gcc'nin bileşik ifade de denilen bir eklentisi (extension) kullanılmıştır. Bu makro ayrıntılar göz ardı edilirse 
    __wait_event_interruptible makrosunu çağırmaktadır. Bu makro şöyle tanımlanmıştır:

    #define __wait_event_interruptible(wq_head, condition)				\
    ___wait_event(wq_head, condition, TASK_INTERRUPTIBLE, 0, 0,		    \
              schedule())

    Burada ___wait_event makrosunun interruptible olan ve olmayan kodların ortak makrosu olduğu görülmektedir. Bu 
    makro da şöyle tanımlanmıştır:

    #define ___wait_event(wq_head, condition, state, exclusive, ret, cmd)		\
    ({										                                    \
        __label__ __out;							                            \
        struct wait_queue_entry __wq_entry;					                    \
        long __ret = ret;	/* explicit shadow */				                \
                                                                                \
        init_wait_entry(&__wq_entry, exclusive ? WQ_FLAG_EXCLUSIVE : 0);	    \
        for (;;) {								                                \
            long __int = prepare_to_wait_event(&wq_head, &__wq_entry, state);   \
                                                                                \
            if (condition)							                            \
                break;							                                \
                                                                                \
            if (___wait_is_interruptible(state) && __int) {			            \
                __ret = __int;						                            \
                goto __out;						                                \
            }								                                    \
                                                                                \
            cmd;								                                \
        }									                                    \
        finish_wait(&wq_head, &__wq_entry);					                    \
    __out:	__ret;									                            \
    })
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bir dosyayı (boru dosyaları da diğer aygıt sürücü dosyaları da dahil olmak üzere) açarken kullanılan bayraklardan biri de 
    O_NONBLOCK bayrağıdır. Bu bayrağın normal dosyalarda (regular file) bir etkisi yoktur. Ancak borularda, soketlerde ve özel 
    bazı aygıt sürücülerde bu bayrak önemli bir işlevselliğe sahiptir. Bu işlevselliğe "blokesiz IO işlemleri (Non-blocking IO)" 
    denilmektedir.

    Blokesiz IO işlemlerinin temel fikri şudur: Bazı aygıtlardan (boru ve soketler de dahil olmak üzere) okuma yazma yapılırken 
    uzun süre beklemeye yol açabilecek bir bloke durumu oluşabilmektedir. Örneğin biz bir borudan okuma yapmak isteyelim. Ancak 
    boruda hiç byte olmasın. Bu durumda read fonksiyonu blokeye yol açacak ve boruya bilgi gelene kadar program akışı kesilecektir. 
    İşte blokesiz işlemlerde eğer ilgili işlem blokeye yol açabilecekse bloke oluşturulmamakta read ve write fonksiyonları
    başarısızlıkla geri dönmekte ve errno değeri de EAGAIN denilen özel bir değerle set edilmektedir. Örneğin biz içerisinde hiç 
    byte olmayan bir borudan read fonksiyonu ile 10 byte okumak isteyelim. Eğer boru default durumda olduğu gibi "blokeli modda" 
    açılmış ise read fonksiyonu en az 1 byte boruya yazılana kadar blokede kalır. Ancak eğer blokesiz modda isek bu durumda read 
    fonksiyonu bloke olmaz -1 değeriyle geri döner ve errno değeri EAGAIN ile set edilir. Böylece programcı arka planda "mademki 
    boruda bir şey yok o zaman ben de başka bir şey yapayım" diyebilmektedir. Aynı durum write sırasında da benzer biçimde söz 
    olmaktadır. Örneğin blokesiz modda biz bir boruya write işlemi yapmak isteyelim ancak boruda yazmak istediğimiz miktar kadar 
    boş alan olmasın. Bu durumda write fonksiyonu -1 ile geri döner ve errno değeri EAGAIN değeri set edilir. Blokesiz modda 
    işlemler blokeli moddaki işlemlere göre oldukça seyrek kullanılmaktadır.

    İsimli boru dosyaları open fonksiyonuyla O_NONBLOCK bayrağı kullanılarak açılırken artık open fonksiyonunda bloke oluşmaz. 
    Anımsanacağı gibi blokesiz modda open karşı taraf boruyu ters modda açana kadar bloke oluşuyordu. open fonksiyonunda 
    O_NONBLOCK bayrağı kullanıldığında proses boruyu read modda açtığında henüz karşı taraf boruyu write modda açmamışsa read 
    fonksiyonu boruyu yazma potansiyelinde olan hiçbir betimleyici olmadığı için 0 ile geri döner.

    İsimli borularda proses boruyu "write" modda açarken normalde blokeli modda open fonksiyonu karşı taraf boruyu "read" modda 
    açana kadar bloke oluşuyordu. Halbuki isimli boruları O_NONBLOCK bayrağı ile "write" modda açmaya çalıştığımızda karşı 
    taraf boruyu henüz "read" modda açmamışsa open başarısız olmaktadır. Bu durumda open fonksiyonu errno değerini ENXIO ile 
    set etmektedir. Bu errno değerinin yazısı "No such device or address" biçimindedir.

    İsimli borularda iki taraf da boruyu O_NONBLOCK bayrağı ile açarsa yukarıda anlattığımız nedenden dolayı senkronizasyona 
    dikkat etmek gerekir. Bu tür durumlarda işlemleri kolaylaştırmak için isimli borular blokeli modda açılıp (O_NONBLOCK 
    kullanılmadan) sonrasında fcntl fonksiyonu ile blokesiz moda geçilebilir.

    Prosesler biri boruyu blokeli modda diğeri blokesiz modda açabilir. Bu da herhangi bir soruna yol açmaz.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aygıt sürücülerimize arzu edersek "blokesiz (non-blocking)" okuma yazma desteği de verebiliriz. Tabii bu desteğin verilebilmesi
    için aygıt sürücünün okuma yazma sırasında bloke oluşturması gerekmektedir. Anımsanacağı gibi blokesiz işlem yapabilmek için 
    open POSIX fonksiyonunda fonksiyonun ikinci parametresine O_NONBLOCK bayrağı ekleniyordu. Normal disk dosyalarında O_NONBLOCK 
    bayrağının bir anlamı yoktu. Ancak boru gibi özel dosyalarda ve aygıt sürücülerde daha önceden de belirttiğimiz gibi bu bayrak 
    şu anlama gelmektedir:

    1) Okuma sırasında eğer okunacak bir bilgi yoksa read fonksiyonu bloke oluşturmaz, başarısızlıkla geri döner ve errno değeri 
    EAGAIN olarak set edilir.

    2) Yazma sırasında yazma eylemi meşguliyet yüzünden yapılamıyorsa write fonksiyonu bloke oluşturmaz, başarısızlıkla geri döner 
    ve errno değeri yine EAGAIN olarak set edilir.

    Aygıt sürücü açıldığında open fonksiyonunun ikinci parametresi file yapısının (dosya nesnesinin) f_flags elemanına yerleştirilmektedir. 
    Dosya nesnesinin adresinin aygıt sürücüdeki fonksiyonlara filp parametresiyle aktarıldığını anımsayınız. Bu durumda biz aygıt 
    dosyasının blokesiz modda açılıp açılmadığını şöyle test edebiliriz:

    if (filp->f_flags & O_NONBLOCK) {		/* blokesiz modda mı açılmış */
        /* open fonksiyonunda aygıt O_NONBLOCK bayrağı ile açılmış */
    }

    Aygıt sürücümüz blokesiz modda işlemlere izin vermiyorsa biz bu durumu kontrol etmeyebiliriz. Yani böyle bir aygıt sürücüde 
    programcı aygıt sürücüyü O_NONBLOCK bayrağını kullanarak açmışsa bu durumu hiç dikkate almayabiliriz. (Örneğin disk dosyalarında
    blokesiz işlemlerin bir anlamı olmadığı halde Linux çekirdeği disk dosyaları O_NONBLOCK bayrağıyla açıldığında hata ile geri 
    dönmeden bayrağı dikkate almamaktadır.) Eğer bu kontrol yapılmak isteniyorsa aygıt sürücünün açılması sırasında kontrol 
    aygıt sürücünün open fonksiyonunda yapılabilir. Bu durumda open fonksiyonunu -EINVAL değeriyle geri döndürebilirsiniz. Örneğin:

    static int generic_open(struct inode *inodep, struct file *filp)
    {
        if (filp->f_flags & O_NONBLOCK)
            return -EINVAL;
        return 0;
    }

    Pekiyi boru aygıt sürücümüze nasıl blokesiz mod desteği verebiliriz? Aslında bunun için iki şeyi yapmamız gerekir:

    1) Yazma yapıldığı zaman boruda yazılanları alacak kadar yer yoksa aygıt sürücümüzün write fonksiyonunu -EAGAIN değeriyle 
    geri döndürmeliyiz. Örneğin:

    ...
    if (down_interruptible(&g_sem))
        return -ERESTARTSYS;

    while (PIPE_BUFSIZE - g_count < size) {
        up(&g_sem);

        if (filp->f_flags & O_NONBLOCK)
            return -EAGAIN;

        if (wait_event_interruptible(g_wqwrite, PIPE_BUFSIZE - g_count >= size))
            return -ERESTARTSYS;

        if (down_interruptible(&g_sem))
            return -ERESTARTSYS;
    }
    ...

    2) Okuma yapıldığı zaman eğer boruda hiç bilgi yoksa aygıt sürücümüzün read fonksiyonunu -EAGAIN değeriyle geri döndürmeliyiz.
    Örneğin:

    ...
    if (down_interruptible(&g_sem))
        return -ERESTARTSYS;

    while (g_count == 0) {
        up(&g_sem);

        if (filp->f_flags & O_NONBLOCK)
            return -EAGAIN;

        if (wait_event_interruptible(g_wqread, g_count > 0))
            return -ERESTARTSYS;

        if (down_interruptible(&g_sem))
            return -ERESTARTSYS;
    }
    ...

    read ve write fonksiyonlarının -EAGAIN değeriyle geri döndürülmeden önce aygıt dosyasının blokesiz modda açılıp açılmadığının
    kontrol edilmesi gerektiğine dikkat ediniz.

    Aşağıdaki örnekte boru aygıt sürücüsüne blokesiz okuma ve yazma desteği verilmiştir.
-----------------------------------------------------------------------------------------------------------------------------*/

/* pipe-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>
#include <linux/semaphore.h>
#include <linux/wait.h>

#define PIPE_BUFFER_SIZE		10
#define MIN(a, b)	((a) < (b) ? (a) : (b))

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("Pipe Device Driver");

static int pipe_driver_open(struct inode *inodep, struct file *filp);
static int pipe_driver_release(struct inode *inodep, struct file *filp);
static ssize_t pipe_driver_read(struct file *filp, char *buf, size_t size, loff_t *off);
static ssize_t pipe_driver_write(struct file *filp, const char *buf, size_t size, loff_t *off);

static dev_t g_dev;
static struct cdev g_cdev;
static struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = pipe_driver_open,
	.read = pipe_driver_read,
	.write = pipe_driver_write,
	.release = pipe_driver_release
};

static unsigned char g_pipebuf[PIPE_BUFFER_SIZE];
static size_t g_head;
static size_t g_tail;
static size_t g_count;
static wait_queue_head_t g_wqwriteopen;
static wait_queue_head_t g_wqreadopen;
static wait_queue_head_t g_wqread;
static wait_queue_head_t g_wqwrite;
static int g_nreaders;
static int g_nwriters;

static DEFINE_SEMAPHORE(g_sem);

static int __init pipe_driver_init(void)
{
	int result;

	printk(KERN_INFO "pipe-driver init...\n");

	if ((result = alloc_chrdev_region(&g_dev, 0, 1, "pipe-driver")) < 0) {
		printk(KERN_ERR "cannot register device!...\n");
		return result;
	}

	cdev_init(&g_cdev, &g_fops);
	if ((result = cdev_add(&g_cdev, g_dev, 1)) < 0) {
		unregister_chrdev_region(g_dev, 1);
		printk(KERN_ERR "cannot add device!...\n");
		return result;
	}

	init_waitqueue_head(&g_wqreadopen);
	init_waitqueue_head(&g_wqwriteopen);
	init_waitqueue_head(&g_wqread);
	init_waitqueue_head(&g_wqwrite);

	return 0;
}

static void __exit pipe_driver_exit(void)
{
	cdev_del(&g_cdev);
	unregister_chrdev_region(g_dev, 1);

	printk(KERN_INFO "pipe-driver exit...\n");
}

static int pipe_driver_open(struct inode *inodep, struct file *filp)
{
	int accmode = filp->f_flags & O_ACCMODE;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	if (accmode == O_RDONLY) {
		++g_nreaders;
		wake_up_interruptible(&g_wqwriteopen);
		while (g_nwriters == 0) {
			up(&g_sem);
			if (filp->f_flags & O_NONBLOCK)
				return 0;
			if (wait_event_interruptible(g_wqreadopen, g_nwriters > 0))
				return -ERESTARTSYS;
			if (down_interruptible(&g_sem))
				return -ERESTARTSYS;
		}
	}
	else if (accmode == O_WRONLY) {
		++g_nwriters;
		wake_up_interruptible(&g_wqreadopen);
		while (g_nreaders == 0) {
			if (filp->f_flags & O_NONBLOCK) {
				--g_nwriters;
				up(&g_sem);
				return -ENXIO;
			}
			up(&g_sem);
			if (wait_event_interruptible(g_wqwriteopen, g_nreaders > 0))
				return -ERESTARTSYS;
			if (down_interruptible(&g_sem))
				return -ERESTARTSYS;
		}
	}
	else if (accmode == O_RDWR) {
		++g_nreaders;
		++g_nwriters;
		wake_up_interruptible(&g_wqreadopen);
		wake_up_interruptible(&g_wqwriteopen);
	}
	up(&g_sem);

	return 0;
}

static int pipe_driver_release(struct inode *inodep, struct file *filp)
{
	int accmode = filp->f_flags & O_ACCMODE;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	if (accmode == O_RDONLY)
		--g_nreaders;
	else if (accmode == O_WRONLY)
		--g_nwriters;
	else if (accmode == O_RDWR) {
		--g_nreaders;
		--g_nwriters;
	}
	if (g_nreaders == 0)
		wake_up_interruptible(&g_wqwrite);
	if (g_nwriters == 0)
		wake_up_interruptible(&g_wqread);

	up(&g_sem);

	return 0;
}

static ssize_t pipe_driver_read(struct file *filp, char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;
	ssize_t result = -EFAULT;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	while (g_count == 0) {
		if (g_nwriters == 0) {
			result = 0;
			goto EXIT;
		}
		up(&g_sem);
		if (filp->f_flags & O_NONBLOCK)
			return -EAGAIN;
		if (wait_event_interruptible(g_wqread, g_count > 0 || g_nwriters == 0) != 0)
			return -ERESTARTSYS;
		if (down_interruptible(&g_sem) != 0)
			return -ERESTARTSYS;
	}

	esize = MIN(size, g_count);
	if (g_head >= g_tail)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_head);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_to_user(buf, g_pipebuf + g_head, size1) != 0)
		goto EXIT;

	if (size2 != 0)
		if (copy_to_user(buf + size1, g_pipebuf, size2) != 0)
			goto EXIT;

	g_head = (g_head + esize) % PIPE_BUFFER_SIZE;
	g_count -= esize;

	result = esize;

	wake_up_interruptible(&g_wqwrite);
EXIT:
	up(&g_sem);

	return result;
}

static ssize_t pipe_driver_write(struct file *filp, const char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;
	ssize_t result = -EFAULT;

	if (size > PIPE_BUFFER_SIZE)
		size = PIPE_BUFFER_SIZE;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	if (g_nreaders == 0) {
		up(&g_sem);
		send_sig(SIGPIPE, current, 0);
		return -EPIPE;
	}
	while (PIPE_BUFFER_SIZE - g_count < size) {
		up(&g_sem);
		if (filp->f_flags & O_NONBLOCK)
			return -EAGAIN;
		if (wait_event_interruptible(g_wqwrite, PIPE_BUFFER_SIZE - g_count >= size || g_nreaders == 0) != 0)
			return -ERESTARTSYS;
		if (down_interruptible(&g_sem) != 0)
			return -ERESTARTSYS;
		if (g_nreaders == 0) {
			up(&g_sem);
			send_sig(SIGPIPE, current, 0);
			return -EPIPE;
		}
	}

	esize = MIN(size, PIPE_BUFFER_SIZE - g_count);

	if (g_tail >= g_head)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_tail);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_from_user(g_pipebuf + g_tail, buf, size1) != 0)
		goto EXIT;
	if (size2 != 0)
		if (copy_from_user(g_pipebuf, buf + size1, size2) != 0)
			goto EXIT;

	g_tail = (g_tail + esize ) % PIPE_BUFFER_SIZE;
	g_count += esize;

	result = esize;

EXIT:
	wake_up_interruptible(&g_wqread);
	up(&g_sem);

	return esize;
}

module_init(pipe_driver_init);
module_exit(pipe_driver_exit);

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* load (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1
mode=666

/sbin/insmod ./$module.ko ${@:2} || exit 1
major=$(awk "\$2 == \"$module\" {print \$1}" /proc/devices)
rm -f $module
mknod -m $mode $module c $major 0

/* unload (bu satırı dosyaya kopyalamayınız ) */

#!/bin/bash

module=$1

/sbin/rmmod ./$module.ko || exit 1
rm -f $module

/* pwriter.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	char *str;
	ssize_t result;

	if ((fd = open("pipe-driver", O_WRONLY|O_NONBLOCK)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Enter text:");
		fflush(stdout);
		if (fgets(buf, BUFFER_SIZE, stdin) == NULL)
			continue;
		if ((str = strchr(buf, '\n')) != NULL)
			*str = '\0';
		if (!strcmp(buf, "quit"))
			break;
		if ((result = write(fd, buf, strlen(buf))) == -1)
			exit_sys("write");

		printf("%jd bytes written...\n", (intmax_t)result);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/* preader.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <errno.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	int n;
	ssize_t result;

	if ((fd = open("pipe-driver", O_RDONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Number of bytes to read? ");
		scanf("%d", &n);
		if (n == 0)
			break;
		if ((result = read(fd, buf, n)) == -1) {
			if (errno != EAGAIN)
				exit_sys("read");
			printf("pipe is empty, let's do something else...\n");
			continue;
		}
		if (result == 0) {
			putchar('\n');
			break;
		}
		buf[result] = '\0';
		printf("%jd bytes read: %s\n", (intmax_t)result, buf);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
												100. Ders 08/05/2025 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdek modülleri ve aygıt sürücüler dinamik bellek tahsis etmeye gereksinim duyabilirler. Ancak çekirdek modunda çalışan 
    programlar dinamik tahsisatları malloc, calloc ve realloc gibi standart C fonksiyonlarıyla yapamazlar. Çünkü bu fonksiyonlar 
    kullanıcı modundaki programlar tarafından kullanılacak biçimde prosesin bellek alanında tahsisat yapmak için tasarlanmışlardır. 
    Oysa çekirdeğin ayrı bir heap sistemi vardır. Bu nedenle çekirdek modülleri ve aygıt sürücüler çekirdeğin sunduğu fonksiyonlarla 
    çekirdeğin heap alanında tahsisat yapabilirler. Biz de bu bölümde çekirdeğin heap sistemi üzerinde tahsisatların nasıl yapıldığı 
    üzerinde duracağız.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Anımsanacağı gibi Linux sistemlerinde proseslerin bellek alanları sayfa tabloları yoluyla izole edilmiştir. Ancak çekirdek 
    tüm proseslerin sayfa tablosunda aynı yerde bulunmaktadır. Başka bir deyişle her prosesin sayfa tablosunda çekirdek hep aynı 
    sanal adreslerde bulunmaktadır. Örneğin sys_open sistem fonksiyonuna girildiğinde bu fonksiyonun sanal adresi her proseste 
    aynıdır.

    32 bit Linux sistemlerinde proseslerin sanal bellek alanları 3 GB kullanıcı (user), 1 GB çekirdek (kernel) olmak üzere iki 
    bölüme ayrılmıştır. 64 bit Linux sistemlerinde ise yalnızca sanal bellek alanının 256 TB'si kullanılmaktadır. Bu sistemlerde 
    kullanıcı alanı için 128 TB, çekirdek alanı için de 128 TB yer ayrılmıştır. 32 bit Linux sistemlerindeki prosesin sanal 
    bellek alanı şöyle gösterilebilir:

    00000000
    ...            USER ALANI (3 GB)
    C0000000
    ...            KERNEL ALANI (1 GB)

    64 bit Linux sistemlerindeki sanal bellek alanı ise kabaca şöyledir:

    0000000000000000
    ...                        USER ALANI (128 TB)
    0000800000000000
    ...                        BOŞ BÖLGE (yaklaşık 16M TB)
    FFFF800000000000
    ...                        KERNEL ALANI (128 TB)
    FFFFFFFFFFFFFFFF
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Bir sistem fonksiyonunun çağrıldığını düşünelim. İşlemci çekirdek moduna otomatik olarak geçirilecektir. Bu durumda sayfa 
    tablosu değişmeyecektir. Pekiyi çekirdek nasıl tüm fiziksel belleğe erişebilmektedir? İşte 32 bitlik sistemlerde proseslerin 
    sayfa tablolarının son 1 GB'yi sayfalandırdığı girişleri tamamen fiziksel belleği eşlemektedir. Başka bir deyişle bu 32 bit 
    sistemlerde çekirdek alanının başlangıcı olan C0000000 adresi aslında sayfa tablosunda 00000000 fiziksel adresini belirtmektedir. 
    Böylece çekirdeğin herhangi bir fiziksel adrese erişmek için yapacağı tek şey bu adrese C00000000 değerini toplamaktır. Bu 
    sistemlerde C0000000 adresinden itibaren proseslerin sayfa tabloları zaten fiziksel belleği 0'dan itibaren haritalandırmaktadır. 
    Ancak 32 bit sistemlerde şöyle bir sorun da vardır: Sayfa tablosunda C0000000'dan itibaren sayfalar fiziksel belleği haritalandırdığına 
    göre 32 bit sistemlerin maksimum sahip olacağı 4 GB fiziksel RAM'in hepsi haritalandırılamamaktadır. İşte Linux tasarımcıları 
    sayfa tablolarında C0000000'dan itibaren fiziksel RAM'in 1 GB'sini değil 896 MB'sini haritalandırmıştır. Geri kalan 128 MB'lik 
    alan fiziksel RAM'de 896 MB'nin ötesine erişmek için değiştirilerek kullanılmaktadır. Yani 32 bit sistemlerde çekirdek 
    fiziksel RAM'in ilk 896 MB'sine doğrudan ancak bunun ötesine sayfa tablosunun son 128 MB'lik bölgesini değiştirerek erişmektedir. 
    32 bit sistemlerde 896 MB'nin ötesine dolaylı biçimde erişildiği için bu bölgeye "high memory zone" denilmektedir. Tabii 
    64 bit sistemlerde böyle bir problem yoktur. Çünkü bu sistemlerde yine sayfa tablolarının çekirdek alanı fiziksel RAM'i 
    başından itibaren haritalandırmaktadır. Ancak 128 TB'lik alan zaten şimdiki bilgisayarlara takılabilecek fiziksel RAM'in 
    çok ötesindedir. Bu nedenle 64 bit sistemlerde "high memory zone" kavramı yoktur.

    Çekirdek kodlarında çekirdek alanının başlangıcı PAGE_OFFSET makrosuyla belirlenmiştir. Örneğin 32 bit sistemlerde bu 
    PAGE_OFFSET değeri 0xC0000000 biçimindedir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz çekirdek modunda kod yazarken belli bir fiziksel adrese erişmek istersek onun sanal adresini bulmamız gerekir. Bu işin 
    manuel yapılması yerine bunun için __va isimli makro kullanılmaktadır. Biz bu makroya bir fiziksel adres veririz o da bize 
    o fiziksel adrese erişmek için gereken sanal adresi verir. Benzer biçimde bir sanal adresin fiziksel RAM karşılığını bulmak 
    için de __pa makrosu kullanılmaktadır. Biz bu makroya sanal adresi veririz o da bize o sanal adresin aslında RAM'deki hangi 
    fiziksel adres olduğunu verir. __va makrosu parametre olarak unsigned long biçiminde fiziksel adresi alır, o fiziksel adrese 
    erişmek için gerekli olan sanal adresi void * türünden bize verir. __pa makrosu bunun tam tersini yapmaktadır. Bu makro bizden 
    unsigned long biçiminde sanal adresi alır. O sanal adrese sayfa tablosunda karşı gelen fiziksel adresi bize verir.

    Çekirdek modunda RAM'in her yerine erişebildiğimize ve bu konuda bizi engelleyen hiçbir mekanizmanın olmadığına dikkat ediniz.
    Dolayısıyla bir aygıt sürücüler içerisinde RAM'in istediğimiz kısmına erişip oratayı değiştirebiliriz. Ancak bu durum 
    kontrolsüz ve amaçsız bir biçimde yapılırsa bu olumsuzluktan tün sistem etkilenebilecektir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux çekirdeği için fiziksel RAM temel olarak 3 bölgeye (zone'a) ayrılmıştır:

    ZONE_DMA
    ZONE_NORMAL
    ZONE_HIGHMEM

    ZONE_DMA ilgili sistemde disk ile RAM arasında transfer yapan DMA'nın erişebildiği RAM alanıdır. Bazı sistemlerde DMA tüm 
    fiziksel RAM'in her yerine transfer yapamamaktadır. ZONE_NORMAL doğrudan çekirdeğin sayfa tablosu yoluyla haritalandırdığı 
    fiziksel bellek bölgesidir. 32 bit Linux sistemlerinde bu bölge RAM'in ilk 896 MB'sidir. Ancak 64 bit Linux sistemlerinde bu 
    bölge tüm fiziksel RAM'i içermektedir. ZONE_HIGHMEM ise 32 bit sistemlerde çekirdeğin doğrudan haritalandıramadığı sayfa 
    tablosunda değişiklik yapılarak erişilebilen fiziksel RAM alanıdır. 32 bit Linux sistemlerinde 896 MB'nin yukarısındaki 
    fiziksel RAM bölgesi ZONE_HIGHMEM alanıdır. Yukarıda da belirttiğimiz gibi 64 bit Intel işlemcilerinde ZONE_HIGHMEM biçiminde 
    bir alan zaten yoktur.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Kullanıcı modundaki programlarda kullandığımız malloc fonksiyonununda en fazla uygulanan tahsisat yöntemi "boş bağlı liste" 
    denilen yöntemdir. Bu yöntemde yalnızca boş alanlar bir bağlı listede tutulmaktadır. Dolayısıyla malloc gibi bir fonksiyon 
    bu bağlı listede uygun bir elemanı bağlı listeyi dolaşarak bulmaktadır. free fonksiyonu da tahsis edilmiş olan alanı bu boş 
    bağlı listeye eklemektedir. Tabii free fonksiyonu aynı zamanda bağlı listedeki komşu alanları da daha büyük bir boş alan 
    oluşturacak biçimde birleştirmektedir. Ancak bu klasik yöntem çekirdek heap sistemi için çok yavaş bir yöntemdir. Bu nedenle 
    çekirdek heap sistemlerinde için daha hızlı çalışan tahsisat algoritmaları kullanılmaktadır.

    Eğer tahsis edilecek bloklar eşit uzunlukta olursa bu durumda tahsisat işlemi ve geri bırakma işlemi O(1) karmaşıklıkta 
    yapılabilir. Örneğin heap içerisindeki tüm blokların 16 byte uzunlukta olduğunu düşünelim. Bu durumda 16 byte'lık tahsisat 
    sırasında uygun bir boş alan aramaya gerek kalmaz. Bir bağlı liste içerisinde boş alanlar tutulabilir. Bu boş alanlardan 
    herhangi biri verilebilir. Tabii uygulamalarda tahsis edilecek alanların büyükleri farklı olmaktadır.

    İşte BSD ve Linux sistemlerinde kullanılan "dilimli tahsisat sistemi (slab allocator)" denilen tahsisat sisteminin anahtar 
    noktası eşit uzunlukta olan ve ismine "dilim (slab)" denilen blokların tahsis edilmesidir. Çekirdek içerisinde çeşitli nesneler 
    için o nesnelerin uzunluğuna ilişkin farklı dilimli tahsisat sistemleri oluşturulmuştur. Örneğin bir proses yaratıldığında 
    task_struct yapısı çekirdeğin heap alanında tahsis edilmektedir. İşte dilimli tahsisat sistemlerinden biri (struct task_struct 
    yapısının uzunluğu kadar dilim uzunluklarından oluşan sistemdir. Böylece pek çok çekirdek nesnesi için ayrı dilimli tahsisat 
    sistemleri oluşturulmuştur. Bu durumu özet olarak şöyle düşünebilirsiniz: Çekirdek sanki kendi içerisindeki her veri yapısı 
    için eşit uzunluklarda bloklardan oluşan farklı heap alanı kullanıyor gibidir.

    Çekirdek içerisindeki veri yapıları için oluşturulmuş olan dilimli tahsisat sistemlerinin dışında ayrıca bir de genel 
    kullanım için blok uzunlukları 32, 64, 96, 128, 192, 256 512, 1024, 2048, 4096, 8192, 16384, 32768, 65536, ... biçiminde 
    olan farklı dilimli tahsisat sistemleri de bulundurulmuştur. Böylece çekirdek mod programcısı belli uzunlukta bir alan 
    tahsis etmek istediğinde bu uzunluğa en yakın fakat bu uzunluktan büyük bir dilimli tahsisat sistemini kullanır. Tabii 
    çekirdek modunda çalışan programcılar isterse kendi nesneleri için de o nesnelerin uzunluğu kadar yeni dilimli tahsisat 
    sistemleri de oluşturabilmektedir.

    Burada aklınıza "mademki dilimli tahsisat sistemi çok hızlı bir sistem" o halde neden kullanıcı modundaki malloc gibi 
    fonksiyonlar da aynı mantıkla çalışmıyor" sorusu aklınıza gelebilir. Bunun iki nedeni vardır:

    1) Bu sistem hızlı olmasına karşın bellek harcaması daha yüksektir. Örneğin bu sistemde 600 byte'lık bir tahsisat yapmak 
    istesek bunu 1024'lük dilimlerin bulunduğu sistemden yaparız. Bu da kullanılmayan boş alanlar oluşturur.

    2) Eğer programcı kendi dilim sistemini oluşturacak olsa bunun da arayüz olarak kullanımı zor olmaktadır.

    O halde bu dilimli tahsisat sistemi çekirdek için uygun ama kullanıcı modu için pek uygun bir sistem değildir.

    Aslında dilimli tahsisat sisteminin hazırda bulundurduğu dilimler işletim sisteminin sayfa tahsisatı yapan başka bir tahsisat
    algoritmasından elde edilmektedir. Linux sistemlerinde sayfa temelinde tahsisat yapmak için kullanılan tahsisat sistemine
    "buddy allocator" denilmektedir. (CSD işletim sisteminde buna "ikiz blok sistemi" denilmektedir.)
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Çekirdek modunda çekirdek alanında dinamik tahsisat yapmak için kullanılan en genel fonksiyon kmalloc isimli fonksiyondur. 
    Bu fonksiyon aslında parametresiyle belirtilen uzunluğa en yakın önceden yaratılmış olan dilimli tahsisat sisteminden dilim 
    vermektedir (yani blok tahsis etmektedir). Örneğin biz kmalloc fonksiyonu ile 100 byte tahsis etmek istesek 100 byte'lık 
    blokların bulunduğu önceden yaratılmış bir dilimli tahsisat sistemi olmadığı için kmalloc 128 byte'lık bloklara sahip dilimli 
    tahsisat sisteminden bir dilim tahsis ederek bize verecektir. Tabii bu örnekte 28 byte boşuna tahsis edilmiş olacaktır. Ancak 
    çekirdek tahsisat sisteminin amacı en uygun miktarda belleği tahsis etmek değil, talep edilen miktarda belleği daha hızlı 
    tahsis etmektir. kmalloc fonksiyonu ile tahsis edilen dilimler kfree fonksiyonu ile serbest bırakılmaktadır. Fonksiyonların 
    prototipleri şöyledir:

    #include <linux/slab.h>

    void *kmalloc (size_t size, int flags);
    void kfree (const void *objp);

    kmalloc fonksiyonunun birinci parametresi tahsis edilecek byte miktarını belirtir. İkincisi parametresi ise tahsis edilecek 
    zone ve tahsisat biçimi hakkında çeşitli bayrakları içermektedir. Bu ikinci parametre çeşitli sembolik sabitlerden oluşturulmaktadır. 
    Burada önemli birkaç bayrak şunlardır:

    GFP_KERNEL: Çekirdek alanı içerisinde normal tahsisat yapmak için kullanılır. Bu bayrak en sık bu kullanılan bayraktır. Burada 
    eğer RAM doluysa işletim sistemi prosesi bloke ederek swap işlemi ile yer açabilmektedir. Yani bu işlem sırasında akış çekirdek 
    modunda bloke olarak thread bekleme kuyruklarında bekletilebilir. Tahsisat işlemi ZONE_NORMAL alanından yapılmaktadır.

    GFP_NOWAIT: GFP_KERNEL gibidir. Ancak hazırda bellek yoksa thread uykuya dalmaz. Fonksiyon başarısız olur.

    GFP_HIGHUSER: 32 bit sistemlerde ZONE_HIGHMEM alanından tahsisat yapar.

    GFP_DMA: İlgili sistemde DMA'nın erişebildiği fiziksel RAM alanından tahsisat yapar.

    kmalloc fonksiyonu başarı durumunda tahsis edilen alanın sanal bellek adresiyle, başarısızlık durumunda NULL adresle geri
    dönmektedir. Çekirdek modülleri ve aygıt sürücüler dinamik tahsisat başarısız olursa tipik olarak -ENOMEM değerine geri 
    dönmelidir.

    kfree fonksiyonu ise daha önce kmalloc ile tahsis edilmiş olan alanın başlangıç adresini parametre olarak almaktadır.

    Aşağıda daha önce yapmış olduğumuz boru aygıt sürücüsündeki kuyruk sistemini kmalloc fonksiyonu ile tahsis edilip kfree
    fonksiyonu ile serbest bırakılmasına örnek verilmiştir.
-----------------------------------------------------------------------------------------------------------------------------*/

/* pipe-driver.c */

#include <linux/module.h>
#include <linux/kernel.h>
#include <linux/fs.h>
#include <linux/cdev.h>
#include <linux/semaphore.h>
#include <linux/wait.h>
#include <linux/slab.h>

#define PIPE_BUFFER_SIZE		10
#define MIN(a, b)	((a) < (b) ? (a) : (b))

MODULE_LICENSE("GPL");
MODULE_AUTHOR("Kaan Aslan");
MODULE_DESCRIPTION("Pipe Device Driver");

static int pipe_driver_open(struct inode *inodep, struct file *filp);
static int pipe_driver_release(struct inode *inodep, struct file *filp);
static ssize_t pipe_driver_read(struct file *filp, char *buf, size_t size, loff_t *off);
static ssize_t pipe_driver_write(struct file *filp, const char *buf, size_t size, loff_t *off);

static dev_t g_dev;
static struct cdev g_cdev;
static struct file_operations g_fops = {
	.owner = THIS_MODULE,
	.open = pipe_driver_open,
	.read = pipe_driver_read,
	.write = pipe_driver_write,
	.release = pipe_driver_release
};

struct PIPE {
	unsigned char buf[PIPE_BUFFER_SIZE];
	size_t head;
	size_t tail;
	size_t count;
};

static wait_queue_head_t g_wqwriteopen;
static wait_queue_head_t g_wqreadopen;
static wait_queue_head_t g_wqread;
static wait_queue_head_t g_wqwrite;
static int g_nreaders;
static int g_nwriters;
static DEFINE_SEMAPHORE(g_sem);
static struct PIPE *g_pipe;

static int __init pipe_driver_init(void)
{
	int result;

	printk(KERN_INFO "pipe-driver init...\n");

	if ((result = alloc_chrdev_region(&g_dev, 0, 1, "pipe-driver")) < 0) {
		printk(KERN_ERR "cannot register device!...\n");
		goto EXIT1;
	}

	cdev_init(&g_cdev, &g_fops);
	if ((result = cdev_add(&g_cdev, g_dev, 1)) < 0) {
		printk(KERN_ERR "cannot add device!...\n");
		goto EXIT2;
	}

	if ((g_pipe = kmalloc(sizeof(struct PIPE), GFP_KERNEL)) == NULL) {
		printk(KERN_ERR "cannot allocate memory!...\n");
		result = -ENOMEM;
		goto EXIT3;
	}

	init_waitqueue_head(&g_wqreadopen);
	init_waitqueue_head(&g_wqwriteopen);
	init_waitqueue_head(&g_wqread);
	init_waitqueue_head(&g_wqwrite);

	return 0;

EXIT3:
	cdev_del(&g_cdev);
EXIT2:
	unregister_chrdev_region(g_dev, 1);
EXIT1:
	return result;
}

static void __exit pipe_driver_exit(void)
{
	kfree(g_pipe);
	cdev_del(&g_cdev);
	unregister_chrdev_region(g_dev, 1);

	printk(KERN_INFO "pipe-driver exit...\n");
}

static int pipe_driver_open(struct inode *inodep, struct file *filp)
{
	int accmode = filp->f_flags & O_ACCMODE;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	if (accmode == O_RDONLY) {
		++g_nreaders;
		wake_up_interruptible(&g_wqwriteopen);
		while (g_nwriters == 0) {
			up(&g_sem);
			if (filp->f_flags & O_NONBLOCK)
				return 0;
			if (wait_event_interruptible(g_wqreadopen, g_nwriters > 0))
				return -ERESTARTSYS;
			if (down_interruptible(&g_sem))
				return -ERESTARTSYS;
		}
	}
	else if (accmode == O_WRONLY) {
		++g_nwriters;
		wake_up_interruptible(&g_wqreadopen);
		while (g_nreaders == 0) {
			if (filp->f_flags & O_NONBLOCK) {
				--g_nwriters;
				up(&g_sem);
				return -ENXIO;
			}
			up(&g_sem);
			if (wait_event_interruptible(g_wqwriteopen, g_nreaders > 0))
				return -ERESTARTSYS;
			if (down_interruptible(&g_sem))
				return -ERESTARTSYS;
		}
	}
	else if (accmode == O_RDWR) {
		++g_nreaders;
		++g_nwriters;
		wake_up_interruptible(&g_wqreadopen);
		wake_up_interruptible(&g_wqwriteopen);
	}
	up(&g_sem);

	return 0;
}

static int pipe_driver_release(struct inode *inodep, struct file *filp)
{
	int accmode = filp->f_flags & O_ACCMODE;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	if (accmode == O_RDONLY)
		--g_nreaders;
	else if (accmode == O_WRONLY)
		--g_nwriters;
	else if (accmode == O_RDWR) {
		--g_nreaders;
		--g_nwriters;
	}
	if (g_nreaders == 0)
		wake_up_interruptible(&g_wqwrite);
	if (g_nwriters == 0)
		wake_up_interruptible(&g_wqread);

	up(&g_sem);

	return 0;
}

static ssize_t pipe_driver_read(struct file *filp, char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;
	ssize_t result = -EFAULT;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	while (g_pipe->count == 0) {
		if (g_nwriters == 0) {
			result = 0;
			goto EXIT;
		}
		up(&g_sem);
		if (filp->f_flags & O_NONBLOCK)
			return -EAGAIN;
		if (wait_event_interruptible(g_wqread, g_pipe->count > 0 || g_nwriters == 0) != 0)
			return -ERESTARTSYS;
		if (down_interruptible(&g_sem) != 0)
			return -ERESTARTSYS;
	}

	esize = MIN(size, g_pipe->count);
	if (g_pipe->head >= g_pipe->tail)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_pipe->head);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_to_user(buf, g_pipe->buf + g_pipe->head, size1) != 0)
		goto EXIT;

	if (size2 != 0)
		if (copy_to_user(buf + size1, g_pipe->buf, size2) != 0)
			goto EXIT;

	g_pipe->head = (g_pipe->head + esize) % PIPE_BUFFER_SIZE;
	g_pipe->count -= esize;

	result = esize;

	wake_up_interruptible(&g_wqwrite);
EXIT:
	up(&g_sem);

	return result;
}

static ssize_t pipe_driver_write(struct file *filp, const char *buf, size_t size, loff_t *off)
{
	size_t esize, size1, size2;
	ssize_t result = -EFAULT;

	if (size > PIPE_BUFFER_SIZE)
		size = PIPE_BUFFER_SIZE;

	if (down_interruptible(&g_sem) != 0)
		return -ERESTARTSYS;

	if (g_nreaders == 0) {
		up(&g_sem);
		send_sig(SIGPIPE, current, 0);
		return -EPIPE;
	}
	while (PIPE_BUFFER_SIZE - g_pipe->count < size) {
		up(&g_sem);
		if (filp->f_flags & O_NONBLOCK)
			return -EAGAIN;
		if (wait_event_interruptible(g_wqwrite, PIPE_BUFFER_SIZE - g_pipe->count >= size || g_nreaders == 0) != 0)
			return -ERESTARTSYS;
		if (down_interruptible(&g_sem) != 0)
			return -ERESTARTSYS;
		if (g_nreaders == 0) {
			up(&g_sem);
			send_sig(SIGPIPE, current, 0);
			return -EPIPE;
		}
	}

	esize = MIN(size, PIPE_BUFFER_SIZE - g_pipe->count);

	if (g_pipe->tail >= g_pipe->head)
		size1 = MIN(esize, PIPE_BUFFER_SIZE - g_pipe->tail);
	else
		size1 = esize;
	size2 = esize - size1;

	if (copy_from_user(g_pipe->buf + g_pipe->tail, buf, size1) != 0)
		goto EXIT;
	if (size2 != 0)
		if (copy_from_user(g_pipe->buf, buf + size1, size2) != 0)
			goto EXIT;

	g_pipe->tail = (g_pipe->tail + esize ) % PIPE_BUFFER_SIZE;
	g_pipe->count += esize;

	result = esize;

EXIT:
	wake_up_interruptible(&g_wqread);
	up(&g_sem);

	return esize;
}

module_init(pipe_driver_init);
module_exit(pipe_driver_exit);

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* load (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1
mode=666

/sbin/insmod ./$module.ko ${@:2} || exit 1
major=$(awk "\$2 == \"$module\" {print \$1}" /proc/devices)
rm -f $module
mknod -m $mode $module c $major 0

/* unload (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1

/sbin/rmmod ./$module.ko || exit 1
rm -f $module

/* pwriter.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	char *str;
	ssize_t result;

	if ((fd = open("pipe-driver", O_WRONLY|O_NONBLOCK)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Enter text:");
		fflush(stdout);
		if (fgets(buf, BUFFER_SIZE, stdin) == NULL)
			continue;
		if ((str = strchr(buf, '\n')) != NULL)
			*str = '\0';
		if (!strcmp(buf, "quit"))
			break;
		if ((result = write(fd, buf, strlen(buf))) == -1)
			exit_sys("write");

		printf("%jd bytes written...\n", (intmax_t)result);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/* preader.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <errno.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	int n;
	ssize_t result;

	if ((fd = open("pipe-driver", O_RDONLY|O_NONBLOCK)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Number of bytes to read? ");
		scanf("%d", &n);
		if (n == 0)
			break;
		if ((result = read(fd, buf, n)) == -1) {
			if (errno != EAGAIN)
				exit_sys("read");
			printf("pipe is empty, let's do something else...\n");
			continue;
		}
		if (result == 0) {
			putchar('\n');
			break;
		}
		buf[result] = '\0';
		printf("%jd bytes read: %s\n", (intmax_t)result, buf);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
												101. Ders 13/05/2025 - Salı
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirttiğimiz gibi istersek genel amaçlı kmalloc fonksiyonunu kullanmak yerine kendimiz de tam istediğimiz büyüklükte
    dilimlere sahip olan yeni bir dilimli tahsisat sistemi yaratıp onu kullanabiliriz. Yeni bir dilimli tahsisat sisteminin 
    yaratılması kmem_cache_create fonksiyonu ile yapılmaktadır. Fonksiyonun prototipi şöyledir:

    #include <linux/slab.h>

    struct kmem_cache *kmem_cache_create(const char *name, unsigned int size, 
            unsigned int align, slab_flags_t flags, void (*ctor)(void *));

    Fonksiyonun birinci parametresi yeni yaratılacak dilimli tahsisat sisteminin ismini belirtmektedir. (Bu isim sys dosya sisteminde 
    bir dizin biçiminde görüntülenebilmektedir.) Burada dilimli tahsisat sistemine herhangi bir isim verilebilir. Linux çekirdeğinde 
    dilimli tahsisat sistemlerine genellikle "xxx_cachep" biçiminde isimlendirilmektedir. İkinci parametre dilimlerin büyüklüğünü 
    belirtmektedir. Üçüncü parametre ise hizalama değerini belirtir. Bu hizalama değerine 0 geçilirse default hizalama kullanılır. 
    Varsayılan hizalama 32 bit sistemlerde 4 byte, 64 bit sistemlerde 8 byte'tır. Fonksiyonun dördüncü parametresi yaratılacak dilimli 
    tahsisat sistemine ilişkin bazı özelliklerin belirlenmesi için kullanılmaktadır. Buradaki bayrakların önemli birkaç tanesi şöyledir:

    SLAB_NO_REAP: Fiziksel RAM'in dolması nedeniyle kullanılmayan dilimlerin otomatik olarak sisteme iade edileceği anlamına gelir. 
    Uç durumlarda bu bayrak kullanılabilir.

    SLAB_HWCACHE_ALIGN: Bu bayrak özellikle SMP sistemlerinde işlemci ya da çekirdeklerin cache alanları için hizalama yapılmasını
    sağlamaktadır. Yaratım sırasında bu parametreyi kullanabilirsiniz.

    SLAB_CACHE_DMA: Bu parametre DMA alanında (DMA zone) tahsisat için kullanılmaktadır. Daha önceden de belirttiğimiz gibi bazı 
    sistemlerde fiziksel RAM'ın ancak bazı bölgelerine DMA tarafından erişilebilmektedir.

    Fonksiyonun son parametresi dilim sistemi yaratıldığında çağrılacak callback fonksiyonu belirtmektedir. Bu parametre için 
    girilecek fonksiyon her yeni dilim tahsis edildiğinde çağrılmaktadır. Böylece yeni bir dilim tahsis edileceği zaman bu fonksiyon
    içerisinde o dilime ilkdeğer verilebilir. Bu fonksiyona tahsis edilen dilimin başlangıç adresi geçirilmektedir. Bu parametre 
    NULL da geçilebilir. Bu durumda dilim tahsis edilirken herhangi bir fonksiyon çağrılmaz. kmem_cache_create fonksiyonu başarı 
    durumunda struct kmem_cache türünden bir yapı nesnesinin adresiyle, başarısızlık durumunda NULL adrese geri dönmektedir. 
    Başarısızlık durumunda aygıt sürücü fonksiyonunun -ENOMEM değeri ile geri döndürülmesi uygundur. Fonksiyon şöyle kullanılabilir:

    struct kmem_cache *g_pipe_cachep;

    if ((g_pipe_cachep = kmem_cache_create("pipe_driver_cachep", sizeof(struct PIPE), 0, SLAB_HWCACHE_ALIGN, NULL)) == NULL) {
        ...
        return -ENOMEM;
    }

    Yaratılmış olan bir dilim sisteminden tahsisatlar kmem_cache_alloc fonksiyonu ile yapılmaktadır. Fonksiyonun prototipi 
    şöyledir:

    #include <linux/slab.h>

    void *kmem_cache_alloc(struct kmem_cache *cache, int flags);

    Fonksiyonun birinci parametresi yaratılmış olan dilim sisteminin handle değerini, ikinci parametresi ise yaratım bayraklarını 
    almaktadır. Bu bayraklar kmalloc fonksiyonundaki bayraklarla aynıdır. Yani örneğin bu parametreye GFP_KERNEL geçilebilir. 
    Fonksiyon başarı durumunda tahsis edilen dilimin sanal adresine, başarısızlık durumunda NULL adrese geri dönmektedir. Başarısızlık 
    durumunda aygıt sürücüdeki fonksiyonun -ENOMEM değeri ile geri döndürülmesi uygundur. Örneğin:

    if ((g_pipe = (struct PIPE *)kmem_cache_alloc(g_pipe_cachep, GFP_KERNEL)) == NULL) {
        ...
        return -ENOMEM;
    }

    kmem_cache_alloc fonksiyonu ile tahsis edilen dinamik alan kmem_cache_free fonksiyonu ile serbest bırakılabilir. Fonksiyonun
    prototipi şöyledir:

    #include <linux/slab.h>

    void kmem_cache_free(struct kmem_cache *cache, const void *obj);

    Fonksiyonun birinci parametresi dilim sisteminin handle değerini, ikincisi parametresi ise serbest bırakılacak dilimin 
    adresini belirtmektedir. Örneğin:

    kmem_cache_free(g_pipe_cachep, g_pipe);

    kmem_cache_create fonksiyonu ile yaratılmış olan dilim sistemi kmem_cache_destroy fonksiyonu ile serbest bırakılabilir. 
    Fonksiyonun prototipi şöyledir.

    #include <linux/slab.h>

    int kmem_cache_destroy(struct kmem_cache *cache);

    Fonksiyon dilim sisteminin handle değerini parametre olarak alır. Başarı durumunda 0 değerine, başarısızlık durumunda 
    negatif errno değerine geri döner. Örneğin:

    kmem_cache_destroy(g_pipe);

    Pekiyi kmalloc yerine yeni bir dilimli tahsisat sisteminin yaratılması tercih edilmeli midir? Yukarıda da belirttiğimiz
    gibi kmalloc fonksiyonu da aslında önceden yaratılmış belli uzunluktaki dilim sistemlerinden tahsisat yapmaktadır. Ancak 
    "çok sayıda aynı büyüklükte alanların" tahsis edildiği durumlarda programcının belli uzunlukta olan kendi dilim sistemini 
    yaratması, bunun dışındaki durumlarda genel amaçlı kmalloc fonksiyonunu tavsiye edilmektedir.

    Tabii kmalloc yerine yeni bir dilimli tahsisat sistemi yaratmanın anlamlı olması için çok sayıda aynı büyüklükte tahsisatın
    yapılıyor olması gerekir. Tek bir tahisat için ya da birkaç tahsisat için yeni bir dilimli tahsisat sistemi yaratmaya hiç 
    gerek yoktur. Doğrudan kmalloc fonksiyonu kullanılabilir.

    Örneğin boru aygıt sürücümüzde yeni bir dilim sisteminin yaratılmasına hiç gerek yoktur. Çünkü zaten boru aygıt sürücüsünde 
    tek bir struct PIPE yapı nesnesi yaratılmaktadır. Ancak biz aşağıdaki bu dilimli tahsisat sistemlerinin nasıl kullanıldığına 
    bir örnek vermek için bu struct PIPE nesnesini kendi yarattığımız dilimli tahsisat sisteminden tahsis ediyoruz.
-----------------------------------------------------------------------------------------------------------------------------*/

/* pwriter.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	char *str;
	ssize_t result;

	if ((fd = open("pipe-driver", O_WRONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Enter text:");
		fflush(stdout);
		if (fgets(buf, BUFFER_SIZE, stdin) == NULL)
			continue;
		if ((str = strchr(buf, '\n')) != NULL)
			*str = '\0';
		if (!strcmp(buf, "quit"))
			break;
		if ((result = write(fd, buf, strlen(buf))) == -1)
			exit_sys("write");

		printf("%jd bytes written...\n", (intmax_t)result);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

# Makefile

obj-m += $(file).o

all:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} modules
clean:
	make -C /lib/modules/$(shell uname -r)/build M=${PWD} clean

/* load (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1
mode=666

/sbin/insmod ./$module.ko ${@:2} || exit 1
major=$(awk "\$2 == \"$module\" {print \$1}" /proc/devices)
rm -f $module
mknod -m $mode $module c $major 0

/* unload (bu satırı dosyaya kopyalamayınız) */

#!/bin/bash

module=$1

/sbin/rmmod ./$module.ko || exit 1
rm -f $module

/* pwriter.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	char *str;
	ssize_t result;

	if ((fd = open("pipe-driver", O_WRONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Enter text:");
		fflush(stdout);
		if (fgets(buf, BUFFER_SIZE, stdin) == NULL)
			continue;
		if ((str = strchr(buf, '\n')) != NULL)
			*str = '\0';
		if (!strcmp(buf, "quit"))
			break;
		if ((result = write(fd, buf, strlen(buf))) == -1)
			exit_sys("write");

		printf("%jd bytes written...\n", (intmax_t)result);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/* preader.c */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <stdint.h>
#include <errno.h>
#include <fcntl.h>
#include <unistd.h>

#define BUFFER_SIZE		8192

void exit_sys(const char *msg);

int main(void)
{
	int fd;
	char buf[BUFFER_SIZE];
	int n;
	ssize_t result;

	if ((fd = open("pipe-driver", O_RDONLY)) == -1)
		exit_sys("open");

	for (;;) {
		printf("Number of bytes to read? ");
		scanf("%d", &n);
		if (n == 0)
			break;
		if ((result = read(fd, buf, n)) == -1) {
			if (errno != EAGAIN)
				exit_sys("read");
			printf("pipe is empty, let's do something else...\n");
			continue;
		}
		if (result == 0) {
			putchar('\n');
			break;
		}
		buf[result] = '\0';
		printf("%jd bytes read: %s\n", (intmax_t)result, buf);
	}

	close(fd);

	return 0;
}

void exit_sys(const char *msg)
{
	perror(msg);

	exit(EXIT_FAILURE);
}

/*-----------------------------------------------------------------------------------------------------------------------------
    Biz kmem_cache_create fonksiyonlarıyla yaratılmış olan dilimli tahsisat sistemlerini proc dosya sistemi ile görüntüleyebiliriz. 
    "/proc/slabinfo" dosyası çekirdek tarafından kullanılan yaratılmış dilimli tahsisat sistemleri hakkında bilgi vermektedir. 
    Ancak bu dosya bizim kmem_cache_create fonksiyonuyla yarattığımız dilimli tahsisat sistemlerini listelememektedir. sys 
    dosya sistemindeki "/sys/kernel/slab" dizini aygıt sürücülerin yaratmış oldukları da dahil olmak üzere bütün dilimli tahsisat 
    sistemleri hakkında bilgiler vermektedir. Burada her kmem_cache_create fonksiyonu ile yaratılmış olan dilimli tahsisat sistemi
    için ayrı bir dizin bulunmaktadır. Ayrıca çekirdeğin kullandığı dilimli tahsisat sistemlerini canlı olarak görüntülemek için
    "slabtop" isimli bir utility program da vardır.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Linux'un dosya sistemi için önemli üç yapı vardır. Bunlar file, dentry ve inode yapılarıdır. file isimli yapıya biz "dosya 
    nesnesi" demiştik. Anımsanacağı gibi ne zaman bir dosya açılsa dosya betimleyici tablosunda dosya betimleyicisi denilen bir 
    indeks bu dosya nesnesini gösterir duruma getirilmektedir. Dosya betimleyici tablosuna (file descriptor table) prosesi temsil 
    eden task_struct yapısından erişilmektedir.

    task_struct ------> dosya betimleyici tablosu

    Dosya Betimleyici Tablosu
    --------------------------

    0 ----> dosya nesnesi (struct file)
    1 ----> dosya nesnesi (struct file)
    2 ----> dosya nesnesi (struct file)
    3 ----> dosya nesnesi (struct file)
    ...

    Dosya nesnesi "açık dosyaların bilgilerini" tutmaktadır. Ne zaman sys_open sistem fonksiyonu çağrılsa sys_open sistem 
    fonksiyonu yeni bir dosya nesnesini (struct file) yaratır, onun adresini dosya betimleyici tablosunda boş bir slota yazar. 
    Bu slotun indeks numarasını dosya betimleyicisi olarak geri döndürür. Aynı dosya ikinci kez açılsa bile yeni bir dosya nesnesi 
    (struct file nesnesi) yaratılmaktadır. Daha önce biz bu struct file yapısının içeriğini görmüştük. Bunu yeniden anımsatmak 
    istiyoruz:

    struct file {
        union {
            /* fput() uses task work when closing and freeing file (default). */
            struct callback_head 	f_task_work;
            /* fput() must use workqueue (most kernel threads). */
            struct llist_node	f_llist;
            unsigned int 		f_iocb_flags;
        };

        /*
        * Protects f_ep, f_flags.
        * Must not be taken from IRQ context.
        */
        spinlock_t				f_lock;
        fmode_t					f_mode;
        atomic_long_t			f_count;
        struct mutex			f_pos_lock;
        loff_t					f_pos;
        unsigned int			f_flags;
        struct fown_struct		f_owner;
        const struct cred		*f_cred;
        struct file_ra_state	f_ra;
        struct path				f_path;
        struct inode			*f_inode;	/* cached value */
        const struct file_operations	*f_op;
        u64			f_version;
    #ifdef CONFIG_SECURITY
        void			*f_security;
    #endif
        /* needed for tty driver, and maybe others */
        void			*private_data;

    #ifdef CONFIG_EPOLL
        /* Used by fs/eventpoll.c to link all the hooks to this file */
        struct hlist_head	*f_ep;
    #endif /* #ifdef CONFIG_EPOLL */
        struct address_space	*f_mapping;
        errseq_t		f_wb_err;
        errseq_t		f_sb_err; /* for syncfs */
    } __randomize_layout
    __attribute__((aligned(4)));	/* lest something weird decides that 2 is OK */

    Eskiden dosya nesnesi dentry nesnesini, dentry nesnesi de inode nesnesini gösteriyordu. Yani durum şöyleydir:

    File ──▶ dentry ──▶ inode

    Daha sonraları dosya nesnesinin içerisinden inode nesnesine daha hızlı erişebilmek için dosya nesnesinin içerisine (yani
    file yapısının içerisine) doğrudan bir inode göstericisi daha eklenmiştir. Mevcut durum şöyledir:

    File ──▶ dentry ──▶ inode
    ╰──────────────────────▶

    inode yapısı dosyanın diskteki bilgilerini tutmaktadır. Yani örneğin aynı dosya üç kez açılsa çekirdek üç farklı file nesnesi 
    oluşturmaktadır. Ancak bu dosya diskte bir tane olduğuna göre çekirdek bunun için toplamda bir tane inode yapısı oluşturacaktır.
    Mevcut çekirdeklerde file yapısının içerisinde dosyanın diskteki bilgilerine ilişkin bu inode yapısına f_inode elemanı yoluyla 
    erişilebilmektedir. Linux işletim sistemi aynı zamanda diskte son erişilen dosyalara ilişkin i-node elemanlarını inode yapısı 
    biçiminde bir cache sisteminde de tutmaktadır. Buna "inode cache" denilmektedir. Örneğin biz "test.txt" isimli bir dosyayı 
    sys_open sistem fonksiyonuyla açmış olalım. İşletim sistemi bunun için bir dosya nesnesi oluşturacak ve bu dosyaya ilişkin 
    inode nesnesi zaten inode cache içerisinde varsa onu cache'ten alıp kullanacaktır. Eğer bu dosyaya ilişkin inode nesnesi 
    "inode cache" içerisinde yoksa işletim sistemi dosyaya ilişkin inode bilgilerini diskten bulup inode nesnesini oluşturacak
    ve "inode cache" içerisine yerleştirecektir. Bu dosya kapatıldığında da işletim sistemi inode yapısını çekirdek alanından 
    atmaz bu inode nesnesi "inode cache" içerisinde kalmaya devam eder. Tabii bu "inode cache" içerisinde belli sayıda inode 
    elemanı tutulmaktadır. Bu cache sistemi dolduğunda LRU (Least Recently Used) algoritmasına göre son zamanlarda en az kullanılan 
    inode elemanı cache'ten atılmaktadır.

    Linux çekirdeğinde dosyanın i-node elemanına erişmekte kullanılan dizin girişleri dentry isimli bir yapıyla temsil edilmiştir. 
    inode yapısı dosyanın diskteki bilgilerini tutarken dentry yapısı dosyanın dizin girişi bilgilerini tutmaktadır. Yukarıda da 
    belirttiğimiz gibi dentry nesnesinin içerisinde inode nesnesinin adresi tutulmaktadır. Örneğin farklı dentry nesneleri aynı 
    inode nesnesini gösteriyor olabilir. Bu tür durumlar "hard link" yoluyla oluşturulmaktadır. Açılmış dosyanın hangi dizinlerin 
    içerisinde bulunduğu bilgisi dentry nesnelerinde tutulmaktadır. Linux işletim sistemi nasıl inode nesnelerini bir cache sisteminde 
    tutuyorsa dentry nesnelerini de ismine "dentry cache" denilen bir cache sistemi içerisinde tutmaktadır. Bir dosyanın open 
    fonksiyonuyla (bu POSIX fonksiyonu doğrudan sys_open sistem fonksiyonunu çağırmaktadır) açıldığını varsayalım. Dosyaya ilişkin 
    dizin girişi bilgilerinin elde edilmesi için ismine "pathname resolution" denilen bir işlem yapılmaktadır. Örneğin biz 
    "/home/kaan/Study/test.txt" dosyasını açmak isteyelim. İşletim sistemi bunun için önce "/home" dizin girişini sonra home 
    dizininde "kaan" dizin girişini, sonra "kaan" dizininde "Study" dizin girişini sonra da "Study" dizininde "test.txt" dizin 
    girişini bulacaktır. İşte tüm bu dizin girişleri aynı zamanda "dentry cache" içerisinde de saklanmaktadır. Böylece bu dosyaya 
    bir daha erişilmek istendiğinde doğrudan bu dizin girişi bilgileri "dentry cache" içerisinden elde edilebilmektedir. Linux 
    işletim sistemi her zaman eğer bir dosyanın dentry nesnesi çekirdek içerisindeyse onun tüm yol ifadesine ilişkin dentry nesnelerini 
    de çekirdek içerisinde tutmaktadır. "dentry cache" sistemi de LRU prensibiyle çalışan bir cache sistemidir.

    Daha önceden de gördüğümüz gibi Bir aygıt sürücü üzerinde dosya işlemi yapıldığında çekirdek aygıt sürücü fonksiyonlarına 
    dosya nesnesinin adresini (filp parametre değişkeni) geçirmektedir. Yalnızca aygıt sürücü open fonksiyonuyla açılırken ve 
    close fonksiyonu ile kapatılırken inode nesnesinin adresi de bu fonksiyonlara geçirilmektedir. Aygıt sürücünün fonksiyonlarının 
    parametrik yapılarını aşağıda yeniden veriyoruz:

    int open(struct inode *inodep, struct file *filp);
    int release(struct inode *inodep, struct file *filp);
    ssize_t read(struct file *filp, char *buf, size_t size, loff_t *off);
    ssize_t write(struct file *filp, const char *buf, size_t size, loff_t *off);
    loff_t llseek(struct file *filp, loff_t off, int whence);
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
												102. Ders 15/05/2025 - Perşembe
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Aygıt sürücünün majör ve minör numaraları ne anlam ifade etmektedir? Majör numara aygıt sürücünün türünü, minör numara ise 
    aynı türden aygıt sürücülerin farklı örneklerini (instance'larını) belirtmektedir. Başka bir deyişle minör numara aygıt sürücünün 
    yönettiği aygıtların numaralarını belirtmektedir. Örneğin biz yukarıdaki "pipe-driver" aygıt sürücümüzün tek bir boruyu değil 
    on farklı boruyu idare etmesini isteyebiliriz. Bu durumda aygıt sürücümüzün bir tane majör numarası ancak 10 tane minör numarası 
    olacaktır. Aygıt sürücülerin majör numaraları aynı ise bunların kodları da aynıdır. O aynı kod birden fazla aygıt için işlev 
    görmektedir. Örneğin seri portu kontrol eden bir aygıt sürücü söz konusu olsun. Ancak bilgisayarımızda dört seri port olsun. 
    İşte bu durumda bu seri porta ilişkin aygıt dosyalarının hepsinin majör numaraları aynıdır. Ancak minör numaraları farklıdır. 
    Ya da örneğin terminal aygıt sürücüsü bir tanedir. Ancak bu aygıt sürücü birden fazla terminali yönetebilmektedir. O halde her 
    terminale ilişkin aygıt dosyasının majör numaraları aynı minör numaraları farklı olacaktır. Örneğin:

    $ ls -l tty1 tty2 tty3 tty4 tty5
    crw--w---- 1 root tty 4, 1 Haz  2 15:05 tty1
    crw--w---- 1 root tty 4, 2 Haz  2 15:05 tty2
    crw--w---- 1 root tty 4, 3 Haz  2 15:05 tty3
    crw--w---- 1 root tty 4, 4 Haz  2 15:05 tty4
    crw--w---- 1 root tty 4, 5 Haz  2 15:05 tty5

    Örneğin diskleri yöneten bir aygıt sürücüsü olsun. Ancak bilgisayarımızda üç farklı fiziksel disk olsun. Bu disklerin 
    yönetimleri aynı biçimde aynı kodlarla yapılmaktadır. Bunları yöneten tek bir aygıt sürücü kodu dolayısıyla majör numarası 
    vardır. Ancak her disk ayrı bir minör numarayla temsil edilir.
-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------
    Şimdi de bir aygıt sürücünün aynı türden birden fazla aygıtı nasıl yönetebileceğini ele alacağız. Birden fazla aygıtı yönetecek 
    (yani birden fazla minör numaraya sahip olan) bir aygıt sürücü nasıl yazılabilir? Her şeyden önce birden fazla minör numara 
    kullanan aygıt sürücüleri yazarken dikkatli olmak gerekir. Çünkü tek bir kod birden fazla aynı türden bağımsız aygıtı idare 
    edecektir. Dolayısıyla bu tür durumlarda bazı nesnelerin senkronize edilmesi gerekebilir.

    Birden fazla minör numara üzerinde çalışacak (yani birden fazla aynı türden aygıt üzerinde çalışacak) aygıt sürücüler tipik 
    olarak şöyle yazılmaktadır:

    1) Aygıt sürücüyü yazan programcı baştan onun kaç minör numaraya ilişkin aygıtı yöneteceğini belirlemelidir. Bunun için default
    bir değer kullanılabilir. Ancak genellikle aygıt sürücünün kaç minör numaraya ilişkin aygıtı yöneteceği aygıt sürücüye komut 
    satırı argümanlarıyla geçirilmektedir. Biz de örneğimizde bu yöntemi kullanacağız. Minör numara sayısının aşağıdaki gibi 
    ndevices isimli parametre yoluyla komut satırından aygıt sürücüye aktarıldığını varsayacağız:

    #define DEF_NDEVICES		10
    ...
    static int ndevices = DEF_NDEVICES;
    module_param(ndevices, int, S_IRUSR|S_IWUSR|S_IRGRP|S_IROTH);

    Bu durumda bu aygıt sürücü yüklenirken ndevices parametresi argüman girilmezse DEF_NDEVICES değeri dikkate alınmaktadır. 
    Örneğin bu aygıt sürücüyü 5 aygıtı yönetecek biçimde aşağıdaki gibi yükleyebiliriz:

    ./insmod pipe-driver.ko ndevices=5

    2) Programcının aygıt sürücü için majör ve minör numaraları tahsis etmesi gerekir. Daha önce yaptığımız gibi majör numara 
    alloc_chrdev_region fonksiyonuyla dinamik olarak belirlenebilmektedir. Bu fonksiyon aynı zamanda belli bir minör numaradan 
    başlayarak n tane minör numarayı da tahsis edebilmektedir. Örneğin:

    if ((result = alloc_chrdev_region(&g_dev, 0, ndevices, "pipe-driver")) < 0) {
        printk(KERN_ERR "cannot register device!...\n");
        goto EXIT1;
    }

    Burada 0'ıncı minör numaradan ndevices tane minör numara için aygıt tahsisatı yapılmıştır. Tabii g_dev nesnesi yalnızca ilk 
    minör numaraya ilişkin (örneğimizde 0) aygıt numarasını tutmaktadır.

    3) Her aygıt bir yapıyla temsil edilmelidir. Bunun için N elemanlı bir yapı dizisi yaratabilirsiniz. Bu dizi global düzeyde 
    tanımlanabileceği gibi kmalloc fonksiyonuyla dinamik biçimde de tahsis edilebilir. Oluşturulan bu yapının içerisine struct cdev 
    nesnesi de eklenmelidir. Örneğin:

    struct PIPE_DEVICE {
        unsigned char pipebuf[PIPE_BUFFER_SIZE];
        size_t head;
        size_t tail;
        size_t count;
        struct semaphore sem;
        wait_queue_head_t wqwriteopen;
        wait_queue_head_t wqreadopen;
        wait_queue_head_t wqread;
        wait_queue_head_t wqwrite;
        int nreaders;
        int nwriters;
        struct cdev cdev;
    };

    Burada görüldüğü gibi her farklı borunun farklı bekleme kuyrukları ve semaphore nesnesi vardır. cdev yapı nesnesinin yapının 
    içerisine yerleştirilmesinin amacı ileride görüleceği gibi bu adresten hareketle yapı nesnesinin adresinin elde edilmesini 
    sağlamaktır. Bunun nasıl yapıldığı izleyen paragraflarda görülecektir.

    Biz tüm minör aygıtları yaratacağımız bir dilimli tahsisat sisteminden tahsis edeceğiz. Bu minör aygıt nesnelerinin adreslerini 
    de kmalloc ile tahsis ettiğimiz bir göstericisi dizisinde saklayacağız:

    if ((g_pipe_cachep = kmem_cache_create("pipe_cachep", sizeof (struct PIPE_DEVICE), 0, SLAB_HWCACHE_ALIGN, NULL)) == NULL) {
        printk(KERN_ERR "cannot create pipe cache!...\n");
        result = -ENOMEM;
        goto EXIT3;
    }
    for (i = 0; i < ndevices; ++i) {
        if ((g_devices[i] = kmem_cache_alloc(g_pipe_cachep, GFP_KERNEL)) == NULL) {
            printk(KERN_ERR "cannot allocate slab from pipe cache!...\n");
            result = -ENOMEM;
            for (k = 0; k < i; ++k)
                kmem_cache_free(g_pipe_cachep, g_devices[k]);
            goto EXIT4;
        }
    }

    3) N tane minör numaralı aygıt için cdev_add fonksiyonuyla aygıtlar çekirdeğe eklenmelidir. Örneğin:

    for (i = 0; i < ndevices; ++i) {
        g_devices[i]->head = g_devices[i]->tail = g_devices[i]->count = 0;
        sema_init(&g_devices[i]->sem, 1);
        init_waitqueue_head(&g_devices[i]->wqwriteopen);
        init_waitqueue_head(&g_devices[i]->wqreadopen);
        init_waitqueue_head(&g_devices[i]->wqread);
        init_waitqueue_head(&g_devices[i]->wqwrite);
        g_devices[i]->nreaders = g_devices[i]->nwriters = 0;
        cdev_init(&g_devices[i]->cdev, &g_fops);
        dev = MKDEV(MAJOR(g_dev), i);
        if ((result = cdev_add(&g_devices[i]->cdev, dev, 1)) < 0) {
            for (k = 0; k < i; ++k)
                cdev_del(&g_devices[k]->cdev);
            printk(KERN_ERR "cannot add device!...\n");
            goto EXIT5;
        }
    }

    Burada yapı dizisinin her elemanındaki elemanlara ilkdeğerleri verilmiştir. Sonra her boru için ayrı bir cdev nesnesi cdev_add 
    fonksiyonu ile eklenmiştir. Eklemelerden biri başarısız olursa daha önce eklenenlerin de cdev_del fonksiyonu ile silindiğine 
    dikkat ediniz.

    4) Aygıt sürücünün exit fonksiyonunda tahsis edilen tüm kaynaklar ters sırada geri bırakılmalıdır. Örneğin:

    static void __exit pipe_driver_exit(void)
    {
        int i;

        for (i = 0; i < ndevices; ++i)
            kmem_cache_free(g_pipe_cachep, g_devices[i]);
        kmem_cache_destroy(g_pipe_cachep);
        kfree(g_devices);
        for (i = 0; i < ndevices; ++i)
            cdev_del(&g_devices[i]->cdev);
        printk(KERN_INFO "pipe-driver module exit...\n");
    }

    5) Bizim read, write gibi aygıt sürücü fonksiyonlarında file yapısı türünden adres belirten filp parametre değişkeni yoluyla 
    PIPE_DEVICE yapısına erişmemiz gerekir. Bu işlem dolaylı bir biçimde şöyle yapılmaktadır:

    <BURADA KALDIK>

    - Önce aygıt sürücünün open fonksiyonunda programcı inode yapısının i_cdev elemanından hareketle cdev nesnesinin içinde 
    bulunduğu yapı nesnesinin başlangıç adresini container_of makrosuyla elde eder. Çünkü inode yapısının i_cdev elemanı cdev_add
    fonksiyonuyla eklenen cdev yapı nesnesinin adresini tutmaktadır.

    - Programcı device nesnesinin adresini elde ettikten sonra onu file yapısının private_data elemanına yerleştirir. file yapısının
    private_data elemanı programcının kendisinin isteğe bağlı olarak yerleştirebileceği bilgiler için bulundurulmuştur.

    Bu işlemler aşağıdaki gibi yapılabilir:

    static int generic_open(struct inode *inodep, struct file *filp)
    {
        struct PIPE_DEVICE *pdevice;

        pdevice = container_of(inodep->i_cdev, struct PIPE_DEVICE, cdev);
        filp->private_data = pdevice;

        printk(KERN_INFO "pipe-driver opened...\n");

        return 0;
    }

    5) Aygıt sürücünün read ve write fonksiyonları yazılır.

    6) release (close) işleminde yapılacak birtakım son işlemler varsa yapılır.

    7) Birden fazla minör numara için çalışacak aygıt sürücülerin birden fazla aygıt dosyası yaratması gerekir. Yani aygıt sürücüsü 
    kaç minör numarayı destekliyorsa o sayıda aygıt dosyalarının yaratılması gerekmektedir. Bu da onları yüklemek için kullandığımız 
    load scriptinde değişiklik yapmayı gerektirmektedir. N tane minör numaraya ilişkin aygıt dosyası yaratacak biçimde yeni bir 
    "loadmulti" isimli script aşağıdaki gibi yazılabilir:

    #!/bin/bash

    module=$2
    mode=666

    /sbin/insmod ./${module}.ko ${@:3} || exit 1
    major=$(awk "\$2 == \"$module\" {print \$1}" /proc/devices)

    for ((i = 0; i < $1; ++i))
    do
        rm -f ${module}$i
        mknod -m $mode ${module}$i c $major $i
    done

    Buradaki "loadmulti" script'i iki komut satırı argümanıyla aşağıdaki örnekteki gibi çalıştırılmalıdır:

    $ sudo ./loadmulti 10 pipe-driver ndevices=10

    Burada "loadmulti" script'i hem aygıt sürücüyü yükleyecek hem de pipe-driver0, pipe-driver1, ..., pipedriver9 biçiminde 
    aygıt dosyalarını yaratacaktır. Aşağıda yaratılmış olan örnek aygıt dosyalarına dikkat ediniz:

    crw-rw-rw- 1 root root  236, 0 Haz  7 22:09 pipe-driver0
    crw-rw-rw- 1 root root  236, 1 Haz  7 22:09 pipe-driver1
    crw-rw-rw- 1 root root  236, 2 Haz  7 22:09 pipe-driver2
    crw-rw-rw- 1 root root  236, 3 Haz  7 22:09 pipe-driver3
    crw-rw-rw- 1 root root  236, 4 Haz  7 22:09 pipe-driver4
    crw-rw-rw- 1 root root  236, 5 Haz  7 22:09 pipe-driver5
    crw-rw-rw- 1 root root  236, 6 Haz  7 22:09 pipe-driver6
    crw-rw-rw- 1 root root  236, 7 Haz  7 22:09 pipe-driver7
    crw-rw-rw- 1 root root  236, 8 Haz  7 22:09 pipe-driver8
    crw-rw-rw- 1 root root  236, 9 Haz  7 22:09 pipe-driver9

    Aygıt dosyalarının majör numaralarının hepsi aynıdır ancak minör numaraları farklıdır. Burada adeta birbirinden bağımsız 
    10 ayrı boru aygıtı var gibidir. Ancak aslında tek bir aygıt sürücü kodu bulunmaktadır. Tabii bizim benzer biçimde "unload"
    script'ini de tüm aygıt dosyalarını silecek biçimde düzeltmemiz gerekir. Bunun için "unloadmulti" script'ini aşağıdaki gibi
    yazabiliriz:

    #!/bin/bash

    module=$2

    /sbin/rmmod ./$module.ko || exit 1
    for ((i = 0; i < $1; ++i))
    do
        rm -f ${module}$i
    done

    Bu script'te biz modülü önce çekirdekten sonra da "loadmulti" ile yarattığımız aygıt dosyalarını dosya sisteminden sildik. 
    Script aşağıdaki örnekteki gibi kullanılmalıdır:

    $ sudo ./unloadmulti 10 pipe-driver

    Daha önce yapmış olduğumuz boru aygıt sürücüsünün 10 farklı minör numarayı destekleyen biçimini aşağıda veriyoruz.

-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------*/

/*-----------------------------------------------------------------------------------------------------------------------------

-----------------------------------------------------------------------------------------------------------------------------*/


