#--------------------------------------------------------------------------------------------------------------------------

                                               C ve Sistem Programcıları Derneği

                                    Üretici Yapay Zeka, Doğal Dil İşleme ve Büyük Dil Modelleri

                                             Sınıfta Özet Notlar ve Örnekler
            
                                                    Eğitmen: Kaan ASLAN
                                                    
            Bu notlar Kaan ASLAN tarafından oluşturulmuştur. Kaynak belirtmek koşulu ile her türlü alıntı yapılabilir.
                Kaynak belirtmek için aşağıdaki referansı kullanabilirsiniz:           

            Aslan, K. (2026), "Doğal Dil İşleme, Büyük Dil Modelleri, Üretici Ağlar Kurssu, Özet Notlar ve Örnekler
                                        C ve Sistem Programcıları Derneği, İstanbul.

                    (Notları sabit genişlikli font kullanan programlama editörleri ile açınız.)
                        (Editörünüzün "Line Wrapping" özelliğini pasif hale getiriniz.)
                                                            
                                        Son Güncelleme Tarihi: 05/02/2026 - Perşembe
                                         
#---------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
                                            1. Ders 02/02/2026 - Pazartesi
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Katılımcılarla tanışıldı.
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Kursun genel işleyişi açıklandı. Kursumuzun Dropbox bağlantısı şöyledir:,

    https://www.dropbox.com/scl/fo/k35ffkp5cuml1d6640m8s/AETyCOuySFvOVcjtwWQjiG0?rlkey=domd0y77v1ka6wgagll85jgp6&dl=0

#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Derneğimiz açtığı bu kursumuzla ilişkili kurslar şunlardır:

    - Python Programlama Dili Kursu : Bu kurs Python Programlama Dilini kapsamlı bir biçimde öğretmeyi hedeflemektedir. 
    "Python Programlama Dili" kursumuzun Dropbox bağlantısı şöyledir:

    https://www.dropbox.com/sh/hez3g36x6xa97cu/AAAJzxu2Yrza9cCcO1DJWrWia?dl=0

    - Python Uygulamaları Kursu: Bu kurs Python Programlama Dilini bilenler için bir uygulama kursudur. Programlama dilinin 
    dışındaki pek çok kütüphane ve framework'ün kullanımı bu kursun konusu içerisindedir. NumPy, Pandas, Matplotlib gibi 
    yapay zeka ve makine öğrenmesinde yoğun kullanılan kütüphaneler resmi olarak bu kursta ele alınmaktadır. "Python 
    Uygulamaları" kursumuzun Dropbox bağlantısı şöyledir:

    https://www.dropbox.com/sh/vylimm3evek0nnl/AABS_KdWdRMO6Xh0Fh6HT3rFa?dl=0

    - Yapay Zeka, Makine Öğrenmesi ve Veri Bilimi Kursu: Bu kurs genel bir yapay zeka, makine öğrenmesi ve veri bilimi 
    kursudur. Kurs içerisinde sinir ağları, çeşitli istatitiksel öğrenme yöntemleri ve veri bilimine ilişkin pek çok 
    konu ele alınmaktadır. "Yapay Zeka, Makine Öğrenmesi ve Veri Bilimi" kursumuzun Dropbox bağlantısı şöyledir:

    https://www.dropbox.com/sh/xvnprjjs7w74x05/AADi9NaU4aiHYHYREwKZgIzQa?dl=0
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Kursumuzda programlama dili olarak Python kullanılacaktır. Python "genel amaçlı, yüksek seviyeli, matematiksel alana 
    yakın ve nispeten basit" bir programlama dilidir. Python "yapay zeka, makine öğrenmesi, veri bilimi ve doğal dil 
    işlemede" halen en çok kullanılan programlama dilidir. Python son 10 senedir bir atak yapmış ve dünyanın en yaygın 
    kullanılan programlama dili haline gelmiştir. Python'un neden bu kadar popüler hale geldiği ve neden yapay zeka, makine 
    öğrenmesi ve veri bilimi alanlarında yaygın biçimde kullanıldığı konusundaki tespitlerimiz şöyledir:

    - Python nispeten basit bir dildir. Python'un basitliği başka alanlardan gelip de ana uğraşı alanı programlama olmayan 
    kişiler için uygun bir seçenek oluşturmaktadır.

    - Python matematiksel ve veri işleme alanları için uygun bir tasarıma sahiptir.

    - Python çeşitli yüksek seviyeli veri yapılarını bünyesinde barındırmaktadır. Python'da az tuşa basılarak çok şey 
    yapmak mümkündür.

    - Python'da yukarıda belirttiğimiz alanlara yönelik pek çok hazır kütüphane ve framework bulunmaktadır. Bu alanlardaki 
    algoritmaları tasarlayanlar onları birincil olarak Python'da gerçekleştirmektedir.

    - Python programlama dili olarak özellikle 3'lü versiyonlarla birlikte oldukça iyileştirilmiştir. 

    - ABD'de MIT gibi üst düzey üniversiteler belli bir süredir Python dilini "Programlamaya Giriş (Introduction to 
    Programming)" gibi derslerde kullanmaya başlamıştır. Bu da dilin prestijini artırmıştır. 

    - Python'un geniş bir standart kütüphanesi vardır. Bu duruma Python dünyasında esprili olarak "bataryası içinde 
    (batteries included)" denilmektedir. Python Standart Kütüphanesi içerisinde çok çeşitli konulara yönelik büyük ölçüde 
    platform bağımsız olan hazır fonksiyonlar ve sınıflar bulunmaktadır. Bu da programlamyı oldukça kolaylaştırmaktadır. 
    Her ne kadar Python Standart Kütüpahesi içerisinde olmasa da NumPy gibi, Pandas gibi, Matplotlib gibi yardımcı 
    kütüphaneler Python'da veri analizine ilişkin işlemleri oldukça kolaylaştırmaktadır. 

    - Python bir prototip dil olarak da kullanılmaktadır. Bir algoritma ya da uygulama "acaba oluyor mu diye" hızlı bir 
    biçimde Python'da oluşturulabilmektedir. Bazı uygulamacılar ve firmalar bu prototipleri daha sonra C/C++, Rust, Java, 
    C# gibi dillerde ürüne dönüştürebilmektedir. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
                                            2. Ders - 18/01/2026 - Pazar
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Python temel olarak yorumlayıcı tabanlı (interpretive) bir propogramlama dilidir. Python kodlarını çalıştıran programlara
    Python dünyasında genel olarak "Python gerçekleştirimleri (Python Implementations)" denilmektedir. Python'un sürdürümünden 
    sorumlu olan "Python Software Foundaion" kurumunun ana Python gerçekleştirimine (Buna İngilizce "reference implementation"
    da denilmektedir) "CPython" denilmektedir. (CPython ismi bu yorumlayıcının C dilinde yazılmış olduğundan dolayı verilmiştir.)
    Python gerçekleştirimlerinin yanı sıra birtakım araçları da bünyesinde barındıran çeşitli Python dağıtımları oluşturulmuştur. 
    Yapay zeka, makine öğrenmesi ve veri bilimi alanlarında en çok Anaconda isimli dağıtım kullanılmaktadır. Biz de kurusumuzda 
    bu dağıtımı kullanacağız. Anaconda dağıtımını aşağıdaki bağlantıdan indirebilirsiniz:

    https://www.anaconda.com/download/success

    Anaconda dağıtımının temel GUI arayüzü "Anaconda Navigator" denilen programdır. Anaconda Navigator dağıtım içerisindeki 
    çeşitli araçları bünyesinde barındıran ve bazı işlemlerin yapılmasını kolaylaştıran yönetici bir program gibidir. 
    Anaconda dağıtımı birincil olarak "Spyder" isimli IDE'yi kullanmaktadır. Spyder IDE'si aslında bağımsız bir projedir. 
    Yani bu IDE'yi Anaconda olmadan da bilgisayarınıza yükleyerek kullanabilirsiniz. Anconda dağıtımı kurulduğu zaman 
    Python Standart Kütüphanesinin dışında pek çok yardımcı kütüphane de kurulmuş olmaktadır. Yani NumPy, Pandas, Matplotlib 
    gibi temel kütüphaneleri ayrıca kurmaya gerek kalmamaktadır. 

    Python diğer bazı yüksek seviyeli diller gibi komut satırı çalışmasına da izin vermektedir. Bu tür komut satırlı 
    çalışmalara son zamanlarda "REPL (Read and Evaluate and Print Loop)" da denilmektedir. Bu çalışma biçiminde bir prompt 
    çıkar. Bu prompt'ta kullanıcı bir Python deyimi yazarak ENTER tuşuna basar. Python yorumlayıcısı da o deyimi o anda 
    çalıştırır ve yeniden prompt'a düşer. 
    
    CPython dağıtımında komut satırında doğrudan "python" programı çalıştırılır ancak bir program dosyası komut satırı argümanı 
    olarak bir kaynak dosya verilmezse komut satırına düşülmektedir. "python" programı çalıştırılırken yanına komut satırı 
    argümanı olarak bir kaynak dosya ismi verilirse python yorumlayıcısı komut satırına düşülmeden o dosya çalıştırılmaktadır. 
    Aslında Python'da deyimleri tek tek çalıştıran başka REPL uygulamaları da vardır. Bunların en yaygın kullanılanılanlarından 
    biri IPython denilen uygulamadır. (Spyder IDE'si de sağ tarafta IPython konsolunu kullanmaktadır.) IPython da aslında 
    bağımsız olarak kurulabilen ayrı bir uygulamadır. IPython'daki bu komut satırı proseslerine "kernel" da denilmektedir. 
    Spyder'daki sağ bölmede birden fazla IPython konsolu açılabilmektedir. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Yapay zeka, makine öğrenmesi ve veri bilimi eğitiminde çok kullanılan ismine "Jupyter Notebook" denilen bir araç da 
    vardır. Jupyter Notebook açıklama yazılarıyla Python kodlarını bir arada farklı hücrelerde tutabilmektedir. Pek çok 
    bulut sistemi Jupyter Notebook hizmeti de vermektedir. Ancak biz kursumuzda çalışma hızını yavaşlattığı gerekçesiyle
    Jupyter Notebook kullanmayacağız. Anaconda Navigator içerisinde Jupyter Notebook da bulunmaktadır. Jupyter Notebook 
    artık pek çok IDE'ye de entegre edilmiştir. Örneğin VSCode IDE'sinde bir plugin olarak da yüklenebilmektedir.
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Yapay zeka, makine öğrenmesi ve veri biliminde Python'un standart kütüphanesinden ziyade birtakım üçüncü patyi 
    kütüphaneler çok daha yoğun bir biçimde kullanılmaktadır. Bu bölümde bu kütüphaneler hakkında bazı temel bilgiler 
    vereceğiz. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    NumPy, Python'da vektörel işlemlerin yapılabilmesine olanak sağlayan en temel kütüphanelerden biridir. NumPy sayesinde 
    örneğin bir dizideki elemanların hepsi tek hamlede işlemlere sokulabilmekte, NumPy dizisi çarpıldığında dizinin 
    karşılıklı elemanları çarpılabilmektedir. Ya da örneğin bir NumPy Dizisinin sinüsü alındığında dizinin tüm elemanlarının 
    sinüsü elde edilebilmektedir. Bu tür özelliklere sahip olan dillere "dizisel diller (array languages)" de denilmektedir. 
    Matlab gibi R gibi matematiksel alana yakın olan dillerin bu biçimde vektörel işlemler yapabilme yeteneği vardır. 
    İşte NumPy kütüphanesi Python'a bu yeteneği kazandırmaktadır. 
    
    NumPy kütüpahnesi C'de yazılmıştır. Dolayısıyla aslında bu kütüphane kullanılarak işlemler yapılırken arka planda C'de 
    yazılmış olan kodlar çalıştırılmaktadır. Bu durum NumPy işlemlerinin Python'un doğal çalışmasına göre daha hızlı 
    yapılabildiği anlamına gelmektedir. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Pandas kütüphanesi NumPy kullanılarak yazılmıştır. Pandas istatistiksel veri tablolarını oluşturabilme olanağını
    sunmaktadır. İstatistikte, veri biliminde ve makine öğrenmesinde her sütunu farklı türden olabilen veri tablolarıyla 
    çok sık karşılaşılmaktadır. Bu tür veri tablolarında satırlarda varlıklar sütunlarda ise onların özellikleri bulunur. 
    Örneğin:

    ┌──────┬──────┬─────────┬────────────────────┐
    │ Boy  │ Kilo │ Cinsiyet│ Tercih Edilen Renk │
    ├──────┼──────┼─────────┼────────────────────┤
    │ 170  │ 68   │ Erkek   │ Mavi               │
    │ 165  │ 55   │ Kadın   │ Yeşil              │
    │ 180  │ 82   │ Erkek   │ Siyah              │
    │ 158  │ 52   │ Kadın   │ Mor                │
    │ 175  │ 74   │ Erkek   │ Gri                │
    │ 162  │ 58   │ Kadın   │ Kırmızı            │
    │ 185  │ 90   │ Erkek   │ Lacivert           │
    │ 168  │ 60   │ Kadın   │ Turuncu            │
    │ 172  │ 70   │ Erkek   │ Beyaz              │
    │ 160  │ 54   │ Kadın   │ Pembe              │
    └──────┴──────┴─────────┴────────────────────┘

    Burada sütunlar farklı türlerdendir. İşte NumPy ile böyle bir temsil oluşturulamamaktadır. Çünkü NumPy'daki iki boyutlu 
    dizilerin her elemanı aynı türden olmak zorundadır. İşte Pandas bizim yukarıdaki gibi veri tablolarını oluşturmamıza 
    olanak sağlamaktadır. Pandas'taki bu biçimde veri tablosu temsilinin yapılmasını sağlayan sınıfa DataFrame denilmektedir. 
    Pandas denilince akla DataFrame sınıfı gelir. DataFrame nesnelerinin sütunlarına da Pandas da Series denilmektedir. 
    Yukarıdaki veri tablosu Pandas kütüphanesi ile bir DataFrame olarak şöyle oluşturulabilmektedir.

    import pandas as pd

    data = {
        "Boy": [170, 165, 180, 158, 175, 162, 185, 168, 172, 160],
        "Kilo": [68, 55, 82, 52, 74, 58, 90, 60, 70, 54],
        "Cinsiyet": [
            "Erkek", "Kadın", "Erkek", "Kadın", "Erkek",
            "Kadın", "Erkek", "Kadın", "Erkek", "Kadın"
        ],
        "Tercih Edilen Renk": [
            "Mavi", "Yeşil", "Siyah", "Mor", "Gri",
            "Kırmızı", "Lacivert", "Turuncu", "Beyaz", "Pembe"
        ]
    }
    df = pd.DataFrame(data)
    print(df)
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Yapay zeka, mekine öğrenmesi ve veri bilimi alanında görselleştirme için en yaygın kullanılan kütüphane "Matplotlib" 
    denilen kütüphanedir. Bu kütüphanenin yanı sıra "Seaborn" ve "Plotly" kütüphaneleri de yaygın kullanılmaktadır. Bu 
    alanlardaki uygulamalarda bir biçimde görselleştirmenin yapılmasına gereksinim duyulmaktadır. Kursumuzda ağırlıklı 
    olarak bu tür görselleştirmeler için Matplotlib kütüphanesini kullanacağız. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
                                            3. Ders - 24/01/2026 - Cumartesi
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Makine öğrenmesinde en çok kullanılan kütüphanelerden biri de "scikit-learn" denilen kütüphanedir. Bu kütüphane 
    makine öğrenmesinin "istatistiksel, olasılıksal ve matematiksel" yöntemlerine ilişkin işlemler yapan sınıfları ve 
    fonksiyonları barındırmaktadır. Bugün en yaygın kullanılan makine öğrenmesi teknikleri yapay sinir ağlarını kullanmaktadır. 
    sckit-learn ise yapay sinir ağlarına ilişkin yöntemleri içermemektedir. (scikit-learn içerisinde ilkel düzeyde yapay 
    sinir ağlarına yönelik birkaç sınıf bulunuyorsa da bunlar son derece yüzeyseldir.) 

    scikit-learn kütüphanesi Python'da yazılmıştır ve NumPy kütüphanesini taban kütüphane olarak kullanmaktadır. Bu 
    kütüphanein diğer programlama dillerinden kullanılması doğrudan mümkün değildir. Ancak dolaylı biçimlerde -verimli 
    olmasa da- kullanım sağlanabilmektedir. Eskiden TensorFlow gibi, PyTorch gibi yapay sinir ağlarına ilişkin kütüphaneler 
    (bunlara "framework" de diyebliriz) bazı temel işlemleri bünyesinde barındırmıyordu. Bu nedenle scikit-learn kullanılması 
    neredeyse zorunlu hale geliyordu. Ancak daha sonraları TensorFlow gibi PyTorch gibi yapay sinir ağı framework'leri de 
    scikit-learn tarafından sınulan bazı işlemleri bünyesine katmıştır. Biz kursumuzda özellikle klasik doğal dil işleme 
    yöntemlerinde scikit-learn kütüphanesini kullanacağız. scikit-learn Anaconda dağıtımında default biçimde yüklü olarak
    bulunmaktadır. Ancak diğer ortamlar için bu kütüphaneyi şöyle kurabilirsiniz:

    pip install scikit-learn

    scikit_learn kütüphanesinde işlemler belli bir kalıba uygun bir biçimde yürütülmektedir. Buna "fit/transform/predict
    kalıbı" diyebiliriz. Kütüphane büyük ölçüde nesne yönelimli biçimde tasarlanmıştır. fit/transform/predict kalıbı 
    şöyle kullanılmaktadır:

    1) Önce ilgili sınıf türünden bir nesne yaratılır. Yaratım sirasında ilgili konuya ilişkin çeşitli argümanlar da 
    girilmektedir. Örneğin:

    cv = CountVectorizer(...)

    2) İlgili sınıf türünden nesne yaratıldıktan sonra eğitimin yapılması gerekir. Burada "eğitim (training)" demekle 
    kullanılacak algoritmanın işletilmesi ve kestirim ya da sonuç için gereken bilgilerin elde edilerek nesnenin 
    özniteliklerinde (attributes) saklanması kastedilmektedir. Örneğin doğrusal regresyon uygulamak için regresyon 
    doğrusuna ilişkin (genel olarak "hyper-plane" denilmektedir) katsayıların elde edilmesi gerekir. İşte LinearRegression 
    sınıfının fit  metodu bu katsayıları elde edip nesnenin özniteliklerinde  sağlamaktadır. fit metoduna tipik olarak 
    bir NumPy dizisi verilir. Ancak bu metotlar Python listeleriyle Pandas'ın series nesneleriyle de çalışabilmektedir. 
    Örneğin:

    cv.fit(dataset)

    fit işlemiyle eğitim sonucunda elde edilen bilgiler nesnenin özniteliklerinde (attributes) saklanmaktadır. 

    3) Artık sıra sonucu elde etmeye gelmiştir. Bunun için transform  metotları kullanılmaktadır. transform metotları 
    programcıdan dönüştürülecek verileri bir NumPy disizi olarak (Python listeleri ve Pandas Series nesneleri de 
    kullanılabilmektedir) alır ve kestirimi yaparak sonucu bize verir. Sınıfların pek çoğunda (ama hepsinde değil) 
    fit ve transform işlemlerini birlikte yapan fit_transform metotları da bulunmaktadır. (Bazı sınıflarda  inverse_transform 
    metotları da vardır. inverse_transform metotları ters işlemi yapmaktadır.) Örneğin:

    transformed_dataset = cv.transform(target_dataset)

    4) Scikit-learn içerisindeki sınıfların bazıları dönüştürme, bazıları ise kestirim yapmaktadır. Dönüştürme yapan 
    sınıflarda dönüştürmeler genel olarak transform isimli metotlarla, kestirim yapan sınıflarda ise kestirimler predict 
    isimli metotlarla yapılmaktadır. predict metotlarına kestirilecek veriler argüman verilir, metotlar da sonucu bize verir. 
    Örneğin:

    lr = LinearRegression(...)
    lr.fit(dataset)
    predict_result = lr.predict(predict_dataset)

    Scikit-learn kütüphanesindeki fit/transform/predict kalıbı boru hattı (pipeline) mekanizmasının uygulanmasını da 
    mümkün hale getirmektedir. Makine öğrenmesinde "boru hattı (pipeline)" bir işlemin çıktısının diğer işleme girdi 
    yapılması, onun çıktısın da diğerine girdi yapılması ve böylece işlemlerin peşi sıra daha zahmetsiz bir biçimde 
    gerçekleştirilmesi anlamına gelmektedir. Örneğin önce SimpleImputer işlemini, onun çıktısı üzerinde de StandardScaler 
    işlemini yapmak isteyelim. StandardScaler işleminin çıktısını da SVM işlemine sokmak isteyelim. Boru hattı kullanmadan 
    bunları aşağıdaki gibi tek tek yapmak zorunda kalırız:

    si = SimpleImputer(...)
    si_transformed = si.fit_transform(...)

    ss = StandardScaler(...)
    ss_transfomed = ss.fit_transform(si_transformed)

    svm = SVM(...)
    result = svm.fit_transform(ss_transfomed)

    İşte boru hattı mekanizması sayesinde bu işlemler tek tek değil önceki çıktıyı sonraki girdiye vererek otomatik 
    bir biçimde de yapılabilmektedir:

    pl = PipeLine([('Imputing', SimpleImputer(...)), ('Scaling', StandardScaler(...)), ('SVM', SVM(...))])
    result = pi.fit_transform(...)
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Bilimsel uygulamalarda en fazla kullanılan kütüphanelerden biri de SciPy isimli kütüphanedir. SciPy temelde bir 
    nümerik analiz kütüphanesidir. Bu kütüphane pek çok matematiksel işlem yapan sınıflara ve fonksiyonlara sahiptir. 
    Örneğin bir fonksiyonun maksimum ve minimum noktalarının elde edilmesi gibi, bir fonksiyonun belli bir noktadaki 
    türevinin elde edilmesi gibi, bir denklemim köklerinin bulunması gibi işlemler SciPy kütüphanesiyle yapılabilmektedir. 
    SciPy lineer cebir ve istatistik paketlerine de sahiptir. Örneğin SciPy ile doğrusal denklem sistemleri çözülebilmekte, 
    bazı istatistiksel hipotez testleri gerçekleştirilebilmektedir. 
    
    Anconda dağıtımında SciPy kütüphanesi de yüklü olarak gelmektedir. Ancak diğer ortamlara kütüphaneyi şöyle kurabilirsiniz:

    pip install scipy

    SciPy kütüphanesi taban kütüphane olarak NumPy kütüphanesini kullanmaktadır. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Yapay sinir ağlarına ilişkin iki taban (base) kütüphane yaygın olarak kullanılmaktadır: TensorFlow ve PyTorch. TensorFlow 
    kütüphanesi Google kökenli, PyTorch ise Meta (Facebook) kökenlidir.  Eskiden TensorFlow en yoğun kullanılan kütüphaneydi. 
    Ancak son yıllarda PyTorch kütüphanesini tercih edenler TensorFlow kütüphanesini tercih edenlerden fazla hale gelmiştir. 
    Bunların yanı sıra eskiden Theano isimli bir kütüphane de özellikle akademik çevreler tarafından kullanılıyordu. Ancak 
    2017 yılından beri bu kütüphanenin geliştirilmesi durdurulmuştur. 

    TensorFlow ve PyTorch için "kütüphane" yerine "framework" terimi de kullanılabilmektedir. Bir yazılımsal araca 
    "framework" denilebilmesi için onun "akışı bazen programcıdan alıp, gerektiğinde programcının belirlediği fonksiyonları 
    çağırabilmesi (inversion of control)" gerekmektedir. Bu açıdan bakıldığında TensorFlow ve PyTorch için "framework" 
    nitelemesi de yapılabilir. Ancak biz kursumuzda bunlara framework yerine kütüphane demeyi tercih edeceğiz. 

    TensorFlow ve PyTorch kütüphaneleri (ya da framework'leri) eskiden yalnızca yapay sinir ağlarına ilişkin temel 
    işlemleri barındırıyordu. Yani bunlar aşağı seviyeli kütüphanelerdi. Ancak zamanla bu kütüphaneler gelişti ve yüksek 
    seviyeli katmanlara da sahip olmaya başladı. Örneğin yüksek seviyeli yapay sinir ağları işlemlerini yapmak için 
    tasarlanmış olaan Keras isimli bir kütüphane bulunmaktadır. Keras başlangıçta bağımsız bir kütüphaneydi. Ancak 
    daha sonraları TensorFlow bünyesine katıldı. Biz kurusumuzda yettiği sürece bu Keras kütüphanesini kullanacağız. 
    PyTorch'a da zamanla Keras gibi yüksek seviyeli katmanlar eklenmiştir.
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Yukarda açıkladığımız kütüphaneler belli bir süredir var olan temel kütüphanelerdir. Doğal dil işlemede kullanılan 
    bu kursta da kullanacağımız alçak seviyeli ve yüksek seviyeli pek çok kütüphane de bulunmaktadır. Bu kütüpahanelerin 
    bir bölümü klasik doğal dil işleme işlemlerine yöneliktir. Diğer bölümü ise transformer sonrası modern doğal dil işleme 
    süreçleriyle ilgildir. Biz zaten kursumuzda yeri geldikçe bu kütüphaneleri tanıtarak kullanacağız. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Doğal dil işlemede veriler genel olarak yazılar biçimindedir. Yazılara ilişkin veri kümeleri için CSV formatı uygun 
    bir format değildir. (Örneğin CSV formatında sütunlar virgüllerle biribirinden ayrılmaktadır. Ancak yazılarda zaten 
    virgül yazının içerisinde oldukça fazla bulunabilen bir karakterdir.) 
    
    Yazısal veri kümeleri çoğu kez doğrudan "düz metin dosyaları (pure text file)" biçiminde karşımıza çıkmaktadır. Düz 
    metin dosyası demekle "içerisinde hiçbir formatlama bilgisinin bulunmadığı, yalnızca yazıların karakterlerinin bulunduğu 
    dosyaları" kastediyoruz. Bu dosyalara genellikle ".txt" uzantısı verilmektedir. Bazı metin dosyalarının içerisinde formatlama
    biligileri de (örneğin yazıların renklerine ilişkin, bold'luk durumuna ilişkin bilgiler gibi) bulunabilmektedir. Ancak 
    bu bilgiler dosyanın içerisinde binary biçimde değil yine yazısal biçimde bulundurulmaktadır. Bu tür dosyalara genel 
    olarak "zengin metin dosyaları (rich text files)" denilmektedir. Örneğin Microsoft'un ".rtf" uzantılı dosyaları, ".md" 
    uzantılı markup dosyaları, ".xml" uzantılı XML dosyaları bu bağlamda zengin metin dosyaları durumundadır. Ancak doğal 
    işlemede zengin metin dosyaları yerine genellikle (ama her zaman değil) düz metin dosyaları kullanılmaktadır. 

    Doğal dil işlemede yazılar metin dosyalarının yanı sıra veritabanlarının içerisinde de bulunabilmektedir. Doğal dil 
    işlemede yüksek miktardaki verileri depolamak için "Parquet" ("parke:" biçiminde okunuyor) "HDF (Hierarchical File 
    Format)" formatları da kullanılabilmektedir. Bazı doğal dil işleme uygulamalarında yazısal veriler web sayfalarından 
    da çekilip kullanıma hazır hale getirilebilmektedir. Web sayfasından bilgilerin elde edilmesina İngilizce "web scraping"
    denilmektedir. ("Scrape" sözcüğü "kazımak, kazıyarak elde etmek" gibi anlamlara gelmektedir.)

    Doğal işlemede en çok kullanılan formatlardan biri de JSON (Java Script Object Notation) denilen formattır. JSON 
    formatı adeta Python'daki sözlük nesnelerinin temsiline benzemektedir. JSON düz metinsel bir biçime sahiptir. Dolayısıyla 
    ayrıca sıkıştırılmamışsa JSON dosyaları büyük yer kaplama eğilimindedir. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Yukarıda da belirttiğimiz gibi doğal dil işlemede Python'un standard kütüphanesinin yanı sıra pek çok özel kütüphaneden 
    de faydalanılmaktadır. Python'un standart kütüphanesinde doğal dil işlemede faydalanabileceğimiz çeşitli modüller
    bulunmaktadır. Örneğin "düzenli ifadeler (regular expressions)" doğal dil işlemede yaygın biçimde kullanılmaktadır. 
    Özellikle aşağı seviyeli önişlem faaliyetlerinde düzenli ifadelerden sıkça faydalanılmaktadır. Düzenli ifadeler 
    "Python Uygulamaları" kursumuzda ele alınan bir konudur. Ancak burada kısaca bu konunun üzerinde durmak istiyoruz. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Düzenli ifadeler (regular expressions, kısaca "regex" de denilmektedir) belli bir kalıba ilişkin yazı parçalarının 
    elde edilmesi amacıyla kullanılan mini bir dildir. Bu dilin de sentaks ve semantik kuralları vardır. Regex dilinde 
    kalıp oluşturulur. Sonra oluşturulan kalıp ismine "düzenli ifade motoru (regular expression engine)" denilen motora 
    verilir. Motor da kalıba uygun parçaları elde ederek birtakım işlemler yapar. Örneğin biz bir metin içerisindeki 
    "dd/aa/yyyy" gibi bir kalıba uygun tüm tarihleri bulmak isteyebiliriz. Ya da önneğin biz bir metindeki sözcükleri 
    bulmak isteyebiliriz. Düzenli ifadeler bu tür işlemlerin kolay yapılmasını sağlamaktadır. Pek çok programlama dilinde 
    düzenli ifadeler üzerinde işlemler yapan sınıflar ve fonksiyonlar onların standart kütüphaneleri içerisinde bulunmaktadır. 
    Hatta Ruby gibi Perl gibi dillerde düzenli ifadeler sentaks bakımından dilin kendi içerisinde built-in bir biçimde 
    desteklenmektedir. Python Standart Kütüphanesinde de düzenli ifadelerle işlemler "re" isimli modülün içerisindeki 
    fonksiyonlar ve sınıflarla yapılmaktadır. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
                                            4. Ders - 25/01/2026 - Pazar
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Burada kısaca düzenli ifadelerle nasıl kalıp oluşturulacağından bahsedeceğiz. Konunun ayrıntıları için "Python 
    Uygulamaları" kursumuza ilişkin kurs notlarını gözden geçirebilirsiniz. Python Standart Kütüphanesindeki düzenli 
    ifadelerle ilgili re modülünün dokmantasyonuna aşağıdaki bağlantıdan erişebilirsiniz:

    https://docs.python.org/3/library/re.html

    Düzenli ifadeler ile ilgili denemeler yapmak için https://regex101.com/ sitesinden faydalanabilirsiniz. 

    Eskiden text editörlerin ve kelime işlem programlarının düzenli ifadelerle işlem yapma özellikleri yoktu. Zamanla bu 
    özellikler pek çok text editöre ve kelime işlem programına eklendi. Bugün Microsoft Word gibi kelime işlemciler, 
    Visual Studio, VSCode gibi IDE'ler ve editörler düzenli ifadelerle işlemlerin yapılmasına olanak sağlamaktadır. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Düzenli ifadeler bir metin içerisindeki belli bir kalıba uygun yazı parçalarını elde etmek ve onlar üzerinde işlemler
    yapabilmek için tasarlanmış olan mini bir dildir. Metin içerisindeki yazı parçaları kalıplar oluşturularak elde 
    edilmektedir. Düzenli ifadelerdeki kalıplarda iki tür karakter kullanılmaktadır: Normal karakterler ve meta karakterler. 
    Normal karakterler kalıpta bulunması istenen gerçek karakterlerdir. Meta karakterler ise "özel anlam ifade eden" 
    karakterlerdir. Örneğin '.' karakteri bir meta karakterdir. Bu karakteri biz bir kalıp içerisinde kullandığımızda 
    bu nokta karakteri anlamına gelmez, '\n' dışındaki herhangi bir karakter" anlamına gelir. Eğer meta karakterlerin 
    normal karakterler olarak ele alınması isteniyorsa onun soluna yapışık bir ters bölü karakteri getirilmelidir. Örneğin 
    ".abc" kalıbındaki '.' "burada herhangi bir karakter bulunabilir" anlamına gelmektdir. Eğer biz bu kalıpta gerçekten 
    nokta karakterini belirtmek istiyorsak kalıbı "\.abc" biçiminde yazmalıyız. 

    Düzenli ifadeler dili maalesef standart hale getirilememiştir. Dolayısıyla ana hatları aynı olmak üzere düzenli ifadeler
    üzerinde işlem yapan motorlar arasında da küçük farklılıklar söz konusu olabilmektedir. 

    Düzenli ifadelere ilişkin kalıp oluşturma kuralları özet olarak şöyledir: (Örneklerimizde iki tırnak içerisindeki 
    kalıplar bir Python string'i olarak değerlendirilmemelidir. Yani örneğin biz "ka\." biçiminde bir kalıp yazdığımızda 
    buradaki ters bölü gerçekten ters bölü karakteridir. Bilindiği gibi Python'da ters bölü karakterlerinin gerçek ters 
    bölü karakteri olarak ele alınması için string'e yapışık r ya da R harfi getirilmektedir.)

     - Nokta bir meta karakterdir, bu karakter "\n (new line) dışındaki herhangi bir karakter" anlamına gelir. Örneğin 
     "al." kalıbı "al" ile başlayan ve üçüncü karakteri herhangi bir karakter olan üç karakteri belirtir. Dolayısıyla "al."
     kalıbı "ali" ile de uyuşabilir "alm" ile de uyuşabilir, "alr" ile de uyuşabilir. (Burada uyuşmak İnglizce "match" 
     sözcüğünün karşılığı olarak kullanılmaktadır.)

    - * meta karakteri "solundaki karakterden sıfır tane ya da daha fazla" anlamına gelmektedir. Bu durumda örneğin 
    "ka*" kalıbı "k" ile, "ka" ile, "kaa" ile, "kaaa" ile, "kaaaaa" ile uyuşur. Örneğin "k.*" kalıbı başı "k" ile başlayan 
    satır sonuna kadar tüm karakterle uyuşur. Nokta meta karakterinin '\n' karakterini içermediğine dikkat ediniz. Bu 
    durumda "k.*" kalıbı satır sonunda etkisini kaybedecektir. 

    - + meta karakteri "solundaki karakterden bir ya da daha fazlasını" belirtir. * ile + meta karakterlerini birbirine 
    karıştırmayınız. * solundaki karakterden sıfır tane ya da çok tane ile uyuşurken, + solundaki karakterden bir tane 
    ya da çok taneyle uyuşmaktadır. Örneğin "ka+" kalıbı "k" ile uyuşmaz. Ancak "ka" ile "kaaaa" ile uyuşur. Fakat "ka*" 
    kalıbı "k" ile "ka" ile "kaaaa" ile uyuşur.

    - ? meta karakteri "solundaki karakterden 0 tane ya da 1 tane" anlamına gelmektedir. Örneğin "ab?c" kalıbı "ac" ile 
    uyuşur "abc" ile de uyuşur ancak örneğin "abbc" ile uyuşmaz. 

    - Yukarıda da belirttiğimiz gibi bir meta karakter normal karakter olarak kullanılacaksa ters bölülenmelidir. Örneğin 
    "ka\." gibi bir kalıp "ka." ile uyuşur. "kal" ile ve "kar" ile uyuşmaz. Tabii ters bölünün kendisi için de '\\' 
    kullanılmalıdır. Eğer '\' karakterinin sağındaki karakter özel bir ters bölü karekteri değilse ve bir meta karakter 
    de değilse ifade geçersizdir.

    - Köşeli parantezler birer meta karakterdir. "İçerisindeki karakterlerin herhangi biri" anlamına gelir. Örneğin 
    "[abc]+" kalıbı "abcaaaabc" ile ya da "aaaabbbbbcccbcbcbca" ile uyşur. "a[bcd]?" kalıbı "a" ile "ab" ile "ac" ile 
    "ad" ile uyuşur.

    - Köşeli parantez içerisinde '-' karakteri kullanılırsa bu "solundaki karakterden sağındaki karaktere kadar herhangi 
    biri" anlamına gelir. Örneğin "[a-z]+" kalıbı "ali" ile "veli" ile "selami" ile uyuşur. Örneğin "[a-zA-Z]+" kalıbı 
    sözcükleri bulmak için kullanılabilir. Ancak default durumda Türkçe karakter bulunamayacaktır. Python'un re modülündeki
    lokal spesifik davranış fonksiyonların flags parametresi ile ayarlanabilmektedir. Normal olarak "-" karakteri bir 
    meta karakter değildir. Ancak köşeli parantezler içerisindeki '-' karakteri bir meta karakter olarak ele alınmaktadır. 
    (Bir istisna olarak köşeli parantezler içerisinde '-' karakteri son karakter olarak bulunuyorsa meta karakter olarak 
    ele alınmamaktadır.) Tabii köşeli parantezler meta karakter olduğu için gerçekten köşeli parantezleri arayacaksak 
    ters bölülemek gerekir. Örneğin amacımız köşeli parantezlerin kendisini aramak ise "\[.*\]" kalıbını kullanabiliriz. 

    - Köşeli parantezin başında '^' karakteri varsa bu durum "köşeli parantezin içerisindeki karakterlerden biri olmayan 
    herhangi bir karakter anlamına gelir. Örneğin "[^abc]" kalıbı 'a' ay da 'b' ya da 'c' olmayan herhangi bir karakter 
    anlamına gelmektedir. 

    - Düzenli ifadelerde uyum sağlayan en uzun karakter kümesi elde edilmektedir. Örneğin "abcabxyz" gibi bir yazıda 
    "[abc]+" kalıbı "abc" ve "ab" ile uyuşacaktır.  

    - Küme parantez kalıbı dört biçimde kullanılabilir: {n}, {n,k} ve {n,}, {, n}. {n} kalıbı "solundaki karakterden tam 
    olarak n tane" anlamına gelmektedir. Örneğin "a{3}" kalıbı "aaa" ile uyuşur. Eğer yazıda "aaaaaaaa" biçiminde a varsa 
    bu kalıp bunun ilk 3 tanesi ile uyuşum sağlayacaktır. {n,k} kalıbı "solundaki karakterden n ile k arasında herhangi 
    tane (n ve k dahil)" anlamına gelmektedir. Örneğin "a{3,5}" kalıbı "aaa" ile uyuşur, "aaaa" ile uyuşur, "aaaaa" ile 
    uyuşur. Ancak örneğin "aa" ile uyuşmaz. "aaaaaaaaaa" daki ilk 5 a ile uyuşur. {n,} kalıbı "solundaki karakterden en 
    az n tane" anlamına gelmektedir. {,n} kalıbı ise "solundaki karakterden en fazla n tane" anlamına gelmektedir. Örneğin 
    "a{,5}" kalıbı "en fazla 5 tane a ile uyuşum sağlar. Bu durumda 0 tane a ile de uyuşum sağlanır. Normal olarak küme 
    parantezlerinin içinde boşluk karakterleri bir soruna yol açmamaktadır. Yani örneğin "a{3,5}" kalıbını "a{3, 5}" 
    biçiminde yazsak da bir sorun oluşmaz. Ancak siz küme parantezlerinin içerisinde SPACE karakteri kullanmayınız. 

    - Köşeli parantezlerin dışındaki '^' meta karakteri "yalnızca satırın başını" dikkate alır. Örneğin "^a+" kalıbı yazının 
    başındaki a'larla uyuşur. Örneğin "^[0-9]+" kalıbı yazının başındaki sayıları bulmaktadır. 

    - '$' meta karakteri yazının sonunu temsil etmektedir. Örneğin "abc$" kalıbı satırın sonundaki "abc" ile uyuşur. 
    Örneğin "[0-9]+$" kalıbı yazının sonundaki sayıları bulur. 

    - \w meta karakterleri "herhangi bir alfabetik, nümerik ya da '_' karakteri" anlamına gelmektedir. Default durumda bu 
    kalıp "[a-zA-Z_0-9]" ile eşdeğerdir. Yani Türkçe karakterler kalıba dahil değildir. Ancak pek çok regex kütüphanesinde 
    bir lokal ayarı yapılabilmektedir. Eğer regex ortamı izin veriyorsa bu ayar yapılarak bu kalıba Türkçe karakterler de 
    dahil edilebilir. Tabii Türkçe karakterleri dahil edecek biçimde kalıp manuel olarak [\wşçğüöıŞÇĞÜÖİ] biçiminde de 
    oluşturulabilir. Düzenli ifade motorlarının "UNICODE" seçeneği de bulunabilmektedir. Bu seçenek aktif hale getirildiğinde 
    artık \w kalıbı UNICODE tablodaki tüm alfabetik karakterleri kapsar hale gelmektedir. Yani UNICODE ayarı adeta "tüm 
    lokalleri içerir" anlamına gelmektedir. "\w+" kalıbı sözcükleri bulmak için sık sık kullanılan bir kalıptır. 
    
    \W meta karakterleri ise "herhangi bir alfabetik, nümerik karakter ya da '_' karakterinin dışındaki karakter" anlamına 
    gelir. Yani \w meta karakterinin tersini belirtir. 

    - \s meta karakterleri "herhangi bir boşluk karakteri (white space)" anlamına gelmektedir. Benzer biçimde \S meta 
    karakterleri ise "herhangi bir boşluk karakteri dışındaki karakter" anlamına gelir. 

    - \d kalıbı "sayısal olan karakterlerden herhangi biri", \D kalıbı ise "sayısal olmayan karakterlerden herhangi biri" 
    anlamına gelmektedir. Örneğin "\d+" kalıbı ile sayıları bulabiliriz. O halde örneğin "[\-+]?\d+" kalıbı tamsayıları 
    bulabilir. Noktalı sayıları da bulabilen kalıp "[\-+]?\d*\.?\d+" bçiminde olabilir. 

    - \b meta karakteri "sözcük başları" anlamına gelmektedir. Örneğin "\ba+" gibi bir kalıp "a" ile başlayan sözcüklerle 
    uyuşur.

    - Parantezler gruplama için kullanılmaktadır. Örneğin "(abc)+" kalıbı ile "abc" uyuşur, "abcabc" uyuşur, "abcabcabc" 
    uyuşur. Ancak örneğin "abab" uyuşmaz.

    - '|' karakteri "veya" anlamına gelmektedir. Örneğin "ali|veli" kalıbı "ali" ya da "veli" ile uyuşabilmektedir. Buradaki
    '|' karakterinin düşük öncelikli olduğuna dikkat ediniz. Örneğin "a+|b+" kalıbı bir ya da daha fazla a ile bir ya da 
    daha fazla b ile uyuşur. 

    Çok kullanılanm bazı kalıpları aşağıda veriyoruz:

    E-Posta kalıbı: [A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}
    Noktalı sayı kalıbı: [+-]?[0-9]+\.[0-9]+|\.[0-9]+|[0-9]+\.
    Tamsayı kalıbı: [+-]?[0-9]+
    Değişken atom kalıbı: [_a-z-A-Z][_a-zA-Z-0-9]+
    day/month/year tarih kalıbı: (0?[1-9]|1[0-2])\/(0?[1-9]|1\d|2\d|3[01])\/(19|20)\d{2}
    dd/mm/yyyy tarih kalıbı: (0[1-9]|1\d|2\d|3[01])\/(0[1-9]|1[0-2])\/(19|20)\d{2}
    IPV4 adresi kalıbı: ([0-9]{1,3}\.){3}[0-9]{1,3}
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Her türlü ayrıştırma işlemi düzenli ifadelerle yapılamayabilmektedir. Bu tür durumlarda belli noktaya kadar düzenli 
    ifadeleri kullanıp sonra manuel kontrollerle hedefinize ulaşabilirsiniz. Örneğin bir programlama dilindeki programı 
    atomlarına ayırmak için düzenli ifadeler yeterli olmayabilir. Yani düzenli ifadeler bizim ayrıştırma ve bulma 
    işlemlerimizde tüm isteklerimizi yerine getiremeyebilmektedir. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Python'da düzenli ifadelerle işlemler re modülündeki fonksiyonlar ve sınıflarla yapılmaktadır. re modülündeki fonksiyonlar 
    genel olarak önce kalıp yazısını sonra da asıl yazıyı parametre olarak alırlar. Yine modüldeki fonksiyonların son 
    paramatreleri düzenli ifadeler üzerindeki bazı seçenekleri belirtmektedir. Bu paramtre flags olarak isimlendirilmiştir. 
    Programcının kalıp yazısını oluşturken string'i "r" ya da "R" öneki ile oluşturması "\" karakterlerinin gerçekten ters 
    bölü karakteri olarak ele alınmasını garanti edecektir.
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    re modülündeki findall isimli fonksiyon yazıdaki regex kalıbına uyan tüm parçaları bir liste olarak bize vermektedir. 
    findall fonksiyonun parametrik yapısı şöyledir:

    findall(pattern, string, flags=0)

    Örneğin:

    text = '17 asal bir sayıdır. 101 de asaldır. Ancak 115 asal sayı değildir.'
    pattern = r'\d+'
    result = re.findall(pattern, text)
    print(result)

    Burada görüldüğü gibi findall fonksiyonuna önce kalıp yazısı sonra da asıl yazı argüman olarak geçirilmiştir. flags 
    parametresi default değer aldığı için hiç kullanılmamıştır.

    findall fonksiyonu parantezli grupları da ayırıp onları birer demet olarak da vermektedir. İzleyen paragraflarda 
    gruplama konusu üzerinde de duracağız. 
#------------------------------------------------------------------------------------------------------------------------

import re

text = 'ali veli 123 selami 628 ayşe fatma 876'
pattern = r'\d+'

result = re.findall(pattern, text)      
print(result)           # ['123', '628', '876']

numbers = list(map(int, result))
print(numbers)          # [123, 628, 876]

#------------------------------------------------------------------------------------------------------------------------
    Aşağıda findall fonksiyonu ile tarihlerin elde edilmesine yönelik bir örnek verilmiştir. 
#------------------------------------------------------------------------------------------------------------------------

import re

text = 'ali veli 10/12/2009 selami 05/07/1998 ayşe fatma 23/11/2014'
pattern = r'\d\d/\d\d/\d\d\d\d'

result = re.findall(pattern, text)
print(result)       # ['10/12/2009', '05/07/1998', '23/11/2014']

#------------------------------------------------------------------------------------------------------------------------
    Aşağıda findall fonksiyonu ile bir yazıdaki e-posta adreslerinin bulunmasına örnek verilmiştir. 
#------------------------------------------------------------------------------------------------------------------------

import re

text = """bana e-posta atabilrsin. E-posta adresim aslank@csystem.org. 
Eğer bana ulaşamazsan info@csystem.org'ye de e-posta gönderebilirsin.'
"""
pattern = r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Za-z]{2,}'

result = re.findall(pattern, text)
print(result)

#------------------------------------------------------------------------------------------------------------------------
    re modülündeki split fonksiyonu str sınıfının split metodundan çok daha güçlü bir biçimde ayrıştırma yapabilmektedir. 
    Bu fonksiyon bir regex kalıbını ayıraç olarak kabul ederek yazıyı parçalarına ayırır. split fonksiyonunda verilen 
    kalıp ayıraçları belirtmektedir. Fonksiyon bu ayıraçları diğer yazının parçalarını ayırmak için kullanacaktır. 
    Fonksiyonun parametrik yapısı şöyledir:

    split(pattern, string, maxsplit=0, flags=0)

    split fonksiyonu her kalıba uygun ayıracı bulduğunda onun solundaki ve sağındaki yazı parçasını elde eder. Eğer 
    yazının başında ve sonunda ayıraç kalıbı varsa split bu ayıraç kalıbının solunda ve sağında bir yazı olmadığı için 
    boş string oluturmaktadır. Örneğin:

    text = '   ,,ali,,,  veli,,   selami   '
    pattern = "[ ,]+"
    result = re.split(pattern, text)
    print(result)

    Burada yazının başı ayırçlarla başlamıştır. O halde yazının başında bir tane boş string bulunacaktır. Yazının sonu da 
    ayırçlarla bitmiştir o halde yazının sonunda da boş string bulunacaktır. Bu kod parçası çalıştırıldığında ekrana 
    şunlar basılacaktır:

    ['', 'ali', 'veli', 'selami', '']
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    re modülündeki search fonksiyonu yazı içerisinde bir regex kalıbını arar. Eğer bulursa ilk bulduğu kalıba ilişkin re 
    modülündeki Match türünden bir sınıf nesnesiyle geri döner. Fonksiyonun parametrik yapısı şöyledir:

    re.search(pattern, string, flags=0)

    Yine fonksiyonun birinci parametresi aranacak kalıbı, ikinci parametresi aramanın yapılacağı yazıyı belirtmektedir. 
    Fonksiyon başarı durumunda Match nesnesine başarısızlık durumunda None değerine geri dönmektedir. 

    Match sınıfının start netodu kalıbın bulunduğu karakterin başlangıç index numarasını, end metodu ise bitiş index 
    numarasının bir fazlasını vermektedir. Böylece biz dilimleme yoluyla bulunan kalıbı elde edebiliriz. Örneğin:

    text = ',,,ali, veli, selami'
    pattern = r'\w+'
    m = re.search(pattern, text)

    Burada ilk uyuşumu yazı içerisindeki "ali" karakterleri sağlamaktadır. Ancak search bize "ali" yazısını değil bir 
    Match türündne bir nesne vermektedir. Bu match nesnesinin start metodu kalıbın yazı içerisindeki başlangıç index 
    numarasını, end metodu ise bitiş indeks numarasından bir sonrak indeks numarasını verir. Dolayısıyla biz bu aralığı 
    dilimlemede kullanabiliriz. Örneğin:
    
    if m:
        print(m.start(), m.end())
        print(text[m.start():m.end()])
#------------------------------------------------------------------------------------------------------------------------

import re

text = 'my email addres is aslank@csystem.org but your email address is serce@csystem.com'
pattern = r'[a-zA-Z0–9+_.-]+@[a-zA-Z0–9.-]+'

m = re.search(pattern, text)
if m:
    result = text[m.start():m.end()]
    print(result)
else:
    print('cannot find match!..')

#------------------------------------------------------------------------------------------------------------------------
    Bir kalıp parantezler kullanılarak oluşturulmuşsa kalıbın içerisindeki parantezli kısımlara "grup (group)" denilmektedir. 
    search fonksiyonu yalnızca ana kalıbı değil parantezler içerisindeki grup'ları da bulabilmektdir. Örneğin şöyle bir 
    kalıp olsun: "(\d+)@(\d+)". 123@456 gibi karakter öbeği bu kalıp ile uyuşmaktadır. İşte biz Match nesnesi ile uyuşan 
    kısmı bir bütün olarak elde edebilceğimiz gibi bunun 123 ve 456'dan oluşan gruplarını da elde edebilmekteyiz. 
    
    Match sınıfının group metodu regex kalıbındaki grupları bize vermektedir. group metodu grubun numarasını parametre 
    olarak alır. Group numaraları 1'den başlamaktadır. 0'ıncı grup numarası kalıbın tamamını belirtir. group metodu ile 
    Match sınıfının [] operatör metodu aynı işlemi yapmaktadır. Örneğin:

    text = 'ali 123@567 veli 135@854 selami'
    pattern = r'(\d+)@(\d+)'
    m = re.search(pattern, text)

    Buradaki kalıp sayı@sayı biçimindeki karakterle uyuşur. Ancak bu kalıpta @ karakterinin iki yanı birer grup biçiminde 
    oluşturulmuştur. Bu sayede biz hem uyuşan kalıbın tamamını elde edebiliriz hem de onun parçalarını elde edebiliriz. 
    Buradaki örnekte search ilk uyuşan kalıbı yani 123@567 karakterini bulacak ve bize bunu bir Match nesnesi biçiminde 
    verecektir. Bu Match nesnesinin 1'inci grubu "123" yazısından, 2'inci grubu "567" yazısından oluşacaktır. İşte biz 
    m[1] ya da m.group(1) ifadeseiyle 1'inci grubu m[2] ya da m.group(2) ifadesiyle de 2'inci grubu elde edebiliriz. 
    m[0] ya da m.group(0) ifadesi ile de biz tüm kalıba erişebiliriz. İster gruplu bir kalıp olsun isterse grupsuz bir 
    kalıp olsun m[0] her zaman uyuşan kalıbı vermektedir. Match sınıfının string örnek özniteliği bize search fonksiyonun 
    çağrılmasında kullanılan asıl yazıyı da vermektedir.
#------------------------------------------------------------------------------------------------------------------------

import re

text = 'ali veli selami 123@789 ayşe fatma'
m = r'(\d+)@(\d+)'

m = re.search(pattern, text)
if m:
    print(m[0])
    print(m[1])
    print(m[2])
else:
    print('kalıp bulunamadı!..')

#------------------------------------------------------------------------------------------------------------------------
    Aslında daha önce görmüş olduğumuz findall metodu da grupla çalışmaktadır. Eğer kalıpta parantezler varsa findall bu 
    grupları bir demet listesi olarak bize vermektedir. Örneğin:

    text = 'ali veli selami 123@789 ayşe fatma 478@456'
    pattern = r'(\d+)@(\d+)'

    result = re.findall(pattern, text)
    print(result)       # [('123', '789'), ('478', '456')]

    Ancak kalıpta tek bir grup varsa findall bize bunları tek elemanlı demet listesi olarak değil düz bir liste olarak 
    verir.

    Gruplama hem bir kalıbın bulunmasına hem de o kalıp içerisindeki bir parçanın elde edilmesine olanak sağlamaktadır.
    Örneğin birisi bize yazıdaki tek tırnak içerisinde bulunan isimleri elde etmemizi istesin. Yazı aşağıdaki gibi olsun:

    text = "ali veli 'selami' ayşe 'fatma' hasan"

    Burada bizden tüm isimlerin değil 'selami' ve 'fatma' isimlerinin bulunması istenmektedir. Kalıbı aşağıdaki oluşturmuş 
    olalım:

    pattern = r"'\w+'"

    Bu kalıpla biz tek tırnak içerisindeki isimleri tek tırnaklarıyla buluruz. Halbuki bizden tek tırnak içerisindeki isimlerin 
    tırnaksız bir biçimde bulunması istenmiştir. Tabii biz bu isimleri tırnaklı bulduktan sonra bu tırnakları atabiliriz. 
    Ancak bu da ek bir çaba gerektirir. İşte bu tür durumlarda gruplama pratik çözüm oluşturmaktadır. Örneğin:

    pattern = r"'(\w+)'"
    result = re.findall(pattern, text)
    print(result)       # ['selami', 'fatma']
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    re modülündeki match fonksiyonu search fonksiyonu gibidir. Yani yine aranan kalıba ilişkin Match nesnesini verir. 
    Ancak kalıbın yazının başında olması gerekir. Yani bu fonksiyon her zaman kalıp sanki yazının başındaymış gibi arama 
    yapmaktadır. Aşağıdaki örnekte uyuşum sağlanamayacaktır.

    text = 'ali veli selami 123@789 ayşe fatma 478@456'
    pattern = r'(\d+)@(\d+)'

    m = re.match(pattern, text)
    print(m)    # None

    Tabii aslında yazının başından arama yapmak için kalıbın başına ^ meta karakteri de getirilebilir. ^ meta karakterinin 
    yazının başından itibaren uyuşama bakacağını daha önce belirtmiştik.
#------------------------------------------------------------------------------------------------------------------------

import re

text = 'ali veli selami 123@789 ayşe fatma 478@456'
pattern = r'(\d+)@(\d+)'

result = re.match(pattern, text)
if result:
    print(result[0])
else:
    print('kalıp bulunamadı!..')

#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    re modülündeki fullmatch fonksiyonu yazının tamamının kalıba uygun olmadığını belirlemekte kullanılır. Bu fonksiyon 
    da başarı durumunda Match nesnesine, başarısızlık durumunda None değerine geri dönmektedir. Fonksiyonun parametrik 
    yapısı diğerleriyle aynıdır:

    re.fullmatch(pattern, string, flags=0)
#------------------------------------------------------------------------------------------------------------------------

import re

text = '10/12/1997'
pattern = r'\d\d/\d\d/\d\d\d\d'

a = re.fullmatch(pattern, text)
if a:
    print('Uyuşum var')
else:
    print('Uyuşum yok')

text = '10/12/1997   '

a = re.fullmatch(pattern, text)
if a:
    print('Kalıba uygun')
else:
    print('Uyuşum yok')

#------------------------------------------------------------------------------------------------------------------------
    re modlündeki sub fonksiyonu belli bir kalıbın yerine başka bir yazı yerleştirmek için kullanılmaktadır. Bu fonksiyon 
    str sınıfının replace metodunun düzenli ifade alan versiyonu gibi düşünülebilir. Fonksiyonun parametrik yapısı şöyledir:

    re.sub(pattern, repl, string, count=0, flags=0)

    Buradaki count parametresi kaç uyuşumun değiştirileceğini belirtmektedir. 0 değeri hepsinin değiştirileceği anlamına 
    gelmektedir. Tabii fonksiyon asıl yazıda bir değişiklik yapmaz, bize değiştirilmiş yeni bir yazıyı verir. Örneğin:

    text = 'ali -veli-, selami -ayşe- fatma -hayri- sibel -hasan-'
    pattern = r'-(\w+)-'

    result = re.sub(pattern, 'xxx', text)
    print(result)               # ali xxx, selami xxx fatma xxx sibel xxx

    Burada tireler arasındaki isimler xxx karakterleri ile yer değiştirilmiştir. 

    sub fonksiyonunun ikinci parametresinde değiştirilecek yazıda \1, \2, \3 gibi \n biçiminde grup belirten meta karakterler 
    kullanılabilmektedir. Bu sayede biz bir uyuşumun belli kısımlarını da değiştirebiliriz. Örneğin ondalıklı sayıların 
    ondalık kısmı '.' karakteri ile biribirinden ayrılmaktadır. Ancak bazı yerel dillerde nokta yerine virgül de kullanılmaktadır. 
    Biz bir metindeki noktalı sayılardaki noktaları virgül ile yer değiştirmek isteyelim. Bunu sağlamak için aşağıdaki gibi 
    bir kalıbı kullanabiliriz:

    text = 'Aynanın eni 18.50 santim. Boyu da 21.50 santim. Ayrıca pi sayısı da kısa bir biçimde 3.14'

    result = re.sub(r'(\d+)\.(\d+)', r'\1,\2', text)
    print(result)   # Aynanın eni 18,50 santim. Boyu da 21,50 santim. Ayrıca pi sayısı da kısa bir biçimde 3,14
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
                                        5. Ders - 31/01/2026 - Cumartesi
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Şimdi de karakter tabloları ve karakter kodlamaları üzerinde temel bilgiler vereceğiz. Doğal dil işleme etkinlikleri 
    yazılar üzerinde yapıldığı için bu alanda çalışacak kişilerin karakter tabloları ve karakter kodlamaları konusunda 
    temel bilgilere sahip olması gerekmektedir. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Yazıda yer kaplayan en küçük birime karakter (character) denilmektedir. Yazılar karakterleden oluşan bir dizi gibi 
    düşünülebilir. Karakterler ise sayılarla temsil edilmektedir. Örneğin "ankara" yazısı karakterlerden oluşmaktadır. 
    Karakterler de sayılarla temsil edildiği için bu yazı aslında sayılardan oluşan bir dizi gibi düşünülebilir. Text 
    editörler bir dosyayı görüntülerken onun içerisindeki sayılara karşı gelen karakter temsillerini bize göstermektedir. 
    İşte hangi karakterlerin hangi sayılarla temsil edildiğini tanımlayan "karakter tabloları" oluşturulmuştur. 
    
    Dünyada bilişim alanında kullanılan ilk karakter tablosu "ASCII (American Standard Code Information Interchange)" 
    denilen tablodur. Orijinal ASCII tablosu 7 bitlikti, 128 farklı karaktere birer numara karşılık düşürülmüştü. (Örneğin 
    'a' karakteri tablonun 97'inci karakteridir, 'b' karakteri 98'inci karakteridir.) ASCII tablosunun yanı sıra daha 
    sonraları "EBCDIC (Extended Binary Coded Decimal Interchange Code)" gibi, "WISCII" gibi başka karakter tabloları da 
    geliştirilmiştir. IBM sistemeri uzun süre EBCDIC tablosunu kullanmıştır. Bu tablo hala IBM'in bazı sistemlerinde 
    geçmişe uyumluluğun sağlanması amacıyla kullanılmaktadır.
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Bir karakter tablosunda üç önemli kavram vardır:

    1) Glyph
    2) Kod numarası (Code Point)
    3) Karakter Kodlaması (Character Encoding)

    Karakter tablosunun desteklediği karakterlerin görsel temsiline "glyph ("glif" biçiminde okunuyor)" denilmektedir. 
    Karakter tablosu içerisindeki her glyph'e 0'dan itibaren bir numara karşılık düşürülmüştür. Buna ilgili karakterin 
    "kod numarası (code point)" denilmektedir. Örneğin ASCII tablosunda 'a' karakterinin kopd numarası 97'dir. Bir glyph'e 
    ilişkin kod numarası doğrudan 2'lik sistemde bir sayı biçiminde kodlanarak dosyalarda saklanabilir. Ancak karakter 
    tabloları kod numaralarını dosyalarda saklamak için onlar üzerinde bazı dönüşümler de yapabilmektedir. İşte yapılan 
    bu dönüştürmeye "karakter kodlaması (character encoding)" denilmektedir. Bazı tablolarda kod numaraları birden fazla 
    karakter kodlaması ile sayısal biçime dönüştürülebilmektedir.  
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Karakter tabloları kabaca "bir byte'lık karakter tabloları" ve "geniş karakter tabloları" olmak üzere ikiye ayrılmaktadır. 
    Bir byte'lık karakter tablolarında karakterlere ilişkin kod numaraları bir byte ile ifade edilebilmektedir. Dolayısıyla 
    bu tablolarda en fazla 256 tane karakter (glyph) tanımlanabilmektedir. Geniş karakter tablolarında kod numaraları bir 
    byte'tan daha fazla byte ile (örneğin 2 byte ile, 4 byte ile) oluşturulmaktadır. Geniş karakter tablolarında yazılar 
    bellekte daha fazla yer kaplıyor olsa da bu karakter tablolarında çok fazla sayıda karakterin temsili yapılabilmektedir. 
    ASCIIi, EBCDIC genel olarak 1 byte'lık karakter tablolarıdır. Belli bir süredir bir byte'lık karakter tabloları artık 
    yetersiz kalmıştır.

    Bir byte'lık karakter tablolarının yetersiz kalmasından dolayı ismine "Unicode Karakter Tablosu" denilen geniş bir 
    karakter tablosu zaman içerisinde yaygınlaşmış ve yeni programlama dillerinde neredeyse default karakter tablosu haline 
    gelmiştir. Unicode karakter tablosu özünde iki byte'lık (16 bitlik) bir karakter tablosudur. Ancak zaman içerisinde 
    yapılan eklemelerle 21 bitlik bir tablo haline gelmiştir. Bu tablo neredeyse dünyanın bütün dillerindeki karakterler
    için, pek çok işaret için glyph bulundurmaktadır. Unicode karakter tablosunun temel kısmına 2^16 = 65536 farklı karakter 
    tanımlabnmıştır.  Böylece aynı dosya içerisinde dünyanın bütün dillerine ilişkin yazılar bir arada bulunabilmektedir. 
    Unicode tablonun sürüdürümü "Unicde Consortium (www.unixode.org)" tarafından yapılmaktadır. Unicode tablo bazı 
    farklılıklarla ISO tarafından da "ISO/IEC 10646" koduyla standardize edilmiştir. 
    
    Unicode tabloda eskiden (1996'ya kadarki zaman diliminde) her glyph için 16 bitlik bir kod numarası karşılık getirilmişti. 
    Sonra tabloya yeni glyp'ler eklendi. Bugün her karakterin kod numarası 21 bitle ifade edilmektedir. Yani yukarıda biz 
    Unicode karalter tablosunun tipik olarak 2 byte'lık (16 bitlik) bir karakter tablosu olduunu söylemiş olsak da aslında 
    güncel durumda 21 bitlik bir karakter tablosudur. 

    Unicode tablonun ilk 128 karakteri standart ASCII tablosu ile aynıdır. Örneğin 'a' karakterinin ASCII tablosundaki 
    kod numarası da Unicode tablodaki kod numarası da 97'dir. Unicode tablonun [128-255] arasındaki karakterleri ASCII 
    Latin-1 kod sayfası ile aynıdır. Türkçe'ye özgü karakterlerin bazılarının (Öneğin 'ş' gibi, 'ğ' gibi) kod numaraları
    256'dan büyüktür. Aşağıda bu karakterlerin Unicode tablodaki kod numaralarını veriyoruz:

    ┌───────────────────────────────────────────────────────────────┐
    │      TÜRKÇE ÖZEL KARAKTERLERİN UNICODE CODE POINT'LERİ        │
    ├───────────────────────────────────────────────────────────────┤
    │                        BÜYÜK HARFLER                          │
    ├──────────────────────────────┬────────────────────────────────┤
    │          Karakter            │      Unicode Kod Numarası      │
    ├──────────────────────────────┼────────────────────────────────┤
    │              Ç               │   U+00C7 (ondalık: 199)        │
    ├──────────────────────────────┼────────────────────────────────┤
    │              Ğ               │   U+011E (ondalık: 286)        │
    ├──────────────────────────────┼────────────────────────────────┤
    │              İ               │   U+0130 (ondalık: 304)        │
    ├──────────────────────────────┼────────────────────────────────┤
    │              Ö               │   U+00D6 (ondalık: 214)        │
    ├──────────────────────────────┼────────────────────────────────┤
    │              Ş               │   U+015E (ondalık: 350)        │
    ├──────────────────────────────┼────────────────────────────────┤
    │              Ü               │   U+00DC (ondalık: 220)        │
    ├──────────────────────────────┴────────────────────────────────┤
    │                        KÜÇÜK HARFLER                          │
    ├──────────────────────────────┬────────────────────────────────┤
    │          Karakter            │      Unicode Kod Numarası      │
    ├──────────────────────────────┼────────────────────────────────┤
    │              ç               │   U+00E7 (ondalık: 231)        │
    ├──────────────────────────────┼────────────────────────────────┤
    │              ğ               │   U+011F (ondalık: 287)        │
    ├──────────────────────────────┼────────────────────────────────┤
    │              ı               │   U+0131 (ondalık: 305)        │
    ├──────────────────────────────┼────────────────────────────────┤
    │              i               │   U+0069 (ondalık: 105)        │
    ├──────────────────────────────┼────────────────────────────────┤
    │              ö               │   U+00F6 (ondalık: 246)        │
    ├──────────────────────────────┼────────────────────────────────┤
    │              ş               │   U+015F (ondalık: 351)        │
    ├──────────────────────────────┼────────────────────────────────┤
    │              ü               │   U+00FC (ondalık: 252)        │
    └──────────────────────────────┴────────────────────────────────┘
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Peki Unocode öncesi devirlerde Türkçe gibi dillerin karakterleri nasıl ifade ediliyordu? İşte zaman içerisinde standart 
    ASCII tablosu diğer dillerin karakterlerini (glyph'lerini de) içerecek biçimde genişletildi. Bu genişletmede ASCII 
    tablosunun [0-127] arası karakterlerine ilişkin kod numaraları sabit bırakıldı. [128-255] arasındaki kod numaralarına 
    latin dillerinin çeşitli karakterlerleri yerleştirildi. Ancak bu konuda bir standardizasyon yapılmamıştı. ASCII tablosunun 
    genişletilmiş bu halleri için sıklıla "kod sayfası (code page)" terimi kullanılıyordu. Türkçe karakterler için zaman 
    içerisinde değişik kod sayfaları (code pages) kullanılmıştır. DOS zamanalarında IBM'in 754 kod sayfası kullanılıyordu. 
    Sonra Microsoft Türkçe karakterler için 1254 diye isimlendirdiği kod sayfasını tasarladı. Nihayet 1999 yılına gelindiğinde 
    ISO durumdan vazife çıkardı ve kod sayfalarını ISO 8859-X kod numarasıyla standardize etti. Örneğin 8859-1 kod sayfasına 
    "Latin-1" kod sayfası denilmektedir. ISO Türkçe karakterler için ISO 8859-9 kod sayfasını oluşturmuştur. Bu kod sayfası 
    bugün Türkçe karakterler için en yaygın kullanılan bir byte'lık karakter tablosu durumundadır. ISO 8859-9 ile Microsoft'un 
    1254 kod sayfaları büyük ölçüde örtüşmektedir. 

    Bugün artık bir byte'lık karakter tablolarının kullanımı iyice azalmış, Unicode tablonun kullanımı ise oldukça 
    yaygınşlaşmıştır. Dolayısıyla ASCII kod sayfalarının karmaşıklığı Unicode tablo sayesinde bertaraf edilmiş durumdadır. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Bugün Unicode tablo için UTF-32, UTF-16 ve UTF-8 denilen üç farklı karakter kodlaması (character encoding) kullanılmaktadır:
    UTF-32'de Unicode karakterlerin kod numaraları 32 bitlik bir sayı biçiminde, UTF-16'da ise 16 bitlik bir sayı biçiminde 
    kodlanmaktadır. UTF-16 kodlamasında Unicode tablodaki ilk 65536 karakterin dışındaki karakterler ya hiç kodlanmamaktadır 
    ya da iki ayrı 16 bit ile kodlanmaktadır. Bu kodlamaya "surrogate çifti" denilmektedir. Ancak bugün en yaygın kullanılan 
    Unicode kodlaması UTF-8'dir. UTF-8 multibyte bir kodlamadır. Bu kodlamada bazı karakterler 1 byte ile, bazıları 2 byte 
    ile, bazıları 3 byte ile ve bazıları da 4 byte ile kodlanmaktadır. Bugün kullandığımız text editörlerin hemen hepsi 
    default durumda metin dosyalarını Unicode UTF-8 olarak açıp save etmektedir. Unicode UTF-8 kodlamasında ASCII tablosunun 
    ilk 128 karakteri 1 byte'la kodlanmaktadır. Türkçe karakterler ise 2 byte ile kodlanmaktadır, Japonca ve Çince Kanjiler 
    3 byte ile kodlanmaktadır. Tamamen İngilizce karakterle yazılmış olan metinlerin ASCII temsili ile Unicode UTF-8 
    temsilinin aynı olduğuna dikkat ediniz. 
    
    Artık pek çok programlama dillerinin derleyicileri ya da yorumlayıcıları kaynak kodları Unicode UTF-8 formatında 
    kabul etmektedir. Tabii bu durum o dillerin resmi dokğmanlarında belirtilmiştir.
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Yazılarla ilgili işlem yapan sistemlerde yazıyı oluşturan tarafla yazıyı yorumlayan tarafın aynı karakter tablosu 
    ve karakter kodlaması üzerinde anlaşmış olmaları gerekir. Örneğin bir metin Unicode UTF-8 ile oluşturulmuşsa bu metni 
    diğer taraf ASCII 8859-9 olarak yorumlarsa karakterler anlamsız biçimde görüntülenecektir. Peki bizim elimizde bir 
    metin dosyası varsa biz onda kullanılan karakter tablosunu ve karakter kodlamasını nasıl tespit edebiliriz? Maalesef bu 
    tespitin yapılabilmesinin güvenilir ve sağlam bir yolu yoktur. Bazı editörler "sezgisel yöntemlerle (heuristics)" bunu 
    tespit etmeye çalışmaktadır. Ancak yukarıda da belirttiğimiz gibi bunun sağlam bir yolu yoktur. Unicode metin dosyaları 
    için "isteğe bağlı olarak (optional)" dosyanın başında "BOM (Byte of Order) marker" denilen bir belirteci bulundurulabilmektedir. 
    Eğer dosyada bu BOM belirteci varsa dosyanın Unicode karakter tablosuyla ve karakter kodlamasıyla oluşturulduğu tespit 
    edilebilmektedir. Ancak yukarıda da belirttiğimiz gibi BOM belirteci bir dosyanın başında bulunmak zoruda değildir. 
    BOM belirteçleri şunlardır:

    ┌─────────────────────────────────────────────────────┐
    │          UNICODE BOM BELİRTEÇLERİ TABLOSU           │
    ├──────────────────────────┬──────────────────────────┤
    │       Kodlama Türü       │      BOM (Hex)           │
    ├──────────────────────────┼──────────────────────────┤
    │         UTF-8            │      EF BB BF            │
    ├──────────────────────────┼──────────────────────────┤
    │       UTF-16 BE          │      FE FF               │
    ├──────────────────────────┼──────────────────────────┤
    │       UTF-16 LE          │      FF FE               │
    ├──────────────────────────┼──────────────────────────┤
    │       UTF-32 BE          │   00 00 FE FF            │
    ├──────────────────────────┼──────────────────────────┤
    │       UTF-32 LE          │   FF FE 00 00            │
    └──────────────────────────┴──────────────────────────┘ 

    İşte text editörler genellikle önce BOM belirteçlerine bakmakta, eğer dosyada BOM belirteci yoksa default olarak 
    belirledikleri bir karakter tablosu ve kodlamasıyla dosyayı açmaktadırlar. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Şimdi de karakter tablolarının programlama dillerini ilgilendiren tarafları üzerinde duralım. Yukarıda da belirttiğimiz 
    gibi artık programlama dillerinin önemli bir bölümüne ilişkin derleyiciler ve yorumlayıcılae kaynak dosyaların Unicode 
    UTF-8 olmasını beklemektedir. Örneğin C#, Java ve Python dillerinde kaynak dosyalar Unicode UTF-8 biçiminde olmalıdır. 
    C Programlama Dilinde kaynak dosyalar için belli bir karakter tablosu ya da karakter kodlaması belirlenmemiştir. Ancak 
    bu dillerin standartları alfabetik ve nümerik karakterlerin kaynak kodda 1 byte yer kaplaması gerektiğini belirtmektedir. 
    Dolayısıyla C ve C++ derleyicileri ASCII kod sayfalarına ilişkin dosyaları ve Unicode UTF-8 dosyalarını kabul edebilmektedir. 
    Tabii programcının derleyiciye komut satırı argümanlarıyla bu kodlama bilgisini vermesi gerekir. Aksi takdirde derleycici 
    kendisinin belirlediği default bir kodlamayı kullanmaktadır. Java ve C# dillerinde char türü zaten 2 byte uyzunluktadır 
    ve string'ler bunların derleyicileri tarafından Unicode UTF-16 ile tutulmaktadır. 
    
    Python'da char biçiminde bir tür yoktur. Python'un str türü 3'lü versiyonlarla birlikte Unicode karakterleri tutma 
    yeteneği kazanmıştır. Yani Python'da programcı artık tüm string'lerin karakterlerinin Unicode karakterler olduğunu 
    varsaymalıdır. Ancak CPython gerçekleştirimi aslında içsel olarak kendisi string'leri mümkün olduğunca daha az yer 
    kaplayacak biçimde tutar. Tabii programcının bu içsel ayrıntıları bilmesine gerek yoktur.
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Artık ana konularımıza başlamak için bazı ön bilgileri edinmiş durumdayız. Şimdi yavaş yavaş klasik doğal dil işlemenin 
    temel konularına giriş yapacağız. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Doğal dil işleme alanının tarhisel gelimini dört döneme ayırabiliriz:

    1) İlk Dönem (1950-1990): Bu döneme "sembolik dönem" de diyebiliriz. Bu dönemde "kural tabanlı (rule based)" yaklaşımlar 
    üzerinde çalışılmıştır. Burada "kural tabanlı yaklaşımlar" demekle kuralların ortaya konması ve işlemlerin bu kurallara 
    uyularak yapılmaya çalışılması kastedilmektedir. 

    2) İstatistiksel Dönem (1990-2010): Bu dönemde veri miktarının artmasıyla ve bilgisayarlar donanımlarının gelişmesiyle 
    birlikte metin yığınlarından (corpus) olasılıkların öğrenilmesi yöntemleri geliştirilmiş ve uygulamaya sokulmuştur.

    3) Derin Öğrenme Ağları Dönemi (2014-2018): Derin öğrenmenin (Deep Learning) sahneye çıkışıyla sözükler, sayılardan 
    oluşan vektörlere (Word Embeddings) dönüştürülmüş ve bu vektörler çok katmanlı sinir ağlarına girdi olarak verilmiştir. 

    4) Dönüştürücüler ve Büyük Dil Modelleri Dönemi (2018-Günümüz): "Dikkat" (Attention) mekanizmasının keşfiyle doğal 
    dil işlemede büyük bir sıçrama yaşanmıştır. Artık modeller yalnızca sözcükleri değil, tüm cümlenin bağlamını aynı anda 
    anlayabilecek hale gelmiştir.
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
                                            6. Ders 01/02/2026 - Pazar
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Doğal dil işleme (natural language processing - NLP) faaliyetlerinin başında yazıların elde edilmesi ve onların üzerinde 
    izleyen paragraflarda açıklayacağımız "ön işlemlerin (preprocessing)" yapılması gerekmektedir. Önce bu ön işlemler 
    üzerinde duracağız. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Makine öğrenmesinin diğer alanlarında olduğu gibi doğal işlemede de birinci aşaması verilerin elde edilmesidir. Doğal 
    dil işlemede veriler yazılar biçimindedir. Yazılar da tipik olarak şu kaynaklardan elde edilmektedir:

    - Metin (text) ve ikili (binary) dosyaların içerisinden    
    - Veritabanlarından
    - Web sitelerinden 
    - Algılayıcılardan (sensörlerden)
    - Diğer başka kaynaklardan

    Python'da metin dosyalarının içerisindeki yazıları dosyayı open fonksiyonuyla açıp read fonksiyonuyla okuyarak elde
    edebilirsiniz. Ancak open fonksiyonunda kod syafasını ya da karakter kodlamasını belirtmeyi unutmayınız. Örneğin:

    f = open('test.txt', encoding='iso-8859-9')
    s = f.read()
    print(s)
    f.close()

    Default encoding genellikle "utf-8" biçimindedir. Ancak yerel makinenin ayarlarına bağlı olarak değişebilmektedir. 
    Unicode UTF-8 kodlamasıyla çalıyorsanız bunu açıkça belirtmelisiniz:

    f = open('test.txt', encoding='utf-8')
    s = f.read()
    print(s)
    f.close()
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Doğal dil işleme üzerinde çalışmalar yapabilmek için oluşturulmuş olan pek çok hazır veri kümesi bulunmaktadır. 
    Biz de kursumuzda klasik doğal dil işleme çalışmalarında hem bu hazır veri kümelerini kullanacağız hem de "terapikulubu.com" 
    sitesindeki veri kümesinden faydalanacağız. "terapikulubu.com" sitesi C ve Sistem Programcıları Derneği tarafından
    geliştirilmiş olan psikolojik bir sosyal ağdır. 
    
    Doğal dil işlemedeki veri kümeleri kullanlan doğal dile özgüdür. Aynı zamanda izleyen paragraflarda da görüleceği gibi 
    önişlem faaliyetlerinin bazıları da dile özgü bir biçimde yapılmaktadır. Biz de kursumuzda mümkün olduğunca Türkçe 
    metinler üzerinde çalışacağız. Bunun için Türkçe metinlerden oluşan veri kümlerine gereksinim duyacağız. Türkçe metinlerden
    oluşan bazı veri kümelerini aşağıda veriyoruz:

    - Turkish National Corpus (TNC)
    - BOUN Corpus
    - Turkish Wikipedia Dump
    - Turkish Product Reviews Dataset
    - Turkish Movie Reviews
    - TTK Turkish News Dataset:
    
    Kursumuzda tüm veri kümelerinin "Src" dizinin altındaki "Data" diininin içerisinde olduğunu varsayacağız ve bu dizine 
    hep göreli yol ifadeleri ile erişeceğiz. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    "beyazperde.com" sitesindeki film yorumlarından oluşan Türkçe veri kümesi aşağıdaki bağlantıdan indirilebilir:

    https://github.com/turkish-nlp-suite/BeyazPerde-Movie-Reviews/blob/main/butun-fimler/all_movies_reviews.json

    Buradan indirdiğimiz "all_movies_reviews.json" dosyasını "Src" dizinimizin altındaki "Data" dizinine yerleştiriyoruz.
    Buradaki veri kümesi JSON formatındadır.  Bu JSON dosyasının içerisindeki bilgilerin organizasyonu şöyledir:

    Veri Kümesi Alanları:

    1. url (string)
    - Filmin Beyazperde.com'daki sayfa bağlantısı
    - Örnek: "https://www.beyazperde.com/filmler/film-288667"

    2. name (string)
    - Filmin adı
    - Örnek: "Kurak Günler", "Avatar: Suyun Yolu"

    3. genre (array/dizi)
    - Film türleri listesi
    - Örnek: ["Dram", "Gerilim"], ["Bilimkurgu", "Macera", "Fantastik", "Aksiyon"]

    4. desc (string)
    - Filmin açıklaması/konusu
    - Film senaryosunun özeti

    5. directors (string)
    - Yönetmen adı
    - Örnek: "Emin Alper", "James Cameron"

    6. actors (string)
    - Başrol oyuncuları (virgülle ayrılmış)
    - Örnek: "Selahattin Paşalı, Ekin Koç, Hatice Aslan, Selin Yeninci"

    7. creators (string)
    - Yapımcı/Senarist
    - Örnek: "Emin Alper"

    8. musicBy (string)
    - Film müziği bestecisi
    - Örnek: "Stefan Will"

    9. rating (nesne/object)
    - totalRating (string): Genel ortalama puan - Örnek: "3,9"
    - ratingCount (string): Toplam oy sayısı - Örnek: "64"
    - reviewCount (string): Yorum sayısı - Örnek: "12"
    - bestRating (string): En yüksek verilebilecek puan - Örnek: "5"
    - worstRating (string): En düşük verilebilecek puan - Örnek: "0,5"

    10. reviews (array/dizi)
        Her yorum nesnesi şu alanları içerir:
        - rating (string): Kullanıcının verdiği puan - Örnek: "3,0", "4,0", "5,0", "0,5", "3,5"
        - review (string): Kullanıcının yazdığı yorum metni (uzun metin, spoiler etiketleri içerebilir: [spoiler][/spoiler])

    Önemli Noktalar:
    - Sayısal değerler string formatında
    - Ondalık ayırıcı olarak virgül (,) kullanılmakta
    - İç içe nesne yapısı mevcut (rating nesnesi)
    - reviews bir dizi/array yapısındadır
    
    Biz JSON formatindaki bu bilgileri tek hamlede Pandas'ın read_json fonksiyonu ile DataFrame nesnesi biçiminde elde 
    edebiliriz:

    import pandas as pd

    df = pd.read_json('../Data/all_movies_reviews.json')

    Pandas bu tür fonksiyonlarda default kodlama biçimini "utf-8" almaktadır. Ancak bunu açıkça da belirtebilirsiniz:

    df = pd.read_json('../Data/all_movies_reviews.json', encoding='utf-8')

    Yukarıda da belirttiğimiz gibi kursumuzda tüm veri kümelerini "Src" dizininin altındaki "Data" dizininde toplayacağız. 
    Her konu için "Src" dizininin altında yeni bir dizin yaratıp o dizini Python yorumlayıcısının "çalışma dizini (current 
    working directory)" haline getireceğiz. Dolayısıyla dosya erişimlerini de "göreli yol ifadesi (relative paths)" kullanarak 
    yapacağız.   
     
    JSON dosyalarını Pandas'ın DataFrame nesnesi biçiminde elde etmek yerine manuel biçimde de okuyabiliriz. Bunun için 
    Python'un standart kütüphanesindeki json modülü kullanılmaktadır. Bunun için dosya open fonksiyonuyla açılıp önce bir 
    dosya nesnesi, bu dosya nesnesi kullanılarak da json modülündeki load fonksiyonu ile bir json nesnesi elde edilir. B
    u json nesnesi aynı zamanda dolaşılabilir (iterable) bir nesnedir. Bu nesne dolaşıldıkça JSON dosyasındaki kayıtlar 
    elde edilmektedir. Örneğin:

    import json

    with open('../Data/all_movies_reviews.json', 'r', encoding='utf-8') as f:
        movies = json.load(f)
        for movie in movies:
            print(movie)    
    <BURADA KALDIM>
    Örneğin biz bu filmdeki tüm yorumları bir Python listesinde şağıdaki yapabiliriz:

    df = pd.read_json('../Data/all_movies_reviews.json', encoding='utf-8')
    all_reviews = []

    for review in df['reviews']:
        for d in review:
            all_reviews.append(d['review'])
    print(all_reviews)

    Veri kümesinde toplam 45280 adet yorum bulunmaktadır. Aynı işlemi şöyle de yapabilirdik:

    import json

    all_reviews = []
    with open('../Data/all_movies_reviews.json', 'r', encoding='utf-8') as f:
        movies = json.load(f)
        for movie in movies:
            for review in movie['reviews']:
                all_reviews.append(review['review'])    

    Biz burada tüm yorum yazılarını bir Python listesi olarak elde ettik. Tabii bunu yeniden Pandas DataFrame nesnesi
    haline getirebiliriz:

    df_reviews = pd.DataFrame({'review': all_reviews})

    Pandas'ın to_xxx isimli çeşitli formatlarda save işlemini yapan fonksiyonları ve metotları vardır. Daha önceden de 
    belirttiğimiz gibi yazılar için CSV formatı uygun bir format değildir. Daha önceden de belirttiğimiz gibi yazılar için 
    en uygun formatlar "parquet" formatı, "hdf5" formatı ve JSON formatıdır. Pandas'ın DataFrame sınıfının değişik formatlarda 
    save işlemi yapan metotlarının önemli olanları şunlardır:

    Pandas'ın DataFrame sınıfının değişik formatlarda save işlemi yapan metotları da vardır:

    to_csv() - CSV/TXT
    to_excel() - Excel
    to_json() - JSON
    to_html() - HTML
    to_xml() - XML
    to_latex() - LaTeX
    to_markdown() - Markdown
    to_pickle() - Pickle (.pkl)
    to_parquet() - Parquet
    to_feather() - Feather
    to_hdf() - HDF5
    to_stata() - Stata (.dta)
    to_sas() - SAS
    to_spss() - SPSS (.sav)

    Örneğin DataFrame nesnesini aşağıdaki gibi JSON dosyası olarak save edebiliriz:

    df_reviews.to_json('../Data/movie-reviews.json', orient='records', force_ascii=False)    

    Geri okumasını da şöyle yapabiliriz:

    df_reviews = pd.read_json('../Data/movie-reviews.json', encoding='utf-8')

    Biz buradaki "movie-reviews.json" dosyasını da "Data" dizininin içerisine yerleştirdik. Parquet ve HDF formatıyla 
    save ve read işlemleri de şöyle yapılabilir:

    df_reviews.to_parquet('../Data/movie-reviews.parquet')
    df_reviews = pd.read_parquet('../Data/movie-reviews.parquet')

    df_reviews.to_hdf('../Data/movie-reviews.hdf5', key='reviews')
    df_reviews = pd.read_hdf('../Data/movie-reviews.hdf5')
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Doğal dil işlemede yazısal verilerin tamamına İngilizce "corpus" denilmektedir. Yani "corpus" terimi doğal dil 
    işlemede faydalanılacak yazısal veri kümesini belirtmektedir. Yukardaki örnekte "beyazperde.com" sitesindem elde edilen 
    tüm yorum yazıları "corpus" oluşturmaktadır. Corpus yalnızca yazısal bilgilerden oluşmak zorunda değildir. Bunlara 
    iliştirilmiş diğer bilgiler de corpus'un bir parçası niteliğindedir. 
    
    Corpus sözcüğü eski Türkçeyle "külliyat" olarak ifade edilebilir. Biz "corpus" yerine kursumuzda kursumuzda "derlem" 
    terimini kullanacağız. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Doğal dil işlemede metinler elde edildikten sonra "normalizasyon" işlemine sokulur. Daha sonra normalize edilmiş 
    metinler atomlarına ayrılır. Buna İngilizce "tokenization" denilmektedir. Atomlara ayırma işleminden sonra da genellikle 
    atomlar üzerinde yeniden normalizasyon işlemi yapılmaktadır. Bu ikinci normalizasyonda "atom normalizasyonu" da diyebiliriz 
    Nihayet yeniden normalize edilmiş olan metinlerden "sözcük haznesi (vocabulary)" oluşturulmaktadır. Bu durumda doğal 
    dil işlemedeki ön işlem adımlarını şekilsel olarak şöyle gösterebiliriz: 

   ┌────────────────────────────┐
   │  Verilerin Elde Edilmesi   │
   └────────────────────────────┘
                │
                │
                ▼
   ┌────────────────────────────┐
   │      Normalizasyon         │
   └────────────────────────────┘
               │
               │
               ▼
   ┌────────────────────────────┐
   │   Atomlara Ayırma          │
   │     (Tokenization)         │
   └────────────────────────────┘
               │
               │
               ▼
   ┌────────────────────────────┐
   │  Atomlara Ayırma Sonrası   │
   │      Normalizasyon         │
   └────────────────────────────┘
               │
               │
               ▼
   ┌────────────────────────────┐
   │     Sözück Haznesinin      │
   │      OLuşturulması         │
   └────────────────────────────┘
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Metin normalizasyonu, henüz bir işleme sokulmamış olan ham metinlerin makine öğrenmesi modelleri için standart ve 
    tutarlı bir biçime dönüştürülmesi sürecidir. Normalizasyon sırasında bilgi kayıpları kaçınılmazdır. Örneğin "harika!!!!",
    "harika!!", "harika!" gibi yazı parçalarını biz tek ! kullanarak "harika!" biçiminde normalize edebiliriz. Ancak burada 
    duygu yoğunluğu bakımından bir kayıp oluşacaktır. Normalizasyondaki kayıplar her zaman olumsuzluk yaratmak zorunda değildir. 
    Hatta bu kayıplar bazı uygulamalarda zarardan daha çok fayda bile sağlayabilmektedir. 
    
    Normalizasyon süreci aslında hedefe uygun biçimde yapılmaktadır. Hedeflenen şey neyse kayıplar ve kazançlar ona göre göz 
    önüne alınmalıdır. Biz aşağıda normalizasyonda kullanılan temel alt yöntemleri açıklayacağız. Ancak bu alt yöntemlerin 
    hepsinin bir doğal dil işleme sürecinde uygulanması gerekmemektedir. Bunların amaca göre gerektiği kadar uygulanması
    gerekir. Doğal dil işleme uzmanı “ne kaybettiğini ve ne kzandığını bilerek" işlemleri yütürmelidir.
    
    Atomlara ayırma öncesindeki normalizasyon işlemini çeşitli alt başlıklara ayırabiliriz:

    - Karakter Düzeyinde Normalizasyon
        - Unicode Normalizasyonu
        - Case Normalization (Büyük/Küçük Harf Dönüşümü)
        - ASCII Dönüşümü (Transliteration)
        - Diacritics (Aksanlar) Kaldırma

    - Yapısal Normalizasyon
        - Boşluk (Whitespace) Normalizasyonu
        - Noktalama Normalizasyonu
        - Kesme İşareti (Apostrophe) Normalizasyonu
        - Satır Sonu ve Kontrol Karakterleri
        
    - İçerik Normalizasyonu
        - URL Normalizasyonu
        - Email Normalizasyonu
        - Sayı Normalizasyonu
        - Emoji ve Özel Semboller
        - Hashtag ve Mention Normalizasyonu
        - Informal Yazım Genişletme (Türkçe Özel)
        - Tekrarlanan Karakter Azaltma       
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------
    Karakter düzeyinde normalizasyon "metinleri karakter temelinde ele alarak onları standart biçime dönüştürmeyi" 
    hedeflemektedir. 
#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------

#------------------------------------------------------------------------------------------------------------------------




